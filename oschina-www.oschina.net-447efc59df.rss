<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:itunes="http://www.itunes.com/dtds/podcast-1.0.dtd" xmlns:googleplay="http://www.google.com/schemas/play-podcasts/1.0" xmlns:media="http://www.rssboard.org/media-rss" version="2.0">
  <channel>
    <title><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></title>
    <link>undefined</link>
    <image>
      <url>https://www.oschina.net/img/logo.gif</url>
      <title>OSCHINA 社区最新新闻[RSS+]</title>
      <link>undefined</link>
    </image>
    <language>zh-CN</language>
    <atom:link href="https://www.oschina.net/news/rss" rel="self" type="application/rss+xml"/>
    <copyright><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></copyright>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[
      OSCHINA - 中文开源技术交流社区<br />
<br />
<a href="https://www.oschina.net/news/rss" target="_blank">https://www.oschina.net/news/rss</a>
      ]]>
    </itunes:summary>
    <description>
      <![CDATA[
      OSCHINA - 中文开源技术交流社区<br />
<br />
<a href="https://www.oschina.net/news/rss" target="_blank">https://www.oschina.net/news/rss</a>
      ]]>
    </description>
    <itunes:owner>
      <itunes:name><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:name>
    </itunes:owner>
    <itunes:image href="https://www.oschina.net/img/logo.gif"/>
<item>
    <title><![CDATA[vivo HDFS EC 大规模落地实践]]></title>
    <link>https://my.oschina.net/vivotech/blog/18695773</link>
    <itunes:title><![CDATA[vivo HDFS EC 大规模落地实践]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<blockquote>
<p>作者：Gu Ruinan - 互联网大数据团队- Zhao Yongxiang</p>
<p>Erasure Coding(简称EC)，是一种纠删码。EC编码能够对部分缺失的数据进行数据恢复，广泛应用于存储与通信领域。在Hadoop3.0版本中，作为一种新的冗余存储的方式引入进来。使用EC编码的方式替代原来的三副本存储，保证数据可靠性的同时可以节约存储。相应地，付出的代价是读取性能的下降，对于访问频率不高的数据，使用EC编码很合适。</p>
<p>vivo目前HDFS集群节点达万台级别，数据规模接近EB级别，并且业务数据规模还在以较高速度持续增长中。在推进压缩算法缓解存储压力的同时，EC编码的推进也是存储降本的一大有力手段。</p>
</blockquote>
<p>1分钟看图掌握核心观点👇</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-5663af9821.gif"></p>
<h1>一、背景</h1>
<p>Reed-Soloman编码(简称：RS码)，是EC里一种经典的编码算法。下面简单介绍一下Reed-Soloman编码过程(不涉及数学原理的详细解析)。</p>
<p>假设我们的输入数据以D1，D2，...D5的向量来表示，矩阵B为编码矩阵，进行编码后得到D和C组成的矩阵，其中D为数据块(data block)，C为校验块(parity block)。我们的数据写入都需要经过编码后才能进行存储。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-ed40bc3031.png" alt="图片"></p>
<p>假设我们抹除掉了D1，D4，C2。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-9e39d4164e.png" alt="图片"></p>
<p>我们能通过编码矩阵得到一个用于恢复的矩阵，将这个矩阵与剩余块相乘，可得到原来完整的输入数据，再次进行编码后可恢复C2。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-f549f93b44.png" alt="图片"></p>
<h1>二、存储布局的改变</h1>
<p>EC编码对HDFS的应用，使数据块存储的结构发生了改变。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-0f88f6ed6f.png" alt="图片"></p>
<p>在传统三副本的策略中，一个文件被划分为不同的块(block)进行存储，一个数据块对应三个副本(replication)，每个副本存储的内容完全一致，数据的存储时连续的，这种布局称为连续块存储布局(Contigous Block Layout)。</p>
<p>在EC策略中，一个文件被划分为不同的块组(Block Group)进行存储，一个块组内划分为多个内部块(Internal Block)，其中，内部块又分为数据块(Data Block)和校验块(Parity Block)。数据块存储文件的数据，校验块存储由数据块生成的校验内容。一个块组内，可容忍的块丢失数量与校验块数量相同，如果丢失块的数量大于校验块数量，则数据不可被恢复。</p>
<p>在块组中，数据并不像三副本策略一样连续存储在一个块中，而是将连续的数据拆分为多个Cell，分散存储在不同的内部块中，形成一个个条带(Stripe)。这种布局称为条带存储布局(Striped Block Layout)。</p>
<p>我们集群目前采用EC策略RS6-3-1024k，其中6表示块组中数据块数量，3表示块组中校验块数量，1024k表示Cell大小。</p>
<p>三副本是HDFS默认的冗余存储方式，优点是当有机器宕机，数据丢失时，不会影响用户的读取，补块的方式也仅仅是副本的复制，简单高效。缺点也很明显，存储的冗余度高，三副本的存储冗余度达到200%。</p>
<p>EC编码通过编码的存储方式，来进行冗余存储。优点是存储的冗余度低(具体的冗余度取决于不同的存储策略)，可靠性高。缺点是写入需要编码，造成性能的下降(大概3-4倍)，补块时间长(校验块越多，补块时间越长)，读取时如果遇到DN宕机，也需要额外的资源与时间进行解码恢复。</p>
<h1>三、HDFS EC 码应用实践</h1>
<h2>3.1 兼容性问题</h2>
<h3>3.1.1 服务端</h3>
<p>早在2020年，EC已经在vivo的HDFS集群中投入使用。EC是Hadoop3.0后推出的新特性，要想正常使用，服务端和客户端都需要升级到3.0或以上版本。</p>
<p>由于离线集群规模庞大，升级的调研和实施需要耗费比较长的时间。因此，我们临时搭建了一套基于3.1版本的冷备专用集群，使用EC来存储冷备数据，如下图：</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-c5b7fe514e.png" alt="图片"></p>
<p>冷备集群使用3.1版本的Yarn，可以同时访问热数据与冷数据，3.1版本的HDFS专门用来存储EC编码的冷数据。</p>
<p>由于新增冷备集群的方案增加了集群运维的成本，架构也不够优雅，只是暂时的解决办法。在2021年，我们离线集群完成了HDFS从2.6到3.1的全面升级，正式支持EC编码，在2022年，我们完成绝大部分冷备集群的数据到离线集群的迁移，增量数据全部写到离线集群中。</p>
<h3>3.1.2 客户端</h3>
<p>我们没有对Client2.x客户端访问EC文件做兼容性的开发，更多是通过推动用户升级客户端来访问EC文件，例如Spark2任务切换至Spark3任务。该方案增加了用户迁移的成本，但同时也减少了HDFS侧的开发成本，用户任务逐步往Spark3迁移也更符合未来的规划。</p>
<h2>3.2 EC 异步转换</h2>
<p>由于EC编码会带来对文件读写性能的下降，对EC编码的定位主要应用在冷数据的存储，业务并不直接写EC数据，而是采用后台转储的方式，把三副本数据转储成EC数据。对不同业务而言，对"冷"的标准都不一致，不能用统一的标准来衡量数据的冷热。在推广EC编码的过程中，平台并不用统一的标准来"强制"把用户数据转为EC，是否转为EC的最终决定权在用户。我们向用户提供分区访问频率的数据作为参考，帮助用户来了解不同分区路径的访问频次，让用户更好地选择哪些分区转为EC编码。用户可以通过大数据开发者平台(Big data developer platform)设置x天前的数据转为EC存储，后台程序会将相应分区通过Hadoop distcp，将三副本写入到已设置EC策略的目录中，再用新目录替换掉原目录，其中目录名称不变，保证了元数据一致，用户无需修改代码。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-33f5ae101f.png" alt="图片"></p>
<h2>3.3 Distcp 数据校验</h2>
<p>先来介绍一下HDFS两种校验和的方式。</p>
<h3>3.3.1 MD5MD5CRC</h3>
<p>此方式为HDFS默认的校验方式，这种校验方式会进行两次MD5计算一次CRC计算，从名字就可以反映出来。</p>
<ul>
<li> <p><strong>块级校验和</strong>：所有chunk CRC的级联的MD5值。（an MD5 of a concatenation of chunk CRCs）</p> </li>
<li> <p><strong>文件级校验和</strong>：所有块校验和的级联的MD5值。（the MD5 of the concatenation of all the block checksums）</p> </li>
</ul>
<p>由定义可知，这种方式对于HDFS分块大小敏感，不同的分块大小块级校验和不一样，导致文件校验和也会不一样。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-440ee80cf7.png" alt="图片"></p>
<h3>3.3.2 Composite CRC</h3>
<p>Composite CRC一个新的校验和计算方式。</p>
<p>当计算块校验和不是简单地将chunk CRC进行级联（concatenation），而是将chunk CRC进行数学式的组合（mathematically compose），计算文件校验和时对文件所有的chunk CRC进行数学式组合。因此，对于文件校验和，该计算方式对于分块大小并不敏感。 CRC算法相关论文。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-c6ffc53153.png" alt="图片"></p>
<p>在数据进行distcp的过程中，HDFS会进行校验和校验，确保distcp的源数据与新数据一致，但正如前文所说，EC编码会带来存储布局的改变，相同的文件三副本与EC数据存储的块大小，块数量都不一致，这让HDFS默认的MD5MD5CRC的方式变得不再适用。</p>
<p>需要将校验方式改为COMPOSITE CRC。</p>
<p>可通过 dfs.checksum.combine.mode 改变校验和校验的方式（MD5MD5CRC(默认值) or COMPOSITE_CRC)。</p>
<p>即使distcp过程中会进行校验，为了确保万无一失，我们还会对前后的分区目录的校验和校验。(目录校验和计算方式为将目录下文件MD5值排序，再进行MD5计算）为了保证转EC前后文件的一致性，多加一道校验的"工序"是值得的。</p>
<h2>3.4 文件损坏与修复</h2>
<p>文件损坏与丢块是HDFS EC应用绕不开的一个话题，原因是在Hadoop EC特性新推出的过程中，有若干与文件损坏相关的bug。EC文件损坏的过程主要发生在补块阶段，计算结果的不准确导致了新补的块与原来的块内容不一致。我们在EC推广的过程中，也狠狠地踩过文件损坏的"坑"。如何避免文件损坏，如何对补块的结果进行校验，如何修复损坏文件是三个重要的需要解决的问题。</p>
<h3>3.4.1 如何避免文件损坏</h3>
<p>通过对社区的调研，我们打了若干的patch来解决文件损坏与丢块的问题。</p>
<h3>3.4.2 对补块结果的校验</h3>
<p>我们引入了HDFS-15759，Patch提供了一个对EC补块的校验功能，在DN执行补块任务时，对补块结果进行校验。如果校验失败会抛出异常，并且补块任务会进行重试。</p>
<h3>3.4.3 EC批量校验工具</h3>
<p>我们对开源的EC批量校验工具进行了定制化的改造，工具能够对EC目录进行批量扫描，扫描出目录中的损坏的EC文件，在此感谢Stephen O'Donnell对工具的开源。</p>
<p>原理大致如下，对数据块进行EC编码，通过比对新生成的校验块和原来的校验块，来验证是否存在文件损坏。如果比对通过，则没有文件损坏，如果比对不通过，则存在文件损坏。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-80ad556a9b.png" alt="图片"></p>
<p>工具支持MR，可以分布式执行，此外，也可只对一个条带进行比对，只生成校验块的第一个条带，比对与原校验块第一个条带是否一致，这些都大大提高了批量校验EC文件的效率。</p>
<p>工具地址：</p>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fsodonnel%2Fhdfs-ec-validator" target="_blank">https://github.com/sodonnel/hdfs-ec-validator</a></p>
<h3>3.4.4 修复损坏文件</h3>
<p>在我们的集群，绝大部分损坏的文件都是ORC文件，ORC文件发生损坏时，由于其元数据分布的方式，会出现元数据的损坏，ORC无法解析。</p>
<p>假设一个块组内，数据块编号为1~6，校验块编号为7~9，数据块1损坏，我们可以通过读取数据块2~6加上任一一个校验块，得到"完好"的文件，对于ORC文件而言，判断是否完好取决于能否正常解析。</p>
<p>HDFS客户端get文件的时候默认只会读取数据块，我们通过改造HDFS客户端，使我们能够读取块组内指定编号的块，通过各种排列组合，得到一个"完好"的文件，之后将"完好"的文件覆盖掉HDFS上的损坏文件，来达到文件修复的目的。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-ff7df263d5.png" alt="图片"></p>
<h2>3.5 机器异构&amp;存储策略</h2>
<p>由于EC数据访问频率低，将EC数据存储到大存储的机器上，利用机器异构降低我们的单位存储成本。</p>
<p>在HDFS中，如果文件写入的路径设置了hot存储策略的目录，则会优先把文件存储到disk存储介质当中，如果设置了cold存储策略的目录，则会优先把文件存储到archive存储介质当中。</p>
<p>因此，当我们将大存储机器的盘都设置为Archive，并且将EC目录设置为Cold存储策略，即可将EC数据存放到大存储机器上，使TCO降低，进一步实现存储降本。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-99835c9495.png" alt="图片"></p>
<h1>四、总结与展望</h1>
<p>vivo的HDFS集群已存有几百PB的数据采用EC-RS6-3-1024k策略存储，相比三副本EC-RS6-3-1024k方式能带来50%的存储收益，节省了数百PB的存储空间，为公司带来了巨大的收益。目前我们推荐用户将访问频次较少的数据转为EC，因为EC会带来读取性能的下降，如何减少EC带来的读取性能下降？以及后续细化对用户数据的冷热分层，对越冷的数据采用冗余度越低的EC策略，EC补块速度优化等，都是后续继续大规模推进EC需要解决的重要难题。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<blockquote>
<p>作者：Gu Ruinan - 互联网大数据团队- Zhao Yongxiang</p>
<p>Erasure Coding(简称EC)，是一种纠删码。EC编码能够对部分缺失的数据进行数据恢复，广泛应用于存储与通信领域。在Hadoop3.0版本中，作为一种新的冗余存储的方式引入进来。使用EC编码的方式替代原来的三副本存储，保证数据可靠性的同时可以节约存储。相应地，付出的代价是读取性能的下降，对于访问频率不高的数据，使用EC编码很合适。</p>
<p>vivo目前HDFS集群节点达万台级别，数据规模接近EB级别，并且业务数据规模还在以较高速度持续增长中。在推进压缩算法缓解存储压力的同时，EC编码的推进也是存储降本的一大有力手段。</p>
</blockquote>
<p>1分钟看图掌握核心观点👇</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-5663af9821.gif"></p>
<h1>一、背景</h1>
<p>Reed-Soloman编码(简称：RS码)，是EC里一种经典的编码算法。下面简单介绍一下Reed-Soloman编码过程(不涉及数学原理的详细解析)。</p>
<p>假设我们的输入数据以D1，D2，...D5的向量来表示，矩阵B为编码矩阵，进行编码后得到D和C组成的矩阵，其中D为数据块(data block)，C为校验块(parity block)。我们的数据写入都需要经过编码后才能进行存储。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-ed40bc3031.png" alt="图片"></p>
<p>假设我们抹除掉了D1，D4，C2。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-9e39d4164e.png" alt="图片"></p>
<p>我们能通过编码矩阵得到一个用于恢复的矩阵，将这个矩阵与剩余块相乘，可得到原来完整的输入数据，再次进行编码后可恢复C2。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-f549f93b44.png" alt="图片"></p>
<h1>二、存储布局的改变</h1>
<p>EC编码对HDFS的应用，使数据块存储的结构发生了改变。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-0f88f6ed6f.png" alt="图片"></p>
<p>在传统三副本的策略中，一个文件被划分为不同的块(block)进行存储，一个数据块对应三个副本(replication)，每个副本存储的内容完全一致，数据的存储时连续的，这种布局称为连续块存储布局(Contigous Block Layout)。</p>
<p>在EC策略中，一个文件被划分为不同的块组(Block Group)进行存储，一个块组内划分为多个内部块(Internal Block)，其中，内部块又分为数据块(Data Block)和校验块(Parity Block)。数据块存储文件的数据，校验块存储由数据块生成的校验内容。一个块组内，可容忍的块丢失数量与校验块数量相同，如果丢失块的数量大于校验块数量，则数据不可被恢复。</p>
<p>在块组中，数据并不像三副本策略一样连续存储在一个块中，而是将连续的数据拆分为多个Cell，分散存储在不同的内部块中，形成一个个条带(Stripe)。这种布局称为条带存储布局(Striped Block Layout)。</p>
<p>我们集群目前采用EC策略RS6-3-1024k，其中6表示块组中数据块数量，3表示块组中校验块数量，1024k表示Cell大小。</p>
<p>三副本是HDFS默认的冗余存储方式，优点是当有机器宕机，数据丢失时，不会影响用户的读取，补块的方式也仅仅是副本的复制，简单高效。缺点也很明显，存储的冗余度高，三副本的存储冗余度达到200%。</p>
<p>EC编码通过编码的存储方式，来进行冗余存储。优点是存储的冗余度低(具体的冗余度取决于不同的存储策略)，可靠性高。缺点是写入需要编码，造成性能的下降(大概3-4倍)，补块时间长(校验块越多，补块时间越长)，读取时如果遇到DN宕机，也需要额外的资源与时间进行解码恢复。</p>
<h1>三、HDFS EC 码应用实践</h1>
<h2>3.1 兼容性问题</h2>
<h3>3.1.1 服务端</h3>
<p>早在2020年，EC已经在vivo的HDFS集群中投入使用。EC是Hadoop3.0后推出的新特性，要想正常使用，服务端和客户端都需要升级到3.0或以上版本。</p>
<p>由于离线集群规模庞大，升级的调研和实施需要耗费比较长的时间。因此，我们临时搭建了一套基于3.1版本的冷备专用集群，使用EC来存储冷备数据，如下图：</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-c5b7fe514e.png" alt="图片"></p>
<p>冷备集群使用3.1版本的Yarn，可以同时访问热数据与冷数据，3.1版本的HDFS专门用来存储EC编码的冷数据。</p>
<p>由于新增冷备集群的方案增加了集群运维的成本，架构也不够优雅，只是暂时的解决办法。在2021年，我们离线集群完成了HDFS从2.6到3.1的全面升级，正式支持EC编码，在2022年，我们完成绝大部分冷备集群的数据到离线集群的迁移，增量数据全部写到离线集群中。</p>
<h3>3.1.2 客户端</h3>
<p>我们没有对Client2.x客户端访问EC文件做兼容性的开发，更多是通过推动用户升级客户端来访问EC文件，例如Spark2任务切换至Spark3任务。该方案增加了用户迁移的成本，但同时也减少了HDFS侧的开发成本，用户任务逐步往Spark3迁移也更符合未来的规划。</p>
<h2>3.2 EC 异步转换</h2>
<p>由于EC编码会带来对文件读写性能的下降，对EC编码的定位主要应用在冷数据的存储，业务并不直接写EC数据，而是采用后台转储的方式，把三副本数据转储成EC数据。对不同业务而言，对"冷"的标准都不一致，不能用统一的标准来衡量数据的冷热。在推广EC编码的过程中，平台并不用统一的标准来"强制"把用户数据转为EC，是否转为EC的最终决定权在用户。我们向用户提供分区访问频率的数据作为参考，帮助用户来了解不同分区路径的访问频次，让用户更好地选择哪些分区转为EC编码。用户可以通过大数据开发者平台(Big data developer platform)设置x天前的数据转为EC存储，后台程序会将相应分区通过Hadoop distcp，将三副本写入到已设置EC策略的目录中，再用新目录替换掉原目录，其中目录名称不变，保证了元数据一致，用户无需修改代码。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-33f5ae101f.png" alt="图片"></p>
<h2>3.3 Distcp 数据校验</h2>
<p>先来介绍一下HDFS两种校验和的方式。</p>
<h3>3.3.1 MD5MD5CRC</h3>
<p>此方式为HDFS默认的校验方式，这种校验方式会进行两次MD5计算一次CRC计算，从名字就可以反映出来。</p>
<ul>
<li> <p><strong>块级校验和</strong>：所有chunk CRC的级联的MD5值。（an MD5 of a concatenation of chunk CRCs）</p> </li>
<li> <p><strong>文件级校验和</strong>：所有块校验和的级联的MD5值。（the MD5 of the concatenation of all the block checksums）</p> </li>
</ul>
<p>由定义可知，这种方式对于HDFS分块大小敏感，不同的分块大小块级校验和不一样，导致文件校验和也会不一样。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-440ee80cf7.png" alt="图片"></p>
<h3>3.3.2 Composite CRC</h3>
<p>Composite CRC一个新的校验和计算方式。</p>
<p>当计算块校验和不是简单地将chunk CRC进行级联（concatenation），而是将chunk CRC进行数学式的组合（mathematically compose），计算文件校验和时对文件所有的chunk CRC进行数学式组合。因此，对于文件校验和，该计算方式对于分块大小并不敏感。 CRC算法相关论文。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-c6ffc53153.png" alt="图片"></p>
<p>在数据进行distcp的过程中，HDFS会进行校验和校验，确保distcp的源数据与新数据一致，但正如前文所说，EC编码会带来存储布局的改变，相同的文件三副本与EC数据存储的块大小，块数量都不一致，这让HDFS默认的MD5MD5CRC的方式变得不再适用。</p>
<p>需要将校验方式改为COMPOSITE CRC。</p>
<p>可通过 dfs.checksum.combine.mode 改变校验和校验的方式（MD5MD5CRC(默认值) or COMPOSITE_CRC)。</p>
<p>即使distcp过程中会进行校验，为了确保万无一失，我们还会对前后的分区目录的校验和校验。(目录校验和计算方式为将目录下文件MD5值排序，再进行MD5计算）为了保证转EC前后文件的一致性，多加一道校验的"工序"是值得的。</p>
<h2>3.4 文件损坏与修复</h2>
<p>文件损坏与丢块是HDFS EC应用绕不开的一个话题，原因是在Hadoop EC特性新推出的过程中，有若干与文件损坏相关的bug。EC文件损坏的过程主要发生在补块阶段，计算结果的不准确导致了新补的块与原来的块内容不一致。我们在EC推广的过程中，也狠狠地踩过文件损坏的"坑"。如何避免文件损坏，如何对补块的结果进行校验，如何修复损坏文件是三个重要的需要解决的问题。</p>
<h3>3.4.1 如何避免文件损坏</h3>
<p>通过对社区的调研，我们打了若干的patch来解决文件损坏与丢块的问题。</p>
<h3>3.4.2 对补块结果的校验</h3>
<p>我们引入了HDFS-15759，Patch提供了一个对EC补块的校验功能，在DN执行补块任务时，对补块结果进行校验。如果校验失败会抛出异常，并且补块任务会进行重试。</p>
<h3>3.4.3 EC批量校验工具</h3>
<p>我们对开源的EC批量校验工具进行了定制化的改造，工具能够对EC目录进行批量扫描，扫描出目录中的损坏的EC文件，在此感谢Stephen O'Donnell对工具的开源。</p>
<p>原理大致如下，对数据块进行EC编码，通过比对新生成的校验块和原来的校验块，来验证是否存在文件损坏。如果比对通过，则没有文件损坏，如果比对不通过，则存在文件损坏。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-80ad556a9b.png" alt="图片"></p>
<p>工具支持MR，可以分布式执行，此外，也可只对一个条带进行比对，只生成校验块的第一个条带，比对与原校验块第一个条带是否一致，这些都大大提高了批量校验EC文件的效率。</p>
<p>工具地址：</p>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fsodonnel%2Fhdfs-ec-validator" target="_blank">https://github.com/sodonnel/hdfs-ec-validator</a></p>
<h3>3.4.4 修复损坏文件</h3>
<p>在我们的集群，绝大部分损坏的文件都是ORC文件，ORC文件发生损坏时，由于其元数据分布的方式，会出现元数据的损坏，ORC无法解析。</p>
<p>假设一个块组内，数据块编号为1~6，校验块编号为7~9，数据块1损坏，我们可以通过读取数据块2~6加上任一一个校验块，得到"完好"的文件，对于ORC文件而言，判断是否完好取决于能否正常解析。</p>
<p>HDFS客户端get文件的时候默认只会读取数据块，我们通过改造HDFS客户端，使我们能够读取块组内指定编号的块，通过各种排列组合，得到一个"完好"的文件，之后将"完好"的文件覆盖掉HDFS上的损坏文件，来达到文件修复的目的。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-ff7df263d5.png" alt="图片"></p>
<h2>3.5 机器异构&amp;存储策略</h2>
<p>由于EC数据访问频率低，将EC数据存储到大存储的机器上，利用机器异构降低我们的单位存储成本。</p>
<p>在HDFS中，如果文件写入的路径设置了hot存储策略的目录，则会优先把文件存储到disk存储介质当中，如果设置了cold存储策略的目录，则会优先把文件存储到archive存储介质当中。</p>
<p>因此，当我们将大存储机器的盘都设置为Archive，并且将EC目录设置为Cold存储策略，即可将EC数据存放到大存储机器上，使TCO降低，进一步实现存储降本。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-99835c9495.png" alt="图片"></p>
<h1>四、总结与展望</h1>
<p>vivo的HDFS集群已存有几百PB的数据采用EC-RS6-3-1024k策略存储，相比三副本EC-RS6-3-1024k方式能带来50%的存储收益，节省了数百PB的存储空间，为公司带来了巨大的收益。目前我们推荐用户将访问频次较少的数据转为EC，因为EC会带来读取性能的下降，如何减少EC带来的读取性能下降？以及后续细化对用户数据的冷热分层，对越冷的数据采用冗余度越低的EC策略，EC补块速度优化等，都是后续继续大规模推进EC需要解决的重要难题。</p>]]>
    </description>
    <content:encoded><![CDATA[<blockquote>
<p>作者：Gu Ruinan - 互联网大数据团队- Zhao Yongxiang</p>
<p>Erasure Coding(简称EC)，是一种纠删码。EC编码能够对部分缺失的数据进行数据恢复，广泛应用于存储与通信领域。在Hadoop3.0版本中，作为一种新的冗余存储的方式引入进来。使用EC编码的方式替代原来的三副本存储，保证数据可靠性的同时可以节约存储。相应地，付出的代价是读取性能的下降，对于访问频率不高的数据，使用EC编码很合适。</p>
<p>vivo目前HDFS集群节点达万台级别，数据规模接近EB级别，并且业务数据规模还在以较高速度持续增长中。在推进压缩算法缓解存储压力的同时，EC编码的推进也是存储降本的一大有力手段。</p>
</blockquote>
<p>1分钟看图掌握核心观点👇</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-5663af9821.gif"></p>
<h1>一、背景</h1>
<p>Reed-Soloman编码(简称：RS码)，是EC里一种经典的编码算法。下面简单介绍一下Reed-Soloman编码过程(不涉及数学原理的详细解析)。</p>
<p>假设我们的输入数据以D1，D2，...D5的向量来表示，矩阵B为编码矩阵，进行编码后得到D和C组成的矩阵，其中D为数据块(data block)，C为校验块(parity block)。我们的数据写入都需要经过编码后才能进行存储。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-ed40bc3031.png" alt="图片"></p>
<p>假设我们抹除掉了D1，D4，C2。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-9e39d4164e.png" alt="图片"></p>
<p>我们能通过编码矩阵得到一个用于恢复的矩阵，将这个矩阵与剩余块相乘，可得到原来完整的输入数据，再次进行编码后可恢复C2。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-f549f93b44.png" alt="图片"></p>
<h1>二、存储布局的改变</h1>
<p>EC编码对HDFS的应用，使数据块存储的结构发生了改变。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-0f88f6ed6f.png" alt="图片"></p>
<p>在传统三副本的策略中，一个文件被划分为不同的块(block)进行存储，一个数据块对应三个副本(replication)，每个副本存储的内容完全一致，数据的存储时连续的，这种布局称为连续块存储布局(Contigous Block Layout)。</p>
<p>在EC策略中，一个文件被划分为不同的块组(Block Group)进行存储，一个块组内划分为多个内部块(Internal Block)，其中，内部块又分为数据块(Data Block)和校验块(Parity Block)。数据块存储文件的数据，校验块存储由数据块生成的校验内容。一个块组内，可容忍的块丢失数量与校验块数量相同，如果丢失块的数量大于校验块数量，则数据不可被恢复。</p>
<p>在块组中，数据并不像三副本策略一样连续存储在一个块中，而是将连续的数据拆分为多个Cell，分散存储在不同的内部块中，形成一个个条带(Stripe)。这种布局称为条带存储布局(Striped Block Layout)。</p>
<p>我们集群目前采用EC策略RS6-3-1024k，其中6表示块组中数据块数量，3表示块组中校验块数量，1024k表示Cell大小。</p>
<p>三副本是HDFS默认的冗余存储方式，优点是当有机器宕机，数据丢失时，不会影响用户的读取，补块的方式也仅仅是副本的复制，简单高效。缺点也很明显，存储的冗余度高，三副本的存储冗余度达到200%。</p>
<p>EC编码通过编码的存储方式，来进行冗余存储。优点是存储的冗余度低(具体的冗余度取决于不同的存储策略)，可靠性高。缺点是写入需要编码，造成性能的下降(大概3-4倍)，补块时间长(校验块越多，补块时间越长)，读取时如果遇到DN宕机，也需要额外的资源与时间进行解码恢复。</p>
<h1>三、HDFS EC 码应用实践</h1>
<h2>3.1 兼容性问题</h2>
<h3>3.1.1 服务端</h3>
<p>早在2020年，EC已经在vivo的HDFS集群中投入使用。EC是Hadoop3.0后推出的新特性，要想正常使用，服务端和客户端都需要升级到3.0或以上版本。</p>
<p>由于离线集群规模庞大，升级的调研和实施需要耗费比较长的时间。因此，我们临时搭建了一套基于3.1版本的冷备专用集群，使用EC来存储冷备数据，如下图：</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-c5b7fe514e.png" alt="图片"></p>
<p>冷备集群使用3.1版本的Yarn，可以同时访问热数据与冷数据，3.1版本的HDFS专门用来存储EC编码的冷数据。</p>
<p>由于新增冷备集群的方案增加了集群运维的成本，架构也不够优雅，只是暂时的解决办法。在2021年，我们离线集群完成了HDFS从2.6到3.1的全面升级，正式支持EC编码，在2022年，我们完成绝大部分冷备集群的数据到离线集群的迁移，增量数据全部写到离线集群中。</p>
<h3>3.1.2 客户端</h3>
<p>我们没有对Client2.x客户端访问EC文件做兼容性的开发，更多是通过推动用户升级客户端来访问EC文件，例如Spark2任务切换至Spark3任务。该方案增加了用户迁移的成本，但同时也减少了HDFS侧的开发成本，用户任务逐步往Spark3迁移也更符合未来的规划。</p>
<h2>3.2 EC 异步转换</h2>
<p>由于EC编码会带来对文件读写性能的下降，对EC编码的定位主要应用在冷数据的存储，业务并不直接写EC数据，而是采用后台转储的方式，把三副本数据转储成EC数据。对不同业务而言，对"冷"的标准都不一致，不能用统一的标准来衡量数据的冷热。在推广EC编码的过程中，平台并不用统一的标准来"强制"把用户数据转为EC，是否转为EC的最终决定权在用户。我们向用户提供分区访问频率的数据作为参考，帮助用户来了解不同分区路径的访问频次，让用户更好地选择哪些分区转为EC编码。用户可以通过大数据开发者平台(Big data developer platform)设置x天前的数据转为EC存储，后台程序会将相应分区通过Hadoop distcp，将三副本写入到已设置EC策略的目录中，再用新目录替换掉原目录，其中目录名称不变，保证了元数据一致，用户无需修改代码。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-33f5ae101f.png" alt="图片"></p>
<h2>3.3 Distcp 数据校验</h2>
<p>先来介绍一下HDFS两种校验和的方式。</p>
<h3>3.3.1 MD5MD5CRC</h3>
<p>此方式为HDFS默认的校验方式，这种校验方式会进行两次MD5计算一次CRC计算，从名字就可以反映出来。</p>
<ul>
<li> <p><strong>块级校验和</strong>：所有chunk CRC的级联的MD5值。（an MD5 of a concatenation of chunk CRCs）</p> </li>
<li> <p><strong>文件级校验和</strong>：所有块校验和的级联的MD5值。（the MD5 of the concatenation of all the block checksums）</p> </li>
</ul>
<p>由定义可知，这种方式对于HDFS分块大小敏感，不同的分块大小块级校验和不一样，导致文件校验和也会不一样。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-440ee80cf7.png" alt="图片"></p>
<h3>3.3.2 Composite CRC</h3>
<p>Composite CRC一个新的校验和计算方式。</p>
<p>当计算块校验和不是简单地将chunk CRC进行级联（concatenation），而是将chunk CRC进行数学式的组合（mathematically compose），计算文件校验和时对文件所有的chunk CRC进行数学式组合。因此，对于文件校验和，该计算方式对于分块大小并不敏感。 CRC算法相关论文。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-c6ffc53153.png" alt="图片"></p>
<p>在数据进行distcp的过程中，HDFS会进行校验和校验，确保distcp的源数据与新数据一致，但正如前文所说，EC编码会带来存储布局的改变，相同的文件三副本与EC数据存储的块大小，块数量都不一致，这让HDFS默认的MD5MD5CRC的方式变得不再适用。</p>
<p>需要将校验方式改为COMPOSITE CRC。</p>
<p>可通过 dfs.checksum.combine.mode 改变校验和校验的方式（MD5MD5CRC(默认值) or COMPOSITE_CRC)。</p>
<p>即使distcp过程中会进行校验，为了确保万无一失，我们还会对前后的分区目录的校验和校验。(目录校验和计算方式为将目录下文件MD5值排序，再进行MD5计算）为了保证转EC前后文件的一致性，多加一道校验的"工序"是值得的。</p>
<h2>3.4 文件损坏与修复</h2>
<p>文件损坏与丢块是HDFS EC应用绕不开的一个话题，原因是在Hadoop EC特性新推出的过程中，有若干与文件损坏相关的bug。EC文件损坏的过程主要发生在补块阶段，计算结果的不准确导致了新补的块与原来的块内容不一致。我们在EC推广的过程中，也狠狠地踩过文件损坏的"坑"。如何避免文件损坏，如何对补块的结果进行校验，如何修复损坏文件是三个重要的需要解决的问题。</p>
<h3>3.4.1 如何避免文件损坏</h3>
<p>通过对社区的调研，我们打了若干的patch来解决文件损坏与丢块的问题。</p>
<h3>3.4.2 对补块结果的校验</h3>
<p>我们引入了HDFS-15759，Patch提供了一个对EC补块的校验功能，在DN执行补块任务时，对补块结果进行校验。如果校验失败会抛出异常，并且补块任务会进行重试。</p>
<h3>3.4.3 EC批量校验工具</h3>
<p>我们对开源的EC批量校验工具进行了定制化的改造，工具能够对EC目录进行批量扫描，扫描出目录中的损坏的EC文件，在此感谢Stephen O'Donnell对工具的开源。</p>
<p>原理大致如下，对数据块进行EC编码，通过比对新生成的校验块和原来的校验块，来验证是否存在文件损坏。如果比对通过，则没有文件损坏，如果比对不通过，则存在文件损坏。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-80ad556a9b.png" alt="图片"></p>
<p>工具支持MR，可以分布式执行，此外，也可只对一个条带进行比对，只生成校验块的第一个条带，比对与原校验块第一个条带是否一致，这些都大大提高了批量校验EC文件的效率。</p>
<p>工具地址：</p>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fsodonnel%2Fhdfs-ec-validator" target="_blank">https://github.com/sodonnel/hdfs-ec-validator</a></p>
<h3>3.4.4 修复损坏文件</h3>
<p>在我们的集群，绝大部分损坏的文件都是ORC文件，ORC文件发生损坏时，由于其元数据分布的方式，会出现元数据的损坏，ORC无法解析。</p>
<p>假设一个块组内，数据块编号为1~6，校验块编号为7~9，数据块1损坏，我们可以通过读取数据块2~6加上任一一个校验块，得到"完好"的文件，对于ORC文件而言，判断是否完好取决于能否正常解析。</p>
<p>HDFS客户端get文件的时候默认只会读取数据块，我们通过改造HDFS客户端，使我们能够读取块组内指定编号的块，通过各种排列组合，得到一个"完好"的文件，之后将"完好"的文件覆盖掉HDFS上的损坏文件，来达到文件修复的目的。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-ff7df263d5.png" alt="图片"></p>
<h2>3.5 机器异构&amp;存储策略</h2>
<p>由于EC数据访问频率低，将EC数据存储到大存储的机器上，利用机器异构降低我们的单位存储成本。</p>
<p>在HDFS中，如果文件写入的路径设置了hot存储策略的目录，则会优先把文件存储到disk存储介质当中，如果设置了cold存储策略的目录，则会优先把文件存储到archive存储介质当中。</p>
<p>因此，当我们将大存储机器的盘都设置为Archive，并且将EC目录设置为Cold存储策略，即可将EC数据存放到大存储机器上，使TCO降低，进一步实现存储降本。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-99835c9495.png" alt="图片"></p>
<h1>四、总结与展望</h1>
<p>vivo的HDFS集群已存有几百PB的数据采用EC-RS6-3-1024k策略存储，相比三副本EC-RS6-3-1024k方式能带来50%的存储收益，节省了数百PB的存储空间，为公司带来了巨大的收益。目前我们推荐用户将访问频次较少的数据转为EC，因为EC会带来读取性能的下降，如何减少EC带来的读取性能下降？以及后续细化对用户数据的冷热分层，对越冷的数据采用冗余度越低的EC策略，EC补块速度优化等，都是后续继续大规模推进EC需要解决的重要难题。</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-5663af9821.gif"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-5663af9821.gif" medium="image"/>
    <pubDate>Thu, 16 Oct 2025 15:36:24 +0800</pubDate>
  </item><item>
    <title><![CDATA[豆包语音合成模型 2.0 升级，语义理解+情感演绎双突破]]></title>
    <link>https://www.oschina.net/news/377759</link>
    <itunes:title><![CDATA[豆包语音合成模型 2.0 升级，语义理解+情感演绎双突破]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p><span>火山引擎<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F9QvctKYTW0TNDv2856uxTw" target="_blank">宣布</a>升级豆包语音合成模型2.0（Doubao-Seed-TTS 2.0）和豆包声音复刻模型2.0（Doubao-Seed-ICL 2.0）。此次升级基于豆包大语言模型研发语音合成新架构，让合成和复刻的声音都能解锁深度语义理解和上下文理解能力，从单纯的文本朗读进化为“理解后的精准情感表达”。</span></p>
<p><span>此外2.0模型针对教育场景专项优化，使得全科复杂公式符号的合成平均准确率高达90%左右。</span></p>
<p><span>公告称，对话式合成让豆包语音合成模型2.0像是一位会思考的“演绎者”，让声音具备深度语义理解能力，并进一步将理解范围从给定文本扩大到多轮对话，理解包括：对话中的用户 Query、明确的自然语音指令，以及描述性的内心活动、背景信息、细腻情感等，让 AI 语音从“听得清”转变到“懂语义知语境”的情感式表达。</span></p>
<p><span>对话式语音合成具备3大核心优势：</span></p>
<ul>
<li><span>更强的互动拟人感：精准呈现与场景匹配的语气、语调、停顿等，让交互充满真实人际沟通的自然感。</span></li>
<li><span>更饱满的情感演绎：深度理解文字背后的情绪延续与变化，让声音的情绪承接更饱满连贯。</span></li>
<li><span>更精准的指令遵循：实现语速、情绪、声线、风格、音调的精准指令控制，提升语音表现可控性。</span></li>
</ul>
<p><span>豆包声音复刻模型2.0同样具有深度语义理解能力，在语音交互、小说配音、播客对话等场景中具备更强的声音表现力。</span></p>
<p><span>此外，豆包语音合成模型2.0和豆包声音复刻模型2.0提升了学科教育场景下复杂公式符号的朗读表现，针对教育场景进行数据增广与模型优化，涵盖单位、函数、幂数、面积、化合物、复分解等上百种类，经过大量客户真实场景的复杂公式评测集测试验证，在小学至高中全学科（数学、英语、化学、物理、地理、生物）的复杂公式符号朗读任务中，平均准确率达90%左右。</span></p>
<p><span><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-9dba7e6834.png"></span></p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p><span>火山引擎<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F9QvctKYTW0TNDv2856uxTw" target="_blank">宣布</a>升级豆包语音合成模型2.0（Doubao-Seed-TTS 2.0）和豆包声音复刻模型2.0（Doubao-Seed-ICL 2.0）。此次升级基于豆包大语言模型研发语音合成新架构，让合成和复刻的声音都能解锁深度语义理解和上下文理解能力，从单纯的文本朗读进化为“理解后的精准情感表达”。</span></p>
<p><span>此外2.0模型针对教育场景专项优化，使得全科复杂公式符号的合成平均准确率高达90%左右。</span></p>
<p><span>公告称，对话式合成让豆包语音合成模型2.0像是一位会思考的“演绎者”，让声音具备深度语义理解能力，并进一步将理解范围从给定文本扩大到多轮对话，理解包括：对话中的用户 Query、明确的自然语音指令，以及描述性的内心活动、背景信息、细腻情感等，让 AI 语音从“听得清”转变到“懂语义知语境”的情感式表达。</span></p>
<p><span>对话式语音合成具备3大核心优势：</span></p>
<ul>
<li><span>更强的互动拟人感：精准呈现与场景匹配的语气、语调、停顿等，让交互充满真实人际沟通的自然感。</span></li>
<li><span>更饱满的情感演绎：深度理解文字背后的情绪延续与变化，让声音的情绪承接更饱满连贯。</span></li>
<li><span>更精准的指令遵循：实现语速、情绪、声线、风格、音调的精准指令控制，提升语音表现可控性。</span></li>
</ul>
<p><span>豆包声音复刻模型2.0同样具有深度语义理解能力，在语音交互、小说配音、播客对话等场景中具备更强的声音表现力。</span></p>
<p><span>此外，豆包语音合成模型2.0和豆包声音复刻模型2.0提升了学科教育场景下复杂公式符号的朗读表现，针对教育场景进行数据增广与模型优化，涵盖单位、函数、幂数、面积、化合物、复分解等上百种类，经过大量客户真实场景的复杂公式评测集测试验证，在小学至高中全学科（数学、英语、化学、物理、地理、生物）的复杂公式符号朗读任务中，平均准确率达90%左右。</span></p>
<p><span><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-9dba7e6834.png"></span></p>]]>
    </description>
    <content:encoded><![CDATA[<p><span>火山引擎<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F9QvctKYTW0TNDv2856uxTw" target="_blank">宣布</a>升级豆包语音合成模型2.0（Doubao-Seed-TTS 2.0）和豆包声音复刻模型2.0（Doubao-Seed-ICL 2.0）。此次升级基于豆包大语言模型研发语音合成新架构，让合成和复刻的声音都能解锁深度语义理解和上下文理解能力，从单纯的文本朗读进化为“理解后的精准情感表达”。</span></p>
<p><span>此外2.0模型针对教育场景专项优化，使得全科复杂公式符号的合成平均准确率高达90%左右。</span></p>
<p><span>公告称，对话式合成让豆包语音合成模型2.0像是一位会思考的“演绎者”，让声音具备深度语义理解能力，并进一步将理解范围从给定文本扩大到多轮对话，理解包括：对话中的用户 Query、明确的自然语音指令，以及描述性的内心活动、背景信息、细腻情感等，让 AI 语音从“听得清”转变到“懂语义知语境”的情感式表达。</span></p>
<p><span>对话式语音合成具备3大核心优势：</span></p>
<ul>
<li><span>更强的互动拟人感：精准呈现与场景匹配的语气、语调、停顿等，让交互充满真实人际沟通的自然感。</span></li>
<li><span>更饱满的情感演绎：深度理解文字背后的情绪延续与变化，让声音的情绪承接更饱满连贯。</span></li>
<li><span>更精准的指令遵循：实现语速、情绪、声线、风格、音调的精准指令控制，提升语音表现可控性。</span></li>
</ul>
<p><span>豆包声音复刻模型2.0同样具有深度语义理解能力，在语音交互、小说配音、播客对话等场景中具备更强的声音表现力。</span></p>
<p><span>此外，豆包语音合成模型2.0和豆包声音复刻模型2.0提升了学科教育场景下复杂公式符号的朗读表现，针对教育场景进行数据增广与模型优化，涵盖单位、函数、幂数、面积、化合物、复分解等上百种类，经过大量客户真实场景的复杂公式评测集测试验证，在小学至高中全学科（数学、英语、化学、物理、地理、生物）的复杂公式符号朗读任务中，平均准确率达90%左右。</span></p>
<p><span><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-9dba7e6834.png"></span></p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-9dba7e6834.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-9dba7e6834.png" medium="image"/>
    <pubDate>Thu, 16 Oct 2025 15:09:58 +0800</pubDate>
  </item><item>
    <title><![CDATA[Arm 首席执行官：将部分工作负载从云端转移将有助降低 AI 电力需求]]></title>
    <link>https://www.oschina.net/news/377755</link>
    <itunes:title><![CDATA[Arm 首席执行官：将部分工作负载从云端转移将有助降低 AI 电力需求]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>芯片设计公司Arm Holdings首席执行官雷内·哈斯（Rene Haas）周三接受采访时表示，将一些人工智能功能从云端移走有助于减少能源消耗。</p>
<p>他认为，随着时间的推移，大量吉瓦级的数据中心是不可持续的。</p>
<p>“我认为有两个载体，”哈斯说，“一个是低功耗，你可以在云中获得最低功耗的解决方案。Arm确实有贡献。但我认为更具体的是将这些人工智能工作负载从云转移到本地应用程序。”</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-93ae046b15.png"></p>
<p>虽然他说AI训练可能总是在云端进行，但运行人工智能，即所谓的推理，可以在本地进行，也就是在人们的手机、电脑和眼镜内的芯片上进行。哈斯说，历史表明，“我们总是采用混合计算模式”。</p>
<p>他认为，在人工智能方面，混合动力将发挥作用，这将有助于减少巨大的电力投资。</p>
<p>Arm的技术为包括微软和亚马逊在内的许多大型科技公司生产的设备提供支持。英伟达持有Arm的多数股份，并在2020年试图收购该公司。</p>
<p>Arm和Meta周三表示，他们将扩大合作伙伴关系，“在跨越AI软件和数据中心基础设施的每一层计算上扩展AI效率”。消息公布后，Arm股价上涨，收盘涨1.49%。</p>
<p>哈斯在采访中表示，与Meta的合作“主要围绕数据中心展开，但更广泛……围绕着软件和与之相关的软件栈。”他还谈到了Arm参与Meta的新款Ray-Ban Wayfarer眼镜，称该技术的人工智能同时在云和本地运行。</p>
<p>哈斯说：“例如，当你对着眼镜说‘嘿，Meta’时，这不是发生在云端，而是发生在你的眼镜上，并在Arm上运行。”</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>芯片设计公司Arm Holdings首席执行官雷内·哈斯（Rene Haas）周三接受采访时表示，将一些人工智能功能从云端移走有助于减少能源消耗。</p>
<p>他认为，随着时间的推移，大量吉瓦级的数据中心是不可持续的。</p>
<p>“我认为有两个载体，”哈斯说，“一个是低功耗，你可以在云中获得最低功耗的解决方案。Arm确实有贡献。但我认为更具体的是将这些人工智能工作负载从云转移到本地应用程序。”</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-93ae046b15.png"></p>
<p>虽然他说AI训练可能总是在云端进行，但运行人工智能，即所谓的推理，可以在本地进行，也就是在人们的手机、电脑和眼镜内的芯片上进行。哈斯说，历史表明，“我们总是采用混合计算模式”。</p>
<p>他认为，在人工智能方面，混合动力将发挥作用，这将有助于减少巨大的电力投资。</p>
<p>Arm的技术为包括微软和亚马逊在内的许多大型科技公司生产的设备提供支持。英伟达持有Arm的多数股份，并在2020年试图收购该公司。</p>
<p>Arm和Meta周三表示，他们将扩大合作伙伴关系，“在跨越AI软件和数据中心基础设施的每一层计算上扩展AI效率”。消息公布后，Arm股价上涨，收盘涨1.49%。</p>
<p>哈斯在采访中表示，与Meta的合作“主要围绕数据中心展开，但更广泛……围绕着软件和与之相关的软件栈。”他还谈到了Arm参与Meta的新款Ray-Ban Wayfarer眼镜，称该技术的人工智能同时在云和本地运行。</p>
<p>哈斯说：“例如，当你对着眼镜说‘嘿，Meta’时，这不是发生在云端，而是发生在你的眼镜上，并在Arm上运行。”</p>]]>
    </description>
    <content:encoded><![CDATA[<p>芯片设计公司Arm Holdings首席执行官雷内·哈斯（Rene Haas）周三接受采访时表示，将一些人工智能功能从云端移走有助于减少能源消耗。</p>
<p>他认为，随着时间的推移，大量吉瓦级的数据中心是不可持续的。</p>
<p>“我认为有两个载体，”哈斯说，“一个是低功耗，你可以在云中获得最低功耗的解决方案。Arm确实有贡献。但我认为更具体的是将这些人工智能工作负载从云转移到本地应用程序。”</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-93ae046b15.png"></p>
<p>虽然他说AI训练可能总是在云端进行，但运行人工智能，即所谓的推理，可以在本地进行，也就是在人们的手机、电脑和眼镜内的芯片上进行。哈斯说，历史表明，“我们总是采用混合计算模式”。</p>
<p>他认为，在人工智能方面，混合动力将发挥作用，这将有助于减少巨大的电力投资。</p>
<p>Arm的技术为包括微软和亚马逊在内的许多大型科技公司生产的设备提供支持。英伟达持有Arm的多数股份，并在2020年试图收购该公司。</p>
<p>Arm和Meta周三表示，他们将扩大合作伙伴关系，“在跨越AI软件和数据中心基础设施的每一层计算上扩展AI效率”。消息公布后，Arm股价上涨，收盘涨1.49%。</p>
<p>哈斯在采访中表示，与Meta的合作“主要围绕数据中心展开，但更广泛……围绕着软件和与之相关的软件栈。”他还谈到了Arm参与Meta的新款Ray-Ban Wayfarer眼镜，称该技术的人工智能同时在云和本地运行。</p>
<p>哈斯说：“例如，当你对着眼镜说‘嘿，Meta’时，这不是发生在云端，而是发生在你的眼镜上，并在Arm上运行。”</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-93ae046b15.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-93ae046b15.png" medium="image"/>
    <pubDate>Thu, 16 Oct 2025 14:53:06 +0800</pubDate>
  </item><item>
    <title><![CDATA[谷歌 Veo 3.1 正式发布：新增音频功能和精细化编辑能力]]></title>
    <link>https://www.oschina.net/news/377754</link>
    <itunes:title><![CDATA[谷歌 Veo 3.1 正式发布：新增音频功能和精细化编辑能力]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>谷歌推出了视频生成模型Veo3.1，这是对今年5月发布的Veo3的升级版本。新版本在音频输出、编辑控制粒度和图像转视频质量等方面实现了改进，能够生成更真实的视频片段并更准确地遵循用户提示指令。</p>
<p>在功能层面，Veo3.1允许用户向视频中添加新对象，系统会自动将其融入原有画面风格。谷歌还透露，即将在其视频编辑工具Flow中支持从视频中移除现有对象的功能，进一步增强编辑灵活性。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-a1236103e8.png"></p>
<p>Veo3此前已经提供了多项编辑特性，包括通过参考图像驱动角色生成、提供首尾帧由AI生成中间内容，以及基于末尾帧扩展现有视频等功能。Veo3.1的核心升级在于为所有这些编辑功能增加了音频生成能力，使输出的视频片段具备声音元素，提升了内容的完整性和沉浸感。</p>
<p>从部署渠道来看，Veo3.1将通过多个平台向用户开放。谷歌正在将该模型集成到视频编辑器Flow、Gemini应用程序，以及面向开发者的Vertex AI和Gemini API接口中。据谷歌披露的数据，自Flow在5月上线以来，用户已在该平台上创作了超过2.75亿个视频。</p>
<p>这次更新体现了AI视频生成技术在两个方向上的演进。一方面是生成质量的持续提升——更真实的画面、更准确的提示词理解;另一方面是编辑能力的细化——从整体生成到局部修改、对象增删等精细操作。音频生成的加入则填补了此前AI视频工具普遍缺乏声音元素的短板。</p>
<p>不过从技术成熟度来看，AI视频生成仍处于快速迭代阶段。视频的连贯性、物理规律的准确性、复杂场景的处理能力等方面，各家模型都在持续改进中。Veo3.1的实际表现，包括音频与画面的同步质量、对象融合的自然度等细节，还需要通过用户实际使用来验证。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>谷歌推出了视频生成模型Veo3.1，这是对今年5月发布的Veo3的升级版本。新版本在音频输出、编辑控制粒度和图像转视频质量等方面实现了改进，能够生成更真实的视频片段并更准确地遵循用户提示指令。</p>
<p>在功能层面，Veo3.1允许用户向视频中添加新对象，系统会自动将其融入原有画面风格。谷歌还透露，即将在其视频编辑工具Flow中支持从视频中移除现有对象的功能，进一步增强编辑灵活性。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-a1236103e8.png"></p>
<p>Veo3此前已经提供了多项编辑特性，包括通过参考图像驱动角色生成、提供首尾帧由AI生成中间内容，以及基于末尾帧扩展现有视频等功能。Veo3.1的核心升级在于为所有这些编辑功能增加了音频生成能力，使输出的视频片段具备声音元素，提升了内容的完整性和沉浸感。</p>
<p>从部署渠道来看，Veo3.1将通过多个平台向用户开放。谷歌正在将该模型集成到视频编辑器Flow、Gemini应用程序，以及面向开发者的Vertex AI和Gemini API接口中。据谷歌披露的数据，自Flow在5月上线以来，用户已在该平台上创作了超过2.75亿个视频。</p>
<p>这次更新体现了AI视频生成技术在两个方向上的演进。一方面是生成质量的持续提升——更真实的画面、更准确的提示词理解;另一方面是编辑能力的细化——从整体生成到局部修改、对象增删等精细操作。音频生成的加入则填补了此前AI视频工具普遍缺乏声音元素的短板。</p>
<p>不过从技术成熟度来看，AI视频生成仍处于快速迭代阶段。视频的连贯性、物理规律的准确性、复杂场景的处理能力等方面，各家模型都在持续改进中。Veo3.1的实际表现，包括音频与画面的同步质量、对象融合的自然度等细节，还需要通过用户实际使用来验证。</p>]]>
    </description>
    <content:encoded><![CDATA[<p>谷歌推出了视频生成模型Veo3.1，这是对今年5月发布的Veo3的升级版本。新版本在音频输出、编辑控制粒度和图像转视频质量等方面实现了改进，能够生成更真实的视频片段并更准确地遵循用户提示指令。</p>
<p>在功能层面，Veo3.1允许用户向视频中添加新对象，系统会自动将其融入原有画面风格。谷歌还透露，即将在其视频编辑工具Flow中支持从视频中移除现有对象的功能，进一步增强编辑灵活性。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-a1236103e8.png"></p>
<p>Veo3此前已经提供了多项编辑特性，包括通过参考图像驱动角色生成、提供首尾帧由AI生成中间内容，以及基于末尾帧扩展现有视频等功能。Veo3.1的核心升级在于为所有这些编辑功能增加了音频生成能力，使输出的视频片段具备声音元素，提升了内容的完整性和沉浸感。</p>
<p>从部署渠道来看，Veo3.1将通过多个平台向用户开放。谷歌正在将该模型集成到视频编辑器Flow、Gemini应用程序，以及面向开发者的Vertex AI和Gemini API接口中。据谷歌披露的数据，自Flow在5月上线以来，用户已在该平台上创作了超过2.75亿个视频。</p>
<p>这次更新体现了AI视频生成技术在两个方向上的演进。一方面是生成质量的持续提升——更真实的画面、更准确的提示词理解;另一方面是编辑能力的细化——从整体生成到局部修改、对象增删等精细操作。音频生成的加入则填补了此前AI视频工具普遍缺乏声音元素的短板。</p>
<p>不过从技术成熟度来看，AI视频生成仍处于快速迭代阶段。视频的连贯性、物理规律的准确性、复杂场景的处理能力等方面，各家模型都在持续改进中。Veo3.1的实际表现，包括音频与画面的同步质量、对象融合的自然度等细节，还需要通过用户实际使用来验证。</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-a1236103e8.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-a1236103e8.png" medium="image"/>
    <pubDate>Thu, 16 Oct 2025 14:42:56 +0800</pubDate>
  </item><item>
    <title><![CDATA[苹果 AI 项目高管跳槽 Meta，Siri 团队面临挑战]]></title>
    <link>https://www.oschina.net/news/377741</link>
    <itunes:title><![CDATA[苹果 AI 项目高管跳槽 Meta，Siri 团队面临挑战]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>苹果公司一名重要的 AI 高管 Ke Yang 近日决定离职，转投 Meta 公司。据彭博社报道，Yang 在几周前刚被任命为苹果的 Answers、Knowledge and Information（AKI）团队负责人。该团队的主要目标是提升 Siri 语音助手的能力，使其更加智能化，能够像 ChatGPT 一样直接从网络上获取信息。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-d48b5e4fad.png"></p>
<p>AKI 团队在苹果 Siri 的大改版中扮演着核心角色，此次改版也是苹果为了重振其 AI 业务而采取的措施。新版 Siri 将引入一些早先推迟的功能，包括处理更复杂请求的能力，以及更好地利用用户的个人数据来提升服务质量。苹果希望通过 “Answers” 功能，能够在快速发展的 AI 搜索市场中与 OpenAI、Google 的 Gemini 等竞争。</p>
<p>Ke Yang 在苹果的 AI 与机器学习高级副总裁 John Giannandrea 的直接领导下工作。在接任 AKI 部门之前，他一直负责与搜索相关的项目。这一改版项目是由苹果的人工智能与机器学习组与 Siri 工程团队共同开发的，Yang 在其中被视为关键的高管之一。Yang 的离职引发了人们对苹果 AI 团队稳定性的担忧，因为今年已经有多名核心成员相继离开。</p>
<p>苹果 AI 团队的流失现象引人关注，其中包括多位负责基础模型研究的成员，他们被称为 “Apple Foundation Models”，以及该团队的创始人兼首席科学家 Ruoming Pang，后者已经加入了 Meta 公司正在组建的 Superintelligence Labs 团队。此外，其他成员如 Sam Wiseman 和 Chong Wang 也纷纷转投 Meta，显示出苹果 AI 团队的不稳定性。</p>
<p>Yang 的离职意味着 AKI 团队将由 Giannandrea 的助手 Benoit Dupin 接手，后者将负责苹果在机器学习领域的云基础设施。</p>
<p><strong>相关阅读：</strong></p>
<ul>
<li><a href="https://www.oschina.net/news/372246" target="_blank">苹果 AI 领域人事调整：前 Siri 高管 Robby Walker 将于 10 月底离职</a></li>
</ul>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>苹果公司一名重要的 AI 高管 Ke Yang 近日决定离职，转投 Meta 公司。据彭博社报道，Yang 在几周前刚被任命为苹果的 Answers、Knowledge and Information（AKI）团队负责人。该团队的主要目标是提升 Siri 语音助手的能力，使其更加智能化，能够像 ChatGPT 一样直接从网络上获取信息。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-d48b5e4fad.png"></p>
<p>AKI 团队在苹果 Siri 的大改版中扮演着核心角色，此次改版也是苹果为了重振其 AI 业务而采取的措施。新版 Siri 将引入一些早先推迟的功能，包括处理更复杂请求的能力，以及更好地利用用户的个人数据来提升服务质量。苹果希望通过 “Answers” 功能，能够在快速发展的 AI 搜索市场中与 OpenAI、Google 的 Gemini 等竞争。</p>
<p>Ke Yang 在苹果的 AI 与机器学习高级副总裁 John Giannandrea 的直接领导下工作。在接任 AKI 部门之前，他一直负责与搜索相关的项目。这一改版项目是由苹果的人工智能与机器学习组与 Siri 工程团队共同开发的，Yang 在其中被视为关键的高管之一。Yang 的离职引发了人们对苹果 AI 团队稳定性的担忧，因为今年已经有多名核心成员相继离开。</p>
<p>苹果 AI 团队的流失现象引人关注，其中包括多位负责基础模型研究的成员，他们被称为 “Apple Foundation Models”，以及该团队的创始人兼首席科学家 Ruoming Pang，后者已经加入了 Meta 公司正在组建的 Superintelligence Labs 团队。此外，其他成员如 Sam Wiseman 和 Chong Wang 也纷纷转投 Meta，显示出苹果 AI 团队的不稳定性。</p>
<p>Yang 的离职意味着 AKI 团队将由 Giannandrea 的助手 Benoit Dupin 接手，后者将负责苹果在机器学习领域的云基础设施。</p>
<p><strong>相关阅读：</strong></p>
<ul>
<li><a href="https://www.oschina.net/news/372246" target="_blank">苹果 AI 领域人事调整：前 Siri 高管 Robby Walker 将于 10 月底离职</a></li>
</ul>]]>
    </description>
    <content:encoded><![CDATA[<p>苹果公司一名重要的 AI 高管 Ke Yang 近日决定离职，转投 Meta 公司。据彭博社报道，Yang 在几周前刚被任命为苹果的 Answers、Knowledge and Information（AKI）团队负责人。该团队的主要目标是提升 Siri 语音助手的能力，使其更加智能化，能够像 ChatGPT 一样直接从网络上获取信息。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-d48b5e4fad.png"></p>
<p>AKI 团队在苹果 Siri 的大改版中扮演着核心角色，此次改版也是苹果为了重振其 AI 业务而采取的措施。新版 Siri 将引入一些早先推迟的功能，包括处理更复杂请求的能力，以及更好地利用用户的个人数据来提升服务质量。苹果希望通过 “Answers” 功能，能够在快速发展的 AI 搜索市场中与 OpenAI、Google 的 Gemini 等竞争。</p>
<p>Ke Yang 在苹果的 AI 与机器学习高级副总裁 John Giannandrea 的直接领导下工作。在接任 AKI 部门之前，他一直负责与搜索相关的项目。这一改版项目是由苹果的人工智能与机器学习组与 Siri 工程团队共同开发的，Yang 在其中被视为关键的高管之一。Yang 的离职引发了人们对苹果 AI 团队稳定性的担忧，因为今年已经有多名核心成员相继离开。</p>
<p>苹果 AI 团队的流失现象引人关注，其中包括多位负责基础模型研究的成员，他们被称为 “Apple Foundation Models”，以及该团队的创始人兼首席科学家 Ruoming Pang，后者已经加入了 Meta 公司正在组建的 Superintelligence Labs 团队。此外，其他成员如 Sam Wiseman 和 Chong Wang 也纷纷转投 Meta，显示出苹果 AI 团队的不稳定性。</p>
<p>Yang 的离职意味着 AKI 团队将由 Giannandrea 的助手 Benoit Dupin 接手，后者将负责苹果在机器学习领域的云基础设施。</p>
<p><strong>相关阅读：</strong></p>
<ul>
<li><a href="https://www.oschina.net/news/372246" target="_blank">苹果 AI 领域人事调整：前 Siri 高管 Robby Walker 将于 10 月底离职</a></li>
</ul>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-d48b5e4fad.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-d48b5e4fad.png" medium="image"/>
    <pubDate>Thu, 16 Oct 2025 13:53:11 +0800</pubDate>
  </item><item>
    <title><![CDATA[国内首个标准化领域大模型"同道"上线]]></title>
    <link>https://www.oschina.net/news/377731</link>
    <itunes:title><![CDATA[国内首个标准化领域大模型"同道"上线]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>中国电子技术标准化研究院开发的标准化领域专用大模型"同道"互联网版于10月14日正式<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FcWpdEBbQmQByqHy_70tYFg" target="_blank">上线</a>。这是国内首个面向标准化工作的垂直领域大模型产品，旨在解决长期困扰行业的标准检索困难、文档撰写效率低和应用场景薄弱等问题。</p>
<p>标准化工作一直面临实际操作层面的挑战。从业人员在处理海量标准文献时，往往需要耗费大量时间进行人工检索和比对，难以快速定位所需信息。"同道"的推出正是针对这一痛点，基于中国电子技术标准化研究院多年积累的标准数据资源，经过技术攻关开发而成。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-73dee54762.png"></p>
<p>从功能架构来看，"同道"互联网版提供了四大核心能力模块。"同道问答"提供标准相关问题的即时解答;"同道编写"辅助标准文档的起草工作;"同道解读"帮助理解复杂的标准条款;"同道认证"则服务于标准符合性验证流程。这四项功能覆盖了标准制定、查询、应用的完整流程，构建起贯穿标准全生命周期的智能服务体系。</p>
<p>在使用方式上，"同道问答"功能的工作机制类似领域专家系统。用户输入标准相关问题后，系统能够快速从标准文本库中检索并整合相关信息，以结构化方式输出答案。这一设计改变了传统的"人找标准"模式，让标准信息能够主动匹配用户需求。</p>
<p>技术实现层面，"同道"支持多种文档格式的输入，具备多模态交互能力。用户可以通过网页端或移动端直接访问服务，无需安装客户端软件。这种轻量化的部署方式降低了使用门槛，使标准化服务能够触达更广泛的用户群体。</p>
<p>从行业影响来看，这类垂直领域大模型的出现代表了AI应用从通用场景向专业领域深化的趋势。标准化工作涉及制造、工程、质量管理等多个产业环节，智能化工具的引入有望提升相关从业人员的工作效率。不过，该产品在实际应用中的准确性、对复杂标准场景的理解深度，以及与现有标准管理系统的集成能力，还需要通过用户反馈和持续迭代来验证。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>中国电子技术标准化研究院开发的标准化领域专用大模型"同道"互联网版于10月14日正式<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FcWpdEBbQmQByqHy_70tYFg" target="_blank">上线</a>。这是国内首个面向标准化工作的垂直领域大模型产品，旨在解决长期困扰行业的标准检索困难、文档撰写效率低和应用场景薄弱等问题。</p>
<p>标准化工作一直面临实际操作层面的挑战。从业人员在处理海量标准文献时，往往需要耗费大量时间进行人工检索和比对，难以快速定位所需信息。"同道"的推出正是针对这一痛点，基于中国电子技术标准化研究院多年积累的标准数据资源，经过技术攻关开发而成。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-73dee54762.png"></p>
<p>从功能架构来看，"同道"互联网版提供了四大核心能力模块。"同道问答"提供标准相关问题的即时解答;"同道编写"辅助标准文档的起草工作;"同道解读"帮助理解复杂的标准条款;"同道认证"则服务于标准符合性验证流程。这四项功能覆盖了标准制定、查询、应用的完整流程，构建起贯穿标准全生命周期的智能服务体系。</p>
<p>在使用方式上，"同道问答"功能的工作机制类似领域专家系统。用户输入标准相关问题后，系统能够快速从标准文本库中检索并整合相关信息，以结构化方式输出答案。这一设计改变了传统的"人找标准"模式，让标准信息能够主动匹配用户需求。</p>
<p>技术实现层面，"同道"支持多种文档格式的输入，具备多模态交互能力。用户可以通过网页端或移动端直接访问服务，无需安装客户端软件。这种轻量化的部署方式降低了使用门槛，使标准化服务能够触达更广泛的用户群体。</p>
<p>从行业影响来看，这类垂直领域大模型的出现代表了AI应用从通用场景向专业领域深化的趋势。标准化工作涉及制造、工程、质量管理等多个产业环节，智能化工具的引入有望提升相关从业人员的工作效率。不过，该产品在实际应用中的准确性、对复杂标准场景的理解深度，以及与现有标准管理系统的集成能力，还需要通过用户反馈和持续迭代来验证。</p>]]>
    </description>
    <content:encoded><![CDATA[<p>中国电子技术标准化研究院开发的标准化领域专用大模型"同道"互联网版于10月14日正式<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FcWpdEBbQmQByqHy_70tYFg" target="_blank">上线</a>。这是国内首个面向标准化工作的垂直领域大模型产品，旨在解决长期困扰行业的标准检索困难、文档撰写效率低和应用场景薄弱等问题。</p>
<p>标准化工作一直面临实际操作层面的挑战。从业人员在处理海量标准文献时，往往需要耗费大量时间进行人工检索和比对，难以快速定位所需信息。"同道"的推出正是针对这一痛点，基于中国电子技术标准化研究院多年积累的标准数据资源，经过技术攻关开发而成。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-73dee54762.png"></p>
<p>从功能架构来看，"同道"互联网版提供了四大核心能力模块。"同道问答"提供标准相关问题的即时解答;"同道编写"辅助标准文档的起草工作;"同道解读"帮助理解复杂的标准条款;"同道认证"则服务于标准符合性验证流程。这四项功能覆盖了标准制定、查询、应用的完整流程，构建起贯穿标准全生命周期的智能服务体系。</p>
<p>在使用方式上，"同道问答"功能的工作机制类似领域专家系统。用户输入标准相关问题后，系统能够快速从标准文本库中检索并整合相关信息，以结构化方式输出答案。这一设计改变了传统的"人找标准"模式，让标准信息能够主动匹配用户需求。</p>
<p>技术实现层面，"同道"支持多种文档格式的输入，具备多模态交互能力。用户可以通过网页端或移动端直接访问服务，无需安装客户端软件。这种轻量化的部署方式降低了使用门槛，使标准化服务能够触达更广泛的用户群体。</p>
<p>从行业影响来看，这类垂直领域大模型的出现代表了AI应用从通用场景向专业领域深化的趋势。标准化工作涉及制造、工程、质量管理等多个产业环节，智能化工具的引入有望提升相关从业人员的工作效率。不过，该产品在实际应用中的准确性、对复杂标准场景的理解深度，以及与现有标准管理系统的集成能力，还需要通过用户反馈和持续迭代来验证。</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-73dee54762.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-73dee54762.png" medium="image"/>
    <pubDate>Thu, 16 Oct 2025 11:57:03 +0800</pubDate>
  </item><item>
    <title><![CDATA[网友扒到宇树 CEO 王兴兴的硕士毕业论文：10 年前就押对了]]></title>
    <link>https://www.oschina.net/news/377730</link>
    <itunes:title><![CDATA[网友扒到宇树 CEO 王兴兴的硕士毕业论文：10 年前就押对了]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>近日，有网友掘地三尺将宇树科技CEO王兴兴的硕士毕业论文扒出来了。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-2765fa60c5.png"></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-a96fa0bd54.png"></p>
<p>众所周知，宇树科技最初的产品是机器狗，而这篇论文完成于2016年，题目为《新型电驱式四足机器人研制与测试》，其中有两点颇让人注意：</p>
<p><strong>首先是王兴兴当时大胆押注的电驱式机器人方案，目前已被业界广泛接受。</strong></p>
<p>当时包括波士顿动力在内的国内外团队都将研究集中于液压方案，但现在这一形式已经发生逆转，其中波士顿动力从去年开始改液压为电驱。</p>
<p><strong>其次是宇树科技的开局就源自论文所提出的“XDog”机器小狗。</strong></p>
<p>值得注意的是，不止王兴兴本人在多个场合公开提到这只小狗，而且它还被明晃晃摆在宇树科技展厅的首要位置。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>近日，有网友掘地三尺将宇树科技CEO王兴兴的硕士毕业论文扒出来了。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-2765fa60c5.png"></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-a96fa0bd54.png"></p>
<p>众所周知，宇树科技最初的产品是机器狗，而这篇论文完成于2016年，题目为《新型电驱式四足机器人研制与测试》，其中有两点颇让人注意：</p>
<p><strong>首先是王兴兴当时大胆押注的电驱式机器人方案，目前已被业界广泛接受。</strong></p>
<p>当时包括波士顿动力在内的国内外团队都将研究集中于液压方案，但现在这一形式已经发生逆转，其中波士顿动力从去年开始改液压为电驱。</p>
<p><strong>其次是宇树科技的开局就源自论文所提出的“XDog”机器小狗。</strong></p>
<p>值得注意的是，不止王兴兴本人在多个场合公开提到这只小狗，而且它还被明晃晃摆在宇树科技展厅的首要位置。</p>]]>
    </description>
    <content:encoded><![CDATA[<p>近日，有网友掘地三尺将宇树科技CEO王兴兴的硕士毕业论文扒出来了。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-2765fa60c5.png"></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-a96fa0bd54.png"></p>
<p>众所周知，宇树科技最初的产品是机器狗，而这篇论文完成于2016年，题目为《新型电驱式四足机器人研制与测试》，其中有两点颇让人注意：</p>
<p><strong>首先是王兴兴当时大胆押注的电驱式机器人方案，目前已被业界广泛接受。</strong></p>
<p>当时包括波士顿动力在内的国内外团队都将研究集中于液压方案，但现在这一形式已经发生逆转，其中波士顿动力从去年开始改液压为电驱。</p>
<p><strong>其次是宇树科技的开局就源自论文所提出的“XDog”机器小狗。</strong></p>
<p>值得注意的是，不止王兴兴本人在多个场合公开提到这只小狗，而且它还被明晃晃摆在宇树科技展厅的首要位置。</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-2765fa60c5.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-2765fa60c5.png" medium="image"/>
    <pubDate>Thu, 16 Oct 2025 11:51:44 +0800</pubDate>
  </item><item>
    <title><![CDATA[智元发布新一代工业级交互式具身作业机器人精灵 G2]]></title>
    <link>https://www.oschina.net/news/377728</link>
    <itunes:title><![CDATA[智元发布新一代工业级交互式具身作业机器人精灵 G2]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>智元机器人举行线上直播发布会，正式发布新一代工业级交互式具身作业机器人智元精灵G2。精灵G2以工业标准打造，搭载高性能运动关节、高精度力矩传感器，集成先进的空间感知系统，支持快速学习部署，拥有出色的多模态语音交互能力，具备工业、物流、导览等多场景通用能力。目前，精灵G2已获数亿元订单，并已开启首批商用交付。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-75618a3fb4.png"></p>
<p>根据介绍，精灵G2基于 2023年11月发布的精灵G1，具备卓越运动能力、感知能力和交互能力。其搭载高性能的关节执行器、多种类型的传感器、高性能AI计算平台，可以实现全场景全向避障，高精度力控作业。其腰部3自由度设计，可实现近似人类的弯腰、转腰和侧向摆动身体能力。</p>
<p>G2配置全球首款十字腕力控臂，全臂搭载高精度关节扭矩传感器，通过关节阻抗控制，能细腻感知外力并做出柔顺反应，搭配快速部署工具链，即便没有任何力控调参能力的普通用户也可实现快速部署。续航方面，精灵G2可自主回到充电站补能，还拥有双电池热插拔换电能力，满足24小时工厂产线节拍。</p>
<p>精灵G2全面支持多人实时智能交互，基于知识库个性化定制讲解内容，并能根据观众提出的不同问题智能作答，还可根据语境切换不同的讲解员人设和音色。此外，基于智元全栈自研的通用基座大模型GO-1和世界模型GE-1，G2处理复杂和长程任务的能力得到全面提升。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>智元机器人举行线上直播发布会，正式发布新一代工业级交互式具身作业机器人智元精灵G2。精灵G2以工业标准打造，搭载高性能运动关节、高精度力矩传感器，集成先进的空间感知系统，支持快速学习部署，拥有出色的多模态语音交互能力，具备工业、物流、导览等多场景通用能力。目前，精灵G2已获数亿元订单，并已开启首批商用交付。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-75618a3fb4.png"></p>
<p>根据介绍，精灵G2基于 2023年11月发布的精灵G1，具备卓越运动能力、感知能力和交互能力。其搭载高性能的关节执行器、多种类型的传感器、高性能AI计算平台，可以实现全场景全向避障，高精度力控作业。其腰部3自由度设计，可实现近似人类的弯腰、转腰和侧向摆动身体能力。</p>
<p>G2配置全球首款十字腕力控臂，全臂搭载高精度关节扭矩传感器，通过关节阻抗控制，能细腻感知外力并做出柔顺反应，搭配快速部署工具链，即便没有任何力控调参能力的普通用户也可实现快速部署。续航方面，精灵G2可自主回到充电站补能，还拥有双电池热插拔换电能力，满足24小时工厂产线节拍。</p>
<p>精灵G2全面支持多人实时智能交互，基于知识库个性化定制讲解内容，并能根据观众提出的不同问题智能作答，还可根据语境切换不同的讲解员人设和音色。此外，基于智元全栈自研的通用基座大模型GO-1和世界模型GE-1，G2处理复杂和长程任务的能力得到全面提升。</p>]]>
    </description>
    <content:encoded><![CDATA[<p>智元机器人举行线上直播发布会，正式发布新一代工业级交互式具身作业机器人智元精灵G2。精灵G2以工业标准打造，搭载高性能运动关节、高精度力矩传感器，集成先进的空间感知系统，支持快速学习部署，拥有出色的多模态语音交互能力，具备工业、物流、导览等多场景通用能力。目前，精灵G2已获数亿元订单，并已开启首批商用交付。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-75618a3fb4.png"></p>
<p>根据介绍，精灵G2基于 2023年11月发布的精灵G1，具备卓越运动能力、感知能力和交互能力。其搭载高性能的关节执行器、多种类型的传感器、高性能AI计算平台，可以实现全场景全向避障，高精度力控作业。其腰部3自由度设计，可实现近似人类的弯腰、转腰和侧向摆动身体能力。</p>
<p>G2配置全球首款十字腕力控臂，全臂搭载高精度关节扭矩传感器，通过关节阻抗控制，能细腻感知外力并做出柔顺反应，搭配快速部署工具链，即便没有任何力控调参能力的普通用户也可实现快速部署。续航方面，精灵G2可自主回到充电站补能，还拥有双电池热插拔换电能力，满足24小时工厂产线节拍。</p>
<p>精灵G2全面支持多人实时智能交互，基于知识库个性化定制讲解内容，并能根据观众提出的不同问题智能作答，还可根据语境切换不同的讲解员人设和音色。此外，基于智元全栈自研的通用基座大模型GO-1和世界模型GE-1，G2处理复杂和长程任务的能力得到全面提升。</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-75618a3fb4.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-75618a3fb4.png" medium="image"/>
    <pubDate>Thu, 16 Oct 2025 11:43:55 +0800</pubDate>
  </item><item>
    <title><![CDATA[DeepMind 携手耶鲁大学发布 C2S-Scale27B 模型]]></title>
    <link>https://www.oschina.net/news/377725</link>
    <itunes:title><![CDATA[DeepMind 携手耶鲁大学发布 C2S-Scale27B 模型]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>谷歌 DeepMind 近日与耶鲁大学合作，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Ftechnology%2Fai%2Fgoogle-gemma-ai-cancer-therapy-discovery%2F" target="_blank">推出</a>了一款名为<span>&nbsp;</span>C2S-Scale27B<span>&nbsp;</span>的全新人工智能模型。该模型基于开放的<span>&nbsp;</span>Gemma 模型系列构建，专注于复杂的单细胞分析，并成功发现了一条此前未知的癌症治疗途径。</p>
<p>C2S-Scale27B 的主要发现是识别出药物<span>&nbsp;</span>Silmitasertib （CX-4945）<span>&nbsp;</span>是一种“条件增强剂”。这意味着在特定条件下，这种药物能够使<span>肿瘤</span>细胞更容易被免疫系统识别并清除。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-0cc3c2e6bf.png"></p>
<p>据 DeepMind 团队称，这一成果为新型生物学发现提供了一个重要蓝图。他们表示:“通过遵循尺度定律并构建像 C2S-Scale27B 这样的大型模型，我们可以创建足够强大的细胞行为预测模型，以运行高通量虚拟筛选、发现情境条件下的生物学，并生成基于生物学的假设。”</p>
<p>在模型识别出这一潜在治疗途径后，研究团队利用人类神经内分泌细胞模型进行了实验室实验，成功证实了这一预测。在此之前，C2S-Scale 模型已经在两种不同的免疫环境中模拟了<span>&nbsp;</span>4000多种药物的作用。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>谷歌 DeepMind 近日与耶鲁大学合作，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Ftechnology%2Fai%2Fgoogle-gemma-ai-cancer-therapy-discovery%2F" target="_blank">推出</a>了一款名为<span>&nbsp;</span>C2S-Scale27B<span>&nbsp;</span>的全新人工智能模型。该模型基于开放的<span>&nbsp;</span>Gemma 模型系列构建，专注于复杂的单细胞分析，并成功发现了一条此前未知的癌症治疗途径。</p>
<p>C2S-Scale27B 的主要发现是识别出药物<span>&nbsp;</span>Silmitasertib （CX-4945）<span>&nbsp;</span>是一种“条件增强剂”。这意味着在特定条件下，这种药物能够使<span>肿瘤</span>细胞更容易被免疫系统识别并清除。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-0cc3c2e6bf.png"></p>
<p>据 DeepMind 团队称，这一成果为新型生物学发现提供了一个重要蓝图。他们表示:“通过遵循尺度定律并构建像 C2S-Scale27B 这样的大型模型，我们可以创建足够强大的细胞行为预测模型，以运行高通量虚拟筛选、发现情境条件下的生物学，并生成基于生物学的假设。”</p>
<p>在模型识别出这一潜在治疗途径后，研究团队利用人类神经内分泌细胞模型进行了实验室实验，成功证实了这一预测。在此之前，C2S-Scale 模型已经在两种不同的免疫环境中模拟了<span>&nbsp;</span>4000多种药物的作用。</p>]]>
    </description>
    <content:encoded><![CDATA[<p>谷歌 DeepMind 近日与耶鲁大学合作，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Ftechnology%2Fai%2Fgoogle-gemma-ai-cancer-therapy-discovery%2F" target="_blank">推出</a>了一款名为<span>&nbsp;</span>C2S-Scale27B<span>&nbsp;</span>的全新人工智能模型。该模型基于开放的<span>&nbsp;</span>Gemma 模型系列构建，专注于复杂的单细胞分析，并成功发现了一条此前未知的癌症治疗途径。</p>
<p>C2S-Scale27B 的主要发现是识别出药物<span>&nbsp;</span>Silmitasertib （CX-4945）<span>&nbsp;</span>是一种“条件增强剂”。这意味着在特定条件下，这种药物能够使<span>肿瘤</span>细胞更容易被免疫系统识别并清除。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-0cc3c2e6bf.png"></p>
<p>据 DeepMind 团队称，这一成果为新型生物学发现提供了一个重要蓝图。他们表示:“通过遵循尺度定律并构建像 C2S-Scale27B 这样的大型模型，我们可以创建足够强大的细胞行为预测模型，以运行高通量虚拟筛选、发现情境条件下的生物学，并生成基于生物学的假设。”</p>
<p>在模型识别出这一潜在治疗途径后，研究团队利用人类神经内分泌细胞模型进行了实验室实验，成功证实了这一预测。在此之前，C2S-Scale 模型已经在两种不同的免疫环境中模拟了<span>&nbsp;</span>4000多种药物的作用。</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-0cc3c2e6bf.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-0cc3c2e6bf.png" medium="image"/>
    <pubDate>Thu, 16 Oct 2025 11:30:34 +0800</pubDate>
  </item><item>
    <title><![CDATA[苹果发布 M5 芯片：CPU 提升 15%、图形性能提升 30%]]></title>
    <link>https://www.oschina.net/news/377718</link>
    <itunes:title><![CDATA[苹果发布 M5 芯片：CPU 提升 15%、图形性能提升 30%]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p><span>苹果正式发布了其全新的M5处理器，这款芯片基于台积电的N3P制程工艺，配备了10核CPU和10核GPU。</span></p>
<p><span>从CPU来看，M5采用了与M4相同的10核配置，不同的是采用了6个性能核心和4个效率核心，虽然核心数量没有变化，但苹果表示M5的CPU的多线程性能相比M4提高了15%。</span></p>
<p><span>在GPU方面，M5配备了10核GPU，苹果宣称相比M4在图形性能上提高了30%，另外每个GPU内核当中都嵌入了一个神经加速器，协同工作下使得M5的计算能力是其前代产品的四倍。</span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-5f2043eca3.png"></p>
<p><span>在内存带宽方面，M5达到了153GB/s，比M4的120GB/s提高了30%，此外由于M5支持硬件加速光线追踪，苹果声称支持该功能的应用程序性能将提升高达45%。NPU方面保持了16核配置，能够在消耗最少电量的情况下提供强大的AI性能。</span></p>
<p><span>苹果表示，M5的NPU将与CPU和GPU中的神经加速器协同工作，使苹果芯片完全优化用于人工智能相关工作负载。例如使用Apple Vision Pro，用户可以在Photos应用中将2D照片转换为空间场景，或者生成一个Persona，这些操作将更加迅速和高效。</span></p>
<p><span>值得注意的是，苹果此次并未发布M5 Pro和M5 Max芯片，不过macOS Tahoe泄露的代码显示，这两款高端芯片将在稍后推出。</span></p>
<p><span>虽然苹果没有给出具体原因，但有推测称，这可能是因为M5 Pro和M5 Max采用了新的芯片设计，将CPU和GPU模块分离，从而允许用户根据工作负载进行完全定制的配置。</span></p>
<p><span>全新 Apple M5 最初将为 MacBook Pro、iPad Pro 和 Vision Pro 等新款机型提供支持。更多 Apple M5 详情，可访问&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.apple.com%2Fnewsroom%2F2025%2F10%2Fapple-unleashes-m5-the-next-big-leap-in-ai-performance-for-apple-silicon%2F" target="_blank">Apple.com</a><span>。</span></p>
<p><span>与此同时，上游 Linux 内核对 Apple Silicon 的支持仍然以老旧的 Apple M1/M2 SoC 和设备为主，其余 Asahi Linux 开发人员仍在推进 Apple M3/M4 的升级。当前Asahi Linux针对上一代Apple Silicon硬件的功能矩阵可通过&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fasahilinux.org%2Fdocs%2Fplatform%2Ffeature-support%2Foverview%2F" target="_blank">AsahiLinux.org</a><span>&nbsp;获取。</span></p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p><span>苹果正式发布了其全新的M5处理器，这款芯片基于台积电的N3P制程工艺，配备了10核CPU和10核GPU。</span></p>
<p><span>从CPU来看，M5采用了与M4相同的10核配置，不同的是采用了6个性能核心和4个效率核心，虽然核心数量没有变化，但苹果表示M5的CPU的多线程性能相比M4提高了15%。</span></p>
<p><span>在GPU方面，M5配备了10核GPU，苹果宣称相比M4在图形性能上提高了30%，另外每个GPU内核当中都嵌入了一个神经加速器，协同工作下使得M5的计算能力是其前代产品的四倍。</span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-5f2043eca3.png"></p>
<p><span>在内存带宽方面，M5达到了153GB/s，比M4的120GB/s提高了30%，此外由于M5支持硬件加速光线追踪，苹果声称支持该功能的应用程序性能将提升高达45%。NPU方面保持了16核配置，能够在消耗最少电量的情况下提供强大的AI性能。</span></p>
<p><span>苹果表示，M5的NPU将与CPU和GPU中的神经加速器协同工作，使苹果芯片完全优化用于人工智能相关工作负载。例如使用Apple Vision Pro，用户可以在Photos应用中将2D照片转换为空间场景，或者生成一个Persona，这些操作将更加迅速和高效。</span></p>
<p><span>值得注意的是，苹果此次并未发布M5 Pro和M5 Max芯片，不过macOS Tahoe泄露的代码显示，这两款高端芯片将在稍后推出。</span></p>
<p><span>虽然苹果没有给出具体原因，但有推测称，这可能是因为M5 Pro和M5 Max采用了新的芯片设计，将CPU和GPU模块分离，从而允许用户根据工作负载进行完全定制的配置。</span></p>
<p><span>全新 Apple M5 最初将为 MacBook Pro、iPad Pro 和 Vision Pro 等新款机型提供支持。更多 Apple M5 详情，可访问&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.apple.com%2Fnewsroom%2F2025%2F10%2Fapple-unleashes-m5-the-next-big-leap-in-ai-performance-for-apple-silicon%2F" target="_blank">Apple.com</a><span>。</span></p>
<p><span>与此同时，上游 Linux 内核对 Apple Silicon 的支持仍然以老旧的 Apple M1/M2 SoC 和设备为主，其余 Asahi Linux 开发人员仍在推进 Apple M3/M4 的升级。当前Asahi Linux针对上一代Apple Silicon硬件的功能矩阵可通过&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fasahilinux.org%2Fdocs%2Fplatform%2Ffeature-support%2Foverview%2F" target="_blank">AsahiLinux.org</a><span>&nbsp;获取。</span></p>]]>
    </description>
    <content:encoded><![CDATA[<p><span>苹果正式发布了其全新的M5处理器，这款芯片基于台积电的N3P制程工艺，配备了10核CPU和10核GPU。</span></p>
<p><span>从CPU来看，M5采用了与M4相同的10核配置，不同的是采用了6个性能核心和4个效率核心，虽然核心数量没有变化，但苹果表示M5的CPU的多线程性能相比M4提高了15%。</span></p>
<p><span>在GPU方面，M5配备了10核GPU，苹果宣称相比M4在图形性能上提高了30%，另外每个GPU内核当中都嵌入了一个神经加速器，协同工作下使得M5的计算能力是其前代产品的四倍。</span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-5f2043eca3.png"></p>
<p><span>在内存带宽方面，M5达到了153GB/s，比M4的120GB/s提高了30%，此外由于M5支持硬件加速光线追踪，苹果声称支持该功能的应用程序性能将提升高达45%。NPU方面保持了16核配置，能够在消耗最少电量的情况下提供强大的AI性能。</span></p>
<p><span>苹果表示，M5的NPU将与CPU和GPU中的神经加速器协同工作，使苹果芯片完全优化用于人工智能相关工作负载。例如使用Apple Vision Pro，用户可以在Photos应用中将2D照片转换为空间场景，或者生成一个Persona，这些操作将更加迅速和高效。</span></p>
<p><span>值得注意的是，苹果此次并未发布M5 Pro和M5 Max芯片，不过macOS Tahoe泄露的代码显示，这两款高端芯片将在稍后推出。</span></p>
<p><span>虽然苹果没有给出具体原因，但有推测称，这可能是因为M5 Pro和M5 Max采用了新的芯片设计，将CPU和GPU模块分离，从而允许用户根据工作负载进行完全定制的配置。</span></p>
<p><span>全新 Apple M5 最初将为 MacBook Pro、iPad Pro 和 Vision Pro 等新款机型提供支持。更多 Apple M5 详情，可访问&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.apple.com%2Fnewsroom%2F2025%2F10%2Fapple-unleashes-m5-the-next-big-leap-in-ai-performance-for-apple-silicon%2F" target="_blank">Apple.com</a><span>。</span></p>
<p><span>与此同时，上游 Linux 内核对 Apple Silicon 的支持仍然以老旧的 Apple M1/M2 SoC 和设备为主，其余 Asahi Linux 开发人员仍在推进 Apple M3/M4 的升级。当前Asahi Linux针对上一代Apple Silicon硬件的功能矩阵可通过&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fasahilinux.org%2Fdocs%2Fplatform%2Ffeature-support%2Foverview%2F" target="_blank">AsahiLinux.org</a><span>&nbsp;获取。</span></p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-5f2043eca3.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-5f2043eca3.png" medium="image"/>
    <pubDate>Thu, 16 Oct 2025 11:04:32 +0800</pubDate>
  </item><item>
    <title><![CDATA[可验证过程奖励在提升大模型推理效率中的探索与实践]]></title>
    <link>https://my.oschina.net/meituantech/blog/18694932</link>
    <itunes:title><![CDATA[可验证过程奖励在提升大模型推理效率中的探索与实践]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<blockquote>
<p>美团业务研发搜推平台部算法团队创新提出可验证过程奖励机制（VSRM），针对大模型推理中的冗余回复与过度思考问题，精准奖励有效推理步骤，显著缩减输出长度并提升推理效率。VSRM通过步骤级正确率增益评估，有效抑制无效步骤，兼容主流强化学习算法，助力高效、可靠的复杂推理任务。</p>
</blockquote>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6f0546822a.png"></p>
<h2>1 背景</h2>
<p>以 DeepSeek-R1 为代表的大规模推理模型，通过简单有效的强化学习后训练方法，培养了强大的推理能力，但却导致模型倾向于生成冗余的回复。这使得模型在为每个输入请求生成响应时，需要花费更多的时间以及计算资源，最终消磨用户的耐心。</p>
<p>针对这一缺陷，来自业务研发搜推平台部的算法团队提出可验证的过程奖励机制（VSRM），鼓励 CoT 中的"有效步骤"，惩戒"无效步骤"，最大限度保持性能的同时，实现高效推理。</p>
<p><strong>论文下载地址</strong> ：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2508.10293" target="_blank">PDF</a></p>
<p>通过在数学任务上的实验显示，在多个常用 Benchmark 上，VSRM 加持的后训练使得不同尺度的模型实现了输出长度的大幅缩减，甚至在部分情况下提升了模型表现。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-0a212a12b9.png"></p>
<h2>2 过度思考问题的本质</h2>
<p>此前的工作将过度思考问题的现象总结为：对于一个问题，模型倾向于给出多种不同的解答，特别简单的问题。在这一认识的基础上，团队更进一步，对现有 LRM 在 MATH-500 上做出的回复进行了深入的 Case Study。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-70241554d8.png"></p>
<p>如图所示，在这个例子中，模型为解决一个非常简单的子问题（[-500,0] 中有多少个小于 0 的整数）进行了反复的思考，在正确和错误之间反复横跳，最终得出了一个不正确的中间结论，进而导致了最终结论的错误。这些无效步骤不但不能指引推理路径的发展，反而会导致中间过程出错。</p>
<p>这样的案例并不孤立，甚至频繁出现。基于上述观察，我们团队提出：大量无效的中间步骤是导致模型过度思考的根本原因。因此，抑制这些无效步骤，鼓励有效步骤，是后训练的核心优化目标。</p>
<h2>3 设计可验证的逐步骤奖励</h2>
<p>现有 RLVR 的机制，通过奖励函数以可验证的二元结果奖励促进模型探索能够获得正确答案的解法。但是 <strong>结果奖励无法精确地奖惩不同的步骤</strong>，也因此无法达到所期望的目标。</p>
<p>过程奖励机制虽然能满足这一要求，但 <strong>过程奖励模型（PRM）往往难以训练且预测结果的可靠性有限</strong> ，针对数学问题/代码编程等推理任务更是 <strong>严重欠缺可解释性</strong>。</p>
<p>搜推技术团队将可验证奖励与步骤级奖励结合在一起，创造性地提出 VSRM，为推理过程中的每个中间步骤分配奖励信号，从而实现对不同步骤的鼓励和抑制，天然地契合推理任务分步作答的特点。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-f4d23828f8.png"></p>
<h3>3.1 步骤划分</h3>
<p>引入步骤级奖励的第一步是定位所有的步骤。</p>
<p>在 CoT 中，<strong>一些特殊的 Token，比如"However"、"Therefore"、"So"、"But"、"Wait"等往往表示模型已经完成了一个推理步骤，即将进行下一步推理（递进或是转折）</strong>。这些特殊 token 的存在将整个轨迹划分成了多个中间步骤。</p>
<p>为了保证划分后内容的可读性，我们额外设计了三条规则：1. 跳过最初的若干 token，这部分内容往往是对问题进行重述。2. 相邻划分点之间必须至少间隔一定距离，避免过度分割。3. 若特殊 token 位于句子内部，将划分点放在该句句首。</p>
<h3>3.2 奖励分配</h3>
<p>为了评估中间步骤有效与否，最直接的方式就是评估该步骤完成前后带来的正确率增益。而正确率是完全可以通过可验证的方式得到的。</p>
<p>只需要在每个划分点的位置前，加上一个 &lt;/think&gt; token，这样，从 query 开始，到该处的 &lt;/think&gt;，就构成了一条子轨迹。</p>
<p><strong>以每个子轨迹为 prompt，模型能够产生多个候选答案，平均正确率体现了当前步骤得到正确答案的概率。</strong></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-d6f2bee4d3.png"></p>
<p>相邻子轨迹的正确率差值，即为完成当前步骤后获得的正确率增益。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-0d05003d47.png"></p>
<p>直接将增益作为步骤级奖励就能够指导模型区分有效与无效步骤。但考虑到，往往若干个步骤才能够导致解题过程的实质性推进，因此，<strong>多个连续步骤的平均正确率很可能保持不变，进而导致稀疏的奖励信号</strong>，不利于优化。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6d71969651.png"></p>
<p>为了避免这种情况，<strong>引入前瞻窗口机制，将未来的正确率变化通过折扣因子传播给当前步，从而确保奖励信号尽量密集</strong>。</p>
<p>通过这种机制，VSRM 机制实现了为每个步骤分配可验证的，步骤级奖励信号，从而鼓励模型减少无效步骤的输出。</p>
<p>与直接施加长度惩罚不同，<strong>VSRM 直接从源头上给予模型最清晰明了的奖励信号，引导模型更多选择对提升最终正确率有帮助的步骤，在缓解过度思考问题的同时，最大限度地保留模型性能</strong>。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-080a3621a8.png"></p>
<p>VSRM 机制本身与 <strong>强化学习算法解耦，能够天然地适配支持过程奖励的方法</strong>，只需将逐步奖励添加到最终的 Reward Tensor 即可，搭配常用的结果二元结果奖励和格式奖励，即可无缝实现高效推理。</p>
<h2>4 实验</h2>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-69816d2230.png"></p>
<p>在数学问题最常用的 Benchmark 上，使用三个不同 Base Model，两种 RL 算法，将 VSRM 与多种最新的相关工作进行对比，实验结果展现出 VSRM 在降低输出长度的同时，能够最大限度地保持性能，取得很好的均衡。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-896a2f7e2c.png"></p>
<p>消融实验的结果显示了 VSRM 中，前瞻窗口机制的有效性，以及，额外的显式长度惩罚对于 VSRM 机制并无帮助。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-2df156c920.png"></p>
<p>在困难 Benchmark 上，随着 k 的增加，Pass<a href="https://my.oschina.net/kaiprince">@k</a> 指标的提升趋势能够反馈模型探索更多可行解的能力。可以看到 VSRM-PPO 训练后的模型，体现了与原本模型一致的趋势，说明模型并没有因为输出长度的压缩而失去了最重要的探索能力。</p>
<h2>5 总结</h2>
<p>通过广泛的对比实验，我们证明了可验证的过程奖励在不同 RL 算法，不同 Base Model 的设置下，均能实现保持性能的同时，极大缓解过度思考问题。消融实验以及进一步的实证分析也展示出，可验证的过程奖励，真正起到了抑制无效步骤，鼓励有效步骤的作用，是从根本上解决过度思考问题，保持模型良好推理行为的有效途径。</p>
<p>| 关注「美团技术团队」微信公众号，在公众号菜单栏对话框回复【2024年货】、【2023年货】、【2022年货】、【2021年货】、【2020年货】、【2019年货】、【2018年货】、【2017年货】等关键词，可查看美团技术团队历年技术文章合集。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-483971fcc8.png"></p>
<p>| 本文系美团技术团队出品，著作权归属美团。欢迎出于分享和交流等非商业目的转载或使用本文内容，敬请注明"内容转载自美团技术团队"。本文未经许可，不得进行商业性转载或者使用。任何商用行为，请发送邮件至 <a href="https://www.oschina.net/action/GoToLink?url=mailto%3Atech%40meituan.com" target="_blank">tech@meituan.com</a> 申请授权。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<blockquote>
<p>美团业务研发搜推平台部算法团队创新提出可验证过程奖励机制（VSRM），针对大模型推理中的冗余回复与过度思考问题，精准奖励有效推理步骤，显著缩减输出长度并提升推理效率。VSRM通过步骤级正确率增益评估，有效抑制无效步骤，兼容主流强化学习算法，助力高效、可靠的复杂推理任务。</p>
</blockquote>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6f0546822a.png"></p>
<h2>1 背景</h2>
<p>以 DeepSeek-R1 为代表的大规模推理模型，通过简单有效的强化学习后训练方法，培养了强大的推理能力，但却导致模型倾向于生成冗余的回复。这使得模型在为每个输入请求生成响应时，需要花费更多的时间以及计算资源，最终消磨用户的耐心。</p>
<p>针对这一缺陷，来自业务研发搜推平台部的算法团队提出可验证的过程奖励机制（VSRM），鼓励 CoT 中的"有效步骤"，惩戒"无效步骤"，最大限度保持性能的同时，实现高效推理。</p>
<p><strong>论文下载地址</strong> ：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2508.10293" target="_blank">PDF</a></p>
<p>通过在数学任务上的实验显示，在多个常用 Benchmark 上，VSRM 加持的后训练使得不同尺度的模型实现了输出长度的大幅缩减，甚至在部分情况下提升了模型表现。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-0a212a12b9.png"></p>
<h2>2 过度思考问题的本质</h2>
<p>此前的工作将过度思考问题的现象总结为：对于一个问题，模型倾向于给出多种不同的解答，特别简单的问题。在这一认识的基础上，团队更进一步，对现有 LRM 在 MATH-500 上做出的回复进行了深入的 Case Study。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-70241554d8.png"></p>
<p>如图所示，在这个例子中，模型为解决一个非常简单的子问题（[-500,0] 中有多少个小于 0 的整数）进行了反复的思考，在正确和错误之间反复横跳，最终得出了一个不正确的中间结论，进而导致了最终结论的错误。这些无效步骤不但不能指引推理路径的发展，反而会导致中间过程出错。</p>
<p>这样的案例并不孤立，甚至频繁出现。基于上述观察，我们团队提出：大量无效的中间步骤是导致模型过度思考的根本原因。因此，抑制这些无效步骤，鼓励有效步骤，是后训练的核心优化目标。</p>
<h2>3 设计可验证的逐步骤奖励</h2>
<p>现有 RLVR 的机制，通过奖励函数以可验证的二元结果奖励促进模型探索能够获得正确答案的解法。但是 <strong>结果奖励无法精确地奖惩不同的步骤</strong>，也因此无法达到所期望的目标。</p>
<p>过程奖励机制虽然能满足这一要求，但 <strong>过程奖励模型（PRM）往往难以训练且预测结果的可靠性有限</strong> ，针对数学问题/代码编程等推理任务更是 <strong>严重欠缺可解释性</strong>。</p>
<p>搜推技术团队将可验证奖励与步骤级奖励结合在一起，创造性地提出 VSRM，为推理过程中的每个中间步骤分配奖励信号，从而实现对不同步骤的鼓励和抑制，天然地契合推理任务分步作答的特点。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-f4d23828f8.png"></p>
<h3>3.1 步骤划分</h3>
<p>引入步骤级奖励的第一步是定位所有的步骤。</p>
<p>在 CoT 中，<strong>一些特殊的 Token，比如"However"、"Therefore"、"So"、"But"、"Wait"等往往表示模型已经完成了一个推理步骤，即将进行下一步推理（递进或是转折）</strong>。这些特殊 token 的存在将整个轨迹划分成了多个中间步骤。</p>
<p>为了保证划分后内容的可读性，我们额外设计了三条规则：1. 跳过最初的若干 token，这部分内容往往是对问题进行重述。2. 相邻划分点之间必须至少间隔一定距离，避免过度分割。3. 若特殊 token 位于句子内部，将划分点放在该句句首。</p>
<h3>3.2 奖励分配</h3>
<p>为了评估中间步骤有效与否，最直接的方式就是评估该步骤完成前后带来的正确率增益。而正确率是完全可以通过可验证的方式得到的。</p>
<p>只需要在每个划分点的位置前，加上一个 &lt;/think&gt; token，这样，从 query 开始，到该处的 &lt;/think&gt;，就构成了一条子轨迹。</p>
<p><strong>以每个子轨迹为 prompt，模型能够产生多个候选答案，平均正确率体现了当前步骤得到正确答案的概率。</strong></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-d6f2bee4d3.png"></p>
<p>相邻子轨迹的正确率差值，即为完成当前步骤后获得的正确率增益。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-0d05003d47.png"></p>
<p>直接将增益作为步骤级奖励就能够指导模型区分有效与无效步骤。但考虑到，往往若干个步骤才能够导致解题过程的实质性推进，因此，<strong>多个连续步骤的平均正确率很可能保持不变，进而导致稀疏的奖励信号</strong>，不利于优化。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6d71969651.png"></p>
<p>为了避免这种情况，<strong>引入前瞻窗口机制，将未来的正确率变化通过折扣因子传播给当前步，从而确保奖励信号尽量密集</strong>。</p>
<p>通过这种机制，VSRM 机制实现了为每个步骤分配可验证的，步骤级奖励信号，从而鼓励模型减少无效步骤的输出。</p>
<p>与直接施加长度惩罚不同，<strong>VSRM 直接从源头上给予模型最清晰明了的奖励信号，引导模型更多选择对提升最终正确率有帮助的步骤，在缓解过度思考问题的同时，最大限度地保留模型性能</strong>。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-080a3621a8.png"></p>
<p>VSRM 机制本身与 <strong>强化学习算法解耦，能够天然地适配支持过程奖励的方法</strong>，只需将逐步奖励添加到最终的 Reward Tensor 即可，搭配常用的结果二元结果奖励和格式奖励，即可无缝实现高效推理。</p>
<h2>4 实验</h2>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-69816d2230.png"></p>
<p>在数学问题最常用的 Benchmark 上，使用三个不同 Base Model，两种 RL 算法，将 VSRM 与多种最新的相关工作进行对比，实验结果展现出 VSRM 在降低输出长度的同时，能够最大限度地保持性能，取得很好的均衡。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-896a2f7e2c.png"></p>
<p>消融实验的结果显示了 VSRM 中，前瞻窗口机制的有效性，以及，额外的显式长度惩罚对于 VSRM 机制并无帮助。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-2df156c920.png"></p>
<p>在困难 Benchmark 上，随着 k 的增加，Pass<a href="https://my.oschina.net/kaiprince">@k</a> 指标的提升趋势能够反馈模型探索更多可行解的能力。可以看到 VSRM-PPO 训练后的模型，体现了与原本模型一致的趋势，说明模型并没有因为输出长度的压缩而失去了最重要的探索能力。</p>
<h2>5 总结</h2>
<p>通过广泛的对比实验，我们证明了可验证的过程奖励在不同 RL 算法，不同 Base Model 的设置下，均能实现保持性能的同时，极大缓解过度思考问题。消融实验以及进一步的实证分析也展示出，可验证的过程奖励，真正起到了抑制无效步骤，鼓励有效步骤的作用，是从根本上解决过度思考问题，保持模型良好推理行为的有效途径。</p>
<p>| 关注「美团技术团队」微信公众号，在公众号菜单栏对话框回复【2024年货】、【2023年货】、【2022年货】、【2021年货】、【2020年货】、【2019年货】、【2018年货】、【2017年货】等关键词，可查看美团技术团队历年技术文章合集。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-483971fcc8.png"></p>
<p>| 本文系美团技术团队出品，著作权归属美团。欢迎出于分享和交流等非商业目的转载或使用本文内容，敬请注明"内容转载自美团技术团队"。本文未经许可，不得进行商业性转载或者使用。任何商用行为，请发送邮件至 <a href="https://www.oschina.net/action/GoToLink?url=mailto%3Atech%40meituan.com" target="_blank">tech@meituan.com</a> 申请授权。</p>]]>
    </description>
    <content:encoded><![CDATA[<blockquote>
<p>美团业务研发搜推平台部算法团队创新提出可验证过程奖励机制（VSRM），针对大模型推理中的冗余回复与过度思考问题，精准奖励有效推理步骤，显著缩减输出长度并提升推理效率。VSRM通过步骤级正确率增益评估，有效抑制无效步骤，兼容主流强化学习算法，助力高效、可靠的复杂推理任务。</p>
</blockquote>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6f0546822a.png"></p>
<h2>1 背景</h2>
<p>以 DeepSeek-R1 为代表的大规模推理模型，通过简单有效的强化学习后训练方法，培养了强大的推理能力，但却导致模型倾向于生成冗余的回复。这使得模型在为每个输入请求生成响应时，需要花费更多的时间以及计算资源，最终消磨用户的耐心。</p>
<p>针对这一缺陷，来自业务研发搜推平台部的算法团队提出可验证的过程奖励机制（VSRM），鼓励 CoT 中的"有效步骤"，惩戒"无效步骤"，最大限度保持性能的同时，实现高效推理。</p>
<p><strong>论文下载地址</strong> ：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2508.10293" target="_blank">PDF</a></p>
<p>通过在数学任务上的实验显示，在多个常用 Benchmark 上，VSRM 加持的后训练使得不同尺度的模型实现了输出长度的大幅缩减，甚至在部分情况下提升了模型表现。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-0a212a12b9.png"></p>
<h2>2 过度思考问题的本质</h2>
<p>此前的工作将过度思考问题的现象总结为：对于一个问题，模型倾向于给出多种不同的解答，特别简单的问题。在这一认识的基础上，团队更进一步，对现有 LRM 在 MATH-500 上做出的回复进行了深入的 Case Study。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-70241554d8.png"></p>
<p>如图所示，在这个例子中，模型为解决一个非常简单的子问题（[-500,0] 中有多少个小于 0 的整数）进行了反复的思考，在正确和错误之间反复横跳，最终得出了一个不正确的中间结论，进而导致了最终结论的错误。这些无效步骤不但不能指引推理路径的发展，反而会导致中间过程出错。</p>
<p>这样的案例并不孤立，甚至频繁出现。基于上述观察，我们团队提出：大量无效的中间步骤是导致模型过度思考的根本原因。因此，抑制这些无效步骤，鼓励有效步骤，是后训练的核心优化目标。</p>
<h2>3 设计可验证的逐步骤奖励</h2>
<p>现有 RLVR 的机制，通过奖励函数以可验证的二元结果奖励促进模型探索能够获得正确答案的解法。但是 <strong>结果奖励无法精确地奖惩不同的步骤</strong>，也因此无法达到所期望的目标。</p>
<p>过程奖励机制虽然能满足这一要求，但 <strong>过程奖励模型（PRM）往往难以训练且预测结果的可靠性有限</strong> ，针对数学问题/代码编程等推理任务更是 <strong>严重欠缺可解释性</strong>。</p>
<p>搜推技术团队将可验证奖励与步骤级奖励结合在一起，创造性地提出 VSRM，为推理过程中的每个中间步骤分配奖励信号，从而实现对不同步骤的鼓励和抑制，天然地契合推理任务分步作答的特点。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-f4d23828f8.png"></p>
<h3>3.1 步骤划分</h3>
<p>引入步骤级奖励的第一步是定位所有的步骤。</p>
<p>在 CoT 中，<strong>一些特殊的 Token，比如"However"、"Therefore"、"So"、"But"、"Wait"等往往表示模型已经完成了一个推理步骤，即将进行下一步推理（递进或是转折）</strong>。这些特殊 token 的存在将整个轨迹划分成了多个中间步骤。</p>
<p>为了保证划分后内容的可读性，我们额外设计了三条规则：1. 跳过最初的若干 token，这部分内容往往是对问题进行重述。2. 相邻划分点之间必须至少间隔一定距离，避免过度分割。3. 若特殊 token 位于句子内部，将划分点放在该句句首。</p>
<h3>3.2 奖励分配</h3>
<p>为了评估中间步骤有效与否，最直接的方式就是评估该步骤完成前后带来的正确率增益。而正确率是完全可以通过可验证的方式得到的。</p>
<p>只需要在每个划分点的位置前，加上一个 &lt;/think&gt; token，这样，从 query 开始，到该处的 &lt;/think&gt;，就构成了一条子轨迹。</p>
<p><strong>以每个子轨迹为 prompt，模型能够产生多个候选答案，平均正确率体现了当前步骤得到正确答案的概率。</strong></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-d6f2bee4d3.png"></p>
<p>相邻子轨迹的正确率差值，即为完成当前步骤后获得的正确率增益。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-0d05003d47.png"></p>
<p>直接将增益作为步骤级奖励就能够指导模型区分有效与无效步骤。但考虑到，往往若干个步骤才能够导致解题过程的实质性推进，因此，<strong>多个连续步骤的平均正确率很可能保持不变，进而导致稀疏的奖励信号</strong>，不利于优化。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6d71969651.png"></p>
<p>为了避免这种情况，<strong>引入前瞻窗口机制，将未来的正确率变化通过折扣因子传播给当前步，从而确保奖励信号尽量密集</strong>。</p>
<p>通过这种机制，VSRM 机制实现了为每个步骤分配可验证的，步骤级奖励信号，从而鼓励模型减少无效步骤的输出。</p>
<p>与直接施加长度惩罚不同，<strong>VSRM 直接从源头上给予模型最清晰明了的奖励信号，引导模型更多选择对提升最终正确率有帮助的步骤，在缓解过度思考问题的同时，最大限度地保留模型性能</strong>。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-080a3621a8.png"></p>
<p>VSRM 机制本身与 <strong>强化学习算法解耦，能够天然地适配支持过程奖励的方法</strong>，只需将逐步奖励添加到最终的 Reward Tensor 即可，搭配常用的结果二元结果奖励和格式奖励，即可无缝实现高效推理。</p>
<h2>4 实验</h2>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-69816d2230.png"></p>
<p>在数学问题最常用的 Benchmark 上，使用三个不同 Base Model，两种 RL 算法，将 VSRM 与多种最新的相关工作进行对比，实验结果展现出 VSRM 在降低输出长度的同时，能够最大限度地保持性能，取得很好的均衡。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-896a2f7e2c.png"></p>
<p>消融实验的结果显示了 VSRM 中，前瞻窗口机制的有效性，以及，额外的显式长度惩罚对于 VSRM 机制并无帮助。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-2df156c920.png"></p>
<p>在困难 Benchmark 上，随着 k 的增加，Pass<a href="https://my.oschina.net/kaiprince">@k</a> 指标的提升趋势能够反馈模型探索更多可行解的能力。可以看到 VSRM-PPO 训练后的模型，体现了与原本模型一致的趋势，说明模型并没有因为输出长度的压缩而失去了最重要的探索能力。</p>
<h2>5 总结</h2>
<p>通过广泛的对比实验，我们证明了可验证的过程奖励在不同 RL 算法，不同 Base Model 的设置下，均能实现保持性能的同时，极大缓解过度思考问题。消融实验以及进一步的实证分析也展示出，可验证的过程奖励，真正起到了抑制无效步骤，鼓励有效步骤的作用，是从根本上解决过度思考问题，保持模型良好推理行为的有效途径。</p>
<p>| 关注「美团技术团队」微信公众号，在公众号菜单栏对话框回复【2024年货】、【2023年货】、【2022年货】、【2021年货】、【2020年货】、【2019年货】、【2018年货】、【2017年货】等关键词，可查看美团技术团队历年技术文章合集。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-483971fcc8.png"></p>
<p>| 本文系美团技术团队出品，著作权归属美团。欢迎出于分享和交流等非商业目的转载或使用本文内容，敬请注明"内容转载自美团技术团队"。本文未经许可，不得进行商业性转载或者使用。任何商用行为，请发送邮件至 <a href="https://www.oschina.net/action/GoToLink?url=mailto%3Atech%40meituan.com" target="_blank">tech@meituan.com</a> 申请授权。</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6f0546822a.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6f0546822a.png" medium="image"/>
    <pubDate>Thu, 16 Oct 2025 10:57:26 +0800</pubDate>
  </item><item>
    <title><![CDATA[全球首个真实物理环境多任务基准 RoboChallenge 发布]]></title>
    <link>https://www.oschina.net/news/377709</link>
    <itunes:title><![CDATA[全球首个真实物理环境多任务基准 RoboChallenge 发布]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>全球首个大规模、多任务的在真实物理环境中由真实机器人执行操作任务的基准测试平台&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frobochallenge.ai%2Fhome" target="_blank">RoboChallenge </a>基准测试平台于近日正式发布。</p>
<p>“<span>我们正在构建一个真实世界的机器人测试和评估平台。在这里，研究人员和开发人员可以在统一的环境中验证和比较他们的机器人策略——涵盖从基本任务到复杂的真实场景。</span>”</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-2c1bd9fdb7.png"></p>
<p>RoboChallenge 由 Dexmal 原力灵机联合 Hugging Face 共同发起。该测试平台的核心价值在于克服了现有机器人基准测试在真实环境下的性能验证、标准化测试条件和公开可访问测试平台等方面的挑战。</p>
<p>优点：</p>
<ul>
<li><span><strong>多样化任务：</strong>从物体操纵和场景交互到长期规划，涵盖机器人智能的多个维度。</span></li>
<li><span><strong>多机器人：</strong>支持各种机器人形态，包括移动机器人和双手机器人。</span></li>
<li><span><strong>公开公正：</strong>所有结果及排名均在平台上透明展示，确保公平可信。</span></li>
</ul>
<p><span>该基准测试将为视觉语言动作模型（VLAs）在机器人中的实际应用提供更加可靠和可比较的评估标准，从而加速 VLA 模型从模拟环境走向实际物理世界的部署和验证进程。</span></p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>全球首个大规模、多任务的在真实物理环境中由真实机器人执行操作任务的基准测试平台&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frobochallenge.ai%2Fhome" target="_blank">RoboChallenge </a>基准测试平台于近日正式发布。</p>
<p>“<span>我们正在构建一个真实世界的机器人测试和评估平台。在这里，研究人员和开发人员可以在统一的环境中验证和比较他们的机器人策略——涵盖从基本任务到复杂的真实场景。</span>”</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-2c1bd9fdb7.png"></p>
<p>RoboChallenge 由 Dexmal 原力灵机联合 Hugging Face 共同发起。该测试平台的核心价值在于克服了现有机器人基准测试在真实环境下的性能验证、标准化测试条件和公开可访问测试平台等方面的挑战。</p>
<p>优点：</p>
<ul>
<li><span><strong>多样化任务：</strong>从物体操纵和场景交互到长期规划，涵盖机器人智能的多个维度。</span></li>
<li><span><strong>多机器人：</strong>支持各种机器人形态，包括移动机器人和双手机器人。</span></li>
<li><span><strong>公开公正：</strong>所有结果及排名均在平台上透明展示，确保公平可信。</span></li>
</ul>
<p><span>该基准测试将为视觉语言动作模型（VLAs）在机器人中的实际应用提供更加可靠和可比较的评估标准，从而加速 VLA 模型从模拟环境走向实际物理世界的部署和验证进程。</span></p>]]>
    </description>
    <content:encoded><![CDATA[<p>全球首个大规模、多任务的在真实物理环境中由真实机器人执行操作任务的基准测试平台&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frobochallenge.ai%2Fhome" target="_blank">RoboChallenge </a>基准测试平台于近日正式发布。</p>
<p>“<span>我们正在构建一个真实世界的机器人测试和评估平台。在这里，研究人员和开发人员可以在统一的环境中验证和比较他们的机器人策略——涵盖从基本任务到复杂的真实场景。</span>”</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-2c1bd9fdb7.png"></p>
<p>RoboChallenge 由 Dexmal 原力灵机联合 Hugging Face 共同发起。该测试平台的核心价值在于克服了现有机器人基准测试在真实环境下的性能验证、标准化测试条件和公开可访问测试平台等方面的挑战。</p>
<p>优点：</p>
<ul>
<li><span><strong>多样化任务：</strong>从物体操纵和场景交互到长期规划，涵盖机器人智能的多个维度。</span></li>
<li><span><strong>多机器人：</strong>支持各种机器人形态，包括移动机器人和双手机器人。</span></li>
<li><span><strong>公开公正：</strong>所有结果及排名均在平台上透明展示，确保公平可信。</span></li>
</ul>
<p><span>该基准测试将为视觉语言动作模型（VLAs）在机器人中的实际应用提供更加可靠和可比较的评估标准，从而加速 VLA 模型从模拟环境走向实际物理世界的部署和验证进程。</span></p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-2c1bd9fdb7.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-2c1bd9fdb7.png" medium="image"/>
    <pubDate>Thu, 16 Oct 2025 10:20:09 +0800</pubDate>
  </item><item>
    <title><![CDATA[Anthropic 发布 Claude Haiku 4.5，速度更快、价格更便宜]]></title>
    <link>https://www.oschina.net/news/377708</link>
    <itunes:title><![CDATA[Anthropic 发布 Claude Haiku 4.5，速度更快、价格更便宜]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>Anthropic 发布了新模型 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.anthropic.com%2Fnews%2Fclaude-haiku-4-5" target="_blank">Claude Haiku 4.5</a>。官方表示该模型以极低的成本提供了接近前沿模型的强大性能，目标成为实时、低延迟任务（如聊天助手和客户服务）的理想选择。</p>
<p>Claude 家族有三个不同参数量级的模型：Claude Opus（大杯）、Sonnet（中杯）和 Haiku（小杯）。 &nbsp;这次更新最大的看点是，小杯 Claude Haiku 4.5 在模型性能保持高水准的同时，速度更快、价格更便宜了。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-3024674639.png"></p>
<p>在应用场景方面，Anthropic 表示，Haiku 4.5 能够完美结合高智能与惊人的处理速度，满足用户对即时反馈的需求，专门针对实时聊天助手、在线客户服务代理以及辅助编程工具等需要高响应速度的应用场景设计。</p>
<p>在性能方面，Claude Haiku 4.5 编码性能与 Sonnet 4 基本持平，但在成本上仅为后者的三分之一，处理速度则提升了超过两倍。据介绍，在衡量编程能力的权威基准测试 SWE-bench Verified 中，Haiku 4.5 取得了 73.3% 的高分，略微领先于 Sonnet 4 的 72.7%。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-bc2d077478.png"></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-3a18c83fe6.png"></p>
<p>价格方面，Haiku 4.5 定价为：每百万输入 token 1 美元，每百万输出 token 5 美元。</p>
<p>对比来看，GPT-5 mini 约为每百万输入 0.25 美元、输出 2.5 美元，Google 的 Gemini 2.5 Flash 价格差不多。也就是说，Haiku 4.5 的价格大约是 GPT-5 mini 或 Flash 的 4 倍。 不过跟 Sonnet 4.5 比，它便宜了约三倍，性能却几乎没差，这对开发者来说算是降本增效了。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>Anthropic 发布了新模型 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.anthropic.com%2Fnews%2Fclaude-haiku-4-5" target="_blank">Claude Haiku 4.5</a>。官方表示该模型以极低的成本提供了接近前沿模型的强大性能，目标成为实时、低延迟任务（如聊天助手和客户服务）的理想选择。</p>
<p>Claude 家族有三个不同参数量级的模型：Claude Opus（大杯）、Sonnet（中杯）和 Haiku（小杯）。 &nbsp;这次更新最大的看点是，小杯 Claude Haiku 4.5 在模型性能保持高水准的同时，速度更快、价格更便宜了。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-3024674639.png"></p>
<p>在应用场景方面，Anthropic 表示，Haiku 4.5 能够完美结合高智能与惊人的处理速度，满足用户对即时反馈的需求，专门针对实时聊天助手、在线客户服务代理以及辅助编程工具等需要高响应速度的应用场景设计。</p>
<p>在性能方面，Claude Haiku 4.5 编码性能与 Sonnet 4 基本持平，但在成本上仅为后者的三分之一，处理速度则提升了超过两倍。据介绍，在衡量编程能力的权威基准测试 SWE-bench Verified 中，Haiku 4.5 取得了 73.3% 的高分，略微领先于 Sonnet 4 的 72.7%。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-bc2d077478.png"></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-3a18c83fe6.png"></p>
<p>价格方面，Haiku 4.5 定价为：每百万输入 token 1 美元，每百万输出 token 5 美元。</p>
<p>对比来看，GPT-5 mini 约为每百万输入 0.25 美元、输出 2.5 美元，Google 的 Gemini 2.5 Flash 价格差不多。也就是说，Haiku 4.5 的价格大约是 GPT-5 mini 或 Flash 的 4 倍。 不过跟 Sonnet 4.5 比，它便宜了约三倍，性能却几乎没差，这对开发者来说算是降本增效了。</p>]]>
    </description>
    <content:encoded><![CDATA[<p>Anthropic 发布了新模型 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.anthropic.com%2Fnews%2Fclaude-haiku-4-5" target="_blank">Claude Haiku 4.5</a>。官方表示该模型以极低的成本提供了接近前沿模型的强大性能，目标成为实时、低延迟任务（如聊天助手和客户服务）的理想选择。</p>
<p>Claude 家族有三个不同参数量级的模型：Claude Opus（大杯）、Sonnet（中杯）和 Haiku（小杯）。 &nbsp;这次更新最大的看点是，小杯 Claude Haiku 4.5 在模型性能保持高水准的同时，速度更快、价格更便宜了。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-3024674639.png"></p>
<p>在应用场景方面，Anthropic 表示，Haiku 4.5 能够完美结合高智能与惊人的处理速度，满足用户对即时反馈的需求，专门针对实时聊天助手、在线客户服务代理以及辅助编程工具等需要高响应速度的应用场景设计。</p>
<p>在性能方面，Claude Haiku 4.5 编码性能与 Sonnet 4 基本持平，但在成本上仅为后者的三分之一，处理速度则提升了超过两倍。据介绍，在衡量编程能力的权威基准测试 SWE-bench Verified 中，Haiku 4.5 取得了 73.3% 的高分，略微领先于 Sonnet 4 的 72.7%。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-bc2d077478.png"></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-3a18c83fe6.png"></p>
<p>价格方面，Haiku 4.5 定价为：每百万输入 token 1 美元，每百万输出 token 5 美元。</p>
<p>对比来看，GPT-5 mini 约为每百万输入 0.25 美元、输出 2.5 美元，Google 的 Gemini 2.5 Flash 价格差不多。也就是说，Haiku 4.5 的价格大约是 GPT-5 mini 或 Flash 的 4 倍。 不过跟 Sonnet 4.5 比，它便宜了约三倍，性能却几乎没差，这对开发者来说算是降本增效了。</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-3024674639.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-3024674639.png" medium="image"/>
    <pubDate>Thu, 16 Oct 2025 10:16:12 +0800</pubDate>
  </item><item>
    <title><![CDATA[北京查处首例 AI 虚假广告案：AI 冒充知名主持人卖鱼油]]></title>
    <link>https://www.oschina.net/news/377706</link>
    <itunes:title><![CDATA[北京查处首例 AI 虚假广告案：AI 冒充知名主持人卖鱼油]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p><span>北京市场监管局近日<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F_oQ9c2iulDU9tVMyzYWCBw" target="_blank">通报</a>了一起利用 AI 技术发布虚假广告的案件。</span></p>
<p><span>2025 年 6 月，北京市海淀区市场监管局查处了某公司利用AI技术冒用央视知名主持人名义和形象的虚假广告案。该公司通过AI技术剪辑知名主持人视频，加入自行设计的口播内容，在自有网络视频账号上以短视频等形式发布普通食品“深海多烯鱼油”广告，宣称“可以解决头晕头痛、手麻脚麻、四肢乏力”等医疗功效，违反了《中华人民共和国广告法》相关规定，已接受行政处罚。</span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-92ce770041.png"></p>
<p><span>北京市市场监管局提醒消费者，</span><span>主持人、网红等公众人物，社会认知度高，一些不法经营者利用AI技术等方式伪造图片、音视频开展虚假宣传，借助公众人物知名度，推销商品服务获利，侵犯了消费者合法权益。</span><span>消费者</span><span>若发现疑似违法行为，可留存证据材料，拨打12315、12345热线向市场监管部门举报。</span></p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p><span>北京市场监管局近日<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F_oQ9c2iulDU9tVMyzYWCBw" target="_blank">通报</a>了一起利用 AI 技术发布虚假广告的案件。</span></p>
<p><span>2025 年 6 月，北京市海淀区市场监管局查处了某公司利用AI技术冒用央视知名主持人名义和形象的虚假广告案。该公司通过AI技术剪辑知名主持人视频，加入自行设计的口播内容，在自有网络视频账号上以短视频等形式发布普通食品“深海多烯鱼油”广告，宣称“可以解决头晕头痛、手麻脚麻、四肢乏力”等医疗功效，违反了《中华人民共和国广告法》相关规定，已接受行政处罚。</span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-92ce770041.png"></p>
<p><span>北京市市场监管局提醒消费者，</span><span>主持人、网红等公众人物，社会认知度高，一些不法经营者利用AI技术等方式伪造图片、音视频开展虚假宣传，借助公众人物知名度，推销商品服务获利，侵犯了消费者合法权益。</span><span>消费者</span><span>若发现疑似违法行为，可留存证据材料，拨打12315、12345热线向市场监管部门举报。</span></p>]]>
    </description>
    <content:encoded><![CDATA[<p><span>北京市场监管局近日<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F_oQ9c2iulDU9tVMyzYWCBw" target="_blank">通报</a>了一起利用 AI 技术发布虚假广告的案件。</span></p>
<p><span>2025 年 6 月，北京市海淀区市场监管局查处了某公司利用AI技术冒用央视知名主持人名义和形象的虚假广告案。该公司通过AI技术剪辑知名主持人视频，加入自行设计的口播内容，在自有网络视频账号上以短视频等形式发布普通食品“深海多烯鱼油”广告，宣称“可以解决头晕头痛、手麻脚麻、四肢乏力”等医疗功效，违反了《中华人民共和国广告法》相关规定，已接受行政处罚。</span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-92ce770041.png"></p>
<p><span>北京市市场监管局提醒消费者，</span><span>主持人、网红等公众人物，社会认知度高，一些不法经营者利用AI技术等方式伪造图片、音视频开展虚假宣传，借助公众人物知名度，推销商品服务获利，侵犯了消费者合法权益。</span><span>消费者</span><span>若发现疑似违法行为，可留存证据材料，拨打12315、12345热线向市场监管部门举报。</span></p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-92ce770041.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-92ce770041.png" medium="image"/>
    <pubDate>Thu, 16 Oct 2025 10:07:40 +0800</pubDate>
  </item><item>
    <title><![CDATA[ONLYOFFICE 文档 9.1 版本已发布：功能更强大的 PDF 编辑器，支持密文功能等多项优化]]></title>
    <link>https://www.oschina.net/news/377623/onlyoffice-9-1-released</link>
    <itunes:title><![CDATA[ONLYOFFICE 文档 9.1 版本已发布：功能更强大的 PDF 编辑器，支持密文功能等多项优化]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>ONLYOFFICE 文档最新更新现已发布，带来10多项新功能、一系列性能改进以及 500 多项修复。阅读本文，了解详情。</p>
<p><img alt="ONLYOFFICE 文档 9.1 版本已发布：功能更强大的 PDF 编辑器，支持密文功能、全新注释、公式运算提速等多项优化" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static-blog.onlyoffice.com-74ffd4bb8c.png"></p>
<h2>关于 ONLYOFFICE 文档</h2>
<p>ONLYOFFICE 是一个<strong>开源项目</strong>，专注于高级和安全的文档处理，是在线办公解决方案的提供者，全球用户已超过1500万。</p>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Foffice-suite" target="_blank">ONLYOFFICE 办公套件</a>提供<strong>文本文档、电子表格、幻灯片、表单和 PDF 编辑器</strong>。ONLYOFFICE 文档高度兼容 MS Office 格式，并提供数百种格式化和样式工具，以及多种协作功能。在智能办公方面，它深度集成了 <strong>AI 插件</strong>功能，用户可在编辑器内直接调用任意 AI 模型（如 DeepSeek、ChatGPT、通义千问、Kimi 等），无需在不同网页或应用间反复切换。</p>
<p>该办公套件可以提供<strong>50多种现成的连接器</strong>，轻松将在线编辑器连接至您使用的平台，如： Nextcloud、Moodle、Confluence、WordPress、Odoo 等。其开发者版本还<strong>支持二次开发</strong>，快速嵌入您自有的平台、网页和系统，满足您的个性化需求。</p>
<p>ONLYOFFICE 支持在任何平台上部署，包括 <strong>Windows、Linux、macOS、Android</strong>，也可以在任何设备上使用。在线、移动和桌面版本均使用同一引擎，确保离线和在线工作之间无缝切换。</p>
<h2>优化的 PDF 编辑器</h2>
<p>我们的&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Fpdf-editor.aspx%3Futm_source%3Dblog%26utm_medium%3Dsocial%26utm_campaign%3Ddocs_9.1" target="_blank">PDF 编辑器</a>已进行多项强大升级，旨在优化您的文档工作流程。</p>
<p><strong>密文</strong><strong>：</strong>需要隐藏 PDF 中的敏感或机密信息吗？现在操作更加简便。</p>
<p>要隐藏敏感信息，请在<strong>编辑</strong>模式下打开文件，然后切换到新增的<strong>“密文”</strong>选项卡。点击<strong>“标记</strong><strong>密文</strong><strong>”</strong>按钮，并突出显示要删除的文本。对于很长的文档，您可以使用<strong>“查找</strong><strong>密文</strong><strong>”</strong>功能快速定位并选择特定词语或短语。此功能还支持隐藏整个页面或指定页面范围内的内容。</p>
<p>准备就绪后，点击<strong>“应用</strong><strong>密文</strong><strong>”</strong>按钮，即可永久删除文件中选定的信息。</p>
<p>路径：密文选项卡</p>
<h2><img alt="ONLYOFFICE 文档 9.1 版本已发布：功能更强大的 PDF 编辑器，支持密文功能、全新注释、公式运算提速等多项优化" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static-blog.onlyoffice.com-97fe101c10.png"></h2>
<p><strong>全新</strong><strong>注释</strong><strong>工具</strong><strong>：</strong>新工具提供更高的灵活性，以提升您的 PDF 编辑体验。您可以选择<strong>矩形</strong>、<strong>圆形</strong>、<strong>箭头</strong>或<strong>连接线</strong>等形状直接在文档上进行批注，也可以根据需要自定义注释的颜色和大小。</p>
<p>路径：批注选项卡</p>
<p><img alt="ONLYOFFICE 文档 9.1 版本已发布：功能更强大的 PDF 编辑器，支持密文功能、全新注释、公式运算提速等多项优化" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static-blog.onlyoffice.com-e5bcfbbd7a.png"></p>
<p><strong>添加图表和</strong><strong>智能图形</strong><strong>：</strong>通过添加图表来优化您的 PDF 文件，以直观地呈现数据、突出关键信息，并增强文档的吸引力。现在您还可以在 PDF 中使用智能图形，轻松查看和交互，更便捷地在 PDF 文件中管理丰富的视觉内容。</p>
<p>路径：插入选项卡</p>
<p><img alt="ONLYOFFICE 文档 9.1 版本已发布：功能更强大的 PDF 编辑器，支持密文功能、全新注释、公式运算提速等多项优化" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static-blog.onlyoffice.com-7135215e4c.png"></p>
<h2>强大的电子表格编辑器更新</h2>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Fspreadsheet-editor.aspx%3Futm_source%3Dblog%26utm_medium%3Dsocial%26utm_campaign%3Ddocs_9.1" target="_blank">ONLYOFFICE 电子表格</a>带来众多更新和改进，旨在提高工作效率并简化数据分析。</p>
<p><strong>单元格文本方向（</strong><strong>从左到右</strong><strong>↔</strong><strong>从右到左</strong><strong>）</strong><strong>：</strong>轻松设置单元格文本方向，根据需要在从左到右和从右到左之间进行切换。</p>
<p>路径：首页选项卡 ➙ 文本方向</p>
<h2><img alt="ONLYOFFICE 文档 9.1 版本已发布：功能更强大的 PDF 编辑器，支持密文功能、全新注释、公式运算提速等多项优化" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static-blog.onlyoffice.com-d4d1a04501.png"></h2>
<p><strong>更快速的 LOOKUP 公式</strong><strong>：</strong>我们对 LOOKUP、VLOOKUP、HLOOKUP 和 XLOOKUP 公式进行了重要更新，以提升其性能和效率。具体改进如下：</p>
<ul>
<li>优化了混合数据类型的处理逻辑，结果更加准确。</li>
<li>降低了公式计算过程中的内存占用。</li>
<li>VLOOKUP 精确匹配的查找速度提升至 4 倍。</li>
<li>XLOOKUP 线性搜索的速度提升至 4 倍。</li>
</ul>
<p><img alt="ONLYOFFICE 文档 9.1 版本已发布：功能更强大的 PDF 编辑器，支持密文功能、全新注释、公式运算提速等多项优化" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-746db6ed08.png"></p>
<p><strong>更多电子表格</strong><strong>改进</strong></p>
<ul>
<li>表格的格式设置已移至专用的<strong>“表格设计”</strong>选项卡中。当您点击表格时，该选项卡就会出现，方便你随时调整表格样式和布局。</li>
</ul>
<p><img alt="ONLYOFFICE 文档 9.1 版本已发布：功能更强大的 PDF 编辑器，支持密文功能、全新注释、公式运算提速等多项优化" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-f2c59cacab.png"></p>
<ul>
<li><strong>数据透视表</strong><strong>已支持日期</strong><strong>筛选器</strong>，便于更轻松地分析与时间相关的数据并发现趋势。</li>
<li><strong>通过内容控件打开和查看文件：</strong>支持复选框、下拉式方框、列表框、微调按钮和滚动条，使您的工作表更加动态和交互性强。</li>
<li><strong>双击工作表名称即可直接重命名</strong>，无需打开其他窗口。</li>
<li>输入公式时，<strong>活动参数将突出显示</strong>，方便您更轻松地追踪和编辑公式。</li>
</ul>
<h2>编辑器的更多实用功能</h2>
<p>除了 PDF 和电子表格编辑器之外，9.1版本还为整个编辑器套件带来了一些实用的改进。</p>
<p><strong>批注</strong><strong>显示</strong><strong>：</strong>为了更好地协作，现支持自定义左侧面板中已解决和打开的批注显示。</p>
<h2><img alt="ONLYOFFICE 文档 9.1 版本已发布：功能更强大的 PDF 编辑器，支持密文功能、全新注释、公式运算提速等多项优化" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-fc11a10f47.png"></h2>
<p><strong>更新</strong><strong>的</strong><strong>图表</strong><strong>：</strong>现已支持打开二维饼图和圆环图的扇区分离效果，方便您查看分离的部分。</p>
<p>您还可以使用<strong>图表的外部数据</strong>，在编辑器之间复制图表时选择嵌入文件或链接到源文件。</p>
<p>此外，您还可以<strong>启用或禁用</strong>特定的图表元素，例如坐标轴标题、数据标签和误差线。</p>
<h2><img alt="ONLYOFFICE 文档 9.1 版本已发布：功能更强大的 PDF 编辑器，支持密文功能、全新注释、公式运算提速等多项优化" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-812f522b76.png"></h2>
<p><strong>幻灯片母版选项卡</strong><strong>：</strong>在演示文稿编辑器中，所有幻灯片母版设置都已移至专用工具栏选项卡，以便于访问。</p>
<h2><img alt="ONLYOFFICE 文档 9.1 版本已发布：功能更强大的 PDF 编辑器，支持密文功能、全新注释、公式运算提速等多项优化" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-c7f9b0ad55.png"></h2>
<p><strong>扩展格式支持</strong><strong>：</strong>编辑器现支持打开和查看<span>&nbsp;</span><strong>HEIF</strong><span>&nbsp;</span>图像及<span>&nbsp;</span><strong>HWPML</strong><span>&nbsp;</span>文档。此外，我们还新增了<span>&nbsp;</span><strong>PDF -&gt; TXT</strong>（直接转换）以及<span>&nbsp;</span><strong>PPTX -&gt; TXT</strong><strong>&nbsp;</strong>的转换功能，并且支持从<span>&nbsp;</span><strong>MathML</strong><span>&nbsp;</span>格式插入数学公式。</p>
<p><strong>分节符</strong><strong>：</strong>文档编辑器支持在任意嵌套级别的块内容控件中使用分节符。</p>
<p><strong>功能完备的图表编辑器</strong><strong>：</strong>文档与幻灯片中现已提供功能完备的图表编辑器，您可以直接打开其中嵌入的 XLSX 文件，无需通过图表缓存。</p>
<h2><img alt="ONLYOFFICE 文档 9.1 版本已发布：功能更强大的 PDF 编辑器，支持密文功能、全新注释、公式运算提速等多项优化" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-a783e0f4e9.png"></h2>
<p><strong>服务器管理</strong><strong>：</strong>ONLYOFFICE 文档的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Fdownload.aspx%3Futm_source%3Dblog%26utm_medium%3Dsocial%26utm_campaign%3Ddocs_9.1%23docs-enterprise" target="_blank">服务器版本</a>新增了管理面板功能。该控制面板支持管理员查看服务器状态与配置设置，从而简化管理工作。</p>
<p><strong>本地化</strong><strong>：</strong>最新版本新增对塞尔维亚拉丁语、塞尔维亚西里尔语及繁体中文的公式翻译支持。</p>
<p>我们诚邀开发者和翻译爱好者加入我们的社区，帮助更多人使用母语版本的编辑器，并获得相应回馈。<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhelpcenter.onlyoffice.com%2Fdocs%2Fcontribution%2Fbecome-translator.aspx%3Futm_source%3Dblog%26utm_medium%3Dsocial%26utm_campaign%3Ddocs_9.1" target="_blank">查看详情</a></p>
<h2>用您的想法塑造 ONLYOFFICE 的未来！</h2>
<p>欢迎分享您的想法、建议和灵感，帮助我们优化产品，为您提供更好的使用体验。您的反馈对我们非常重要，立即访问平台，留下您的建议！<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffeedback.onlyoffice.com%2Fforums%2F966080-your-voice-matters" target="_blank">留下反馈</a></p>
<h2>如何使用新功能</h2>
<p>为帮助您深入了解本次更新的各项功能与改进，我们特于10月28日举办<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fblog%2Fzh-hans%2F2025%2F09%2Fdocs-9-1-is-coming%3Futm_source%3Dblog%26utm_medium%3Dsocial%26utm_campaign%3Ddocs_9.1%23docs-enterprise" target="_blank">线上直播</a>。欢迎大家参与！</p>
<h2>获取 ONLYOFFICE 文档 9.1</h2>
<p>在<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Fdownload.aspx%3Futm_source%3Dblog%26utm_medium%3Dsocial%26utm_campaign%3Ddocs_9.1%23docs-enterprise" target="_blank">ONLYOFFICE官网</a>下载 ONLYOFFICE 文档 9.1 自托管版本。云端解决方案的新版本将稍后上线，敬请期待！</p>
<div>
<h3>相关链接</h3>
<ul>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FONLYOFFICE%2FDocumentServer%2Fblob%2Fmaster%2FCHANGELOG.md" target="_blank">完整更新日志</a></li>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Fdocs-enterprise.aspx%3Futm_source%3Dblog%26utm_medium%3Dsocial%26utm_campaign%3Ddocs_9.1" target="_blank">ONLYOFFICE 文档企业版</a></li>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Fdeveloper-edition.aspx%3Futm_source%3Dblog%26utm_medium%3Dsocial%26utm_campaign%3Ddocs_9.1" target="_blank">ONLYOFFICE 文档开发者版</a></li>
</ul>
</div>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>ONLYOFFICE 文档最新更新现已发布，带来10多项新功能、一系列性能改进以及 500 多项修复。阅读本文，了解详情。</p>
<p><img alt="ONLYOFFICE 文档 9.1 版本已发布：功能更强大的 PDF 编辑器，支持密文功能、全新注释、公式运算提速等多项优化" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static-blog.onlyoffice.com-74ffd4bb8c.png"></p>
<h2>关于 ONLYOFFICE 文档</h2>
<p>ONLYOFFICE 是一个<strong>开源项目</strong>，专注于高级和安全的文档处理，是在线办公解决方案的提供者，全球用户已超过1500万。</p>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Foffice-suite" target="_blank">ONLYOFFICE 办公套件</a>提供<strong>文本文档、电子表格、幻灯片、表单和 PDF 编辑器</strong>。ONLYOFFICE 文档高度兼容 MS Office 格式，并提供数百种格式化和样式工具，以及多种协作功能。在智能办公方面，它深度集成了 <strong>AI 插件</strong>功能，用户可在编辑器内直接调用任意 AI 模型（如 DeepSeek、ChatGPT、通义千问、Kimi 等），无需在不同网页或应用间反复切换。</p>
<p>该办公套件可以提供<strong>50多种现成的连接器</strong>，轻松将在线编辑器连接至您使用的平台，如： Nextcloud、Moodle、Confluence、WordPress、Odoo 等。其开发者版本还<strong>支持二次开发</strong>，快速嵌入您自有的平台、网页和系统，满足您的个性化需求。</p>
<p>ONLYOFFICE 支持在任何平台上部署，包括 <strong>Windows、Linux、macOS、Android</strong>，也可以在任何设备上使用。在线、移动和桌面版本均使用同一引擎，确保离线和在线工作之间无缝切换。</p>
<h2>优化的 PDF 编辑器</h2>
<p>我们的&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Fpdf-editor.aspx%3Futm_source%3Dblog%26utm_medium%3Dsocial%26utm_campaign%3Ddocs_9.1" target="_blank">PDF 编辑器</a>已进行多项强大升级，旨在优化您的文档工作流程。</p>
<p><strong>密文</strong><strong>：</strong>需要隐藏 PDF 中的敏感或机密信息吗？现在操作更加简便。</p>
<p>要隐藏敏感信息，请在<strong>编辑</strong>模式下打开文件，然后切换到新增的<strong>“密文”</strong>选项卡。点击<strong>“标记</strong><strong>密文</strong><strong>”</strong>按钮，并突出显示要删除的文本。对于很长的文档，您可以使用<strong>“查找</strong><strong>密文</strong><strong>”</strong>功能快速定位并选择特定词语或短语。此功能还支持隐藏整个页面或指定页面范围内的内容。</p>
<p>准备就绪后，点击<strong>“应用</strong><strong>密文</strong><strong>”</strong>按钮，即可永久删除文件中选定的信息。</p>
<p>路径：密文选项卡</p>
<h2><img alt="ONLYOFFICE 文档 9.1 版本已发布：功能更强大的 PDF 编辑器，支持密文功能、全新注释、公式运算提速等多项优化" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static-blog.onlyoffice.com-97fe101c10.png"></h2>
<p><strong>全新</strong><strong>注释</strong><strong>工具</strong><strong>：</strong>新工具提供更高的灵活性，以提升您的 PDF 编辑体验。您可以选择<strong>矩形</strong>、<strong>圆形</strong>、<strong>箭头</strong>或<strong>连接线</strong>等形状直接在文档上进行批注，也可以根据需要自定义注释的颜色和大小。</p>
<p>路径：批注选项卡</p>
<p><img alt="ONLYOFFICE 文档 9.1 版本已发布：功能更强大的 PDF 编辑器，支持密文功能、全新注释、公式运算提速等多项优化" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static-blog.onlyoffice.com-e5bcfbbd7a.png"></p>
<p><strong>添加图表和</strong><strong>智能图形</strong><strong>：</strong>通过添加图表来优化您的 PDF 文件，以直观地呈现数据、突出关键信息，并增强文档的吸引力。现在您还可以在 PDF 中使用智能图形，轻松查看和交互，更便捷地在 PDF 文件中管理丰富的视觉内容。</p>
<p>路径：插入选项卡</p>
<p><img alt="ONLYOFFICE 文档 9.1 版本已发布：功能更强大的 PDF 编辑器，支持密文功能、全新注释、公式运算提速等多项优化" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static-blog.onlyoffice.com-7135215e4c.png"></p>
<h2>强大的电子表格编辑器更新</h2>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Fspreadsheet-editor.aspx%3Futm_source%3Dblog%26utm_medium%3Dsocial%26utm_campaign%3Ddocs_9.1" target="_blank">ONLYOFFICE 电子表格</a>带来众多更新和改进，旨在提高工作效率并简化数据分析。</p>
<p><strong>单元格文本方向（</strong><strong>从左到右</strong><strong>↔</strong><strong>从右到左</strong><strong>）</strong><strong>：</strong>轻松设置单元格文本方向，根据需要在从左到右和从右到左之间进行切换。</p>
<p>路径：首页选项卡 ➙ 文本方向</p>
<h2><img alt="ONLYOFFICE 文档 9.1 版本已发布：功能更强大的 PDF 编辑器，支持密文功能、全新注释、公式运算提速等多项优化" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static-blog.onlyoffice.com-d4d1a04501.png"></h2>
<p><strong>更快速的 LOOKUP 公式</strong><strong>：</strong>我们对 LOOKUP、VLOOKUP、HLOOKUP 和 XLOOKUP 公式进行了重要更新，以提升其性能和效率。具体改进如下：</p>
<ul>
<li>优化了混合数据类型的处理逻辑，结果更加准确。</li>
<li>降低了公式计算过程中的内存占用。</li>
<li>VLOOKUP 精确匹配的查找速度提升至 4 倍。</li>
<li>XLOOKUP 线性搜索的速度提升至 4 倍。</li>
</ul>
<p><img alt="ONLYOFFICE 文档 9.1 版本已发布：功能更强大的 PDF 编辑器，支持密文功能、全新注释、公式运算提速等多项优化" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-746db6ed08.png"></p>
<p><strong>更多电子表格</strong><strong>改进</strong></p>
<ul>
<li>表格的格式设置已移至专用的<strong>“表格设计”</strong>选项卡中。当您点击表格时，该选项卡就会出现，方便你随时调整表格样式和布局。</li>
</ul>
<p><img alt="ONLYOFFICE 文档 9.1 版本已发布：功能更强大的 PDF 编辑器，支持密文功能、全新注释、公式运算提速等多项优化" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-f2c59cacab.png"></p>
<ul>
<li><strong>数据透视表</strong><strong>已支持日期</strong><strong>筛选器</strong>，便于更轻松地分析与时间相关的数据并发现趋势。</li>
<li><strong>通过内容控件打开和查看文件：</strong>支持复选框、下拉式方框、列表框、微调按钮和滚动条，使您的工作表更加动态和交互性强。</li>
<li><strong>双击工作表名称即可直接重命名</strong>，无需打开其他窗口。</li>
<li>输入公式时，<strong>活动参数将突出显示</strong>，方便您更轻松地追踪和编辑公式。</li>
</ul>
<h2>编辑器的更多实用功能</h2>
<p>除了 PDF 和电子表格编辑器之外，9.1版本还为整个编辑器套件带来了一些实用的改进。</p>
<p><strong>批注</strong><strong>显示</strong><strong>：</strong>为了更好地协作，现支持自定义左侧面板中已解决和打开的批注显示。</p>
<h2><img alt="ONLYOFFICE 文档 9.1 版本已发布：功能更强大的 PDF 编辑器，支持密文功能、全新注释、公式运算提速等多项优化" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-fc11a10f47.png"></h2>
<p><strong>更新</strong><strong>的</strong><strong>图表</strong><strong>：</strong>现已支持打开二维饼图和圆环图的扇区分离效果，方便您查看分离的部分。</p>
<p>您还可以使用<strong>图表的外部数据</strong>，在编辑器之间复制图表时选择嵌入文件或链接到源文件。</p>
<p>此外，您还可以<strong>启用或禁用</strong>特定的图表元素，例如坐标轴标题、数据标签和误差线。</p>
<h2><img alt="ONLYOFFICE 文档 9.1 版本已发布：功能更强大的 PDF 编辑器，支持密文功能、全新注释、公式运算提速等多项优化" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-812f522b76.png"></h2>
<p><strong>幻灯片母版选项卡</strong><strong>：</strong>在演示文稿编辑器中，所有幻灯片母版设置都已移至专用工具栏选项卡，以便于访问。</p>
<h2><img alt="ONLYOFFICE 文档 9.1 版本已发布：功能更强大的 PDF 编辑器，支持密文功能、全新注释、公式运算提速等多项优化" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-c7f9b0ad55.png"></h2>
<p><strong>扩展格式支持</strong><strong>：</strong>编辑器现支持打开和查看<span>&nbsp;</span><strong>HEIF</strong><span>&nbsp;</span>图像及<span>&nbsp;</span><strong>HWPML</strong><span>&nbsp;</span>文档。此外，我们还新增了<span>&nbsp;</span><strong>PDF -&gt; TXT</strong>（直接转换）以及<span>&nbsp;</span><strong>PPTX -&gt; TXT</strong><strong>&nbsp;</strong>的转换功能，并且支持从<span>&nbsp;</span><strong>MathML</strong><span>&nbsp;</span>格式插入数学公式。</p>
<p><strong>分节符</strong><strong>：</strong>文档编辑器支持在任意嵌套级别的块内容控件中使用分节符。</p>
<p><strong>功能完备的图表编辑器</strong><strong>：</strong>文档与幻灯片中现已提供功能完备的图表编辑器，您可以直接打开其中嵌入的 XLSX 文件，无需通过图表缓存。</p>
<h2><img alt="ONLYOFFICE 文档 9.1 版本已发布：功能更强大的 PDF 编辑器，支持密文功能、全新注释、公式运算提速等多项优化" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-a783e0f4e9.png"></h2>
<p><strong>服务器管理</strong><strong>：</strong>ONLYOFFICE 文档的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Fdownload.aspx%3Futm_source%3Dblog%26utm_medium%3Dsocial%26utm_campaign%3Ddocs_9.1%23docs-enterprise" target="_blank">服务器版本</a>新增了管理面板功能。该控制面板支持管理员查看服务器状态与配置设置，从而简化管理工作。</p>
<p><strong>本地化</strong><strong>：</strong>最新版本新增对塞尔维亚拉丁语、塞尔维亚西里尔语及繁体中文的公式翻译支持。</p>
<p>我们诚邀开发者和翻译爱好者加入我们的社区，帮助更多人使用母语版本的编辑器，并获得相应回馈。<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhelpcenter.onlyoffice.com%2Fdocs%2Fcontribution%2Fbecome-translator.aspx%3Futm_source%3Dblog%26utm_medium%3Dsocial%26utm_campaign%3Ddocs_9.1" target="_blank">查看详情</a></p>
<h2>用您的想法塑造 ONLYOFFICE 的未来！</h2>
<p>欢迎分享您的想法、建议和灵感，帮助我们优化产品，为您提供更好的使用体验。您的反馈对我们非常重要，立即访问平台，留下您的建议！<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffeedback.onlyoffice.com%2Fforums%2F966080-your-voice-matters" target="_blank">留下反馈</a></p>
<h2>如何使用新功能</h2>
<p>为帮助您深入了解本次更新的各项功能与改进，我们特于10月28日举办<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fblog%2Fzh-hans%2F2025%2F09%2Fdocs-9-1-is-coming%3Futm_source%3Dblog%26utm_medium%3Dsocial%26utm_campaign%3Ddocs_9.1%23docs-enterprise" target="_blank">线上直播</a>。欢迎大家参与！</p>
<h2>获取 ONLYOFFICE 文档 9.1</h2>
<p>在<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Fdownload.aspx%3Futm_source%3Dblog%26utm_medium%3Dsocial%26utm_campaign%3Ddocs_9.1%23docs-enterprise" target="_blank">ONLYOFFICE官网</a>下载 ONLYOFFICE 文档 9.1 自托管版本。云端解决方案的新版本将稍后上线，敬请期待！</p>
<div>
<h3>相关链接</h3>
<ul>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FONLYOFFICE%2FDocumentServer%2Fblob%2Fmaster%2FCHANGELOG.md" target="_blank">完整更新日志</a></li>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Fdocs-enterprise.aspx%3Futm_source%3Dblog%26utm_medium%3Dsocial%26utm_campaign%3Ddocs_9.1" target="_blank">ONLYOFFICE 文档企业版</a></li>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Fdeveloper-edition.aspx%3Futm_source%3Dblog%26utm_medium%3Dsocial%26utm_campaign%3Ddocs_9.1" target="_blank">ONLYOFFICE 文档开发者版</a></li>
</ul>
</div>]]>
    </description>
    <content:encoded><![CDATA[<p>ONLYOFFICE 文档最新更新现已发布，带来10多项新功能、一系列性能改进以及 500 多项修复。阅读本文，了解详情。</p>
<p><img alt="ONLYOFFICE 文档 9.1 版本已发布：功能更强大的 PDF 编辑器，支持密文功能、全新注释、公式运算提速等多项优化" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static-blog.onlyoffice.com-74ffd4bb8c.png"></p>
<h2>关于 ONLYOFFICE 文档</h2>
<p>ONLYOFFICE 是一个<strong>开源项目</strong>，专注于高级和安全的文档处理，是在线办公解决方案的提供者，全球用户已超过1500万。</p>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Foffice-suite" target="_blank">ONLYOFFICE 办公套件</a>提供<strong>文本文档、电子表格、幻灯片、表单和 PDF 编辑器</strong>。ONLYOFFICE 文档高度兼容 MS Office 格式，并提供数百种格式化和样式工具，以及多种协作功能。在智能办公方面，它深度集成了 <strong>AI 插件</strong>功能，用户可在编辑器内直接调用任意 AI 模型（如 DeepSeek、ChatGPT、通义千问、Kimi 等），无需在不同网页或应用间反复切换。</p>
<p>该办公套件可以提供<strong>50多种现成的连接器</strong>，轻松将在线编辑器连接至您使用的平台，如： Nextcloud、Moodle、Confluence、WordPress、Odoo 等。其开发者版本还<strong>支持二次开发</strong>，快速嵌入您自有的平台、网页和系统，满足您的个性化需求。</p>
<p>ONLYOFFICE 支持在任何平台上部署，包括 <strong>Windows、Linux、macOS、Android</strong>，也可以在任何设备上使用。在线、移动和桌面版本均使用同一引擎，确保离线和在线工作之间无缝切换。</p>
<h2>优化的 PDF 编辑器</h2>
<p>我们的&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Fpdf-editor.aspx%3Futm_source%3Dblog%26utm_medium%3Dsocial%26utm_campaign%3Ddocs_9.1" target="_blank">PDF 编辑器</a>已进行多项强大升级，旨在优化您的文档工作流程。</p>
<p><strong>密文</strong><strong>：</strong>需要隐藏 PDF 中的敏感或机密信息吗？现在操作更加简便。</p>
<p>要隐藏敏感信息，请在<strong>编辑</strong>模式下打开文件，然后切换到新增的<strong>“密文”</strong>选项卡。点击<strong>“标记</strong><strong>密文</strong><strong>”</strong>按钮，并突出显示要删除的文本。对于很长的文档，您可以使用<strong>“查找</strong><strong>密文</strong><strong>”</strong>功能快速定位并选择特定词语或短语。此功能还支持隐藏整个页面或指定页面范围内的内容。</p>
<p>准备就绪后，点击<strong>“应用</strong><strong>密文</strong><strong>”</strong>按钮，即可永久删除文件中选定的信息。</p>
<p>路径：密文选项卡</p>
<h2><img alt="ONLYOFFICE 文档 9.1 版本已发布：功能更强大的 PDF 编辑器，支持密文功能、全新注释、公式运算提速等多项优化" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static-blog.onlyoffice.com-97fe101c10.png"></h2>
<p><strong>全新</strong><strong>注释</strong><strong>工具</strong><strong>：</strong>新工具提供更高的灵活性，以提升您的 PDF 编辑体验。您可以选择<strong>矩形</strong>、<strong>圆形</strong>、<strong>箭头</strong>或<strong>连接线</strong>等形状直接在文档上进行批注，也可以根据需要自定义注释的颜色和大小。</p>
<p>路径：批注选项卡</p>
<p><img alt="ONLYOFFICE 文档 9.1 版本已发布：功能更强大的 PDF 编辑器，支持密文功能、全新注释、公式运算提速等多项优化" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static-blog.onlyoffice.com-e5bcfbbd7a.png"></p>
<p><strong>添加图表和</strong><strong>智能图形</strong><strong>：</strong>通过添加图表来优化您的 PDF 文件，以直观地呈现数据、突出关键信息，并增强文档的吸引力。现在您还可以在 PDF 中使用智能图形，轻松查看和交互，更便捷地在 PDF 文件中管理丰富的视觉内容。</p>
<p>路径：插入选项卡</p>
<p><img alt="ONLYOFFICE 文档 9.1 版本已发布：功能更强大的 PDF 编辑器，支持密文功能、全新注释、公式运算提速等多项优化" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static-blog.onlyoffice.com-7135215e4c.png"></p>
<h2>强大的电子表格编辑器更新</h2>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Fspreadsheet-editor.aspx%3Futm_source%3Dblog%26utm_medium%3Dsocial%26utm_campaign%3Ddocs_9.1" target="_blank">ONLYOFFICE 电子表格</a>带来众多更新和改进，旨在提高工作效率并简化数据分析。</p>
<p><strong>单元格文本方向（</strong><strong>从左到右</strong><strong>↔</strong><strong>从右到左</strong><strong>）</strong><strong>：</strong>轻松设置单元格文本方向，根据需要在从左到右和从右到左之间进行切换。</p>
<p>路径：首页选项卡 ➙ 文本方向</p>
<h2><img alt="ONLYOFFICE 文档 9.1 版本已发布：功能更强大的 PDF 编辑器，支持密文功能、全新注释、公式运算提速等多项优化" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static-blog.onlyoffice.com-d4d1a04501.png"></h2>
<p><strong>更快速的 LOOKUP 公式</strong><strong>：</strong>我们对 LOOKUP、VLOOKUP、HLOOKUP 和 XLOOKUP 公式进行了重要更新，以提升其性能和效率。具体改进如下：</p>
<ul>
<li>优化了混合数据类型的处理逻辑，结果更加准确。</li>
<li>降低了公式计算过程中的内存占用。</li>
<li>VLOOKUP 精确匹配的查找速度提升至 4 倍。</li>
<li>XLOOKUP 线性搜索的速度提升至 4 倍。</li>
</ul>
<p><img alt="ONLYOFFICE 文档 9.1 版本已发布：功能更强大的 PDF 编辑器，支持密文功能、全新注释、公式运算提速等多项优化" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-746db6ed08.png"></p>
<p><strong>更多电子表格</strong><strong>改进</strong></p>
<ul>
<li>表格的格式设置已移至专用的<strong>“表格设计”</strong>选项卡中。当您点击表格时，该选项卡就会出现，方便你随时调整表格样式和布局。</li>
</ul>
<p><img alt="ONLYOFFICE 文档 9.1 版本已发布：功能更强大的 PDF 编辑器，支持密文功能、全新注释、公式运算提速等多项优化" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-f2c59cacab.png"></p>
<ul>
<li><strong>数据透视表</strong><strong>已支持日期</strong><strong>筛选器</strong>，便于更轻松地分析与时间相关的数据并发现趋势。</li>
<li><strong>通过内容控件打开和查看文件：</strong>支持复选框、下拉式方框、列表框、微调按钮和滚动条，使您的工作表更加动态和交互性强。</li>
<li><strong>双击工作表名称即可直接重命名</strong>，无需打开其他窗口。</li>
<li>输入公式时，<strong>活动参数将突出显示</strong>，方便您更轻松地追踪和编辑公式。</li>
</ul>
<h2>编辑器的更多实用功能</h2>
<p>除了 PDF 和电子表格编辑器之外，9.1版本还为整个编辑器套件带来了一些实用的改进。</p>
<p><strong>批注</strong><strong>显示</strong><strong>：</strong>为了更好地协作，现支持自定义左侧面板中已解决和打开的批注显示。</p>
<h2><img alt="ONLYOFFICE 文档 9.1 版本已发布：功能更强大的 PDF 编辑器，支持密文功能、全新注释、公式运算提速等多项优化" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-fc11a10f47.png"></h2>
<p><strong>更新</strong><strong>的</strong><strong>图表</strong><strong>：</strong>现已支持打开二维饼图和圆环图的扇区分离效果，方便您查看分离的部分。</p>
<p>您还可以使用<strong>图表的外部数据</strong>，在编辑器之间复制图表时选择嵌入文件或链接到源文件。</p>
<p>此外，您还可以<strong>启用或禁用</strong>特定的图表元素，例如坐标轴标题、数据标签和误差线。</p>
<h2><img alt="ONLYOFFICE 文档 9.1 版本已发布：功能更强大的 PDF 编辑器，支持密文功能、全新注释、公式运算提速等多项优化" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-812f522b76.png"></h2>
<p><strong>幻灯片母版选项卡</strong><strong>：</strong>在演示文稿编辑器中，所有幻灯片母版设置都已移至专用工具栏选项卡，以便于访问。</p>
<h2><img alt="ONLYOFFICE 文档 9.1 版本已发布：功能更强大的 PDF 编辑器，支持密文功能、全新注释、公式运算提速等多项优化" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-c7f9b0ad55.png"></h2>
<p><strong>扩展格式支持</strong><strong>：</strong>编辑器现支持打开和查看<span>&nbsp;</span><strong>HEIF</strong><span>&nbsp;</span>图像及<span>&nbsp;</span><strong>HWPML</strong><span>&nbsp;</span>文档。此外，我们还新增了<span>&nbsp;</span><strong>PDF -&gt; TXT</strong>（直接转换）以及<span>&nbsp;</span><strong>PPTX -&gt; TXT</strong><strong>&nbsp;</strong>的转换功能，并且支持从<span>&nbsp;</span><strong>MathML</strong><span>&nbsp;</span>格式插入数学公式。</p>
<p><strong>分节符</strong><strong>：</strong>文档编辑器支持在任意嵌套级别的块内容控件中使用分节符。</p>
<p><strong>功能完备的图表编辑器</strong><strong>：</strong>文档与幻灯片中现已提供功能完备的图表编辑器，您可以直接打开其中嵌入的 XLSX 文件，无需通过图表缓存。</p>
<h2><img alt="ONLYOFFICE 文档 9.1 版本已发布：功能更强大的 PDF 编辑器，支持密文功能、全新注释、公式运算提速等多项优化" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-a783e0f4e9.png"></h2>
<p><strong>服务器管理</strong><strong>：</strong>ONLYOFFICE 文档的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Fdownload.aspx%3Futm_source%3Dblog%26utm_medium%3Dsocial%26utm_campaign%3Ddocs_9.1%23docs-enterprise" target="_blank">服务器版本</a>新增了管理面板功能。该控制面板支持管理员查看服务器状态与配置设置，从而简化管理工作。</p>
<p><strong>本地化</strong><strong>：</strong>最新版本新增对塞尔维亚拉丁语、塞尔维亚西里尔语及繁体中文的公式翻译支持。</p>
<p>我们诚邀开发者和翻译爱好者加入我们的社区，帮助更多人使用母语版本的编辑器，并获得相应回馈。<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhelpcenter.onlyoffice.com%2Fdocs%2Fcontribution%2Fbecome-translator.aspx%3Futm_source%3Dblog%26utm_medium%3Dsocial%26utm_campaign%3Ddocs_9.1" target="_blank">查看详情</a></p>
<h2>用您的想法塑造 ONLYOFFICE 的未来！</h2>
<p>欢迎分享您的想法、建议和灵感，帮助我们优化产品，为您提供更好的使用体验。您的反馈对我们非常重要，立即访问平台，留下您的建议！<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffeedback.onlyoffice.com%2Fforums%2F966080-your-voice-matters" target="_blank">留下反馈</a></p>
<h2>如何使用新功能</h2>
<p>为帮助您深入了解本次更新的各项功能与改进，我们特于10月28日举办<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fblog%2Fzh-hans%2F2025%2F09%2Fdocs-9-1-is-coming%3Futm_source%3Dblog%26utm_medium%3Dsocial%26utm_campaign%3Ddocs_9.1%23docs-enterprise" target="_blank">线上直播</a>。欢迎大家参与！</p>
<h2>获取 ONLYOFFICE 文档 9.1</h2>
<p>在<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Fdownload.aspx%3Futm_source%3Dblog%26utm_medium%3Dsocial%26utm_campaign%3Ddocs_9.1%23docs-enterprise" target="_blank">ONLYOFFICE官网</a>下载 ONLYOFFICE 文档 9.1 自托管版本。云端解决方案的新版本将稍后上线，敬请期待！</p>
<div>
<h3>相关链接</h3>
<ul>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FONLYOFFICE%2FDocumentServer%2Fblob%2Fmaster%2FCHANGELOG.md" target="_blank">完整更新日志</a></li>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Fdocs-enterprise.aspx%3Futm_source%3Dblog%26utm_medium%3Dsocial%26utm_campaign%3Ddocs_9.1" target="_blank">ONLYOFFICE 文档企业版</a></li>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Fdeveloper-edition.aspx%3Futm_source%3Dblog%26utm_medium%3Dsocial%26utm_campaign%3Ddocs_9.1" target="_blank">ONLYOFFICE 文档开发者版</a></li>
</ul>
</div>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static-blog.onlyoffice.com-74ffd4bb8c.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static-blog.onlyoffice.com-74ffd4bb8c.png" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 18:30:01 +0800</pubDate>
  </item><item>
    <title><![CDATA[miniaudio - 音频播放和采样库]]></title>
    <link>https://www.oschina.net/p/miniaudio</link>
    <itunes:title><![CDATA[miniaudio - 音频播放和采样库]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>miniaudio 使用 C 语言编写，除了标准库之外没有任何依赖项，可以在所有主流编译器上顺利编译，无需安装任何其他开发包。它支持所有主流桌面和移动平台。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p>
<p><strong><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>特性</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></p>
<ul>
<li>简单的构建系统，没有外部依赖。</li>
<li>简单灵活的 API。</li>
<li>用于直接访问原始音频数据的低级 API。</li>
<li>用于声音管理、混合、效果和可选 3D 空间化的高级 API。</li>
<li>灵活的节点图系统，用于高级混合和效果处理。</li>
<li>用于加载声音文件的资源管理。</li>
<li>解码，内置对 WAV、FLAC 和 MP3 的支持，此外还能够插入自定义解码器。</li>
<li>编码（仅限 WAV）。</li>
<li>数据转换。</li>
<li>重采样，包括自定义重采样器。</li>
<li>通道映射。</li>
<li>波形和噪声的基本生成。</li>
<li>基本效果和过滤器。</li>
</ul>
<p><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>有关 miniaudio 中可用功能的更完整描述，参阅<a href="https://miniaud.io/docs/manual/">编程手册。</a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p>
<div>
<p><strong><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>示例</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></p>
</div>
<p><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>此示例展示了使用高级 API 播放声音的一种方法。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p>
<div>
<pre><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>#include</span></span> <span><span>"miniaudio/miniaudio.h"</span></span>
<span><span>#include</span></span> <span><span>&lt;stdio.h&gt;</span></span>
<span><span>int</span></span> <span><span>main</span></span>()
{
<span><span>ma_result</span></span> <span>result</span>;
<span><span>ma_engine</span></span> <span>engine</span>;
<span>result</span> <span><span>=</span></span> <span><span>ma_engine_init</span></span>(<span><span>NULL</span></span>, <span><span>&amp;</span></span><span>engine</span>);
<span><span>if</span></span> (<span>result</span> <span><span>!=</span></span> <span><span>MA_SUCCESS</span></span>) {
<span><span>return</span></span> <span><span>-1</span></span>;
}
<span><span>ma_engine_play_sound</span></span>(<span><span>&amp;</span></span><span>engine</span>, <span><span>"sound.wav"</span></span>, <span><span>NULL</span></span>);
<span><span>printf</span></span>(<span><span>"Press Enter to quit..."</span></span>);
<span><span>getchar</span></span>();
<span><span>ma_engine_uninit</span></span>(<span><span>&amp;</span></span><span>engine</span>);
<span><span>return</span></span> <span><span>0</span></span>;
}</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>
</pre>
</div>
<p><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>此示例展示了如何使用低级 API 解码和播放声音。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p>
<div>
<pre><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>#include</span></span> <span><span>"miniaudio/miniaudio.h"</span></span>
<span><span>#include</span></span> <span><span>&lt;stdio.h&gt;</span></span>
<span><span>void</span></span> <span><span>data_callback</span></span>(<span><span>ma_device</span></span><span><span>*</span></span> <span>pDevice</span>, <span><span>void</span></span><span><span>*</span></span> <span>pOutput</span>, <span><span>const</span></span> <span><span>void</span></span><span><span>*</span></span> <span>pInput</span>, <span><span>ma_uint32</span></span> <span>frameCount</span>)
{
<span><span>ma_decoder</span></span><span><span>*</span></span> <span>pDecoder</span> <span><span>=</span></span> (<span><span>ma_decoder</span></span><span><span>*</span></span>)<span>pDevice</span><span><span>-&gt;</span></span><span><span>pUserData</span></span>;
<span><span>if</span></span> (<span>pDecoder</span> <span><span>==</span></span> <span><span>NULL</span></span>) {
<span><span>return</span></span>;
}
<span><span>ma_decoder_read_pcm_frames</span></span>(<span>pDecoder</span>, <span>pOutput</span>, <span>frameCount</span>, <span><span>NULL</span></span>);
(<span><span>void</span></span>)<span>pInput</span>;
}
<span><span>int</span></span> <span><span>main</span></span>(<span><span>int</span></span> <span>argc</span>, <span><span>char</span></span><span><span>*</span></span><span><span>*</span></span> <span>argv</span>)
{
<span><span>ma_result</span></span> <span>result</span>;
<span><span>ma_decoder</span></span> <span>decoder</span>;
<span><span>ma_device_config</span></span> <span>deviceConfig</span>;
<span><span>ma_device</span></span> <span>device</span>;
<span><span>if</span></span> (<span>argc</span> <span><span>&lt;</span></span> <span><span>2</span></span>) {
<span><span>printf</span></span>(<span><span>"No input file.
"</span></span>);
<span><span>return</span></span> <span><span>-1</span></span>;
}
<span>result</span> <span><span>=</span></span> <span><span>ma_decoder_init_file</span></span>(<span>argv</span>[<span><span>1</span></span>], <span><span>NULL</span></span>, <span><span>&amp;</span></span><span>decoder</span>);
<span><span>if</span></span> (<span>result</span> <span><span>!=</span></span> <span><span>MA_SUCCESS</span></span>) {
<span><span>return</span></span> <span><span>-2</span></span>;
}
<span>deviceConfig</span> <span><span>=</span></span> <span><span>ma_device_config_init</span></span>(<span>ma_device_type_playback</span>);
<span>deviceConfig</span>.<span><span>playback</span></span>.<span><span>format</span></span>   <span><span>=</span></span> <span>decoder</span>.<span><span>outputFormat</span></span>;
<span>deviceConfig</span>.<span><span>playback</span></span>.<span><span>channels</span></span> <span><span>=</span></span> <span>decoder</span>.<span><span>outputChannels</span></span>;
<span>deviceConfig</span>.<span><span>sampleRate</span></span>        <span><span>=</span></span> <span>decoder</span>.<span><span>outputSampleRate</span></span>;
<span>deviceConfig</span>.<span><span>dataCallback</span></span>      <span><span>=</span></span> <span>data_callback</span>;
<span>deviceConfig</span>.<span><span>pUserData</span></span>         <span><span>=</span></span> <span><span>&amp;</span></span><span>decoder</span>;
<span><span>if</span></span> (<span><span>ma_device_init</span></span>(<span><span>NULL</span></span>, <span><span>&amp;</span></span><span>deviceConfig</span>, <span><span>&amp;</span></span><span>device</span>) <span><span>!=</span></span> <span><span>MA_SUCCESS</span></span>) {
<span><span>printf</span></span>(<span><span>"Failed to open playback device.
"</span></span>);
<span><span>ma_decoder_uninit</span></span>(<span><span>&amp;</span></span><span>decoder</span>);
<span><span>return</span></span> <span><span>-3</span></span>;
}
<span><span>if</span></span> (<span><span>ma_device_start</span></span>(<span><span>&amp;</span></span><span>device</span>) <span><span>!=</span></span> <span><span>MA_SUCCESS</span></span>) {
<span><span>printf</span></span>(<span><span>"Failed to start playback device.
"</span></span>);
<span><span>ma_device_uninit</span></span>(<span><span>&amp;</span></span><span>device</span>);
<span><span>ma_decoder_uninit</span></span>(<span><span>&amp;</span></span><span>decoder</span>);
<span><span>return</span></span> <span><span>-4</span></span>;
}
<span><span>printf</span></span>(<span><span>"Press Enter to quit..."</span></span>);
<span><span>getchar</span></span>();
<span><span>ma_device_uninit</span></span>(<span><span>&amp;</span></span><span>device</span>);
<span><span>ma_decoder_uninit</span></span>(<span><span>&amp;</span></span><span>decoder</span>);
<span><span>return</span></span> <span><span>0</span></span>;
}</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>
</pre>
</div>
<p><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><a href="https://github.com/mackron/miniaudio/blob/master/examples">更多示例可以在示例</a>文件夹或在线此处找到：&nbsp;<a href="https://miniaud.io/docs/examples/">https://miniaud.io/docs/examples/</a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>miniaudio 使用 C 语言编写，除了标准库之外没有任何依赖项，可以在所有主流编译器上顺利编译，无需安装任何其他开发包。它支持所有主流桌面和移动平台。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p>
<p><strong><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>特性</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></p>
<ul>
<li>简单的构建系统，没有外部依赖。</li>
<li>简单灵活的 API。</li>
<li>用于直接访问原始音频数据的低级 API。</li>
<li>用于声音管理、混合、效果和可选 3D 空间化的高级 API。</li>
<li>灵活的节点图系统，用于高级混合和效果处理。</li>
<li>用于加载声音文件的资源管理。</li>
<li>解码，内置对 WAV、FLAC 和 MP3 的支持，此外还能够插入自定义解码器。</li>
<li>编码（仅限 WAV）。</li>
<li>数据转换。</li>
<li>重采样，包括自定义重采样器。</li>
<li>通道映射。</li>
<li>波形和噪声的基本生成。</li>
<li>基本效果和过滤器。</li>
</ul>
<p><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>有关 miniaudio 中可用功能的更完整描述，参阅<a href="https://miniaud.io/docs/manual/">编程手册。</a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p>
<div>
<p><strong><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>示例</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></p>
</div>
<p><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>此示例展示了使用高级 API 播放声音的一种方法。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p>
<div>
<pre><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>#include</span></span> <span><span>"miniaudio/miniaudio.h"</span></span>
<span><span>#include</span></span> <span><span>&lt;stdio.h&gt;</span></span>
<span><span>int</span></span> <span><span>main</span></span>()
{
<span><span>ma_result</span></span> <span>result</span>;
<span><span>ma_engine</span></span> <span>engine</span>;
<span>result</span> <span><span>=</span></span> <span><span>ma_engine_init</span></span>(<span><span>NULL</span></span>, <span><span>&amp;</span></span><span>engine</span>);
<span><span>if</span></span> (<span>result</span> <span><span>!=</span></span> <span><span>MA_SUCCESS</span></span>) {
<span><span>return</span></span> <span><span>-1</span></span>;
}
<span><span>ma_engine_play_sound</span></span>(<span><span>&amp;</span></span><span>engine</span>, <span><span>"sound.wav"</span></span>, <span><span>NULL</span></span>);
<span><span>printf</span></span>(<span><span>"Press Enter to quit..."</span></span>);
<span><span>getchar</span></span>();
<span><span>ma_engine_uninit</span></span>(<span><span>&amp;</span></span><span>engine</span>);
<span><span>return</span></span> <span><span>0</span></span>;
}</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>
</pre>
</div>
<p><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>此示例展示了如何使用低级 API 解码和播放声音。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p>
<div>
<pre><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>#include</span></span> <span><span>"miniaudio/miniaudio.h"</span></span>
<span><span>#include</span></span> <span><span>&lt;stdio.h&gt;</span></span>
<span><span>void</span></span> <span><span>data_callback</span></span>(<span><span>ma_device</span></span><span><span>*</span></span> <span>pDevice</span>, <span><span>void</span></span><span><span>*</span></span> <span>pOutput</span>, <span><span>const</span></span> <span><span>void</span></span><span><span>*</span></span> <span>pInput</span>, <span><span>ma_uint32</span></span> <span>frameCount</span>)
{
<span><span>ma_decoder</span></span><span><span>*</span></span> <span>pDecoder</span> <span><span>=</span></span> (<span><span>ma_decoder</span></span><span><span>*</span></span>)<span>pDevice</span><span><span>-&gt;</span></span><span><span>pUserData</span></span>;
<span><span>if</span></span> (<span>pDecoder</span> <span><span>==</span></span> <span><span>NULL</span></span>) {
<span><span>return</span></span>;
}
<span><span>ma_decoder_read_pcm_frames</span></span>(<span>pDecoder</span>, <span>pOutput</span>, <span>frameCount</span>, <span><span>NULL</span></span>);
(<span><span>void</span></span>)<span>pInput</span>;
}
<span><span>int</span></span> <span><span>main</span></span>(<span><span>int</span></span> <span>argc</span>, <span><span>char</span></span><span><span>*</span></span><span><span>*</span></span> <span>argv</span>)
{
<span><span>ma_result</span></span> <span>result</span>;
<span><span>ma_decoder</span></span> <span>decoder</span>;
<span><span>ma_device_config</span></span> <span>deviceConfig</span>;
<span><span>ma_device</span></span> <span>device</span>;
<span><span>if</span></span> (<span>argc</span> <span><span>&lt;</span></span> <span><span>2</span></span>) {
<span><span>printf</span></span>(<span><span>"No input file.
"</span></span>);
<span><span>return</span></span> <span><span>-1</span></span>;
}
<span>result</span> <span><span>=</span></span> <span><span>ma_decoder_init_file</span></span>(<span>argv</span>[<span><span>1</span></span>], <span><span>NULL</span></span>, <span><span>&amp;</span></span><span>decoder</span>);
<span><span>if</span></span> (<span>result</span> <span><span>!=</span></span> <span><span>MA_SUCCESS</span></span>) {
<span><span>return</span></span> <span><span>-2</span></span>;
}
<span>deviceConfig</span> <span><span>=</span></span> <span><span>ma_device_config_init</span></span>(<span>ma_device_type_playback</span>);
<span>deviceConfig</span>.<span><span>playback</span></span>.<span><span>format</span></span>   <span><span>=</span></span> <span>decoder</span>.<span><span>outputFormat</span></span>;
<span>deviceConfig</span>.<span><span>playback</span></span>.<span><span>channels</span></span> <span><span>=</span></span> <span>decoder</span>.<span><span>outputChannels</span></span>;
<span>deviceConfig</span>.<span><span>sampleRate</span></span>        <span><span>=</span></span> <span>decoder</span>.<span><span>outputSampleRate</span></span>;
<span>deviceConfig</span>.<span><span>dataCallback</span></span>      <span><span>=</span></span> <span>data_callback</span>;
<span>deviceConfig</span>.<span><span>pUserData</span></span>         <span><span>=</span></span> <span><span>&amp;</span></span><span>decoder</span>;
<span><span>if</span></span> (<span><span>ma_device_init</span></span>(<span><span>NULL</span></span>, <span><span>&amp;</span></span><span>deviceConfig</span>, <span><span>&amp;</span></span><span>device</span>) <span><span>!=</span></span> <span><span>MA_SUCCESS</span></span>) {
<span><span>printf</span></span>(<span><span>"Failed to open playback device.
"</span></span>);
<span><span>ma_decoder_uninit</span></span>(<span><span>&amp;</span></span><span>decoder</span>);
<span><span>return</span></span> <span><span>-3</span></span>;
}
<span><span>if</span></span> (<span><span>ma_device_start</span></span>(<span><span>&amp;</span></span><span>device</span>) <span><span>!=</span></span> <span><span>MA_SUCCESS</span></span>) {
<span><span>printf</span></span>(<span><span>"Failed to start playback device.
"</span></span>);
<span><span>ma_device_uninit</span></span>(<span><span>&amp;</span></span><span>device</span>);
<span><span>ma_decoder_uninit</span></span>(<span><span>&amp;</span></span><span>decoder</span>);
<span><span>return</span></span> <span><span>-4</span></span>;
}
<span><span>printf</span></span>(<span><span>"Press Enter to quit..."</span></span>);
<span><span>getchar</span></span>();
<span><span>ma_device_uninit</span></span>(<span><span>&amp;</span></span><span>device</span>);
<span><span>ma_decoder_uninit</span></span>(<span><span>&amp;</span></span><span>decoder</span>);
<span><span>return</span></span> <span><span>0</span></span>;
}</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>
</pre>
</div>
<p><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><a href="https://github.com/mackron/miniaudio/blob/master/examples">更多示例可以在示例</a>文件夹或在线此处找到：&nbsp;<a href="https://miniaud.io/docs/examples/">https://miniaud.io/docs/examples/</a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p>]]>
    </description>
    <content:encoded><![CDATA[<p><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>miniaudio 使用 C 语言编写，除了标准库之外没有任何依赖项，可以在所有主流编译器上顺利编译，无需安装任何其他开发包。它支持所有主流桌面和移动平台。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p>
<p><strong><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>特性</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></p>
<ul>
<li>简单的构建系统，没有外部依赖。</li>
<li>简单灵活的 API。</li>
<li>用于直接访问原始音频数据的低级 API。</li>
<li>用于声音管理、混合、效果和可选 3D 空间化的高级 API。</li>
<li>灵活的节点图系统，用于高级混合和效果处理。</li>
<li>用于加载声音文件的资源管理。</li>
<li>解码，内置对 WAV、FLAC 和 MP3 的支持，此外还能够插入自定义解码器。</li>
<li>编码（仅限 WAV）。</li>
<li>数据转换。</li>
<li>重采样，包括自定义重采样器。</li>
<li>通道映射。</li>
<li>波形和噪声的基本生成。</li>
<li>基本效果和过滤器。</li>
</ul>
<p><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>有关 miniaudio 中可用功能的更完整描述，参阅<a href="https://miniaud.io/docs/manual/">编程手册。</a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p>
<div>
<p><strong><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>示例</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></p>
</div>
<p><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>此示例展示了使用高级 API 播放声音的一种方法。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p>
<div>
<pre><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>#include</span></span> <span><span>"miniaudio/miniaudio.h"</span></span>
<span><span>#include</span></span> <span><span>&lt;stdio.h&gt;</span></span>
<span><span>int</span></span> <span><span>main</span></span>()
{
<span><span>ma_result</span></span> <span>result</span>;
<span><span>ma_engine</span></span> <span>engine</span>;
<span>result</span> <span><span>=</span></span> <span><span>ma_engine_init</span></span>(<span><span>NULL</span></span>, <span><span>&amp;</span></span><span>engine</span>);
<span><span>if</span></span> (<span>result</span> <span><span>!=</span></span> <span><span>MA_SUCCESS</span></span>) {
<span><span>return</span></span> <span><span>-1</span></span>;
}
<span><span>ma_engine_play_sound</span></span>(<span><span>&amp;</span></span><span>engine</span>, <span><span>"sound.wav"</span></span>, <span><span>NULL</span></span>);
<span><span>printf</span></span>(<span><span>"Press Enter to quit..."</span></span>);
<span><span>getchar</span></span>();
<span><span>ma_engine_uninit</span></span>(<span><span>&amp;</span></span><span>engine</span>);
<span><span>return</span></span> <span><span>0</span></span>;
}</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>
</pre>
</div>
<p><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>此示例展示了如何使用低级 API 解码和播放声音。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p>
<div>
<pre><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>#include</span></span> <span><span>"miniaudio/miniaudio.h"</span></span>
<span><span>#include</span></span> <span><span>&lt;stdio.h&gt;</span></span>
<span><span>void</span></span> <span><span>data_callback</span></span>(<span><span>ma_device</span></span><span><span>*</span></span> <span>pDevice</span>, <span><span>void</span></span><span><span>*</span></span> <span>pOutput</span>, <span><span>const</span></span> <span><span>void</span></span><span><span>*</span></span> <span>pInput</span>, <span><span>ma_uint32</span></span> <span>frameCount</span>)
{
<span><span>ma_decoder</span></span><span><span>*</span></span> <span>pDecoder</span> <span><span>=</span></span> (<span><span>ma_decoder</span></span><span><span>*</span></span>)<span>pDevice</span><span><span>-&gt;</span></span><span><span>pUserData</span></span>;
<span><span>if</span></span> (<span>pDecoder</span> <span><span>==</span></span> <span><span>NULL</span></span>) {
<span><span>return</span></span>;
}
<span><span>ma_decoder_read_pcm_frames</span></span>(<span>pDecoder</span>, <span>pOutput</span>, <span>frameCount</span>, <span><span>NULL</span></span>);
(<span><span>void</span></span>)<span>pInput</span>;
}
<span><span>int</span></span> <span><span>main</span></span>(<span><span>int</span></span> <span>argc</span>, <span><span>char</span></span><span><span>*</span></span><span><span>*</span></span> <span>argv</span>)
{
<span><span>ma_result</span></span> <span>result</span>;
<span><span>ma_decoder</span></span> <span>decoder</span>;
<span><span>ma_device_config</span></span> <span>deviceConfig</span>;
<span><span>ma_device</span></span> <span>device</span>;
<span><span>if</span></span> (<span>argc</span> <span><span>&lt;</span></span> <span><span>2</span></span>) {
<span><span>printf</span></span>(<span><span>"No input file.
"</span></span>);
<span><span>return</span></span> <span><span>-1</span></span>;
}
<span>result</span> <span><span>=</span></span> <span><span>ma_decoder_init_file</span></span>(<span>argv</span>[<span><span>1</span></span>], <span><span>NULL</span></span>, <span><span>&amp;</span></span><span>decoder</span>);
<span><span>if</span></span> (<span>result</span> <span><span>!=</span></span> <span><span>MA_SUCCESS</span></span>) {
<span><span>return</span></span> <span><span>-2</span></span>;
}
<span>deviceConfig</span> <span><span>=</span></span> <span><span>ma_device_config_init</span></span>(<span>ma_device_type_playback</span>);
<span>deviceConfig</span>.<span><span>playback</span></span>.<span><span>format</span></span>   <span><span>=</span></span> <span>decoder</span>.<span><span>outputFormat</span></span>;
<span>deviceConfig</span>.<span><span>playback</span></span>.<span><span>channels</span></span> <span><span>=</span></span> <span>decoder</span>.<span><span>outputChannels</span></span>;
<span>deviceConfig</span>.<span><span>sampleRate</span></span>        <span><span>=</span></span> <span>decoder</span>.<span><span>outputSampleRate</span></span>;
<span>deviceConfig</span>.<span><span>dataCallback</span></span>      <span><span>=</span></span> <span>data_callback</span>;
<span>deviceConfig</span>.<span><span>pUserData</span></span>         <span><span>=</span></span> <span><span>&amp;</span></span><span>decoder</span>;
<span><span>if</span></span> (<span><span>ma_device_init</span></span>(<span><span>NULL</span></span>, <span><span>&amp;</span></span><span>deviceConfig</span>, <span><span>&amp;</span></span><span>device</span>) <span><span>!=</span></span> <span><span>MA_SUCCESS</span></span>) {
<span><span>printf</span></span>(<span><span>"Failed to open playback device.
"</span></span>);
<span><span>ma_decoder_uninit</span></span>(<span><span>&amp;</span></span><span>decoder</span>);
<span><span>return</span></span> <span><span>-3</span></span>;
}
<span><span>if</span></span> (<span><span>ma_device_start</span></span>(<span><span>&amp;</span></span><span>device</span>) <span><span>!=</span></span> <span><span>MA_SUCCESS</span></span>) {
<span><span>printf</span></span>(<span><span>"Failed to start playback device.
"</span></span>);
<span><span>ma_device_uninit</span></span>(<span><span>&amp;</span></span><span>device</span>);
<span><span>ma_decoder_uninit</span></span>(<span><span>&amp;</span></span><span>decoder</span>);
<span><span>return</span></span> <span><span>-4</span></span>;
}
<span><span>printf</span></span>(<span><span>"Press Enter to quit..."</span></span>);
<span><span>getchar</span></span>();
<span><span>ma_device_uninit</span></span>(<span><span>&amp;</span></span><span>device</span>);
<span><span>ma_decoder_uninit</span></span>(<span><span>&amp;</span></span><span>decoder</span>);
<span><span>return</span></span> <span><span>0</span></span>;
}</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>
</pre>
</div>
<p><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><a href="https://github.com/mackron/miniaudio/blob/master/examples">更多示例可以在示例</a>文件夹或在线此处找到：&nbsp;<a href="https://miniaud.io/docs/examples/">https://miniaud.io/docs/examples/</a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p>]]></content:encoded>
    
    <pubDate>Wed, 15 Oct 2025 18:28:29 +0800</pubDate>
  </item><item>
    <title><![CDATA[消息称谷歌即将在 Gemini 和 API 上发布 VEO 3.1 版本]]></title>
    <link>https://www.oschina.net/news/377617</link>
    <itunes:title><![CDATA[消息称谷歌即将在 Gemini 和 API 上发布 VEO 3.1 版本]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>谷歌近期有消息称，VEO3.1的公共发布即将来临。随着 Gemini 应用程序中出现相关免责声明，谷歌正在为广泛用户群展示 VEO3.1的功能，这可能会在用户熟悉的 Gemini 界面中实现。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-75d5aeee11.png"></p>
<p>社区中知名人士 Logan Kilpatrick 在社交媒体平台 X 上发布的帖子被广泛视为谷歌 AI 新产品发布的早期确认。此外，在 Vertex AI 中也出现了 “VEO3.0Generate” 和 “VEO3.0Fast Generate” 等预览模型的引用，这表明谷歌正在为早期用户和企业用户提供多个访问渠道，符合他们在生成视频工具发布中的传统策略。</p>
<p>关于输出时长，社区中的讨论热烈，有证据表明视频时长可能从之前的8秒延长至30秒，尽管这一点尚待确认。过去的泄露信息显示，快速模式的质量较低，而标准模式预计将解锁更高的输出质量，这对希望提升视觉质量和叙事潜力的创作者尤为重要。根据 TestingCatalog 的报道，之前的720p 视频生成已展现出 VEO3.1的进步，包括新的音频能力和改进的视觉效果，这使其在竞争中挑战了类似 Sora2的产品。</p>
<p>谷歌的整体产品战略是将 Gemini 打造为一个中央工作区，VEO 模型则整合为消费者和企业用户所用。通过在 Vertex AI 上进行的预览发布，企业可以尝试生成视频，而 Gemini 应用程序的主流推广则可以触及普通用户。这种分阶段的发布策略不仅可以<span>最大</span>限度地获取开发者反馈，还能促进公众的接受度，这与谷歌持续努力弥补功能差距并巩固其在生成媒体领域的地位的目标相一致。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>谷歌近期有消息称，VEO3.1的公共发布即将来临。随着 Gemini 应用程序中出现相关免责声明，谷歌正在为广泛用户群展示 VEO3.1的功能，这可能会在用户熟悉的 Gemini 界面中实现。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-75d5aeee11.png"></p>
<p>社区中知名人士 Logan Kilpatrick 在社交媒体平台 X 上发布的帖子被广泛视为谷歌 AI 新产品发布的早期确认。此外，在 Vertex AI 中也出现了 “VEO3.0Generate” 和 “VEO3.0Fast Generate” 等预览模型的引用，这表明谷歌正在为早期用户和企业用户提供多个访问渠道，符合他们在生成视频工具发布中的传统策略。</p>
<p>关于输出时长，社区中的讨论热烈，有证据表明视频时长可能从之前的8秒延长至30秒，尽管这一点尚待确认。过去的泄露信息显示，快速模式的质量较低，而标准模式预计将解锁更高的输出质量，这对希望提升视觉质量和叙事潜力的创作者尤为重要。根据 TestingCatalog 的报道，之前的720p 视频生成已展现出 VEO3.1的进步，包括新的音频能力和改进的视觉效果，这使其在竞争中挑战了类似 Sora2的产品。</p>
<p>谷歌的整体产品战略是将 Gemini 打造为一个中央工作区，VEO 模型则整合为消费者和企业用户所用。通过在 Vertex AI 上进行的预览发布，企业可以尝试生成视频，而 Gemini 应用程序的主流推广则可以触及普通用户。这种分阶段的发布策略不仅可以<span>最大</span>限度地获取开发者反馈，还能促进公众的接受度，这与谷歌持续努力弥补功能差距并巩固其在生成媒体领域的地位的目标相一致。</p>]]>
    </description>
    <content:encoded><![CDATA[<p>谷歌近期有消息称，VEO3.1的公共发布即将来临。随着 Gemini 应用程序中出现相关免责声明，谷歌正在为广泛用户群展示 VEO3.1的功能，这可能会在用户熟悉的 Gemini 界面中实现。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-75d5aeee11.png"></p>
<p>社区中知名人士 Logan Kilpatrick 在社交媒体平台 X 上发布的帖子被广泛视为谷歌 AI 新产品发布的早期确认。此外，在 Vertex AI 中也出现了 “VEO3.0Generate” 和 “VEO3.0Fast Generate” 等预览模型的引用，这表明谷歌正在为早期用户和企业用户提供多个访问渠道，符合他们在生成视频工具发布中的传统策略。</p>
<p>关于输出时长，社区中的讨论热烈，有证据表明视频时长可能从之前的8秒延长至30秒，尽管这一点尚待确认。过去的泄露信息显示，快速模式的质量较低，而标准模式预计将解锁更高的输出质量，这对希望提升视觉质量和叙事潜力的创作者尤为重要。根据 TestingCatalog 的报道，之前的720p 视频生成已展现出 VEO3.1的进步，包括新的音频能力和改进的视觉效果，这使其在竞争中挑战了类似 Sora2的产品。</p>
<p>谷歌的整体产品战略是将 Gemini 打造为一个中央工作区，VEO 模型则整合为消费者和企业用户所用。通过在 Vertex AI 上进行的预览发布，企业可以尝试生成视频，而 Gemini 应用程序的主流推广则可以触及普通用户。这种分阶段的发布策略不仅可以<span>最大</span>限度地获取开发者反馈，还能促进公众的接受度，这与谷歌持续努力弥补功能差距并巩固其在生成媒体领域的地位的目标相一致。</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-75d5aeee11.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-75d5aeee11.png" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 18:07:51 +0800</pubDate>
  </item><item>
    <title><![CDATA[腾讯提出无训练优化方法：120 元成本实现传统 7 万元微调效果]]></title>
    <link>https://www.oschina.net/news/377608</link>
    <itunes:title><![CDATA[腾讯提出无训练优化方法：120 元成本实现传统 7 万元微调效果]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>腾讯AI实验室近期<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2510.08191" target="_blank">发布</a>了一种名为"无训练组相对策略优化"（Training-Free GRPO）的新型模型优化技术。这一方法通过外部知识库更新替代传统参数微调，在大幅降低训练成本的同时，实现了与昂贵微调方案相当的性能提升。</p>
<p>该技术的核心创新在于将经验知识转化为token级别的先验信息，使大模型在参数完全冻结的状态下完成性能优化。腾讯研究团队在DeepSeek-V3.1-Terminus模型上进行的实验显示，这种方法在数学推理和网络搜索等任务中均取得了显著效果。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-dcf87efd67.png"></p>
<p>从技术实现角度看，传统大语言模型在处理需要外部工具调用的复杂任务时常常表现欠佳。而Training-Free GRPO通过保持模型主体参数不变，仅动态维护一个外部经验知识库的方式来提升能力。这种设计不仅大幅削减了计算资源消耗，还增强了模型的跨领域泛化能力。</p>
<p>实验数据具体体现了这一方法的有效性。在数学竞赛级测试AIME24和AIME25中，经过Training-Free GRPO优化的DeepSeek-V3.1-Terminus模型准确率分别从80%和67.9%提升至82.7%和73.3%。更关键的是，这一提升仅使用了100个跨域训练样本，而传统强化学习方法通常需要数千个样本才能达到类似效果，后者的成本往往高达数万美元。</p>
<p>在网络搜索任务的测试中，该方法同样表现出色，模型的Pass@1指标从63.2%提升至67.8%。这一系列测试结果表明，Training-Free GRPO在保持低成本投入的前提下，能够在多种任务类型中实现稳定的性能改善。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-b881eab620.png"></p>
<p>从成本对比来看，官方数据显示使用Training-Free GRPO优化一个模型仅需约120元人民币，而传统的参数微调方案通常需要投入7万元左右的计算资源。这一成本差距主要源于该方法无需进行梯度回传和参数更新等计算密集型操作。</p>
<p>这项技术的发布为AI模型优化提供了新的思路方向。特别是对于资源受限的中小企业和研究机构而言，这种低成本高效率的优化方案降低了大模型应用的门槛。不过需要注意的是，该方法的适用范围和在更多场景下的表现还有待进一步验证，当前公布的测试数据主要集中在数学推理和信息检索等特定任务上。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>腾讯AI实验室近期<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2510.08191" target="_blank">发布</a>了一种名为"无训练组相对策略优化"（Training-Free GRPO）的新型模型优化技术。这一方法通过外部知识库更新替代传统参数微调，在大幅降低训练成本的同时，实现了与昂贵微调方案相当的性能提升。</p>
<p>该技术的核心创新在于将经验知识转化为token级别的先验信息，使大模型在参数完全冻结的状态下完成性能优化。腾讯研究团队在DeepSeek-V3.1-Terminus模型上进行的实验显示，这种方法在数学推理和网络搜索等任务中均取得了显著效果。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-dcf87efd67.png"></p>
<p>从技术实现角度看，传统大语言模型在处理需要外部工具调用的复杂任务时常常表现欠佳。而Training-Free GRPO通过保持模型主体参数不变，仅动态维护一个外部经验知识库的方式来提升能力。这种设计不仅大幅削减了计算资源消耗，还增强了模型的跨领域泛化能力。</p>
<p>实验数据具体体现了这一方法的有效性。在数学竞赛级测试AIME24和AIME25中，经过Training-Free GRPO优化的DeepSeek-V3.1-Terminus模型准确率分别从80%和67.9%提升至82.7%和73.3%。更关键的是，这一提升仅使用了100个跨域训练样本，而传统强化学习方法通常需要数千个样本才能达到类似效果，后者的成本往往高达数万美元。</p>
<p>在网络搜索任务的测试中，该方法同样表现出色，模型的Pass@1指标从63.2%提升至67.8%。这一系列测试结果表明，Training-Free GRPO在保持低成本投入的前提下，能够在多种任务类型中实现稳定的性能改善。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-b881eab620.png"></p>
<p>从成本对比来看，官方数据显示使用Training-Free GRPO优化一个模型仅需约120元人民币，而传统的参数微调方案通常需要投入7万元左右的计算资源。这一成本差距主要源于该方法无需进行梯度回传和参数更新等计算密集型操作。</p>
<p>这项技术的发布为AI模型优化提供了新的思路方向。特别是对于资源受限的中小企业和研究机构而言，这种低成本高效率的优化方案降低了大模型应用的门槛。不过需要注意的是，该方法的适用范围和在更多场景下的表现还有待进一步验证，当前公布的测试数据主要集中在数学推理和信息检索等特定任务上。</p>]]>
    </description>
    <content:encoded><![CDATA[<p>腾讯AI实验室近期<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2510.08191" target="_blank">发布</a>了一种名为"无训练组相对策略优化"（Training-Free GRPO）的新型模型优化技术。这一方法通过外部知识库更新替代传统参数微调，在大幅降低训练成本的同时，实现了与昂贵微调方案相当的性能提升。</p>
<p>该技术的核心创新在于将经验知识转化为token级别的先验信息，使大模型在参数完全冻结的状态下完成性能优化。腾讯研究团队在DeepSeek-V3.1-Terminus模型上进行的实验显示，这种方法在数学推理和网络搜索等任务中均取得了显著效果。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-dcf87efd67.png"></p>
<p>从技术实现角度看，传统大语言模型在处理需要外部工具调用的复杂任务时常常表现欠佳。而Training-Free GRPO通过保持模型主体参数不变，仅动态维护一个外部经验知识库的方式来提升能力。这种设计不仅大幅削减了计算资源消耗，还增强了模型的跨领域泛化能力。</p>
<p>实验数据具体体现了这一方法的有效性。在数学竞赛级测试AIME24和AIME25中，经过Training-Free GRPO优化的DeepSeek-V3.1-Terminus模型准确率分别从80%和67.9%提升至82.7%和73.3%。更关键的是，这一提升仅使用了100个跨域训练样本，而传统强化学习方法通常需要数千个样本才能达到类似效果，后者的成本往往高达数万美元。</p>
<p>在网络搜索任务的测试中，该方法同样表现出色，模型的Pass@1指标从63.2%提升至67.8%。这一系列测试结果表明，Training-Free GRPO在保持低成本投入的前提下，能够在多种任务类型中实现稳定的性能改善。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-b881eab620.png"></p>
<p>从成本对比来看，官方数据显示使用Training-Free GRPO优化一个模型仅需约120元人民币，而传统的参数微调方案通常需要投入7万元左右的计算资源。这一成本差距主要源于该方法无需进行梯度回传和参数更新等计算密集型操作。</p>
<p>这项技术的发布为AI模型优化提供了新的思路方向。特别是对于资源受限的中小企业和研究机构而言，这种低成本高效率的优化方案降低了大模型应用的门槛。不过需要注意的是，该方法的适用范围和在更多场景下的表现还有待进一步验证，当前公布的测试数据主要集中在数学推理和信息检索等特定任务上。</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-dcf87efd67.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-dcf87efd67.png" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 17:43:39 +0800</pubDate>
  </item><item>
    <title><![CDATA[马斯克：xAI 将大力投入视频游戏，因为我喜欢玩、赚钱是次要的]]></title>
    <link>https://www.oschina.net/news/377603</link>
    <itunes:title><![CDATA[马斯克：xAI 将大力投入视频游戏，因为我喜欢玩、赚钱是次要的]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>特斯拉首席执行官马斯克表示，他旗下的人工智能公司xAI将很快利用先进的“世界模型”（world models）大举进军电子游戏领域。</p>
<p>他在社交平台X上发文称：“xAI将大力投入视频游戏，因为我热爱并经常玩电子游戏。赚钱是次要的事情。”</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-369cee6f91.png"></p>
<p>这一表态是马斯克对《金融时报》关于该公司招聘英伟达专家报道的回应。<a href="https://www.oschina.net/news/377075" target="_blank">此前相关报道称</a>，马斯克的xAI正在开发一种名为“世界模型”的技术，这是一类新一代人工智能系统，旨在理解现实世界。</p>
<p><span>xAI 计划通过世界模型实现 “物理规律理解”，使 AI 能模拟真实环境并实时交互。首批应用聚焦游戏领域，目标 2026 年底推出由 AI 动态生成的 3D 游戏，场景可随玩家行为实时变化。</span></p>
<p>据了解，“世界模型”通过训练来自视频和机器人采集的数据来理解现实世界，其能力有望超越主要基于文本训练的大语言模型。在最近的一次发文中，马斯克确认了他去年提出的目标：xAI将在“明年年底前发布一款出色的AI生成游戏”</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>特斯拉首席执行官马斯克表示，他旗下的人工智能公司xAI将很快利用先进的“世界模型”（world models）大举进军电子游戏领域。</p>
<p>他在社交平台X上发文称：“xAI将大力投入视频游戏，因为我热爱并经常玩电子游戏。赚钱是次要的事情。”</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-369cee6f91.png"></p>
<p>这一表态是马斯克对《金融时报》关于该公司招聘英伟达专家报道的回应。<a href="https://www.oschina.net/news/377075" target="_blank">此前相关报道称</a>，马斯克的xAI正在开发一种名为“世界模型”的技术，这是一类新一代人工智能系统，旨在理解现实世界。</p>
<p><span>xAI 计划通过世界模型实现 “物理规律理解”，使 AI 能模拟真实环境并实时交互。首批应用聚焦游戏领域，目标 2026 年底推出由 AI 动态生成的 3D 游戏，场景可随玩家行为实时变化。</span></p>
<p>据了解，“世界模型”通过训练来自视频和机器人采集的数据来理解现实世界，其能力有望超越主要基于文本训练的大语言模型。在最近的一次发文中，马斯克确认了他去年提出的目标：xAI将在“明年年底前发布一款出色的AI生成游戏”</p>]]>
    </description>
    <content:encoded><![CDATA[<p>特斯拉首席执行官马斯克表示，他旗下的人工智能公司xAI将很快利用先进的“世界模型”（world models）大举进军电子游戏领域。</p>
<p>他在社交平台X上发文称：“xAI将大力投入视频游戏，因为我热爱并经常玩电子游戏。赚钱是次要的事情。”</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-369cee6f91.png"></p>
<p>这一表态是马斯克对《金融时报》关于该公司招聘英伟达专家报道的回应。<a href="https://www.oschina.net/news/377075" target="_blank">此前相关报道称</a>，马斯克的xAI正在开发一种名为“世界模型”的技术，这是一类新一代人工智能系统，旨在理解现实世界。</p>
<p><span>xAI 计划通过世界模型实现 “物理规律理解”，使 AI 能模拟真实环境并实时交互。首批应用聚焦游戏领域，目标 2026 年底推出由 AI 动态生成的 3D 游戏，场景可随玩家行为实时变化。</span></p>
<p>据了解，“世界模型”通过训练来自视频和机器人采集的数据来理解现实世界，其能力有望超越主要基于文本训练的大语言模型。在最近的一次发文中，马斯克确认了他去年提出的目标：xAI将在“明年年底前发布一款出色的AI生成游戏”</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-369cee6f91.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-369cee6f91.png" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 17:30:24 +0800</pubDate>
  </item><item>
    <title><![CDATA[deepin 大佬为爱发电「极简待办神器」，实力颜值双在线]]></title>
    <link>https://www.oschina.net/news/377600</link>
    <itunes:title><![CDATA[deepin 大佬为爱发电「极简待办神器」，实力颜值双在线]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<div>
<div>
<p><span><span>你是否也曾被琐碎的任务淹没，忙到忘记自己做到哪一步？尝试过多种待办工具，却总被频繁的广告、联网、或是永中的功能一次次劝退？</span></span></p>
<p><span>正是洞察到这一痛点，deepin(深度)社区用户@Anthony Lu 开发了一款简洁、美观、本地化的待办管理工具——uyouToDo。不仅完全免费，还没有任何广告和冗余功能，只为还原一个清爽高效的任务管理体验。</span></p>
<h2><span>关于uyou ToDo</span></h2>
<p><span>uyou ToDo 是一款基于 Electron 和 Vue.js 构建的本地开源待办事项管理工具。</span></p>
<p><span>它</span><span>支持 Windows、macOS、Linux、Android 及浏览器扩展等多个平台，集任务创建、分类管理、进度跟踪、多设备同步等核心功能于一身，满足不同场景下的记录与管理需求。</span></p>
<p><strong><strong>极简视觉设计</strong></strong></p>
<ul>
<li><span>高颜值设计：界面设计高度致敬经典的锤子便签风格，采用毛玻璃模糊效果，观感清新舒适；</span></li>
<li><span>双模式启航：首次使用时，可在「标准模式」和更具沉浸感的「便签纸模式」中自由选择；</span></li>
<li><span>极简主义：若觉得标准功能仍显复杂，只需在设置中一键开启 </span><strong><strong>“简易模式”</strong></strong><span> ，即可享受极致的轻量操作。</span></li>
</ul>
</div>
</div>
<div>
<div>
<p><img align="left" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-ffa148b98b.jpg"></p>
</div>
</div>
<div>
<div>
<p><strong><strong><strong>强大的任务管理</strong></strong></strong></p>
<ul>
<li><span>任务创建与分类：自由创建任务，并支持自定义分类（工作、学习、生活等）；</span></li>
<li><span>优先级与提醒：可为重要任务设置高优先级和截止时间，临期自动提醒；</span></li>
<li><span>进度跟踪：实时更新任务进度，清晰掌握完成情况；</span></li>
<li><span>重复任务：支持为固定事项设置重复规则，如每周例会、每日打卡等。</span></li>
</ul>
</div>
</div>
<div>
<div>
<p><img align="left" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-9c20c3fdd7.jpg"></p>
</div>
</div>
<div>
<div>
<p><strong><strong><strong>多平台数据同步与本地备份</strong></strong></strong></p>
<ul>
<li><span>数据同步：登录同一账号，即可在电脑、手机、平板等多设备间实时同步任务数据；</span></li>
<li><span>本地备份：自 3.1.0 版本起，新增本地备份功能，可手动备份任务与分类数据，方便在不同设备间迁移，保障数据安全；</span></li>
<li><span>一键清理：支持一键删除所有已完成任务，助你快速清空已完成事项，保持界面持久清爽。</span></li>
</ul>
</div>
</div>
<div>
<div>
<p><img align="left" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-1acd1bd503.jpg"></p>
</div>
</div>
<div>
<div>
<h2><span>安装与获取</span></h2>
<p><span>目前，uyouToDo已上架 deepin 应用商店，deepin 用户可直接从应用商店一键下载安装体验。</span></p>
</div>
</div>
<div>
<div>
<p><img align="left" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6d78f65f24.jpg"></p>
</div>
</div>
<div>
<div>
<p><span>其他 Linux 发行版用户可从下方项目地址通过 .deb 安装包进行安装，欢迎大家使用与反馈。</span></p>
<p><span>项目地址：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ftonylu110%2Fuyou-todo-electron" target="_blank"><span>https://github.com/tonylu110/uyou-todo-electron</span></a></p>
<h2><strong><strong>参与共建</strong></strong></h2>
<p><span><span>uyouToDo 目前仍是一款“冷门但用心”的小众工具，</span></span><span>我们由衷感谢 deepin 社区用户 </span><strong><strong>@Anthony Lu</strong></strong><span> 的卓越贡献与投递。deepin 的应用繁荣生态离不开每一位社区成员，无论您是应用的开发者还是愿意参与维护的热心用户，都欢迎通过「社区投递系统」加入我们，共同丰富 deepin 的应用生态。</span></p>
<p><strong><strong><strong>社区投递系统使用说明</strong></strong></strong></p>
<p><span><span>1、通过 deepin 官网进入社区应用投递系统，并登录 deepin(深度)社区账号。</span></span></p>
</div>
</div>
<div>
<div>
<p><img align="center" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-47d0bb7caa.jpg"></p>
</div>
</div>
<div>
<div>
<p><span><span>2、点击右上角“上传应用”进行应用投递。</span></span></p>
<p><img align="center" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-4e3b4d0de0.jpg"></p>
<div>
<div>
<p><span><span>3、应用维护</span></span></p>
<p><span><span>成功投递应用后会进入审核流程，您可以在平台中查看审核进度，并对已投递的应用进行版本更新、信息维护等操作。</span></span></p>
</div>
</div>
</div>
</div>]]>
    </itunes:summary>
    <description>
      <![CDATA[<div>
<div>
<p><span><span>你是否也曾被琐碎的任务淹没，忙到忘记自己做到哪一步？尝试过多种待办工具，却总被频繁的广告、联网、或是永中的功能一次次劝退？</span></span></p>
<p><span>正是洞察到这一痛点，deepin(深度)社区用户@Anthony Lu 开发了一款简洁、美观、本地化的待办管理工具——uyouToDo。不仅完全免费，还没有任何广告和冗余功能，只为还原一个清爽高效的任务管理体验。</span></p>
<h2><span>关于uyou ToDo</span></h2>
<p><span>uyou ToDo 是一款基于 Electron 和 Vue.js 构建的本地开源待办事项管理工具。</span></p>
<p><span>它</span><span>支持 Windows、macOS、Linux、Android 及浏览器扩展等多个平台，集任务创建、分类管理、进度跟踪、多设备同步等核心功能于一身，满足不同场景下的记录与管理需求。</span></p>
<p><strong><strong>极简视觉设计</strong></strong></p>
<ul>
<li><span>高颜值设计：界面设计高度致敬经典的锤子便签风格，采用毛玻璃模糊效果，观感清新舒适；</span></li>
<li><span>双模式启航：首次使用时，可在「标准模式」和更具沉浸感的「便签纸模式」中自由选择；</span></li>
<li><span>极简主义：若觉得标准功能仍显复杂，只需在设置中一键开启 </span><strong><strong>“简易模式”</strong></strong><span> ，即可享受极致的轻量操作。</span></li>
</ul>
</div>
</div>
<div>
<div>
<p><img align="left" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-ffa148b98b.jpg"></p>
</div>
</div>
<div>
<div>
<p><strong><strong><strong>强大的任务管理</strong></strong></strong></p>
<ul>
<li><span>任务创建与分类：自由创建任务，并支持自定义分类（工作、学习、生活等）；</span></li>
<li><span>优先级与提醒：可为重要任务设置高优先级和截止时间，临期自动提醒；</span></li>
<li><span>进度跟踪：实时更新任务进度，清晰掌握完成情况；</span></li>
<li><span>重复任务：支持为固定事项设置重复规则，如每周例会、每日打卡等。</span></li>
</ul>
</div>
</div>
<div>
<div>
<p><img align="left" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-9c20c3fdd7.jpg"></p>
</div>
</div>
<div>
<div>
<p><strong><strong><strong>多平台数据同步与本地备份</strong></strong></strong></p>
<ul>
<li><span>数据同步：登录同一账号，即可在电脑、手机、平板等多设备间实时同步任务数据；</span></li>
<li><span>本地备份：自 3.1.0 版本起，新增本地备份功能，可手动备份任务与分类数据，方便在不同设备间迁移，保障数据安全；</span></li>
<li><span>一键清理：支持一键删除所有已完成任务，助你快速清空已完成事项，保持界面持久清爽。</span></li>
</ul>
</div>
</div>
<div>
<div>
<p><img align="left" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-1acd1bd503.jpg"></p>
</div>
</div>
<div>
<div>
<h2><span>安装与获取</span></h2>
<p><span>目前，uyouToDo已上架 deepin 应用商店，deepin 用户可直接从应用商店一键下载安装体验。</span></p>
</div>
</div>
<div>
<div>
<p><img align="left" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6d78f65f24.jpg"></p>
</div>
</div>
<div>
<div>
<p><span>其他 Linux 发行版用户可从下方项目地址通过 .deb 安装包进行安装，欢迎大家使用与反馈。</span></p>
<p><span>项目地址：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ftonylu110%2Fuyou-todo-electron" target="_blank"><span>https://github.com/tonylu110/uyou-todo-electron</span></a></p>
<h2><strong><strong>参与共建</strong></strong></h2>
<p><span><span>uyouToDo 目前仍是一款“冷门但用心”的小众工具，</span></span><span>我们由衷感谢 deepin 社区用户 </span><strong><strong>@Anthony Lu</strong></strong><span> 的卓越贡献与投递。deepin 的应用繁荣生态离不开每一位社区成员，无论您是应用的开发者还是愿意参与维护的热心用户，都欢迎通过「社区投递系统」加入我们，共同丰富 deepin 的应用生态。</span></p>
<p><strong><strong><strong>社区投递系统使用说明</strong></strong></strong></p>
<p><span><span>1、通过 deepin 官网进入社区应用投递系统，并登录 deepin(深度)社区账号。</span></span></p>
</div>
</div>
<div>
<div>
<p><img align="center" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-47d0bb7caa.jpg"></p>
</div>
</div>
<div>
<div>
<p><span><span>2、点击右上角“上传应用”进行应用投递。</span></span></p>
<p><img align="center" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-4e3b4d0de0.jpg"></p>
<div>
<div>
<p><span><span>3、应用维护</span></span></p>
<p><span><span>成功投递应用后会进入审核流程，您可以在平台中查看审核进度，并对已投递的应用进行版本更新、信息维护等操作。</span></span></p>
</div>
</div>
</div>
</div>]]>
    </description>
    <content:encoded><![CDATA[<div>
<div>
<p><span><span>你是否也曾被琐碎的任务淹没，忙到忘记自己做到哪一步？尝试过多种待办工具，却总被频繁的广告、联网、或是永中的功能一次次劝退？</span></span></p>
<p><span>正是洞察到这一痛点，deepin(深度)社区用户@Anthony Lu 开发了一款简洁、美观、本地化的待办管理工具——uyouToDo。不仅完全免费，还没有任何广告和冗余功能，只为还原一个清爽高效的任务管理体验。</span></p>
<h2><span>关于uyou ToDo</span></h2>
<p><span>uyou ToDo 是一款基于 Electron 和 Vue.js 构建的本地开源待办事项管理工具。</span></p>
<p><span>它</span><span>支持 Windows、macOS、Linux、Android 及浏览器扩展等多个平台，集任务创建、分类管理、进度跟踪、多设备同步等核心功能于一身，满足不同场景下的记录与管理需求。</span></p>
<p><strong><strong>极简视觉设计</strong></strong></p>
<ul>
<li><span>高颜值设计：界面设计高度致敬经典的锤子便签风格，采用毛玻璃模糊效果，观感清新舒适；</span></li>
<li><span>双模式启航：首次使用时，可在「标准模式」和更具沉浸感的「便签纸模式」中自由选择；</span></li>
<li><span>极简主义：若觉得标准功能仍显复杂，只需在设置中一键开启 </span><strong><strong>“简易模式”</strong></strong><span> ，即可享受极致的轻量操作。</span></li>
</ul>
</div>
</div>
<div>
<div>
<p><img align="left" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-ffa148b98b.jpg"></p>
</div>
</div>
<div>
<div>
<p><strong><strong><strong>强大的任务管理</strong></strong></strong></p>
<ul>
<li><span>任务创建与分类：自由创建任务，并支持自定义分类（工作、学习、生活等）；</span></li>
<li><span>优先级与提醒：可为重要任务设置高优先级和截止时间，临期自动提醒；</span></li>
<li><span>进度跟踪：实时更新任务进度，清晰掌握完成情况；</span></li>
<li><span>重复任务：支持为固定事项设置重复规则，如每周例会、每日打卡等。</span></li>
</ul>
</div>
</div>
<div>
<div>
<p><img align="left" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-9c20c3fdd7.jpg"></p>
</div>
</div>
<div>
<div>
<p><strong><strong><strong>多平台数据同步与本地备份</strong></strong></strong></p>
<ul>
<li><span>数据同步：登录同一账号，即可在电脑、手机、平板等多设备间实时同步任务数据；</span></li>
<li><span>本地备份：自 3.1.0 版本起，新增本地备份功能，可手动备份任务与分类数据，方便在不同设备间迁移，保障数据安全；</span></li>
<li><span>一键清理：支持一键删除所有已完成任务，助你快速清空已完成事项，保持界面持久清爽。</span></li>
</ul>
</div>
</div>
<div>
<div>
<p><img align="left" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-1acd1bd503.jpg"></p>
</div>
</div>
<div>
<div>
<h2><span>安装与获取</span></h2>
<p><span>目前，uyouToDo已上架 deepin 应用商店，deepin 用户可直接从应用商店一键下载安装体验。</span></p>
</div>
</div>
<div>
<div>
<p><img align="left" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6d78f65f24.jpg"></p>
</div>
</div>
<div>
<div>
<p><span>其他 Linux 发行版用户可从下方项目地址通过 .deb 安装包进行安装，欢迎大家使用与反馈。</span></p>
<p><span>项目地址：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ftonylu110%2Fuyou-todo-electron" target="_blank"><span>https://github.com/tonylu110/uyou-todo-electron</span></a></p>
<h2><strong><strong>参与共建</strong></strong></h2>
<p><span><span>uyouToDo 目前仍是一款“冷门但用心”的小众工具，</span></span><span>我们由衷感谢 deepin 社区用户 </span><strong><strong>@Anthony Lu</strong></strong><span> 的卓越贡献与投递。deepin 的应用繁荣生态离不开每一位社区成员，无论您是应用的开发者还是愿意参与维护的热心用户，都欢迎通过「社区投递系统」加入我们，共同丰富 deepin 的应用生态。</span></p>
<p><strong><strong><strong>社区投递系统使用说明</strong></strong></strong></p>
<p><span><span>1、通过 deepin 官网进入社区应用投递系统，并登录 deepin(深度)社区账号。</span></span></p>
</div>
</div>
<div>
<div>
<p><img align="center" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-47d0bb7caa.jpg"></p>
</div>
</div>
<div>
<div>
<p><span><span>2、点击右上角“上传应用”进行应用投递。</span></span></p>
<p><img align="center" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-4e3b4d0de0.jpg"></p>
<div>
<div>
<p><span><span>3、应用维护</span></span></p>
<p><span><span>成功投递应用后会进入审核流程，您可以在平台中查看审核进度，并对已投递的应用进行版本更新、信息维护等操作。</span></span></p>
</div>
</div>
</div>
</div>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-ffa148b98b.jpg"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-ffa148b98b.jpg" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 17:16:35 +0800</pubDate>
  </item><item>
    <title><![CDATA[ODC25 内容生态分论坛： 聚焦 AI 与全场景协同，共创内容增长新路径]]></title>
    <link>https://www.oschina.net/news/377599</link>
    <itunes:title><![CDATA[ODC25 内容生态分论坛： 聚焦 AI 与全场景协同，共创内容增长新路径]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p><span><span><span><span>10 月 15 日，2025 年 OPPO 开发者大会（ODC25）在深圳国际会展中心召开。作为大会的重要组成部分，内容生态分论坛系统性展示了&nbsp;OPPO&nbsp;在内容场景升级、分发机制革新、创作者赋能等领域的战略布局。论坛围绕浏览器、信息流、全局搜索、桌面上滑·今日、视频、乐划锁屏、主题商店七大产品矩阵，结合AI能力与 OS&nbsp;全场景联动能力，为行业探索内容价值增长提供了可落地的新玩法。</span></span></span></span></p>
<p><span><strong><span><span><strong>OPPO浏览器：AI 重塑浏览效率，开放生态赋能伙伴增长</strong></span></span></strong></span></p>
<p><span><span><span><span>当用户需求从海量搜索迈向精准答案与即时服务，浏览器这一最经典的工具正被AI技术重新定义。从“连接信息”到“赋能服务”，OPPO浏览器已成为2.2亿月活用户获取信息、解决问题的高效平台。</span></span></span></span></p>
<p><span><span><span><span>“AI能力正在重塑浏览效率，帮助用户更快搜到结果、更轻松理解内容、更无缝享受服务。”浏览器高级产品经理刘叶介绍。通过深度集成包括DeepSeek在内的多家AI大模型能力，用户既可以自行浏览网页寻求答案，也可以选择让AI实时生成一个精准、摘要式的总结性回答；此外，浏览器还配置多种AI Agent，围绕学习、办公、出行等场景，提供定制化方案，切实贴合用户需求。</span></span></span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-ae1ceee95b.png"></p>
<p><em><span><span><span><span>OPPO 浏览器高级产品经理 刘叶</span></span></span></span></em></p>
<p><span><span><span><span>持续升级用户体验的同时，OPPO浏览器不断释放全域生态价值，通过&nbsp;“一端接入、全域分发”的轻量化合作模式，为合作伙伴提供日均超 11 亿次曝光资源。合作方仅需一步内容接入，即可获得固定展示入口、全链路功能支持及专业运营服务，这既带来了可观的流量分成收益，也开辟了与平台生态共同成长的新路径。OPPO浏览器正与合作伙伴携手，实现内容价值与用户需求的双向奔赴。</span></span></span></span></p>
<p><span><strong><span><span><strong>桌面上滑·今日：一步即达，打造“与我有关”的内容中心</strong></span></span></strong></span></p>
<p><span><span><span><span>基于对用户内容获取需求的深度洞察，在本次开发者大会上，OPPO推出了全新桌面级入口“桌面上滑・今日”，该功能支持用户在桌面任意界面通过上滑手势，直接唤起内容聚合界面，无需跳转不同应用即可访问个性化内容流。</span></span></span></span></p>
<p><span><span><span><span>“桌面上滑・今日”以全网内容聚合为核心能力，据悉，目前已接入B站、抖音、快手等多个平台，支持显示用户关注列表、感兴趣内容与浏览历史。此外，据桌面上滑高级产品经理陈沛楠介绍，其功能同时接入了多家头部平台的影视、小说等优质热门IP资源，能够通过统一入口解决用户跨平台内容获取的痛点，实现从分散浏览到集约化管理的体验升级。“我们希望为用户打造一个专属的内容资产中心，真正实现从'多平台分散浏览'到'一人一中心'的内容体验升级。”陈沛楠表示。</span></span></span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-8bc5f2ca7b.png"></p>
<p><em><span><span><span>OPPO 桌面上滑高级产品经理 陈沛楠</span></span></span></em></p>
<p><span><span><span><span>据透露，该功能未来将拓展内容维度，计划接入游戏、电商、本地生活等多元内容，打造一个集成度更高、便捷性更强的全新一站式内容入口。“桌面上滑・今日”预计 2025 年底用户规模将突破 2000 万，相关负责人表示，希望“桌面上滑 · 今日”成为内容合作伙伴的新增长渠道。</span></span></span></span></p>
<p><span><strong><span><span><strong>OPPO视频：全域整合视界，让精彩内容随“触”可得</strong></span></span></strong></span></p>
<p><span><span><span><span>视频内容日益丰富的今天，用户却常面临“内容难寻”的困境。为此，OPPO 视频通过深度开放合作与系统级全场景融合，让优质影视内容真正“随需可见”。</span></span></span></span></p>
<p><span><span><span><span>OPPO 视频以轻量化方式引入优酷、央视频等多家主流平台资源，通过内嵌快应用、H5 页面等灵活形式，放大内容价值—— 用户无需反复跳转或下载独立应用，在OPPO 视频里即可直接观看。内容呈现方面，视频入口已覆盖包括锁屏、信息流、全局搜索在内的OS系统全场景，并通过多种创新方式进行内容推荐，其中锁屏场景通过图文标签自动关联 IP 内容，用户看到感兴趣的标签后，点击即可直达视频内容，进行深入了解。</span></span></span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-eb9f88ff95.png"></p>
<p><em><span><span><span>OPPO 视频高级产品运营经理 苏胜波</span></span></span></em></p>
<p><span><span><span><span>同时，OPPO 视频推出“繁星计划”，旨在全面布局精品化、一体化、系列化的视频服务生态。依托日覆盖影视用户超6000万、年累计播放用户达2.1亿的庞大用户基础，OPPO视频将通过“1+N”多端场景联动能力和高效分发体系，与合作伙伴建立更为紧密、常态的协作机制，聚力共筑视频服务新生态。</span></span></span></span></p>
<p><span><strong><span><span><strong>乐划锁屏：点亮屏幕即惊喜，打造“千面锁屏”新体验</strong></span></span></strong></span></p>
<p><span><span><span><span>点亮手机屏幕，即可进入一个轻量化的内容空间——OPPO乐划锁屏凭借90 亿次日均曝光、超千万用户互动的活跃生态，正成为越来越多用户利用碎片化时间进行“数字小憩”的首选。</span></span></span></span></p>
<p><span><span><span><span>据OPPO 乐划锁屏运营负责人郑金晶介绍，乐划锁屏已覆盖资讯、影视、游戏、知识等多类垂直内容，从泛大众关注的潮流热点到特定群体偏好的教育类信息，可基于用户画像实现个性化推送，真正做到“一屏千面，因人而异”。此外，针对晨起、晚间等不同时段，乐划锁屏还推出“早安壁纸”“入梦书单”等场景化内容，支持用户一键订阅，即亮即看。</span></span></span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-16dc1522f1.png"></p>
<p><em><span><span><span>OPPO 乐划锁屏高级产品经理</span></span></span></em></p>
<p><span><span><span><span>在助力合作伙伴实现高效触达方面，乐划锁屏通过合作分级，定制差异化宣推策略、IP 联动、热点营销等方式，持续放大品牌传播价值。据透露，电影《长安的荔枝》在与乐划锁屏的合作推广中，单周曝光超4.6亿次；同程“五一旅行”活动期间，总曝光量近3843万，互动人数突破200万。据悉，乐划锁屏正逐步构建跨端、跨场景的内容协同生态，已完成与负一屏等系统级场景的打通，为合作伙伴拓展了更多元的用户连接路径。</span></span></span></span></p>
<p><span><strong><span><span><strong>OPPO主题商店：AI 赋能创作者全链路，全球化布局开拓增量空间</strong></span></span></strong></span></p>
<p><span><span><span><span>作为OPPO内容生态的重要组成部分，OPPO主题商店已成为用户个性化装扮和创作者变现的关键平台。大会数据显示，&nbsp;OPPO 主题商店月装扮用户已超过4000万、月付费用户近1000 万，头部个人创作者凭借优质主题、字体和壁纸等内容，月平均收益可达10万元以上。</span></span></span></span></p>
<p><span><span><span><span>为帮助更多创作者把握生态机遇，OPPO 主题商店正通过市场洞察与AI技术全面赋能创作流程。据 OPPO 个性化增值高级产品运营经理蔡彩玲介绍，新升级的 5.0 标签体系结合即将上线的可视化词云功能，可清晰呈现热门趋势与市场机会，辅助创作者精准定位创作方向。此外，AI 技术也已深入创作全流程：通过主题编辑器，用户仅需提供基础图标，即可延展为成套或切换视觉风格的图标，显著提升创作效率；AI 辅助审核有助于筛除低质内容，加速作品上线，进一步优化内容生态。</span></span></span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-f19fbafae0.png"></p>
<p><em><span><span><span>OPPO 个性化增值高级产品运营经理 蔡彩玲</span></span></span></em></p>
<p><span><span><span><span>据透露，OPPO主题商店即将面向全球六大区域、200多个国家开放内容分发通道。未来，创作者的一套壁纸、一款主题，不仅能被国内用户看到，还将触达海外超5亿用户，实现“一次创作，全球分发”。</span></span></span></span></p>
<p><span><strong><span><span><strong>OPPO信息流：聚焦年轻用户，构建优质内容增长生态</strong></span></span></strong></span></p>
<p><span><span><span><span>基于对年轻群体内容偏好的洞察，OPPO 信息流已在影视、旅行、学习等核心领域开展深度运营，并将推出“AI日报”“热点大事件”等创新内容栏目，旨在为年轻用户提供“有吸引力、有实用性”的浏览体验。</span></span></span></span></p>
<p><span><span><span><span>提升内容触达精准度的同时，OPPO信息流也建立了符合“真、善、美”价值导向的内容标准，并通过成本与流量的资源倾斜调配，推动优质内容的创作与分发。据透露，过去一年信息流优质内容曝光量增长 135%，消费量提升 116%。</span></span></span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-7e524376d9.png"></p>
<p><em><span><span><span>OPPO 信息流高级产品运营经理 杨秀君</span></span></span></em></p>
<p><span><span><span><span>据OPPO信息流高级产品运营经理杨秀君介绍，为实现健康、可持续的内容生态循环，OPPO信息流正持续完善优质内容的识别与推荐机制，从海量信息中筛选高质量内容，并深化对优质内容特征与用户偏好的理解，通过双向优化，为合作伙伴搭建了一条触达年轻消费群体的新通道。</span></span></span></span></p>
<p><span><strong><span><span><strong>OPPO全局搜索：从“即搜即得”到“服务直达”，开放合作提升转化效率</strong></span></span></strong></span></p>
<p><span><span><span><span>随着用户搜索行为逐渐从“寻找答案”转向“解决问题”，移动生态的服务模式也在持续演进。当前，OPPO全局搜索已成为超2亿月活用户解决问题的系统级搜索入口——搜索“省电模式”可直接设置开关，搜索“凡人修仙传”，相关视频和小说的最新内容一点即达，体验变化背后，是全局搜索从“搜本机应用”到“应用服务直达”的升级。</span></span></span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-80ee8f0a9d.png"></p>
<p><em><span><span><span>OPPO 全局搜索高级产品运营经理 袁诗谣</span></span></span></em></p>
<p><span><span><span><span>对合作伙伴而言，全局搜索已成为触达亿级规模用户、提升转化效率的重要渠道。据OPPO全局搜索高级产品运营经理袁诗谣介绍，全局搜索在首页便捷服务专区为开发者提供了多种标准化模板，帮助开发者快速接入，共享日均超亿次的曝光资源；“超级品牌 bigday”活动则支持为合作伙伴提供定制化IP专场服务，帮助合作伙伴提高转化效率。在用户体验方面，全局搜索可精准理解用户搜索意图，并结合AI智能总结展示相关内容，提供一键跳转至第三方应用结果页的服务，减少用户操作步骤，实现高效直达。</span></span></span></span></p>
<p><span><span><span><span>此外，全局搜索还与开发者生态共建“数据捐赠”合作模式，实现“本机应用内容在系统皆可搜到”的愿景，为开发者提供更多更精准的OS生态场景流量，协同推动用户与商业价值的提升。</span></span></span></span></p>
<p><strong><span><span><strong>生态协同共筑未来，OPPO 引领内容生态新增长</strong></span></span></strong></p>
<p><span><span><span><span>本次大会上，OPPO首次完整展示了由七大内容产品构成的生态布局，系统阐述了"AI+全场景"的内容服务战略。据悉，该布局覆盖了浏览器的AI功能升级、桌面上滑入口构建、视频全场景服务、主题商店的AI创作工具等多个维度，旨在通过技术升级与生态协同，让用户更高效便捷地获取优质内容，同时助力创作者和合作伙伴实现增长。</span></span></span></span></p>
<p><span><span><span><span>面向未来发展，OPPO表示将持续投入AI技术研发，深化多场景整合能力，在优化用户内容体验的同时，探索AI时代下的内容价值创新模式，推动内容生态的健康发展与多方共赢。</span></span></span></span></p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p><span><span><span><span>10 月 15 日，2025 年 OPPO 开发者大会（ODC25）在深圳国际会展中心召开。作为大会的重要组成部分，内容生态分论坛系统性展示了&nbsp;OPPO&nbsp;在内容场景升级、分发机制革新、创作者赋能等领域的战略布局。论坛围绕浏览器、信息流、全局搜索、桌面上滑·今日、视频、乐划锁屏、主题商店七大产品矩阵，结合AI能力与 OS&nbsp;全场景联动能力，为行业探索内容价值增长提供了可落地的新玩法。</span></span></span></span></p>
<p><span><strong><span><span><strong>OPPO浏览器：AI 重塑浏览效率，开放生态赋能伙伴增长</strong></span></span></strong></span></p>
<p><span><span><span><span>当用户需求从海量搜索迈向精准答案与即时服务，浏览器这一最经典的工具正被AI技术重新定义。从“连接信息”到“赋能服务”，OPPO浏览器已成为2.2亿月活用户获取信息、解决问题的高效平台。</span></span></span></span></p>
<p><span><span><span><span>“AI能力正在重塑浏览效率，帮助用户更快搜到结果、更轻松理解内容、更无缝享受服务。”浏览器高级产品经理刘叶介绍。通过深度集成包括DeepSeek在内的多家AI大模型能力，用户既可以自行浏览网页寻求答案，也可以选择让AI实时生成一个精准、摘要式的总结性回答；此外，浏览器还配置多种AI Agent，围绕学习、办公、出行等场景，提供定制化方案，切实贴合用户需求。</span></span></span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-ae1ceee95b.png"></p>
<p><em><span><span><span><span>OPPO 浏览器高级产品经理 刘叶</span></span></span></span></em></p>
<p><span><span><span><span>持续升级用户体验的同时，OPPO浏览器不断释放全域生态价值，通过&nbsp;“一端接入、全域分发”的轻量化合作模式，为合作伙伴提供日均超 11 亿次曝光资源。合作方仅需一步内容接入，即可获得固定展示入口、全链路功能支持及专业运营服务，这既带来了可观的流量分成收益，也开辟了与平台生态共同成长的新路径。OPPO浏览器正与合作伙伴携手，实现内容价值与用户需求的双向奔赴。</span></span></span></span></p>
<p><span><strong><span><span><strong>桌面上滑·今日：一步即达，打造“与我有关”的内容中心</strong></span></span></strong></span></p>
<p><span><span><span><span>基于对用户内容获取需求的深度洞察，在本次开发者大会上，OPPO推出了全新桌面级入口“桌面上滑・今日”，该功能支持用户在桌面任意界面通过上滑手势，直接唤起内容聚合界面，无需跳转不同应用即可访问个性化内容流。</span></span></span></span></p>
<p><span><span><span><span>“桌面上滑・今日”以全网内容聚合为核心能力，据悉，目前已接入B站、抖音、快手等多个平台，支持显示用户关注列表、感兴趣内容与浏览历史。此外，据桌面上滑高级产品经理陈沛楠介绍，其功能同时接入了多家头部平台的影视、小说等优质热门IP资源，能够通过统一入口解决用户跨平台内容获取的痛点，实现从分散浏览到集约化管理的体验升级。“我们希望为用户打造一个专属的内容资产中心，真正实现从'多平台分散浏览'到'一人一中心'的内容体验升级。”陈沛楠表示。</span></span></span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-8bc5f2ca7b.png"></p>
<p><em><span><span><span>OPPO 桌面上滑高级产品经理 陈沛楠</span></span></span></em></p>
<p><span><span><span><span>据透露，该功能未来将拓展内容维度，计划接入游戏、电商、本地生活等多元内容，打造一个集成度更高、便捷性更强的全新一站式内容入口。“桌面上滑・今日”预计 2025 年底用户规模将突破 2000 万，相关负责人表示，希望“桌面上滑 · 今日”成为内容合作伙伴的新增长渠道。</span></span></span></span></p>
<p><span><strong><span><span><strong>OPPO视频：全域整合视界，让精彩内容随“触”可得</strong></span></span></strong></span></p>
<p><span><span><span><span>视频内容日益丰富的今天，用户却常面临“内容难寻”的困境。为此，OPPO 视频通过深度开放合作与系统级全场景融合，让优质影视内容真正“随需可见”。</span></span></span></span></p>
<p><span><span><span><span>OPPO 视频以轻量化方式引入优酷、央视频等多家主流平台资源，通过内嵌快应用、H5 页面等灵活形式，放大内容价值—— 用户无需反复跳转或下载独立应用，在OPPO 视频里即可直接观看。内容呈现方面，视频入口已覆盖包括锁屏、信息流、全局搜索在内的OS系统全场景，并通过多种创新方式进行内容推荐，其中锁屏场景通过图文标签自动关联 IP 内容，用户看到感兴趣的标签后，点击即可直达视频内容，进行深入了解。</span></span></span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-eb9f88ff95.png"></p>
<p><em><span><span><span>OPPO 视频高级产品运营经理 苏胜波</span></span></span></em></p>
<p><span><span><span><span>同时，OPPO 视频推出“繁星计划”，旨在全面布局精品化、一体化、系列化的视频服务生态。依托日覆盖影视用户超6000万、年累计播放用户达2.1亿的庞大用户基础，OPPO视频将通过“1+N”多端场景联动能力和高效分发体系，与合作伙伴建立更为紧密、常态的协作机制，聚力共筑视频服务新生态。</span></span></span></span></p>
<p><span><strong><span><span><strong>乐划锁屏：点亮屏幕即惊喜，打造“千面锁屏”新体验</strong></span></span></strong></span></p>
<p><span><span><span><span>点亮手机屏幕，即可进入一个轻量化的内容空间——OPPO乐划锁屏凭借90 亿次日均曝光、超千万用户互动的活跃生态，正成为越来越多用户利用碎片化时间进行“数字小憩”的首选。</span></span></span></span></p>
<p><span><span><span><span>据OPPO 乐划锁屏运营负责人郑金晶介绍，乐划锁屏已覆盖资讯、影视、游戏、知识等多类垂直内容，从泛大众关注的潮流热点到特定群体偏好的教育类信息，可基于用户画像实现个性化推送，真正做到“一屏千面，因人而异”。此外，针对晨起、晚间等不同时段，乐划锁屏还推出“早安壁纸”“入梦书单”等场景化内容，支持用户一键订阅，即亮即看。</span></span></span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-16dc1522f1.png"></p>
<p><em><span><span><span>OPPO 乐划锁屏高级产品经理</span></span></span></em></p>
<p><span><span><span><span>在助力合作伙伴实现高效触达方面，乐划锁屏通过合作分级，定制差异化宣推策略、IP 联动、热点营销等方式，持续放大品牌传播价值。据透露，电影《长安的荔枝》在与乐划锁屏的合作推广中，单周曝光超4.6亿次；同程“五一旅行”活动期间，总曝光量近3843万，互动人数突破200万。据悉，乐划锁屏正逐步构建跨端、跨场景的内容协同生态，已完成与负一屏等系统级场景的打通，为合作伙伴拓展了更多元的用户连接路径。</span></span></span></span></p>
<p><span><strong><span><span><strong>OPPO主题商店：AI 赋能创作者全链路，全球化布局开拓增量空间</strong></span></span></strong></span></p>
<p><span><span><span><span>作为OPPO内容生态的重要组成部分，OPPO主题商店已成为用户个性化装扮和创作者变现的关键平台。大会数据显示，&nbsp;OPPO 主题商店月装扮用户已超过4000万、月付费用户近1000 万，头部个人创作者凭借优质主题、字体和壁纸等内容，月平均收益可达10万元以上。</span></span></span></span></p>
<p><span><span><span><span>为帮助更多创作者把握生态机遇，OPPO 主题商店正通过市场洞察与AI技术全面赋能创作流程。据 OPPO 个性化增值高级产品运营经理蔡彩玲介绍，新升级的 5.0 标签体系结合即将上线的可视化词云功能，可清晰呈现热门趋势与市场机会，辅助创作者精准定位创作方向。此外，AI 技术也已深入创作全流程：通过主题编辑器，用户仅需提供基础图标，即可延展为成套或切换视觉风格的图标，显著提升创作效率；AI 辅助审核有助于筛除低质内容，加速作品上线，进一步优化内容生态。</span></span></span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-f19fbafae0.png"></p>
<p><em><span><span><span>OPPO 个性化增值高级产品运营经理 蔡彩玲</span></span></span></em></p>
<p><span><span><span><span>据透露，OPPO主题商店即将面向全球六大区域、200多个国家开放内容分发通道。未来，创作者的一套壁纸、一款主题，不仅能被国内用户看到，还将触达海外超5亿用户，实现“一次创作，全球分发”。</span></span></span></span></p>
<p><span><strong><span><span><strong>OPPO信息流：聚焦年轻用户，构建优质内容增长生态</strong></span></span></strong></span></p>
<p><span><span><span><span>基于对年轻群体内容偏好的洞察，OPPO 信息流已在影视、旅行、学习等核心领域开展深度运营，并将推出“AI日报”“热点大事件”等创新内容栏目，旨在为年轻用户提供“有吸引力、有实用性”的浏览体验。</span></span></span></span></p>
<p><span><span><span><span>提升内容触达精准度的同时，OPPO信息流也建立了符合“真、善、美”价值导向的内容标准，并通过成本与流量的资源倾斜调配，推动优质内容的创作与分发。据透露，过去一年信息流优质内容曝光量增长 135%，消费量提升 116%。</span></span></span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-7e524376d9.png"></p>
<p><em><span><span><span>OPPO 信息流高级产品运营经理 杨秀君</span></span></span></em></p>
<p><span><span><span><span>据OPPO信息流高级产品运营经理杨秀君介绍，为实现健康、可持续的内容生态循环，OPPO信息流正持续完善优质内容的识别与推荐机制，从海量信息中筛选高质量内容，并深化对优质内容特征与用户偏好的理解，通过双向优化，为合作伙伴搭建了一条触达年轻消费群体的新通道。</span></span></span></span></p>
<p><span><strong><span><span><strong>OPPO全局搜索：从“即搜即得”到“服务直达”，开放合作提升转化效率</strong></span></span></strong></span></p>
<p><span><span><span><span>随着用户搜索行为逐渐从“寻找答案”转向“解决问题”，移动生态的服务模式也在持续演进。当前，OPPO全局搜索已成为超2亿月活用户解决问题的系统级搜索入口——搜索“省电模式”可直接设置开关，搜索“凡人修仙传”，相关视频和小说的最新内容一点即达，体验变化背后，是全局搜索从“搜本机应用”到“应用服务直达”的升级。</span></span></span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-80ee8f0a9d.png"></p>
<p><em><span><span><span>OPPO 全局搜索高级产品运营经理 袁诗谣</span></span></span></em></p>
<p><span><span><span><span>对合作伙伴而言，全局搜索已成为触达亿级规模用户、提升转化效率的重要渠道。据OPPO全局搜索高级产品运营经理袁诗谣介绍，全局搜索在首页便捷服务专区为开发者提供了多种标准化模板，帮助开发者快速接入，共享日均超亿次的曝光资源；“超级品牌 bigday”活动则支持为合作伙伴提供定制化IP专场服务，帮助合作伙伴提高转化效率。在用户体验方面，全局搜索可精准理解用户搜索意图，并结合AI智能总结展示相关内容，提供一键跳转至第三方应用结果页的服务，减少用户操作步骤，实现高效直达。</span></span></span></span></p>
<p><span><span><span><span>此外，全局搜索还与开发者生态共建“数据捐赠”合作模式，实现“本机应用内容在系统皆可搜到”的愿景，为开发者提供更多更精准的OS生态场景流量，协同推动用户与商业价值的提升。</span></span></span></span></p>
<p><strong><span><span><strong>生态协同共筑未来，OPPO 引领内容生态新增长</strong></span></span></strong></p>
<p><span><span><span><span>本次大会上，OPPO首次完整展示了由七大内容产品构成的生态布局，系统阐述了"AI+全场景"的内容服务战略。据悉，该布局覆盖了浏览器的AI功能升级、桌面上滑入口构建、视频全场景服务、主题商店的AI创作工具等多个维度，旨在通过技术升级与生态协同，让用户更高效便捷地获取优质内容，同时助力创作者和合作伙伴实现增长。</span></span></span></span></p>
<p><span><span><span><span>面向未来发展，OPPO表示将持续投入AI技术研发，深化多场景整合能力，在优化用户内容体验的同时，探索AI时代下的内容价值创新模式，推动内容生态的健康发展与多方共赢。</span></span></span></span></p>]]>
    </description>
    <content:encoded><![CDATA[<p><span><span><span><span>10 月 15 日，2025 年 OPPO 开发者大会（ODC25）在深圳国际会展中心召开。作为大会的重要组成部分，内容生态分论坛系统性展示了&nbsp;OPPO&nbsp;在内容场景升级、分发机制革新、创作者赋能等领域的战略布局。论坛围绕浏览器、信息流、全局搜索、桌面上滑·今日、视频、乐划锁屏、主题商店七大产品矩阵，结合AI能力与 OS&nbsp;全场景联动能力，为行业探索内容价值增长提供了可落地的新玩法。</span></span></span></span></p>
<p><span><strong><span><span><strong>OPPO浏览器：AI 重塑浏览效率，开放生态赋能伙伴增长</strong></span></span></strong></span></p>
<p><span><span><span><span>当用户需求从海量搜索迈向精准答案与即时服务，浏览器这一最经典的工具正被AI技术重新定义。从“连接信息”到“赋能服务”，OPPO浏览器已成为2.2亿月活用户获取信息、解决问题的高效平台。</span></span></span></span></p>
<p><span><span><span><span>“AI能力正在重塑浏览效率，帮助用户更快搜到结果、更轻松理解内容、更无缝享受服务。”浏览器高级产品经理刘叶介绍。通过深度集成包括DeepSeek在内的多家AI大模型能力，用户既可以自行浏览网页寻求答案，也可以选择让AI实时生成一个精准、摘要式的总结性回答；此外，浏览器还配置多种AI Agent，围绕学习、办公、出行等场景，提供定制化方案，切实贴合用户需求。</span></span></span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-ae1ceee95b.png"></p>
<p><em><span><span><span><span>OPPO 浏览器高级产品经理 刘叶</span></span></span></span></em></p>
<p><span><span><span><span>持续升级用户体验的同时，OPPO浏览器不断释放全域生态价值，通过&nbsp;“一端接入、全域分发”的轻量化合作模式，为合作伙伴提供日均超 11 亿次曝光资源。合作方仅需一步内容接入，即可获得固定展示入口、全链路功能支持及专业运营服务，这既带来了可观的流量分成收益，也开辟了与平台生态共同成长的新路径。OPPO浏览器正与合作伙伴携手，实现内容价值与用户需求的双向奔赴。</span></span></span></span></p>
<p><span><strong><span><span><strong>桌面上滑·今日：一步即达，打造“与我有关”的内容中心</strong></span></span></strong></span></p>
<p><span><span><span><span>基于对用户内容获取需求的深度洞察，在本次开发者大会上，OPPO推出了全新桌面级入口“桌面上滑・今日”，该功能支持用户在桌面任意界面通过上滑手势，直接唤起内容聚合界面，无需跳转不同应用即可访问个性化内容流。</span></span></span></span></p>
<p><span><span><span><span>“桌面上滑・今日”以全网内容聚合为核心能力，据悉，目前已接入B站、抖音、快手等多个平台，支持显示用户关注列表、感兴趣内容与浏览历史。此外，据桌面上滑高级产品经理陈沛楠介绍，其功能同时接入了多家头部平台的影视、小说等优质热门IP资源，能够通过统一入口解决用户跨平台内容获取的痛点，实现从分散浏览到集约化管理的体验升级。“我们希望为用户打造一个专属的内容资产中心，真正实现从'多平台分散浏览'到'一人一中心'的内容体验升级。”陈沛楠表示。</span></span></span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-8bc5f2ca7b.png"></p>
<p><em><span><span><span>OPPO 桌面上滑高级产品经理 陈沛楠</span></span></span></em></p>
<p><span><span><span><span>据透露，该功能未来将拓展内容维度，计划接入游戏、电商、本地生活等多元内容，打造一个集成度更高、便捷性更强的全新一站式内容入口。“桌面上滑・今日”预计 2025 年底用户规模将突破 2000 万，相关负责人表示，希望“桌面上滑 · 今日”成为内容合作伙伴的新增长渠道。</span></span></span></span></p>
<p><span><strong><span><span><strong>OPPO视频：全域整合视界，让精彩内容随“触”可得</strong></span></span></strong></span></p>
<p><span><span><span><span>视频内容日益丰富的今天，用户却常面临“内容难寻”的困境。为此，OPPO 视频通过深度开放合作与系统级全场景融合，让优质影视内容真正“随需可见”。</span></span></span></span></p>
<p><span><span><span><span>OPPO 视频以轻量化方式引入优酷、央视频等多家主流平台资源，通过内嵌快应用、H5 页面等灵活形式，放大内容价值—— 用户无需反复跳转或下载独立应用，在OPPO 视频里即可直接观看。内容呈现方面，视频入口已覆盖包括锁屏、信息流、全局搜索在内的OS系统全场景，并通过多种创新方式进行内容推荐，其中锁屏场景通过图文标签自动关联 IP 内容，用户看到感兴趣的标签后，点击即可直达视频内容，进行深入了解。</span></span></span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-eb9f88ff95.png"></p>
<p><em><span><span><span>OPPO 视频高级产品运营经理 苏胜波</span></span></span></em></p>
<p><span><span><span><span>同时，OPPO 视频推出“繁星计划”，旨在全面布局精品化、一体化、系列化的视频服务生态。依托日覆盖影视用户超6000万、年累计播放用户达2.1亿的庞大用户基础，OPPO视频将通过“1+N”多端场景联动能力和高效分发体系，与合作伙伴建立更为紧密、常态的协作机制，聚力共筑视频服务新生态。</span></span></span></span></p>
<p><span><strong><span><span><strong>乐划锁屏：点亮屏幕即惊喜，打造“千面锁屏”新体验</strong></span></span></strong></span></p>
<p><span><span><span><span>点亮手机屏幕，即可进入一个轻量化的内容空间——OPPO乐划锁屏凭借90 亿次日均曝光、超千万用户互动的活跃生态，正成为越来越多用户利用碎片化时间进行“数字小憩”的首选。</span></span></span></span></p>
<p><span><span><span><span>据OPPO 乐划锁屏运营负责人郑金晶介绍，乐划锁屏已覆盖资讯、影视、游戏、知识等多类垂直内容，从泛大众关注的潮流热点到特定群体偏好的教育类信息，可基于用户画像实现个性化推送，真正做到“一屏千面，因人而异”。此外，针对晨起、晚间等不同时段，乐划锁屏还推出“早安壁纸”“入梦书单”等场景化内容，支持用户一键订阅，即亮即看。</span></span></span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-16dc1522f1.png"></p>
<p><em><span><span><span>OPPO 乐划锁屏高级产品经理</span></span></span></em></p>
<p><span><span><span><span>在助力合作伙伴实现高效触达方面，乐划锁屏通过合作分级，定制差异化宣推策略、IP 联动、热点营销等方式，持续放大品牌传播价值。据透露，电影《长安的荔枝》在与乐划锁屏的合作推广中，单周曝光超4.6亿次；同程“五一旅行”活动期间，总曝光量近3843万，互动人数突破200万。据悉，乐划锁屏正逐步构建跨端、跨场景的内容协同生态，已完成与负一屏等系统级场景的打通，为合作伙伴拓展了更多元的用户连接路径。</span></span></span></span></p>
<p><span><strong><span><span><strong>OPPO主题商店：AI 赋能创作者全链路，全球化布局开拓增量空间</strong></span></span></strong></span></p>
<p><span><span><span><span>作为OPPO内容生态的重要组成部分，OPPO主题商店已成为用户个性化装扮和创作者变现的关键平台。大会数据显示，&nbsp;OPPO 主题商店月装扮用户已超过4000万、月付费用户近1000 万，头部个人创作者凭借优质主题、字体和壁纸等内容，月平均收益可达10万元以上。</span></span></span></span></p>
<p><span><span><span><span>为帮助更多创作者把握生态机遇，OPPO 主题商店正通过市场洞察与AI技术全面赋能创作流程。据 OPPO 个性化增值高级产品运营经理蔡彩玲介绍，新升级的 5.0 标签体系结合即将上线的可视化词云功能，可清晰呈现热门趋势与市场机会，辅助创作者精准定位创作方向。此外，AI 技术也已深入创作全流程：通过主题编辑器，用户仅需提供基础图标，即可延展为成套或切换视觉风格的图标，显著提升创作效率；AI 辅助审核有助于筛除低质内容，加速作品上线，进一步优化内容生态。</span></span></span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-f19fbafae0.png"></p>
<p><em><span><span><span>OPPO 个性化增值高级产品运营经理 蔡彩玲</span></span></span></em></p>
<p><span><span><span><span>据透露，OPPO主题商店即将面向全球六大区域、200多个国家开放内容分发通道。未来，创作者的一套壁纸、一款主题，不仅能被国内用户看到，还将触达海外超5亿用户，实现“一次创作，全球分发”。</span></span></span></span></p>
<p><span><strong><span><span><strong>OPPO信息流：聚焦年轻用户，构建优质内容增长生态</strong></span></span></strong></span></p>
<p><span><span><span><span>基于对年轻群体内容偏好的洞察，OPPO 信息流已在影视、旅行、学习等核心领域开展深度运营，并将推出“AI日报”“热点大事件”等创新内容栏目，旨在为年轻用户提供“有吸引力、有实用性”的浏览体验。</span></span></span></span></p>
<p><span><span><span><span>提升内容触达精准度的同时，OPPO信息流也建立了符合“真、善、美”价值导向的内容标准，并通过成本与流量的资源倾斜调配，推动优质内容的创作与分发。据透露，过去一年信息流优质内容曝光量增长 135%，消费量提升 116%。</span></span></span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-7e524376d9.png"></p>
<p><em><span><span><span>OPPO 信息流高级产品运营经理 杨秀君</span></span></span></em></p>
<p><span><span><span><span>据OPPO信息流高级产品运营经理杨秀君介绍，为实现健康、可持续的内容生态循环，OPPO信息流正持续完善优质内容的识别与推荐机制，从海量信息中筛选高质量内容，并深化对优质内容特征与用户偏好的理解，通过双向优化，为合作伙伴搭建了一条触达年轻消费群体的新通道。</span></span></span></span></p>
<p><span><strong><span><span><strong>OPPO全局搜索：从“即搜即得”到“服务直达”，开放合作提升转化效率</strong></span></span></strong></span></p>
<p><span><span><span><span>随着用户搜索行为逐渐从“寻找答案”转向“解决问题”，移动生态的服务模式也在持续演进。当前，OPPO全局搜索已成为超2亿月活用户解决问题的系统级搜索入口——搜索“省电模式”可直接设置开关，搜索“凡人修仙传”，相关视频和小说的最新内容一点即达，体验变化背后，是全局搜索从“搜本机应用”到“应用服务直达”的升级。</span></span></span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-80ee8f0a9d.png"></p>
<p><em><span><span><span>OPPO 全局搜索高级产品运营经理 袁诗谣</span></span></span></em></p>
<p><span><span><span><span>对合作伙伴而言，全局搜索已成为触达亿级规模用户、提升转化效率的重要渠道。据OPPO全局搜索高级产品运营经理袁诗谣介绍，全局搜索在首页便捷服务专区为开发者提供了多种标准化模板，帮助开发者快速接入，共享日均超亿次的曝光资源；“超级品牌 bigday”活动则支持为合作伙伴提供定制化IP专场服务，帮助合作伙伴提高转化效率。在用户体验方面，全局搜索可精准理解用户搜索意图，并结合AI智能总结展示相关内容，提供一键跳转至第三方应用结果页的服务，减少用户操作步骤，实现高效直达。</span></span></span></span></p>
<p><span><span><span><span>此外，全局搜索还与开发者生态共建“数据捐赠”合作模式，实现“本机应用内容在系统皆可搜到”的愿景，为开发者提供更多更精准的OS生态场景流量，协同推动用户与商业价值的提升。</span></span></span></span></p>
<p><strong><span><span><strong>生态协同共筑未来，OPPO 引领内容生态新增长</strong></span></span></strong></p>
<p><span><span><span><span>本次大会上，OPPO首次完整展示了由七大内容产品构成的生态布局，系统阐述了"AI+全场景"的内容服务战略。据悉，该布局覆盖了浏览器的AI功能升级、桌面上滑入口构建、视频全场景服务、主题商店的AI创作工具等多个维度，旨在通过技术升级与生态协同，让用户更高效便捷地获取优质内容，同时助力创作者和合作伙伴实现增长。</span></span></span></span></p>
<p><span><span><span><span>面向未来发展，OPPO表示将持续投入AI技术研发，深化多场景整合能力，在优化用户内容体验的同时，探索AI时代下的内容价值创新模式，推动内容生态的健康发展与多方共赢。</span></span></span></span></p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-ae1ceee95b.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-ae1ceee95b.png" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 17:09:08 +0800</pubDate>
  </item><item>
    <title><![CDATA[强化安全底座，OPPO 应用生态多维度助力全球开发者高效增长]]></title>
    <link>https://www.oschina.net/news/377596</link>
    <itunes:title><![CDATA[强化安全底座，OPPO 应用生态多维度助力全球开发者高效增长]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p><span><span><span>2025 OPPO开发者大会（ODC25）于10月15日在深圳圆满落幕，在应用生态分论坛上，OPPO正式推出——"OPPO隐私安全智护体系"。该体系通过全新升级的权限管理机制，帮助用户实现隐私的透明可控与精细管理。同时，平台宣布对合作策略进行全面升级，包括向个人开发者开放应用上传权限、推出"一键出海"等全新功能，为开发者提供从技术支撑到规模增长的全链路解决方案，助力开发者在安全合规基础上实现高效增长。</span></span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-461de15b51.png"></p>
<p><strong><span><span>安全筑基：更便捷的隐私保护流程和接入方案，让用户成为数据的主人</span></span></strong></p>
<p><span><span>据工信部数据显示，截至2025年6月末移动电话用户规模已达18.1亿，5G用户突破11.18亿，QQuestMobile发布的2025年春季报告显示，中国移动互联网月活跃用户规模达到12.59亿。随着移动设备深度融入人们的工作与生活，隐私安全保护已从基本诉求升级为构建用户信任的核心要素。</span></span></p>
<p><span><span>同时对用户而言，</span></span><span><span><span>理想的安全保护不应是复杂的设置或频繁的弹窗，而是一种&nbsp;“无感却可靠”&nbsp;的基础体验。为实现这一目标，OPPO针对“上架-下载-安装-运行”的全链路进行优化升</span></span></span><span><span>级：上架阶段，平台提前完成上架应用的安装包审核并提前检测包体风险；下载环节，在用户授权下，系统可直接拉起安装流程，不打扰正常操作；安装时，简化冗余验证步骤，不用反复点击确认。</span></span><span><span><span>这一机制在从源头保障安全的同时，也将显著简化用户下载流程，提升用户使用体验，帮助开发者更高效进行应用分发。</span></span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-79c6fda51d.png"></p>
<p><span><span>在此基础上，平台还上线了全新的 “OPPO隐私安全智护体系”，通过 Picker 等系统级安全控件，为联系人、相册等 5 类高敏隐私数据提供安全访问能力。从此，在用户主动授权的前提下，应用方可读取对应数据，从技术层将“最小必要”原则落地。例如用户上传个人照片时，用户勾选哪几张，应用就只能获取相应内容，无需访问整个相册所有资料。整个授权过程不会打断原有的聊天、分享，在避免数据泄密风险的同时，保证了体验的连贯顺畅。</span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-1dc0a48d79.png"></p>
<p><span><span><span>该体系由OPPO与国内主流安卓厂商协同共建，基于统一的行业规范，为开发者提供清晰的数据使用标准</span></span></span><span><span>与“一次接入、多端兼容”的标准化接口，</span></span><span><span><span>有效降低多端适配的复杂度与开发成本。这一进展标志着平台正与开发者共同推进</span></span></span><span><span>更安全、可靠的应用生态建设。</span></span></p>
<p><strong><span><span>赋能个人开发，开拓海外增量，OPPO 注入生态增长新动能</span></span></strong></p>
<p><span><span><span>在生态构建上，OPPO一方面致力于提升用户隐私安全水平，另一方面则通过覆盖应用全生命周期的支持体系，助力开发者应对从本土创新到全球运营的挑战，实现长期发展。</span></span></span></p>
<p><span><span>平台首次向个人开发者全面开放应用上传权限，从此个人开发者的创意能够获得正式分发机会，享受与企业同等的成长支持，助力更多"一个人的 App"实现“创意-应用上架-用户增长”的价值闭环，为应用生态注入源源不断的创新动力。</span></span><span><span><span>官方透露，相关能力于2025年12月底正式对外开放，平台将以</span></span></span><span><span>“邀请制”形式定向邀约个人开发者进行合作，并在后续陆续扩大开放规模。</span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-953a0c7ea3.png"></p>
<p><span><span>同时，OPPO 应用生态全新的“一键出海”功能，为全球开发者提供更方便的海外增长通道</span></span><span><span><span>。</span></span></span><span><span><span>在OPPO应用服务所覆盖的108个国家或地区范围内，开发者均可实现APP的快速分发，</span></span></span><span><span><span>无需重复打包或多次上传，真正实现"开发一次，全球发布"。</span></span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-5a97d94441.png"></p>
<p><span><span>在应用增长阶段，OPPO 通过场景与技术融合为开发者高效获客。例如软件商店联动负一屏、小布建议等高活跃入口，可以让应用精准触达千万级用户；新兴的小游戏、智能体专区则支持多种载体的应用形式触达。全新升级的ColorOS 16 流体云，作为直达用户的服务入口，全面兼容原生“Live Updates”特性。开发者完成原生适配后，应用的实时活动可通过流体云融入系统，在不同界面完成交互，不仅适配成本进一步降低，还为用户提供了更便捷流畅的实时服务。作为连接用户与应用的关键服务，OPPO PUSH 推送能力亦全面升级，它依托系统级通道，保障消息的稳定推送与毫秒级触达，并提供VOIP通话、扩展通知等能力，在优化用户体验的同时，有效助力开发者提升用户活跃度与留存率。</span></span></p>
<p><span><span><span>在生态服务闭环中，OPPO广告联盟基于用户增长基础，持续优化流量分发与变现效率。该平台通过智能算法与多样化广告形态，助力开发者实现收益的稳步提升。数据显示，联盟25年日均新增流量达到50亿+，覆盖系统多场景，为开发者构建了可持续的增长路径。</span></span></span></p>
<p><strong><span><span>双轮驱动，共筑全球应用生态新图景</span></span></strong></p>
<p><span><span>作为平台方，OPPO 始终以"用户安全"与"开发者增长"为双轮驱动，在守护用户隐私与激发创新活力之间构建可持续的生态平衡。</span></span></p>
<p><span><span>未来，OPPO表示将继续完善平台基础设施，通过技术开放与资源协同，为开发者打造更优质的创新环境，在保护用户隐私安全的前提下，推动应用生态向更加健康、可持续的方向发展。</span></span></p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p><span><span><span>2025 OPPO开发者大会（ODC25）于10月15日在深圳圆满落幕，在应用生态分论坛上，OPPO正式推出——"OPPO隐私安全智护体系"。该体系通过全新升级的权限管理机制，帮助用户实现隐私的透明可控与精细管理。同时，平台宣布对合作策略进行全面升级，包括向个人开发者开放应用上传权限、推出"一键出海"等全新功能，为开发者提供从技术支撑到规模增长的全链路解决方案，助力开发者在安全合规基础上实现高效增长。</span></span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-461de15b51.png"></p>
<p><strong><span><span>安全筑基：更便捷的隐私保护流程和接入方案，让用户成为数据的主人</span></span></strong></p>
<p><span><span>据工信部数据显示，截至2025年6月末移动电话用户规模已达18.1亿，5G用户突破11.18亿，QQuestMobile发布的2025年春季报告显示，中国移动互联网月活跃用户规模达到12.59亿。随着移动设备深度融入人们的工作与生活，隐私安全保护已从基本诉求升级为构建用户信任的核心要素。</span></span></p>
<p><span><span>同时对用户而言，</span></span><span><span><span>理想的安全保护不应是复杂的设置或频繁的弹窗，而是一种&nbsp;“无感却可靠”&nbsp;的基础体验。为实现这一目标，OPPO针对“上架-下载-安装-运行”的全链路进行优化升</span></span></span><span><span>级：上架阶段，平台提前完成上架应用的安装包审核并提前检测包体风险；下载环节，在用户授权下，系统可直接拉起安装流程，不打扰正常操作；安装时，简化冗余验证步骤，不用反复点击确认。</span></span><span><span><span>这一机制在从源头保障安全的同时，也将显著简化用户下载流程，提升用户使用体验，帮助开发者更高效进行应用分发。</span></span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-79c6fda51d.png"></p>
<p><span><span>在此基础上，平台还上线了全新的 “OPPO隐私安全智护体系”，通过 Picker 等系统级安全控件，为联系人、相册等 5 类高敏隐私数据提供安全访问能力。从此，在用户主动授权的前提下，应用方可读取对应数据，从技术层将“最小必要”原则落地。例如用户上传个人照片时，用户勾选哪几张，应用就只能获取相应内容，无需访问整个相册所有资料。整个授权过程不会打断原有的聊天、分享，在避免数据泄密风险的同时，保证了体验的连贯顺畅。</span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-1dc0a48d79.png"></p>
<p><span><span><span>该体系由OPPO与国内主流安卓厂商协同共建，基于统一的行业规范，为开发者提供清晰的数据使用标准</span></span></span><span><span>与“一次接入、多端兼容”的标准化接口，</span></span><span><span><span>有效降低多端适配的复杂度与开发成本。这一进展标志着平台正与开发者共同推进</span></span></span><span><span>更安全、可靠的应用生态建设。</span></span></p>
<p><strong><span><span>赋能个人开发，开拓海外增量，OPPO 注入生态增长新动能</span></span></strong></p>
<p><span><span><span>在生态构建上，OPPO一方面致力于提升用户隐私安全水平，另一方面则通过覆盖应用全生命周期的支持体系，助力开发者应对从本土创新到全球运营的挑战，实现长期发展。</span></span></span></p>
<p><span><span>平台首次向个人开发者全面开放应用上传权限，从此个人开发者的创意能够获得正式分发机会，享受与企业同等的成长支持，助力更多"一个人的 App"实现“创意-应用上架-用户增长”的价值闭环，为应用生态注入源源不断的创新动力。</span></span><span><span><span>官方透露，相关能力于2025年12月底正式对外开放，平台将以</span></span></span><span><span>“邀请制”形式定向邀约个人开发者进行合作，并在后续陆续扩大开放规模。</span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-953a0c7ea3.png"></p>
<p><span><span>同时，OPPO 应用生态全新的“一键出海”功能，为全球开发者提供更方便的海外增长通道</span></span><span><span><span>。</span></span></span><span><span><span>在OPPO应用服务所覆盖的108个国家或地区范围内，开发者均可实现APP的快速分发，</span></span></span><span><span><span>无需重复打包或多次上传，真正实现"开发一次，全球发布"。</span></span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-5a97d94441.png"></p>
<p><span><span>在应用增长阶段，OPPO 通过场景与技术融合为开发者高效获客。例如软件商店联动负一屏、小布建议等高活跃入口，可以让应用精准触达千万级用户；新兴的小游戏、智能体专区则支持多种载体的应用形式触达。全新升级的ColorOS 16 流体云，作为直达用户的服务入口，全面兼容原生“Live Updates”特性。开发者完成原生适配后，应用的实时活动可通过流体云融入系统，在不同界面完成交互，不仅适配成本进一步降低，还为用户提供了更便捷流畅的实时服务。作为连接用户与应用的关键服务，OPPO PUSH 推送能力亦全面升级，它依托系统级通道，保障消息的稳定推送与毫秒级触达，并提供VOIP通话、扩展通知等能力，在优化用户体验的同时，有效助力开发者提升用户活跃度与留存率。</span></span></p>
<p><span><span><span>在生态服务闭环中，OPPO广告联盟基于用户增长基础，持续优化流量分发与变现效率。该平台通过智能算法与多样化广告形态，助力开发者实现收益的稳步提升。数据显示，联盟25年日均新增流量达到50亿+，覆盖系统多场景，为开发者构建了可持续的增长路径。</span></span></span></p>
<p><strong><span><span>双轮驱动，共筑全球应用生态新图景</span></span></strong></p>
<p><span><span>作为平台方，OPPO 始终以"用户安全"与"开发者增长"为双轮驱动，在守护用户隐私与激发创新活力之间构建可持续的生态平衡。</span></span></p>
<p><span><span>未来，OPPO表示将继续完善平台基础设施，通过技术开放与资源协同，为开发者打造更优质的创新环境，在保护用户隐私安全的前提下，推动应用生态向更加健康、可持续的方向发展。</span></span></p>]]>
    </description>
    <content:encoded><![CDATA[<p><span><span><span>2025 OPPO开发者大会（ODC25）于10月15日在深圳圆满落幕，在应用生态分论坛上，OPPO正式推出——"OPPO隐私安全智护体系"。该体系通过全新升级的权限管理机制，帮助用户实现隐私的透明可控与精细管理。同时，平台宣布对合作策略进行全面升级，包括向个人开发者开放应用上传权限、推出"一键出海"等全新功能，为开发者提供从技术支撑到规模增长的全链路解决方案，助力开发者在安全合规基础上实现高效增长。</span></span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-461de15b51.png"></p>
<p><strong><span><span>安全筑基：更便捷的隐私保护流程和接入方案，让用户成为数据的主人</span></span></strong></p>
<p><span><span>据工信部数据显示，截至2025年6月末移动电话用户规模已达18.1亿，5G用户突破11.18亿，QQuestMobile发布的2025年春季报告显示，中国移动互联网月活跃用户规模达到12.59亿。随着移动设备深度融入人们的工作与生活，隐私安全保护已从基本诉求升级为构建用户信任的核心要素。</span></span></p>
<p><span><span>同时对用户而言，</span></span><span><span><span>理想的安全保护不应是复杂的设置或频繁的弹窗，而是一种&nbsp;“无感却可靠”&nbsp;的基础体验。为实现这一目标，OPPO针对“上架-下载-安装-运行”的全链路进行优化升</span></span></span><span><span>级：上架阶段，平台提前完成上架应用的安装包审核并提前检测包体风险；下载环节，在用户授权下，系统可直接拉起安装流程，不打扰正常操作；安装时，简化冗余验证步骤，不用反复点击确认。</span></span><span><span><span>这一机制在从源头保障安全的同时，也将显著简化用户下载流程，提升用户使用体验，帮助开发者更高效进行应用分发。</span></span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-79c6fda51d.png"></p>
<p><span><span>在此基础上，平台还上线了全新的 “OPPO隐私安全智护体系”，通过 Picker 等系统级安全控件，为联系人、相册等 5 类高敏隐私数据提供安全访问能力。从此，在用户主动授权的前提下，应用方可读取对应数据，从技术层将“最小必要”原则落地。例如用户上传个人照片时，用户勾选哪几张，应用就只能获取相应内容，无需访问整个相册所有资料。整个授权过程不会打断原有的聊天、分享，在避免数据泄密风险的同时，保证了体验的连贯顺畅。</span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-1dc0a48d79.png"></p>
<p><span><span><span>该体系由OPPO与国内主流安卓厂商协同共建，基于统一的行业规范，为开发者提供清晰的数据使用标准</span></span></span><span><span>与“一次接入、多端兼容”的标准化接口，</span></span><span><span><span>有效降低多端适配的复杂度与开发成本。这一进展标志着平台正与开发者共同推进</span></span></span><span><span>更安全、可靠的应用生态建设。</span></span></p>
<p><strong><span><span>赋能个人开发，开拓海外增量，OPPO 注入生态增长新动能</span></span></strong></p>
<p><span><span><span>在生态构建上，OPPO一方面致力于提升用户隐私安全水平，另一方面则通过覆盖应用全生命周期的支持体系，助力开发者应对从本土创新到全球运营的挑战，实现长期发展。</span></span></span></p>
<p><span><span>平台首次向个人开发者全面开放应用上传权限，从此个人开发者的创意能够获得正式分发机会，享受与企业同等的成长支持，助力更多"一个人的 App"实现“创意-应用上架-用户增长”的价值闭环，为应用生态注入源源不断的创新动力。</span></span><span><span><span>官方透露，相关能力于2025年12月底正式对外开放，平台将以</span></span></span><span><span>“邀请制”形式定向邀约个人开发者进行合作，并在后续陆续扩大开放规模。</span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-953a0c7ea3.png"></p>
<p><span><span>同时，OPPO 应用生态全新的“一键出海”功能，为全球开发者提供更方便的海外增长通道</span></span><span><span><span>。</span></span></span><span><span><span>在OPPO应用服务所覆盖的108个国家或地区范围内，开发者均可实现APP的快速分发，</span></span></span><span><span><span>无需重复打包或多次上传，真正实现"开发一次，全球发布"。</span></span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-5a97d94441.png"></p>
<p><span><span>在应用增长阶段，OPPO 通过场景与技术融合为开发者高效获客。例如软件商店联动负一屏、小布建议等高活跃入口，可以让应用精准触达千万级用户；新兴的小游戏、智能体专区则支持多种载体的应用形式触达。全新升级的ColorOS 16 流体云，作为直达用户的服务入口，全面兼容原生“Live Updates”特性。开发者完成原生适配后，应用的实时活动可通过流体云融入系统，在不同界面完成交互，不仅适配成本进一步降低，还为用户提供了更便捷流畅的实时服务。作为连接用户与应用的关键服务，OPPO PUSH 推送能力亦全面升级，它依托系统级通道，保障消息的稳定推送与毫秒级触达，并提供VOIP通话、扩展通知等能力，在优化用户体验的同时，有效助力开发者提升用户活跃度与留存率。</span></span></p>
<p><span><span><span>在生态服务闭环中，OPPO广告联盟基于用户增长基础，持续优化流量分发与变现效率。该平台通过智能算法与多样化广告形态，助力开发者实现收益的稳步提升。数据显示，联盟25年日均新增流量达到50亿+，覆盖系统多场景，为开发者构建了可持续的增长路径。</span></span></span></p>
<p><strong><span><span>双轮驱动，共筑全球应用生态新图景</span></span></strong></p>
<p><span><span>作为平台方，OPPO 始终以"用户安全"与"开发者增长"为双轮驱动，在守护用户隐私与激发创新活力之间构建可持续的生态平衡。</span></span></p>
<p><span><span>未来，OPPO表示将继续完善平台基础设施，通过技术开放与资源协同，为开发者打造更优质的创新环境，在保护用户隐私安全的前提下，推动应用生态向更加健康、可持续的方向发展。</span></span></p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-461de15b51.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-461de15b51.png" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 16:55:26 +0800</pubDate>
  </item><item>
    <title><![CDATA[字节跳动开源 FaceCLIP：文本驱动的高保真人脸生成技术上线]]></title>
    <link>https://www.oschina.net/news/377587</link>
    <itunes:title><![CDATA[字节跳动开源 FaceCLIP：文本驱动的高保真人脸生成技术上线]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>字节跳动近日发布了FaceCLIP，一款专注于人脸理解与生成的视觉-语言模型。该工具通过文本提示和参考图像即可生成保持身份一致性的多样化人脸图像，在多模态AI的人脸语义处理领域实现了新的技术突破。</p>
<p>FaceCLIP的核心技术在于其身份保持型图像生成框架。用户输入一张参考人脸照片和文本描述后，模型能够生成保留原始身份特征的新图像，同时根据文本指令调整表情、姿态和风格等属性。与传统方法不同，FaceCLIP摒弃了适配器模块，转而采用多模态编码策略同步捕获身份信息和文本语义，实现了人脸特征与文本提示的深度融合。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-873a461c5a.png"></p>
<p>从技术架构来看，FaceCLIP基于开源基础模型构建，提供了两个主要版本。FaceCLIP-SDXL版本采用FaceCLIP-L-14和FaceCLIP-bigG-14编码器训练，而FaceT5-FLUX版本则集成了FaceT5编码器，进一步增强了文本到图像的转换精度。这些设计使模型在处理复杂场景描述时具备更强的灵活性，例如能够准确生成"戴眼镜的老年男性在咖啡厅阅读"等具体场景，同时保持参考人脸的核心识别特征。</p>
<p>在性能表现方面，官方数据显示FaceCLIP在真实感、身份保持度和文本对齐等指标上优于现有同类方法。模型采用解耦学习方案，能够将风格特征与内容特征分离处理，从而在保证身份一致性的同时实现风格的灵活变化。不过，早期测试也暴露出一些局限性，包括对特定族裔面部特征的细微偏差，以及30GB以上显存的硬件要求。</p>
<p>应用场景方面，FaceCLIP可用于游戏角色设计、数字漫画创作、广告视觉制作等领域。开发者可以通过GitHub仓库获取代码，按照文档指引进行本地部署和集成。目前该模型在低分辨率训练条件下已能达到接近专业水准的输出质量，未来对高分辨率生成的优化将进一步拓展其商业应用价值。</p>
<p>字节跳动明确表示，FaceCLIP采用Creative Commons Attribution-NonCommercial4.0许可协议，仅限学术研究使用，并提醒用户注意AI生成内容的伦理规范。开发者社区对该模型的发布反响积极，但也有声音指出其在硬件门槛和特定场景适配上仍有改进空间。从技术演进角度看，这类身份一致性生成工具正在成为文本到图像模型发展的重要方向之一。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>字节跳动近日发布了FaceCLIP，一款专注于人脸理解与生成的视觉-语言模型。该工具通过文本提示和参考图像即可生成保持身份一致性的多样化人脸图像，在多模态AI的人脸语义处理领域实现了新的技术突破。</p>
<p>FaceCLIP的核心技术在于其身份保持型图像生成框架。用户输入一张参考人脸照片和文本描述后，模型能够生成保留原始身份特征的新图像，同时根据文本指令调整表情、姿态和风格等属性。与传统方法不同，FaceCLIP摒弃了适配器模块，转而采用多模态编码策略同步捕获身份信息和文本语义，实现了人脸特征与文本提示的深度融合。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-873a461c5a.png"></p>
<p>从技术架构来看，FaceCLIP基于开源基础模型构建，提供了两个主要版本。FaceCLIP-SDXL版本采用FaceCLIP-L-14和FaceCLIP-bigG-14编码器训练，而FaceT5-FLUX版本则集成了FaceT5编码器，进一步增强了文本到图像的转换精度。这些设计使模型在处理复杂场景描述时具备更强的灵活性，例如能够准确生成"戴眼镜的老年男性在咖啡厅阅读"等具体场景，同时保持参考人脸的核心识别特征。</p>
<p>在性能表现方面，官方数据显示FaceCLIP在真实感、身份保持度和文本对齐等指标上优于现有同类方法。模型采用解耦学习方案，能够将风格特征与内容特征分离处理，从而在保证身份一致性的同时实现风格的灵活变化。不过，早期测试也暴露出一些局限性，包括对特定族裔面部特征的细微偏差，以及30GB以上显存的硬件要求。</p>
<p>应用场景方面，FaceCLIP可用于游戏角色设计、数字漫画创作、广告视觉制作等领域。开发者可以通过GitHub仓库获取代码，按照文档指引进行本地部署和集成。目前该模型在低分辨率训练条件下已能达到接近专业水准的输出质量，未来对高分辨率生成的优化将进一步拓展其商业应用价值。</p>
<p>字节跳动明确表示，FaceCLIP采用Creative Commons Attribution-NonCommercial4.0许可协议，仅限学术研究使用，并提醒用户注意AI生成内容的伦理规范。开发者社区对该模型的发布反响积极，但也有声音指出其在硬件门槛和特定场景适配上仍有改进空间。从技术演进角度看，这类身份一致性生成工具正在成为文本到图像模型发展的重要方向之一。</p>]]>
    </description>
    <content:encoded><![CDATA[<p>字节跳动近日发布了FaceCLIP，一款专注于人脸理解与生成的视觉-语言模型。该工具通过文本提示和参考图像即可生成保持身份一致性的多样化人脸图像，在多模态AI的人脸语义处理领域实现了新的技术突破。</p>
<p>FaceCLIP的核心技术在于其身份保持型图像生成框架。用户输入一张参考人脸照片和文本描述后，模型能够生成保留原始身份特征的新图像，同时根据文本指令调整表情、姿态和风格等属性。与传统方法不同，FaceCLIP摒弃了适配器模块，转而采用多模态编码策略同步捕获身份信息和文本语义，实现了人脸特征与文本提示的深度融合。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-873a461c5a.png"></p>
<p>从技术架构来看，FaceCLIP基于开源基础模型构建，提供了两个主要版本。FaceCLIP-SDXL版本采用FaceCLIP-L-14和FaceCLIP-bigG-14编码器训练，而FaceT5-FLUX版本则集成了FaceT5编码器，进一步增强了文本到图像的转换精度。这些设计使模型在处理复杂场景描述时具备更强的灵活性，例如能够准确生成"戴眼镜的老年男性在咖啡厅阅读"等具体场景，同时保持参考人脸的核心识别特征。</p>
<p>在性能表现方面，官方数据显示FaceCLIP在真实感、身份保持度和文本对齐等指标上优于现有同类方法。模型采用解耦学习方案，能够将风格特征与内容特征分离处理，从而在保证身份一致性的同时实现风格的灵活变化。不过，早期测试也暴露出一些局限性，包括对特定族裔面部特征的细微偏差，以及30GB以上显存的硬件要求。</p>
<p>应用场景方面，FaceCLIP可用于游戏角色设计、数字漫画创作、广告视觉制作等领域。开发者可以通过GitHub仓库获取代码，按照文档指引进行本地部署和集成。目前该模型在低分辨率训练条件下已能达到接近专业水准的输出质量，未来对高分辨率生成的优化将进一步拓展其商业应用价值。</p>
<p>字节跳动明确表示，FaceCLIP采用Creative Commons Attribution-NonCommercial4.0许可协议，仅限学术研究使用，并提醒用户注意AI生成内容的伦理规范。开发者社区对该模型的发布反响积极，但也有声音指出其在硬件门槛和特定场景适配上仍有改进空间。从技术演进角度看，这类身份一致性生成工具正在成为文本到图像模型发展的重要方向之一。</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-873a461c5a.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-873a461c5a.png" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 16:35:18 +0800</pubDate>
  </item><item>
    <title><![CDATA[驳 “AI 泡沫论”：一场被误读的、正在进行中的产业结构性调整]]></title>
    <link>https://my.oschina.net/IDP/blog/18695597</link>
    <itunes:title><![CDATA[驳 “AI 泡沫论”：一场被误读的、正在进行中的产业结构性调整]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>&gt; <strong>编者按：</strong> 当&nbsp;GPT-5&nbsp;的表现未达预期，当众多&nbsp;AI&nbsp;应用试点项目收效甚微，当市场开始质疑人工智能的发展前景时，我们是否正在经历一场&nbsp;AI&nbsp;泡沫的破裂？还是说，这些表面现象背后隐藏着更深层次的产业逻辑？ &gt; &gt; 我们今天为大家带来的这篇文章，作者的观点是：当前 AI 市场并非陷入停滞或崩溃，而是进入了一个必要的“消化阶段”，这一过程虽伴随阵痛，却蕴含着持续的发展动能。 &gt; &gt; 文章通过四个层次的分析框架，系统性地解构了当前 AI 市场的真实状况：首先厘清了产品体验设计与技术能力上限的区别，指出用户对 GPT-5 的失望更多源于产品策略而非能力倒退；第二，应用层回报不明朗的根源在于组织流程滞后于技术能力，真正有价值的垂直整合方案正在悄然建立护城河；第三，基础设施投资正从粗放扩张转向精细化运营，算力合约结构化、算力利用率优化和电力资源争夺成为新焦点；最后阐述了技术演进已超越“规模至上”的初级阶段，转向测试时计算、工具调用、数据质量与智能体系统等更深层次的创新。作者还提供了判断行业是否真正崩溃的具体指标，并为资金配置方、应用层创业者和基础设施构建者提供了清晰的战略建议。</p>
<p><strong>作者 | Dave Friedman</strong></p>
<p><strong>编译 | 岳扬</strong></p>
<p>目前流传着一种看似合理的说法：GPT-5 表现未达预期，因此 AI 泡沫正在破裂。这个观点看似顺理成章，实则是错误的。这个说法将四个不同维度的事情强行捆绑，硬是揉成了一个整体：（1）产品体验的设计选择；（2）应用层的投资回报；（3）基础设施投入与供应链；（4）科研进展与规模化应用。当你拆解这层层架构时，看似崩盘的态势其实正转化为一个“消化阶段” —— 既有可预见的阵痛，也伴随着同样可预见的持续动能。</p>
<p>以下是一个用于厘清思路的清晰框架。</p>
<h1><strong>01 Layer 1：产品体验 ≠ 能力上限</strong></h1>
<p>围绕 GPT-5 的争议大多聚焦于使用感受：语气转变、拒绝机制，以及有时将用户导向更安全但乏味的交互模式。<strong>这些属于产品决策（模型对齐过程中的参数选择、安全护栏、模型路由配置、默认设置），而非技术能力的倒退。</strong> 安全调校的悖论在于：当交互界面改变“对话风格”或严格限制高风险场景时，即便能力略有提升，用户仍可能感知为性能倒退。</p>
<p>三大常见认知误区：</p>
<p>1）<strong>对齐策略与核心能力</strong>：若模型规避特定输出或在高风险领域缩短推理链条，用户就会判断“模型变差”。此时衡量的实则为安全策略，而非底层能力。</p>
<p>2）<strong>路由系统与核心模型</strong>：AI 助手类产品常采用多个模型混合调用方案。若路由系统误将请求导向更保守的小模型，用户体验到的性能波动会被错误归于旗舰模型。</p>
<p>3）<strong>大家的心理预期比较高</strong>：被冠以“划时代”称号的发布版本会设定参照标准，而实际改进幅度往往难以匹配这种预期。但即便不如宣传片震撼，这些改进（尤其在编程、长程任务和工具调用领域）仍然具有重要意义。</p>
<p>本层结论：这是产品管理策略引发的争议，并非能力停滞的证据。</p>
<h1><strong>02 Layer 2：应用层投资回报混沌不清，且与基础设施需求背道而驰</strong></h1>
<p>的确，很多企业试点项目都没有达到预期目标。但原因很简单：数据管道尚未就绪；工作流未重新设计；激励机制阻碍落地；风控措施拖慢部署；套壳应用同质化严重。当技术普及速度超过组织流程改造速度时，市场必然会出现应用层淘汰洗牌。</p>
<p>关键差异点：</p>
<p>1）<strong>套壳应用与系统重构</strong>：基于 API 的套壳聊天应用会快速同质化，而重构工作流的系统（如智能体、工具调用、私有数据检索、知识图谱）虽见效慢，却能建立更持久的优势。</p>
<p>2）<strong>横向与纵向方案之别</strong>：横向通用助手的市场声量大，但深度融合领域工具的垂直方案才真正能产生回报。后者需与一线操作者共同设计且销售周期更长，但正是护城河所在。</p>
<p>3）<strong>核心评估指标</strong>：节省工时数量和客户满意度这类脱离利润的虚荣指标毫无意义。应关注误差调整后的吞吐量、营运资金周转率或事件率变化值。若无法将成效折算为财务收益，下一轮预算审议时项目必然被否决。</p>
<p>这一层的低迷与基础设施层的蓬勃发展并不矛盾：边缘应用的弱产品市场匹配度，不会削弱对训练迭代、模型升级或智能体框架的需求，只会重新分配价值捕获的主体。</p>
<h1><strong>03 Layer 3：基础设施资本支出正从冲刺期转向消化期，而非断崖式下跌</strong></h1>
<p>基础设施领域并非“投资枯竭”，而是进入了一个新阶段：资源配置结构与利用效率将成为决胜关键。三个同时存在的事实：</p>
<p>1）<strong>产能持续扩张</strong>：电力、高频宽存储器（HBM）与先进封装（CoWoS 级）仍是关键制约因素。即便积极扩产，2026 年前多数地区的供应仍将紧张。这支撑着定价并持续激励基建投入。</p>
<p>2）<strong>算力闲置风险是局部性的而非系统性的</strong>：拥有全栈需求（搜索、广告、云服务、办公软件、消费应用）的超大规模厂商可通过模型轮替与吸纳测试时计算阶段的算力消耗保持 GPU 满载。风险主要集中在独立的 AI 云服务商和专项供应商 —— 它们面临租赁成本攀升、客户集中度高和短期采购协议的压力。即便总体需求增长，这类企业仍可能遭遇阶段性的困境。</p>
<p>3）<strong>从粗放式短期算力租赁向精细化长期商业协议</strong>：随着市场逐渐成熟，短期的算力现货租赁将减少，结构化的采购协议将成为主流（包括更长的合约期限、最低采购量承诺以及指数化定价机制）。算力金融化工具（期货/远期合约、容量预留、风险对冲）将平滑市场的消化过程，同时降低建设方与采购方的资金成本。</p>
<p>“资本支出消化期”意味着：在供应增速超越短期客户需求的领域将出现价格体系调整。行业重点正转向电力采购、互联技术、散热系统和可用性保障，并对 GPU 利用率管理赋予更高溢价 —— 这与市场崩溃的论调截然不同。</p>
<h1><strong>04 Layer 4：“规模即王道”从来就不是严肃的理论命题</strong></h1>
<p>有一种夸张的片面观点宣称：“我们已经扩大了预训练规模，现在就此止步”。<strong>而真正严谨的技术演进路径实则是：规模 × 算法创新 × 测试时计算 × 工具调用 × 高质量数据。</strong> 技术前沿正在发生范式转移：</p>
<p>1）<strong>测试时计算与规划能力</strong>：更多思维链、外部记忆、验证机制以及搜索/规划循环的运用。这方面的突破不需要更大的基础模型，而更依赖更智能的推理计算。</p>
<p>2）<strong>工具调用与智能体</strong>：将代码执行、数据库操作和服务调用作为默认运行模式（而非演示功能），使模型从文本预测器升级为行动系统。</p>
<p>3）<strong>数据质量与课程学习</strong>：当粗暴的数据规模扩张效益递减时，数据精加工、合成数据方案、基于结果指标的强化学习以及针对特定任务设计的课程学习将成为突破性能瓶颈的关键。</p>
<p>单纯扩张预训练规模的收益递减并不意味进步终结，而是改变了规模化的方向。</p>
<p>结合这四个层面来看：AI 助手默认设置的重设计带来了不好的用户体验；大量应用型初创公司遭遇试点价值的转化困境；基础设施投入正在进行结构化调整与专业化升级；研究重点从无序的规模扩张转向结构化推理。这些内容无一指向 AI 泡沫破裂，而是符合幂律分布特征的技术走向成熟的必然形态。</p>
<h1><strong>05 需要出现怎样的证据，才能真正推翻“行业处于消化期”的判断？</strong></h1>
<p>请关注下面这个简单明了的核查清单：</p>
<p>1）多家超大规模厂商连续两轮以上资本支出下调（非仅投资结构调整），且明确推迟数据中心建设（而非仅重新排序工期）</p>
<p>2）顶级 GPU 集群出现价格战（通过公开价目表可量化），同时披露闲置产能或明显延长 GPU 闲置周期。</p>
<p>3）需连续多代模型版本在复杂推理基准测试和智能体工作流中出现平台期，工具使用可靠性（如代码执行成功率）停止提升。</p>
<p>4）电网互联排队周期长和变电站扩容项目延期导致项目大规模取消（非仅工期延后），联邦能源监管委员会/公用事业约束硬性限制建设规模。</p>
<p>5）两个及以上客户群在经过深度工作流整合后，AI 套件/助手的续约率显著低于试点期表现。</p>
<p><strong>若同时触发 2-3 项指标则需重新评估“行业处于消化期”这一判断。否则应预期行业处于结构性调整而非崩溃状态。</strong></p>
<h1><strong>06 战略要点</strong></h1>
<h2><strong>6.1 资金配置方</strong></h2>
<ul>
<li><strong>优先布局瓶颈环节，而非追逐品牌光环。</strong> 高频宽存储器（HBM）、芯片基板、先进封装、电网升级、变压器/变电站设备以及散热系统。这些领域的供给制约持续时间将远超市场预期。</li>
<li><strong>审慎评估独立厂商的资本结构。</strong> 关注租赁费用递增条款与收入条款的匹配度、客户集中度及合同期限。用仅持续 90 天的收入流去支撑长达 36 个月的债务责任，便是在重演硅谷版的 WeWork 式危机。</li>
<li><strong>优先选择与约定期限关联的风险敞口。</strong> 优先选择包含阶梯价格、保底/封顶机制和电力成本传导条款的容量预留与算力采购协议。此类合约正在快速完善风控体系。</li>
</ul>
<h2><strong>6.2 应用层创业者</strong></h2>
<ul>
<li><strong>构建系统级解决方案，而非浅层套壳应用。</strong> 开发深度整合私有数据与领域工具的智能体工作流，用财务收益衡量成效而非使用演示效果衡量。</li>
<li><strong>掌控评估体系。</strong> 评估能力是产品的核心模块而不是纯研究属性的功能。若无法基于客户自有指标证明成果差异，则终将沦为附属功能。</li>
<li><strong>善用测试时计算（test-time compute）。</strong> 部署轻量基础模型搭配强大的规划/搜索框架，可在成本与质量上超越暴力扩展方案。</li>
</ul>
<h2><strong>6.3 基础设施构建者</strong></h2>
<ul>
<li><strong>优先获取电力资源。</strong> 土地易得，充足的电力难求。变电站的交付周期与等待电网公司审批接入的排队时间对项目进度的影响，远超过芯片供应短缺。</li>
<li><strong>为算力利用率而设计。</strong> 多租户隔离、拓扑感知以及适配智能体工作流的任务调度系统，将成为差异化优势。“90%+的持续算力利用率”已成为核心销售卖点。</li>
<li><strong>对冲周期波动。</strong> 勿将市场波动视为意外。在可锁定处签订长期合约，在不可控处保持灵活选择权。</li>
</ul>
<h1><strong>07 为何“AI 崩盘论”看似可信却实非如此</strong></h1>
<ul>
<li>人们倾向于只关注那些容易被包装成故事的信息。一个旗舰产品的风格发生变化，人人都能立刻感知；但 HBM（高频宽存储器）的供应量变化，却鲜有人注意。我们总是过度重视那些显而易见、容易被讲述的事物。</li>
<li>炒作后的幻灭。人们的期望以比科学进步快得多的速度膨胀；当新产品发布时，现实达不到大家的想象，我们又立刻从狂热跌入过度失望。</li>
<li>我们把“我的 AI 助手没改变生活”这种个人体验，和“没人会买 GPU”这种市场趋势混为一谈。可这是两个完全不同的市场，运行在不同的节奏上。</li>
</ul>
<p>在这里使用消化期这个隐喻还是蛮恰当的。过去一段时间，整个行业像饕餮一样吞下产能，疯狂追逐产能扩张、快速推出原型产品，并不断制造吸引眼球的故事。但现在，热潮过去了，身体吃得太撑，需要停下来好好消化。这表现为新闻头条不再那么激动人心，进展看起来变慢了；企业采购变得更谨慎、更难；大家开始认真讨论投入产出比（ROI）：不再问“能不能做”，而是问“值不值得做”；技术进步的重点，从“往训练里砸多少算力”转向“如何更聪明地使用模型”——追求的是质的跃升，而不是量的堆砌；资本运作也回归理性：短期投机减少，长期规划增多；不再靠“感觉”和“氛围”融资，而是靠扎实的财务评估和风险控制。</p>
<p>如果你想贬低它的话，你可以称之为“回落期”或“降温阶段”。但实际上，这其实是一个关键时期：护城河正在被真正挖深，财务脆弱的公司开始崩塌，而真正持久的运营杠杆（即成本不变但产出大幅增加的优势）开始在那些不起眼的地方显现出来 —— 比如电力供应、芯片封装、互联技术，以及让智能体（agents）真正可靠干活的、枯燥却至关重要的工程细节。</p>
<p><strong>归根结底，如果你的投资或判断是基于“GPT-5 让我失望，所以 AI 泡沫要破了”这种感受，那你其实是在用情绪做决策，而不是分析真实市场。</strong> 你应该分清表层情绪和底层现实，关注那些能证伪你观点的信号（比如数据、产能、需求），并做好准备 —— 迎接的可能是一段消化调整期，而不是突然的崩盘。</p>
<p><strong>END</strong></p>
<p><strong>本期互动内容 🍻</strong></p>
<p><strong>❓如果你是一家企业的决策者，在当前的“消化期”，你会更倾向于投资基础设施，还是深耕垂直场景的 AI 应用？为什么？</strong></p>
<p><strong>原文链接：</strong></p>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdavefriedman.substack.com%2Fp%2Fthe-ai-market-isnt-collapsing-its" target="_blank">https://davefriedman.substack.com/p/the-ai-market-isnt-collapsing-its</a></p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>&gt; <strong>编者按：</strong> 当&nbsp;GPT-5&nbsp;的表现未达预期，当众多&nbsp;AI&nbsp;应用试点项目收效甚微，当市场开始质疑人工智能的发展前景时，我们是否正在经历一场&nbsp;AI&nbsp;泡沫的破裂？还是说，这些表面现象背后隐藏着更深层次的产业逻辑？ &gt; &gt; 我们今天为大家带来的这篇文章，作者的观点是：当前 AI 市场并非陷入停滞或崩溃，而是进入了一个必要的“消化阶段”，这一过程虽伴随阵痛，却蕴含着持续的发展动能。 &gt; &gt; 文章通过四个层次的分析框架，系统性地解构了当前 AI 市场的真实状况：首先厘清了产品体验设计与技术能力上限的区别，指出用户对 GPT-5 的失望更多源于产品策略而非能力倒退；第二，应用层回报不明朗的根源在于组织流程滞后于技术能力，真正有价值的垂直整合方案正在悄然建立护城河；第三，基础设施投资正从粗放扩张转向精细化运营，算力合约结构化、算力利用率优化和电力资源争夺成为新焦点；最后阐述了技术演进已超越“规模至上”的初级阶段，转向测试时计算、工具调用、数据质量与智能体系统等更深层次的创新。作者还提供了判断行业是否真正崩溃的具体指标，并为资金配置方、应用层创业者和基础设施构建者提供了清晰的战略建议。</p>
<p><strong>作者 | Dave Friedman</strong></p>
<p><strong>编译 | 岳扬</strong></p>
<p>目前流传着一种看似合理的说法：GPT-5 表现未达预期，因此 AI 泡沫正在破裂。这个观点看似顺理成章，实则是错误的。这个说法将四个不同维度的事情强行捆绑，硬是揉成了一个整体：（1）产品体验的设计选择；（2）应用层的投资回报；（3）基础设施投入与供应链；（4）科研进展与规模化应用。当你拆解这层层架构时，看似崩盘的态势其实正转化为一个“消化阶段” —— 既有可预见的阵痛，也伴随着同样可预见的持续动能。</p>
<p>以下是一个用于厘清思路的清晰框架。</p>
<h1><strong>01 Layer 1：产品体验 ≠ 能力上限</strong></h1>
<p>围绕 GPT-5 的争议大多聚焦于使用感受：语气转变、拒绝机制，以及有时将用户导向更安全但乏味的交互模式。<strong>这些属于产品决策（模型对齐过程中的参数选择、安全护栏、模型路由配置、默认设置），而非技术能力的倒退。</strong> 安全调校的悖论在于：当交互界面改变“对话风格”或严格限制高风险场景时，即便能力略有提升，用户仍可能感知为性能倒退。</p>
<p>三大常见认知误区：</p>
<p>1）<strong>对齐策略与核心能力</strong>：若模型规避特定输出或在高风险领域缩短推理链条，用户就会判断“模型变差”。此时衡量的实则为安全策略，而非底层能力。</p>
<p>2）<strong>路由系统与核心模型</strong>：AI 助手类产品常采用多个模型混合调用方案。若路由系统误将请求导向更保守的小模型，用户体验到的性能波动会被错误归于旗舰模型。</p>
<p>3）<strong>大家的心理预期比较高</strong>：被冠以“划时代”称号的发布版本会设定参照标准，而实际改进幅度往往难以匹配这种预期。但即便不如宣传片震撼，这些改进（尤其在编程、长程任务和工具调用领域）仍然具有重要意义。</p>
<p>本层结论：这是产品管理策略引发的争议，并非能力停滞的证据。</p>
<h1><strong>02 Layer 2：应用层投资回报混沌不清，且与基础设施需求背道而驰</strong></h1>
<p>的确，很多企业试点项目都没有达到预期目标。但原因很简单：数据管道尚未就绪；工作流未重新设计；激励机制阻碍落地；风控措施拖慢部署；套壳应用同质化严重。当技术普及速度超过组织流程改造速度时，市场必然会出现应用层淘汰洗牌。</p>
<p>关键差异点：</p>
<p>1）<strong>套壳应用与系统重构</strong>：基于 API 的套壳聊天应用会快速同质化，而重构工作流的系统（如智能体、工具调用、私有数据检索、知识图谱）虽见效慢，却能建立更持久的优势。</p>
<p>2）<strong>横向与纵向方案之别</strong>：横向通用助手的市场声量大，但深度融合领域工具的垂直方案才真正能产生回报。后者需与一线操作者共同设计且销售周期更长，但正是护城河所在。</p>
<p>3）<strong>核心评估指标</strong>：节省工时数量和客户满意度这类脱离利润的虚荣指标毫无意义。应关注误差调整后的吞吐量、营运资金周转率或事件率变化值。若无法将成效折算为财务收益，下一轮预算审议时项目必然被否决。</p>
<p>这一层的低迷与基础设施层的蓬勃发展并不矛盾：边缘应用的弱产品市场匹配度，不会削弱对训练迭代、模型升级或智能体框架的需求，只会重新分配价值捕获的主体。</p>
<h1><strong>03 Layer 3：基础设施资本支出正从冲刺期转向消化期，而非断崖式下跌</strong></h1>
<p>基础设施领域并非“投资枯竭”，而是进入了一个新阶段：资源配置结构与利用效率将成为决胜关键。三个同时存在的事实：</p>
<p>1）<strong>产能持续扩张</strong>：电力、高频宽存储器（HBM）与先进封装（CoWoS 级）仍是关键制约因素。即便积极扩产，2026 年前多数地区的供应仍将紧张。这支撑着定价并持续激励基建投入。</p>
<p>2）<strong>算力闲置风险是局部性的而非系统性的</strong>：拥有全栈需求（搜索、广告、云服务、办公软件、消费应用）的超大规模厂商可通过模型轮替与吸纳测试时计算阶段的算力消耗保持 GPU 满载。风险主要集中在独立的 AI 云服务商和专项供应商 —— 它们面临租赁成本攀升、客户集中度高和短期采购协议的压力。即便总体需求增长，这类企业仍可能遭遇阶段性的困境。</p>
<p>3）<strong>从粗放式短期算力租赁向精细化长期商业协议</strong>：随着市场逐渐成熟，短期的算力现货租赁将减少，结构化的采购协议将成为主流（包括更长的合约期限、最低采购量承诺以及指数化定价机制）。算力金融化工具（期货/远期合约、容量预留、风险对冲）将平滑市场的消化过程，同时降低建设方与采购方的资金成本。</p>
<p>“资本支出消化期”意味着：在供应增速超越短期客户需求的领域将出现价格体系调整。行业重点正转向电力采购、互联技术、散热系统和可用性保障，并对 GPU 利用率管理赋予更高溢价 —— 这与市场崩溃的论调截然不同。</p>
<h1><strong>04 Layer 4：“规模即王道”从来就不是严肃的理论命题</strong></h1>
<p>有一种夸张的片面观点宣称：“我们已经扩大了预训练规模，现在就此止步”。<strong>而真正严谨的技术演进路径实则是：规模 × 算法创新 × 测试时计算 × 工具调用 × 高质量数据。</strong> 技术前沿正在发生范式转移：</p>
<p>1）<strong>测试时计算与规划能力</strong>：更多思维链、外部记忆、验证机制以及搜索/规划循环的运用。这方面的突破不需要更大的基础模型，而更依赖更智能的推理计算。</p>
<p>2）<strong>工具调用与智能体</strong>：将代码执行、数据库操作和服务调用作为默认运行模式（而非演示功能），使模型从文本预测器升级为行动系统。</p>
<p>3）<strong>数据质量与课程学习</strong>：当粗暴的数据规模扩张效益递减时，数据精加工、合成数据方案、基于结果指标的强化学习以及针对特定任务设计的课程学习将成为突破性能瓶颈的关键。</p>
<p>单纯扩张预训练规模的收益递减并不意味进步终结，而是改变了规模化的方向。</p>
<p>结合这四个层面来看：AI 助手默认设置的重设计带来了不好的用户体验；大量应用型初创公司遭遇试点价值的转化困境；基础设施投入正在进行结构化调整与专业化升级；研究重点从无序的规模扩张转向结构化推理。这些内容无一指向 AI 泡沫破裂，而是符合幂律分布特征的技术走向成熟的必然形态。</p>
<h1><strong>05 需要出现怎样的证据，才能真正推翻“行业处于消化期”的判断？</strong></h1>
<p>请关注下面这个简单明了的核查清单：</p>
<p>1）多家超大规模厂商连续两轮以上资本支出下调（非仅投资结构调整），且明确推迟数据中心建设（而非仅重新排序工期）</p>
<p>2）顶级 GPU 集群出现价格战（通过公开价目表可量化），同时披露闲置产能或明显延长 GPU 闲置周期。</p>
<p>3）需连续多代模型版本在复杂推理基准测试和智能体工作流中出现平台期，工具使用可靠性（如代码执行成功率）停止提升。</p>
<p>4）电网互联排队周期长和变电站扩容项目延期导致项目大规模取消（非仅工期延后），联邦能源监管委员会/公用事业约束硬性限制建设规模。</p>
<p>5）两个及以上客户群在经过深度工作流整合后，AI 套件/助手的续约率显著低于试点期表现。</p>
<p><strong>若同时触发 2-3 项指标则需重新评估“行业处于消化期”这一判断。否则应预期行业处于结构性调整而非崩溃状态。</strong></p>
<h1><strong>06 战略要点</strong></h1>
<h2><strong>6.1 资金配置方</strong></h2>
<ul>
<li><strong>优先布局瓶颈环节，而非追逐品牌光环。</strong> 高频宽存储器（HBM）、芯片基板、先进封装、电网升级、变压器/变电站设备以及散热系统。这些领域的供给制约持续时间将远超市场预期。</li>
<li><strong>审慎评估独立厂商的资本结构。</strong> 关注租赁费用递增条款与收入条款的匹配度、客户集中度及合同期限。用仅持续 90 天的收入流去支撑长达 36 个月的债务责任，便是在重演硅谷版的 WeWork 式危机。</li>
<li><strong>优先选择与约定期限关联的风险敞口。</strong> 优先选择包含阶梯价格、保底/封顶机制和电力成本传导条款的容量预留与算力采购协议。此类合约正在快速完善风控体系。</li>
</ul>
<h2><strong>6.2 应用层创业者</strong></h2>
<ul>
<li><strong>构建系统级解决方案，而非浅层套壳应用。</strong> 开发深度整合私有数据与领域工具的智能体工作流，用财务收益衡量成效而非使用演示效果衡量。</li>
<li><strong>掌控评估体系。</strong> 评估能力是产品的核心模块而不是纯研究属性的功能。若无法基于客户自有指标证明成果差异，则终将沦为附属功能。</li>
<li><strong>善用测试时计算（test-time compute）。</strong> 部署轻量基础模型搭配强大的规划/搜索框架，可在成本与质量上超越暴力扩展方案。</li>
</ul>
<h2><strong>6.3 基础设施构建者</strong></h2>
<ul>
<li><strong>优先获取电力资源。</strong> 土地易得，充足的电力难求。变电站的交付周期与等待电网公司审批接入的排队时间对项目进度的影响，远超过芯片供应短缺。</li>
<li><strong>为算力利用率而设计。</strong> 多租户隔离、拓扑感知以及适配智能体工作流的任务调度系统，将成为差异化优势。“90%+的持续算力利用率”已成为核心销售卖点。</li>
<li><strong>对冲周期波动。</strong> 勿将市场波动视为意外。在可锁定处签订长期合约，在不可控处保持灵活选择权。</li>
</ul>
<h1><strong>07 为何“AI 崩盘论”看似可信却实非如此</strong></h1>
<ul>
<li>人们倾向于只关注那些容易被包装成故事的信息。一个旗舰产品的风格发生变化，人人都能立刻感知；但 HBM（高频宽存储器）的供应量变化，却鲜有人注意。我们总是过度重视那些显而易见、容易被讲述的事物。</li>
<li>炒作后的幻灭。人们的期望以比科学进步快得多的速度膨胀；当新产品发布时，现实达不到大家的想象，我们又立刻从狂热跌入过度失望。</li>
<li>我们把“我的 AI 助手没改变生活”这种个人体验，和“没人会买 GPU”这种市场趋势混为一谈。可这是两个完全不同的市场，运行在不同的节奏上。</li>
</ul>
<p>在这里使用消化期这个隐喻还是蛮恰当的。过去一段时间，整个行业像饕餮一样吞下产能，疯狂追逐产能扩张、快速推出原型产品，并不断制造吸引眼球的故事。但现在，热潮过去了，身体吃得太撑，需要停下来好好消化。这表现为新闻头条不再那么激动人心，进展看起来变慢了；企业采购变得更谨慎、更难；大家开始认真讨论投入产出比（ROI）：不再问“能不能做”，而是问“值不值得做”；技术进步的重点，从“往训练里砸多少算力”转向“如何更聪明地使用模型”——追求的是质的跃升，而不是量的堆砌；资本运作也回归理性：短期投机减少，长期规划增多；不再靠“感觉”和“氛围”融资，而是靠扎实的财务评估和风险控制。</p>
<p>如果你想贬低它的话，你可以称之为“回落期”或“降温阶段”。但实际上，这其实是一个关键时期：护城河正在被真正挖深，财务脆弱的公司开始崩塌，而真正持久的运营杠杆（即成本不变但产出大幅增加的优势）开始在那些不起眼的地方显现出来 —— 比如电力供应、芯片封装、互联技术，以及让智能体（agents）真正可靠干活的、枯燥却至关重要的工程细节。</p>
<p><strong>归根结底，如果你的投资或判断是基于“GPT-5 让我失望，所以 AI 泡沫要破了”这种感受，那你其实是在用情绪做决策，而不是分析真实市场。</strong> 你应该分清表层情绪和底层现实，关注那些能证伪你观点的信号（比如数据、产能、需求），并做好准备 —— 迎接的可能是一段消化调整期，而不是突然的崩盘。</p>
<p><strong>END</strong></p>
<p><strong>本期互动内容 🍻</strong></p>
<p><strong>❓如果你是一家企业的决策者，在当前的“消化期”，你会更倾向于投资基础设施，还是深耕垂直场景的 AI 应用？为什么？</strong></p>
<p><strong>原文链接：</strong></p>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdavefriedman.substack.com%2Fp%2Fthe-ai-market-isnt-collapsing-its" target="_blank">https://davefriedman.substack.com/p/the-ai-market-isnt-collapsing-its</a></p>]]>
    </description>
    <content:encoded><![CDATA[<p>&gt; <strong>编者按：</strong> 当&nbsp;GPT-5&nbsp;的表现未达预期，当众多&nbsp;AI&nbsp;应用试点项目收效甚微，当市场开始质疑人工智能的发展前景时，我们是否正在经历一场&nbsp;AI&nbsp;泡沫的破裂？还是说，这些表面现象背后隐藏着更深层次的产业逻辑？ &gt; &gt; 我们今天为大家带来的这篇文章，作者的观点是：当前 AI 市场并非陷入停滞或崩溃，而是进入了一个必要的“消化阶段”，这一过程虽伴随阵痛，却蕴含着持续的发展动能。 &gt; &gt; 文章通过四个层次的分析框架，系统性地解构了当前 AI 市场的真实状况：首先厘清了产品体验设计与技术能力上限的区别，指出用户对 GPT-5 的失望更多源于产品策略而非能力倒退；第二，应用层回报不明朗的根源在于组织流程滞后于技术能力，真正有价值的垂直整合方案正在悄然建立护城河；第三，基础设施投资正从粗放扩张转向精细化运营，算力合约结构化、算力利用率优化和电力资源争夺成为新焦点；最后阐述了技术演进已超越“规模至上”的初级阶段，转向测试时计算、工具调用、数据质量与智能体系统等更深层次的创新。作者还提供了判断行业是否真正崩溃的具体指标，并为资金配置方、应用层创业者和基础设施构建者提供了清晰的战略建议。</p>
<p><strong>作者 | Dave Friedman</strong></p>
<p><strong>编译 | 岳扬</strong></p>
<p>目前流传着一种看似合理的说法：GPT-5 表现未达预期，因此 AI 泡沫正在破裂。这个观点看似顺理成章，实则是错误的。这个说法将四个不同维度的事情强行捆绑，硬是揉成了一个整体：（1）产品体验的设计选择；（2）应用层的投资回报；（3）基础设施投入与供应链；（4）科研进展与规模化应用。当你拆解这层层架构时，看似崩盘的态势其实正转化为一个“消化阶段” —— 既有可预见的阵痛，也伴随着同样可预见的持续动能。</p>
<p>以下是一个用于厘清思路的清晰框架。</p>
<h1><strong>01 Layer 1：产品体验 ≠ 能力上限</strong></h1>
<p>围绕 GPT-5 的争议大多聚焦于使用感受：语气转变、拒绝机制，以及有时将用户导向更安全但乏味的交互模式。<strong>这些属于产品决策（模型对齐过程中的参数选择、安全护栏、模型路由配置、默认设置），而非技术能力的倒退。</strong> 安全调校的悖论在于：当交互界面改变“对话风格”或严格限制高风险场景时，即便能力略有提升，用户仍可能感知为性能倒退。</p>
<p>三大常见认知误区：</p>
<p>1）<strong>对齐策略与核心能力</strong>：若模型规避特定输出或在高风险领域缩短推理链条，用户就会判断“模型变差”。此时衡量的实则为安全策略，而非底层能力。</p>
<p>2）<strong>路由系统与核心模型</strong>：AI 助手类产品常采用多个模型混合调用方案。若路由系统误将请求导向更保守的小模型，用户体验到的性能波动会被错误归于旗舰模型。</p>
<p>3）<strong>大家的心理预期比较高</strong>：被冠以“划时代”称号的发布版本会设定参照标准，而实际改进幅度往往难以匹配这种预期。但即便不如宣传片震撼，这些改进（尤其在编程、长程任务和工具调用领域）仍然具有重要意义。</p>
<p>本层结论：这是产品管理策略引发的争议，并非能力停滞的证据。</p>
<h1><strong>02 Layer 2：应用层投资回报混沌不清，且与基础设施需求背道而驰</strong></h1>
<p>的确，很多企业试点项目都没有达到预期目标。但原因很简单：数据管道尚未就绪；工作流未重新设计；激励机制阻碍落地；风控措施拖慢部署；套壳应用同质化严重。当技术普及速度超过组织流程改造速度时，市场必然会出现应用层淘汰洗牌。</p>
<p>关键差异点：</p>
<p>1）<strong>套壳应用与系统重构</strong>：基于 API 的套壳聊天应用会快速同质化，而重构工作流的系统（如智能体、工具调用、私有数据检索、知识图谱）虽见效慢，却能建立更持久的优势。</p>
<p>2）<strong>横向与纵向方案之别</strong>：横向通用助手的市场声量大，但深度融合领域工具的垂直方案才真正能产生回报。后者需与一线操作者共同设计且销售周期更长，但正是护城河所在。</p>
<p>3）<strong>核心评估指标</strong>：节省工时数量和客户满意度这类脱离利润的虚荣指标毫无意义。应关注误差调整后的吞吐量、营运资金周转率或事件率变化值。若无法将成效折算为财务收益，下一轮预算审议时项目必然被否决。</p>
<p>这一层的低迷与基础设施层的蓬勃发展并不矛盾：边缘应用的弱产品市场匹配度，不会削弱对训练迭代、模型升级或智能体框架的需求，只会重新分配价值捕获的主体。</p>
<h1><strong>03 Layer 3：基础设施资本支出正从冲刺期转向消化期，而非断崖式下跌</strong></h1>
<p>基础设施领域并非“投资枯竭”，而是进入了一个新阶段：资源配置结构与利用效率将成为决胜关键。三个同时存在的事实：</p>
<p>1）<strong>产能持续扩张</strong>：电力、高频宽存储器（HBM）与先进封装（CoWoS 级）仍是关键制约因素。即便积极扩产，2026 年前多数地区的供应仍将紧张。这支撑着定价并持续激励基建投入。</p>
<p>2）<strong>算力闲置风险是局部性的而非系统性的</strong>：拥有全栈需求（搜索、广告、云服务、办公软件、消费应用）的超大规模厂商可通过模型轮替与吸纳测试时计算阶段的算力消耗保持 GPU 满载。风险主要集中在独立的 AI 云服务商和专项供应商 —— 它们面临租赁成本攀升、客户集中度高和短期采购协议的压力。即便总体需求增长，这类企业仍可能遭遇阶段性的困境。</p>
<p>3）<strong>从粗放式短期算力租赁向精细化长期商业协议</strong>：随着市场逐渐成熟，短期的算力现货租赁将减少，结构化的采购协议将成为主流（包括更长的合约期限、最低采购量承诺以及指数化定价机制）。算力金融化工具（期货/远期合约、容量预留、风险对冲）将平滑市场的消化过程，同时降低建设方与采购方的资金成本。</p>
<p>“资本支出消化期”意味着：在供应增速超越短期客户需求的领域将出现价格体系调整。行业重点正转向电力采购、互联技术、散热系统和可用性保障，并对 GPU 利用率管理赋予更高溢价 —— 这与市场崩溃的论调截然不同。</p>
<h1><strong>04 Layer 4：“规模即王道”从来就不是严肃的理论命题</strong></h1>
<p>有一种夸张的片面观点宣称：“我们已经扩大了预训练规模，现在就此止步”。<strong>而真正严谨的技术演进路径实则是：规模 × 算法创新 × 测试时计算 × 工具调用 × 高质量数据。</strong> 技术前沿正在发生范式转移：</p>
<p>1）<strong>测试时计算与规划能力</strong>：更多思维链、外部记忆、验证机制以及搜索/规划循环的运用。这方面的突破不需要更大的基础模型，而更依赖更智能的推理计算。</p>
<p>2）<strong>工具调用与智能体</strong>：将代码执行、数据库操作和服务调用作为默认运行模式（而非演示功能），使模型从文本预测器升级为行动系统。</p>
<p>3）<strong>数据质量与课程学习</strong>：当粗暴的数据规模扩张效益递减时，数据精加工、合成数据方案、基于结果指标的强化学习以及针对特定任务设计的课程学习将成为突破性能瓶颈的关键。</p>
<p>单纯扩张预训练规模的收益递减并不意味进步终结，而是改变了规模化的方向。</p>
<p>结合这四个层面来看：AI 助手默认设置的重设计带来了不好的用户体验；大量应用型初创公司遭遇试点价值的转化困境；基础设施投入正在进行结构化调整与专业化升级；研究重点从无序的规模扩张转向结构化推理。这些内容无一指向 AI 泡沫破裂，而是符合幂律分布特征的技术走向成熟的必然形态。</p>
<h1><strong>05 需要出现怎样的证据，才能真正推翻“行业处于消化期”的判断？</strong></h1>
<p>请关注下面这个简单明了的核查清单：</p>
<p>1）多家超大规模厂商连续两轮以上资本支出下调（非仅投资结构调整），且明确推迟数据中心建设（而非仅重新排序工期）</p>
<p>2）顶级 GPU 集群出现价格战（通过公开价目表可量化），同时披露闲置产能或明显延长 GPU 闲置周期。</p>
<p>3）需连续多代模型版本在复杂推理基准测试和智能体工作流中出现平台期，工具使用可靠性（如代码执行成功率）停止提升。</p>
<p>4）电网互联排队周期长和变电站扩容项目延期导致项目大规模取消（非仅工期延后），联邦能源监管委员会/公用事业约束硬性限制建设规模。</p>
<p>5）两个及以上客户群在经过深度工作流整合后，AI 套件/助手的续约率显著低于试点期表现。</p>
<p><strong>若同时触发 2-3 项指标则需重新评估“行业处于消化期”这一判断。否则应预期行业处于结构性调整而非崩溃状态。</strong></p>
<h1><strong>06 战略要点</strong></h1>
<h2><strong>6.1 资金配置方</strong></h2>
<ul>
<li><strong>优先布局瓶颈环节，而非追逐品牌光环。</strong> 高频宽存储器（HBM）、芯片基板、先进封装、电网升级、变压器/变电站设备以及散热系统。这些领域的供给制约持续时间将远超市场预期。</li>
<li><strong>审慎评估独立厂商的资本结构。</strong> 关注租赁费用递增条款与收入条款的匹配度、客户集中度及合同期限。用仅持续 90 天的收入流去支撑长达 36 个月的债务责任，便是在重演硅谷版的 WeWork 式危机。</li>
<li><strong>优先选择与约定期限关联的风险敞口。</strong> 优先选择包含阶梯价格、保底/封顶机制和电力成本传导条款的容量预留与算力采购协议。此类合约正在快速完善风控体系。</li>
</ul>
<h2><strong>6.2 应用层创业者</strong></h2>
<ul>
<li><strong>构建系统级解决方案，而非浅层套壳应用。</strong> 开发深度整合私有数据与领域工具的智能体工作流，用财务收益衡量成效而非使用演示效果衡量。</li>
<li><strong>掌控评估体系。</strong> 评估能力是产品的核心模块而不是纯研究属性的功能。若无法基于客户自有指标证明成果差异，则终将沦为附属功能。</li>
<li><strong>善用测试时计算（test-time compute）。</strong> 部署轻量基础模型搭配强大的规划/搜索框架，可在成本与质量上超越暴力扩展方案。</li>
</ul>
<h2><strong>6.3 基础设施构建者</strong></h2>
<ul>
<li><strong>优先获取电力资源。</strong> 土地易得，充足的电力难求。变电站的交付周期与等待电网公司审批接入的排队时间对项目进度的影响，远超过芯片供应短缺。</li>
<li><strong>为算力利用率而设计。</strong> 多租户隔离、拓扑感知以及适配智能体工作流的任务调度系统，将成为差异化优势。“90%+的持续算力利用率”已成为核心销售卖点。</li>
<li><strong>对冲周期波动。</strong> 勿将市场波动视为意外。在可锁定处签订长期合约，在不可控处保持灵活选择权。</li>
</ul>
<h1><strong>07 为何“AI 崩盘论”看似可信却实非如此</strong></h1>
<ul>
<li>人们倾向于只关注那些容易被包装成故事的信息。一个旗舰产品的风格发生变化，人人都能立刻感知；但 HBM（高频宽存储器）的供应量变化，却鲜有人注意。我们总是过度重视那些显而易见、容易被讲述的事物。</li>
<li>炒作后的幻灭。人们的期望以比科学进步快得多的速度膨胀；当新产品发布时，现实达不到大家的想象，我们又立刻从狂热跌入过度失望。</li>
<li>我们把“我的 AI 助手没改变生活”这种个人体验，和“没人会买 GPU”这种市场趋势混为一谈。可这是两个完全不同的市场，运行在不同的节奏上。</li>
</ul>
<p>在这里使用消化期这个隐喻还是蛮恰当的。过去一段时间，整个行业像饕餮一样吞下产能，疯狂追逐产能扩张、快速推出原型产品，并不断制造吸引眼球的故事。但现在，热潮过去了，身体吃得太撑，需要停下来好好消化。这表现为新闻头条不再那么激动人心，进展看起来变慢了；企业采购变得更谨慎、更难；大家开始认真讨论投入产出比（ROI）：不再问“能不能做”，而是问“值不值得做”；技术进步的重点，从“往训练里砸多少算力”转向“如何更聪明地使用模型”——追求的是质的跃升，而不是量的堆砌；资本运作也回归理性：短期投机减少，长期规划增多；不再靠“感觉”和“氛围”融资，而是靠扎实的财务评估和风险控制。</p>
<p>如果你想贬低它的话，你可以称之为“回落期”或“降温阶段”。但实际上，这其实是一个关键时期：护城河正在被真正挖深，财务脆弱的公司开始崩塌，而真正持久的运营杠杆（即成本不变但产出大幅增加的优势）开始在那些不起眼的地方显现出来 —— 比如电力供应、芯片封装、互联技术，以及让智能体（agents）真正可靠干活的、枯燥却至关重要的工程细节。</p>
<p><strong>归根结底，如果你的投资或判断是基于“GPT-5 让我失望，所以 AI 泡沫要破了”这种感受，那你其实是在用情绪做决策，而不是分析真实市场。</strong> 你应该分清表层情绪和底层现实，关注那些能证伪你观点的信号（比如数据、产能、需求），并做好准备 —— 迎接的可能是一段消化调整期，而不是突然的崩盘。</p>
<p><strong>END</strong></p>
<p><strong>本期互动内容 🍻</strong></p>
<p><strong>❓如果你是一家企业的决策者，在当前的“消化期”，你会更倾向于投资基础设施，还是深耕垂直场景的 AI 应用？为什么？</strong></p>
<p><strong>原文链接：</strong></p>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdavefriedman.substack.com%2Fp%2Fthe-ai-market-isnt-collapsing-its" target="_blank">https://davefriedman.substack.com/p/the-ai-market-isnt-collapsing-its</a></p>]]></content:encoded>
    
    <pubDate>Wed, 15 Oct 2025 15:51:22 +0800</pubDate>
  </item><item>
    <title><![CDATA[RustDesk 即将突破 100K stars]]></title>
    <link>https://www.oschina.net/news/377574</link>
    <itunes:title><![CDATA[RustDesk 即将突破 100K stars]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<div>
<p><span><span><span><span>截至目前，RustDesk 在 GitHub 上的 Star 数已超过&nbsp;</span></span><span><span><span><span>99.9k</span></span></span></span><span><span>，最晚明天就能达到 10 万。作为用 Rust 开发的远程桌面软件，RustDesk 有望成为继 </span></span><span><span><span><span>Rust 语言</span></span></span></span><span><span>（107k Star）和 </span></span><span><span><span><span>Deno</span></span></span></span><span><span>（104k Star）后，</span></span><span><span><span><span>第三个 10 万 Star 的 Rust 项目</span></span></span></span><span><span>。我们由衷感谢社区的每份贡献！</span></span></span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-f67db08c84.jpg"></p>
<h2>RustDesk：简单实用的开源工具</h2>
<div>
<span>RustDesk 是一款开源跨平台远程桌面软件，特点包括：</span>
</div>
<div>
<ul>
<li><span><span><span><span><span>开源透明</span></span></span></span><span><span>：AGPL-3.0 协议，代码公开，欢迎改进。</span></span></span></li>
<li><span><span><span><span><span>高效稳定</span></span></span></span><span><span>：Rust 语言确保性能和安全。</span></span></span></li>
<li><span><span><span><span><span>自托管</span></span></span></span><span><span>：支持私有服务器，保护隐私。</span></span></span></li>
<li><span><span><span><span><span>跨平台</span></span></span></span><span><span>：支持 Windows (&gt;=Win7)、macOS、Linux (X11/Wayland)、Android、iOS、 Web。</span></span></span></li>
</ul>
</div>
<p><span><span><span><span>自2021年3月开源，RustDesk 靠社区的代码、翻译和反馈不断完善。遗憾的是，它曾被诈骗分子冒用，诱导用户授予远程权限。团队已添加警告提示，提醒只与可信方共享访问，并呼吁社区加强安全意识。</span></span></span></span></p>
</div>
<h2>社区的每一步支持</h2>
<div>
10 万 Star 凝聚了社区的信任，离不开每位贡献者的努力。RustDesk 还有改进空间，我们会继续与大家一起完善：
<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Frustdesk%2Frustdesk" target="_blank">https://github.com/rustdesk/rustdesk</a>
</div>]]>
    </itunes:summary>
    <description>
      <![CDATA[<div>
<p><span><span><span><span>截至目前，RustDesk 在 GitHub 上的 Star 数已超过&nbsp;</span></span><span><span><span><span>99.9k</span></span></span></span><span><span>，最晚明天就能达到 10 万。作为用 Rust 开发的远程桌面软件，RustDesk 有望成为继 </span></span><span><span><span><span>Rust 语言</span></span></span></span><span><span>（107k Star）和 </span></span><span><span><span><span>Deno</span></span></span></span><span><span>（104k Star）后，</span></span><span><span><span><span>第三个 10 万 Star 的 Rust 项目</span></span></span></span><span><span>。我们由衷感谢社区的每份贡献！</span></span></span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-f67db08c84.jpg"></p>
<h2>RustDesk：简单实用的开源工具</h2>
<div>
<span>RustDesk 是一款开源跨平台远程桌面软件，特点包括：</span>
</div>
<div>
<ul>
<li><span><span><span><span><span>开源透明</span></span></span></span><span><span>：AGPL-3.0 协议，代码公开，欢迎改进。</span></span></span></li>
<li><span><span><span><span><span>高效稳定</span></span></span></span><span><span>：Rust 语言确保性能和安全。</span></span></span></li>
<li><span><span><span><span><span>自托管</span></span></span></span><span><span>：支持私有服务器，保护隐私。</span></span></span></li>
<li><span><span><span><span><span>跨平台</span></span></span></span><span><span>：支持 Windows (&gt;=Win7)、macOS、Linux (X11/Wayland)、Android、iOS、 Web。</span></span></span></li>
</ul>
</div>
<p><span><span><span><span>自2021年3月开源，RustDesk 靠社区的代码、翻译和反馈不断完善。遗憾的是，它曾被诈骗分子冒用，诱导用户授予远程权限。团队已添加警告提示，提醒只与可信方共享访问，并呼吁社区加强安全意识。</span></span></span></span></p>
</div>
<h2>社区的每一步支持</h2>
<div>
10 万 Star 凝聚了社区的信任，离不开每位贡献者的努力。RustDesk 还有改进空间，我们会继续与大家一起完善：
<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Frustdesk%2Frustdesk" target="_blank">https://github.com/rustdesk/rustdesk</a>
</div>]]>
    </description>
    <content:encoded><![CDATA[<div>
<p><span><span><span><span>截至目前，RustDesk 在 GitHub 上的 Star 数已超过&nbsp;</span></span><span><span><span><span>99.9k</span></span></span></span><span><span>，最晚明天就能达到 10 万。作为用 Rust 开发的远程桌面软件，RustDesk 有望成为继 </span></span><span><span><span><span>Rust 语言</span></span></span></span><span><span>（107k Star）和 </span></span><span><span><span><span>Deno</span></span></span></span><span><span>（104k Star）后，</span></span><span><span><span><span>第三个 10 万 Star 的 Rust 项目</span></span></span></span><span><span>。我们由衷感谢社区的每份贡献！</span></span></span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-f67db08c84.jpg"></p>
<h2>RustDesk：简单实用的开源工具</h2>
<div>
<span>RustDesk 是一款开源跨平台远程桌面软件，特点包括：</span>
</div>
<div>
<ul>
<li><span><span><span><span><span>开源透明</span></span></span></span><span><span>：AGPL-3.0 协议，代码公开，欢迎改进。</span></span></span></li>
<li><span><span><span><span><span>高效稳定</span></span></span></span><span><span>：Rust 语言确保性能和安全。</span></span></span></li>
<li><span><span><span><span><span>自托管</span></span></span></span><span><span>：支持私有服务器，保护隐私。</span></span></span></li>
<li><span><span><span><span><span>跨平台</span></span></span></span><span><span>：支持 Windows (&gt;=Win7)、macOS、Linux (X11/Wayland)、Android、iOS、 Web。</span></span></span></li>
</ul>
</div>
<p><span><span><span><span>自2021年3月开源，RustDesk 靠社区的代码、翻译和反馈不断完善。遗憾的是，它曾被诈骗分子冒用，诱导用户授予远程权限。团队已添加警告提示，提醒只与可信方共享访问，并呼吁社区加强安全意识。</span></span></span></span></p>
</div>
<h2>社区的每一步支持</h2>
<div>
10 万 Star 凝聚了社区的信任，离不开每位贡献者的努力。RustDesk 还有改进空间，我们会继续与大家一起完善：
<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Frustdesk%2Frustdesk" target="_blank">https://github.com/rustdesk/rustdesk</a>
</div>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-f67db08c84.jpg"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-f67db08c84.jpg" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 15:50:35 +0800</pubDate>
  </item><item>
    <title><![CDATA[巨人网络&amp;清华大学开源 DiaMoE-TTS，多方言语音合成大模型框架]]></title>
    <link>https://www.oschina.net/news/377568</link>
    <itunes:title><![CDATA[巨人网络&amp;清华大学开源 DiaMoE-TTS，多方言语音合成大模型框架]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p><span>巨人网络AI Lab与清华大学电子工程系SATLab研究团队近日联合发布一项重大突破：</span>首创多方言语音合成大模型框架DiaMoE-TTS<span>，并宣布将</span>数据、代码、方法全方位开源<span>，旨在推动方言语音合成的公平与普惠。</span></p>
<p>在当前通用TTS（文本转语音）大模型能力惊人的时代，方言TTS(Dialect TTS)仍是业界难以触及的“灰色地带”。现有的工业级方言模型过于依赖巨量的专有数据，导致方言从业者和研究者面临缺乏统一语料构建方法和端到端开源框架的困境。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-f36d8f0626.png"></p>
<p>由双方联合首创的DiaMoE-TTS框架，为这一难题提供了一套开源的完整解决方案，其性能在一定程度上可媲美工业级方言TTS模型。该方案的关键创新在于：</p>
<ol>
<li> <p>统一的IPA表达体系：基于语言学家的专业经验，构建了一个统一的国际音标（IPA）表达体系。</p> </li>
<li> <p>数据高效性：该框架仅依赖开源方言ASR（自动语音识别）数据，解决了巨量专有数据依赖的痛点。</p> </li>
</ol>
<p>在推出广东话、四川话、上海话等中文方言版本之前，该研究团队已在英语、法语、德语、荷兰比尔茨语等多语种场景中进行过验证，证明该方法具备全球范围内的多语言可扩展性与稳健性。</p>
<p>巨人网络AI Lab与清华大学电子工程系SATLab表示，希望通过DiaMoE-TTS框架的开源，让任何研究者、开发者乃至语言文化保护工作者都能自由使用、改进与扩展这一框架，确保小众语言与方言的声音不再被通用大模型的洪流所淹没，而是能通过开源的力量被更广泛地听见与传承。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p><span>巨人网络AI Lab与清华大学电子工程系SATLab研究团队近日联合发布一项重大突破：</span>首创多方言语音合成大模型框架DiaMoE-TTS<span>，并宣布将</span>数据、代码、方法全方位开源<span>，旨在推动方言语音合成的公平与普惠。</span></p>
<p>在当前通用TTS（文本转语音）大模型能力惊人的时代，方言TTS(Dialect TTS)仍是业界难以触及的“灰色地带”。现有的工业级方言模型过于依赖巨量的专有数据，导致方言从业者和研究者面临缺乏统一语料构建方法和端到端开源框架的困境。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-f36d8f0626.png"></p>
<p>由双方联合首创的DiaMoE-TTS框架，为这一难题提供了一套开源的完整解决方案，其性能在一定程度上可媲美工业级方言TTS模型。该方案的关键创新在于：</p>
<ol>
<li> <p>统一的IPA表达体系：基于语言学家的专业经验，构建了一个统一的国际音标（IPA）表达体系。</p> </li>
<li> <p>数据高效性：该框架仅依赖开源方言ASR（自动语音识别）数据，解决了巨量专有数据依赖的痛点。</p> </li>
</ol>
<p>在推出广东话、四川话、上海话等中文方言版本之前，该研究团队已在英语、法语、德语、荷兰比尔茨语等多语种场景中进行过验证，证明该方法具备全球范围内的多语言可扩展性与稳健性。</p>
<p>巨人网络AI Lab与清华大学电子工程系SATLab表示，希望通过DiaMoE-TTS框架的开源，让任何研究者、开发者乃至语言文化保护工作者都能自由使用、改进与扩展这一框架，确保小众语言与方言的声音不再被通用大模型的洪流所淹没，而是能通过开源的力量被更广泛地听见与传承。</p>]]>
    </description>
    <content:encoded><![CDATA[<p><span>巨人网络AI Lab与清华大学电子工程系SATLab研究团队近日联合发布一项重大突破：</span>首创多方言语音合成大模型框架DiaMoE-TTS<span>，并宣布将</span>数据、代码、方法全方位开源<span>，旨在推动方言语音合成的公平与普惠。</span></p>
<p>在当前通用TTS（文本转语音）大模型能力惊人的时代，方言TTS(Dialect TTS)仍是业界难以触及的“灰色地带”。现有的工业级方言模型过于依赖巨量的专有数据，导致方言从业者和研究者面临缺乏统一语料构建方法和端到端开源框架的困境。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-f36d8f0626.png"></p>
<p>由双方联合首创的DiaMoE-TTS框架，为这一难题提供了一套开源的完整解决方案，其性能在一定程度上可媲美工业级方言TTS模型。该方案的关键创新在于：</p>
<ol>
<li> <p>统一的IPA表达体系：基于语言学家的专业经验，构建了一个统一的国际音标（IPA）表达体系。</p> </li>
<li> <p>数据高效性：该框架仅依赖开源方言ASR（自动语音识别）数据，解决了巨量专有数据依赖的痛点。</p> </li>
</ol>
<p>在推出广东话、四川话、上海话等中文方言版本之前，该研究团队已在英语、法语、德语、荷兰比尔茨语等多语种场景中进行过验证，证明该方法具备全球范围内的多语言可扩展性与稳健性。</p>
<p>巨人网络AI Lab与清华大学电子工程系SATLab表示，希望通过DiaMoE-TTS框架的开源，让任何研究者、开发者乃至语言文化保护工作者都能自由使用、改进与扩展这一框架，确保小众语言与方言的声音不再被通用大模型的洪流所淹没，而是能通过开源的力量被更广泛地听见与传承。</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-f36d8f0626.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-f36d8f0626.png" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 15:33:19 +0800</pubDate>
  </item><item>
    <title><![CDATA[FSF 推出 Librephone 项目：为手机用户带来自由]]></title>
    <link>https://www.oschina.net/news/377567/fsf-librephone-project</link>
    <itunes:title><![CDATA[FSF 推出 Librephone 项目：为手机用户带来自由]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p><span>自由软件基金会 (FSF) <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.fsf.org%2Fnews%2Flibrephone-project" target="_blank">宣布</a>推出 LibrePhone 项目，旨在为移动设备打造一款完全自由的软件操作系统，并在必要时进行逆向工程，以突破障碍。</span></p>
<blockquote>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffsf.org%2Fcampaigns%2Flibrephone" target="_blank">Librephone 是</a>&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffsf.org%2F" target="_blank">FSF</a>&nbsp;<span>的一项新举措，旨在为移动计算环境带来完全的自由。全球绝大多数软件用户都使用手机作为其主要的计算设备。在倡导计算自由四十年后，FSF 现在将致力于将</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.gnu.org%2Fphilosophy%2Ffree-sw.html" target="_blank">学习、修改、共享和修改</a><span>用户日常生活所依赖的程序的权利引入手机。</span></p>
<p><span>“四十年前，FSF 成立之初，我们的重点是提供一款人们可以在台式电脑和服务器电脑上自由使用的操作系统。时代变了，技术进步了，但我们对自由的承诺却始终如一，”FSF 执行董事 Zoë Kooyman 表示。“多年来，我们在手机自由方面已经做了大量工作，我们将在此基础上继续努力。FSF 现已准备好采取一切必要措施，为手机用户带来自由。鉴于设备的复杂性，这项工作需要时间，但我们已习惯于打持久战。”</span></p>
</blockquote>
<p><span>公告称，Librephone 的目标是弥合现有 Android 操作系统发行版与软件自由之间的最后差距。FSF 已聘请 Rob Savoye（曾参与 DejaGNU、Gnash、OpenStreetMap 等项目）来领导该项目。初期工作由 FSF 董事会成员 John Gilmore 的捐款资助。</span></p>
<p><span>具体来说，FSF 方面计划第一步筛选现有软件包并根据设备兼容性找到一款自由问题最少、最易修复的手机。在此基础上，FSF 和 Savoye 的目标是对剩余的非自由软件进行逆向工程并替换掉它们。Librephone 将服务于现有的开发者和项目，帮助他们构建一个功能齐全且 free 的 Android 兼容操作系统。</span></p>
<p><span>当被要求对该项目发表评论时，Savoye 表示：“作为一名在移动设备上工作了几十年的长期嵌入式系统工程师，我期待着有机会致力于开发一款支持自由的手机，并帮助用户控制他们的手机硬件。为现代商用手机开发完全免费的软件并非易事，成本也高昂，但我们的项目受益于站在巨人的肩膀上，他们已经完成了大部分工作。请加入我们，贡献您的力量和/或捐款。”</span></p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p><span>自由软件基金会 (FSF) <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.fsf.org%2Fnews%2Flibrephone-project" target="_blank">宣布</a>推出 LibrePhone 项目，旨在为移动设备打造一款完全自由的软件操作系统，并在必要时进行逆向工程，以突破障碍。</span></p>
<blockquote>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffsf.org%2Fcampaigns%2Flibrephone" target="_blank">Librephone 是</a>&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffsf.org%2F" target="_blank">FSF</a>&nbsp;<span>的一项新举措，旨在为移动计算环境带来完全的自由。全球绝大多数软件用户都使用手机作为其主要的计算设备。在倡导计算自由四十年后，FSF 现在将致力于将</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.gnu.org%2Fphilosophy%2Ffree-sw.html" target="_blank">学习、修改、共享和修改</a><span>用户日常生活所依赖的程序的权利引入手机。</span></p>
<p><span>“四十年前，FSF 成立之初，我们的重点是提供一款人们可以在台式电脑和服务器电脑上自由使用的操作系统。时代变了，技术进步了，但我们对自由的承诺却始终如一，”FSF 执行董事 Zoë Kooyman 表示。“多年来，我们在手机自由方面已经做了大量工作，我们将在此基础上继续努力。FSF 现已准备好采取一切必要措施，为手机用户带来自由。鉴于设备的复杂性，这项工作需要时间，但我们已习惯于打持久战。”</span></p>
</blockquote>
<p><span>公告称，Librephone 的目标是弥合现有 Android 操作系统发行版与软件自由之间的最后差距。FSF 已聘请 Rob Savoye（曾参与 DejaGNU、Gnash、OpenStreetMap 等项目）来领导该项目。初期工作由 FSF 董事会成员 John Gilmore 的捐款资助。</span></p>
<p><span>具体来说，FSF 方面计划第一步筛选现有软件包并根据设备兼容性找到一款自由问题最少、最易修复的手机。在此基础上，FSF 和 Savoye 的目标是对剩余的非自由软件进行逆向工程并替换掉它们。Librephone 将服务于现有的开发者和项目，帮助他们构建一个功能齐全且 free 的 Android 兼容操作系统。</span></p>
<p><span>当被要求对该项目发表评论时，Savoye 表示：“作为一名在移动设备上工作了几十年的长期嵌入式系统工程师，我期待着有机会致力于开发一款支持自由的手机，并帮助用户控制他们的手机硬件。为现代商用手机开发完全免费的软件并非易事，成本也高昂，但我们的项目受益于站在巨人的肩膀上，他们已经完成了大部分工作。请加入我们，贡献您的力量和/或捐款。”</span></p>]]>
    </description>
    <content:encoded><![CDATA[<p><span>自由软件基金会 (FSF) <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.fsf.org%2Fnews%2Flibrephone-project" target="_blank">宣布</a>推出 LibrePhone 项目，旨在为移动设备打造一款完全自由的软件操作系统，并在必要时进行逆向工程，以突破障碍。</span></p>
<blockquote>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffsf.org%2Fcampaigns%2Flibrephone" target="_blank">Librephone 是</a>&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffsf.org%2F" target="_blank">FSF</a>&nbsp;<span>的一项新举措，旨在为移动计算环境带来完全的自由。全球绝大多数软件用户都使用手机作为其主要的计算设备。在倡导计算自由四十年后，FSF 现在将致力于将</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.gnu.org%2Fphilosophy%2Ffree-sw.html" target="_blank">学习、修改、共享和修改</a><span>用户日常生活所依赖的程序的权利引入手机。</span></p>
<p><span>“四十年前，FSF 成立之初，我们的重点是提供一款人们可以在台式电脑和服务器电脑上自由使用的操作系统。时代变了，技术进步了，但我们对自由的承诺却始终如一，”FSF 执行董事 Zoë Kooyman 表示。“多年来，我们在手机自由方面已经做了大量工作，我们将在此基础上继续努力。FSF 现已准备好采取一切必要措施，为手机用户带来自由。鉴于设备的复杂性，这项工作需要时间，但我们已习惯于打持久战。”</span></p>
</blockquote>
<p><span>公告称，Librephone 的目标是弥合现有 Android 操作系统发行版与软件自由之间的最后差距。FSF 已聘请 Rob Savoye（曾参与 DejaGNU、Gnash、OpenStreetMap 等项目）来领导该项目。初期工作由 FSF 董事会成员 John Gilmore 的捐款资助。</span></p>
<p><span>具体来说，FSF 方面计划第一步筛选现有软件包并根据设备兼容性找到一款自由问题最少、最易修复的手机。在此基础上，FSF 和 Savoye 的目标是对剩余的非自由软件进行逆向工程并替换掉它们。Librephone 将服务于现有的开发者和项目，帮助他们构建一个功能齐全且 free 的 Android 兼容操作系统。</span></p>
<p><span>当被要求对该项目发表评论时，Savoye 表示：“作为一名在移动设备上工作了几十年的长期嵌入式系统工程师，我期待着有机会致力于开发一款支持自由的手机，并帮助用户控制他们的手机硬件。为现代商用手机开发完全免费的软件并非易事，成本也高昂，但我们的项目受益于站在巨人的肩膀上，他们已经完成了大部分工作。请加入我们，贡献您的力量和/或捐款。”</span></p>]]></content:encoded>
    
    <pubDate>Wed, 15 Oct 2025 15:15:50 +0800</pubDate>
  </item><item>
    <title><![CDATA[stateof.ai 发布 2025 人工智能现状报告]]></title>
    <link>https://www.oschina.net/news/377560</link>
    <itunes:title><![CDATA[stateof.ai 发布 2025 人工智能现状报告]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>stateof.ai发布了2025年度人工智能现状报告 (State of AI Report 2025)。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-5fc353d2f1.png"></p>
<p>这个系列报告每年更新一次，今年值得关注的亮点：<br> ---------------------<br> 🌟OpenAI在前沿领域保持微弱领先， 但随着Meta让出领先地位，竞争日益激烈。中国的DeepSeek、Qwen和Kimi在推理和编码任务上缩小了差距，使中国成为可靠的第二名。</p>
<p>🌟推理能力定义了这一年， 前沿实验室将强化学习、基于评分标准（rubric-based）的奖励和可验证推理与新颖的环境相结合，创造出能够规划、反思、自我纠正，并在更长时间跨度上工作的模型。</p>
<p>🌟人工智能正成为科学合作者， 像DeepMind的Co-Scientist和斯坦福的Virtual Lab等系统能够自主生成、测试和验证假说。在生物学领域，Profluent的ProGen3表明，规模法则（scaling laws）现在也适用于蛋白质。</p>
<p>🌟结构化推理通过“行动链”（Chain-of-Action）规划进入物理世界， 像AI2的Molmo-Act和谷歌的Gemini Robotics 1.5等具身AI系统开始在行动前进行逐步推理。</p>
<p>🌟商业应用急剧加速。 根据Ramp和Standard Metrics的数据，44%的美国企业现在为AI工具付费（2023年为5%），平均合同金额达到53万美元，而以AI为先的初创公司比同行增长快1.5倍。</p>
<p>🌟我们的首届AI从业者调查 吸引了超过1200名受访者，结果显示95%的专业人士现在在工作或家庭中使用AI，76%的人自费购买AI工具，大多数人报告生产力持续提升，这表明AI的实际应用已成为主流。</p>
<p>🌟人工智能的工业时代已经开启。 像Stargate这样的数吉瓦（Multi-GW）数据中心标志着新一轮计算基础设施浪潮的到来，这些设施由美国、阿联酋和中国的主权基金支持，而电力供应正成为新的制约因素。</p>
<p>🌟人工智能政治进一步固化。 美国倾向于“美国优先的AI”政策，欧洲的《人工智能法案》遭遇挫折，而中国则扩大了其开源权重生态系统和国内芯片的雄心。</p>
<p>🌟安全研究进入了一个新的、更务实的阶段。 模型现在可以在监督下模仿对齐（alignment），这引发了一场关于透明度与能力之间取舍的辩论。与此同时，外部安全组织的运营预算甚至低于一个前沿实验室的单日消耗。</p>
<p>🌟关于存在性风险的辩论已经降温， 取而代之的是关于可靠性、网络韧性以及日益自主的系统的长期治理等具体问题。</p>
<p><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.google.com%2Fpresentation%2Fd%2F1xiLl0VdrlNMAei8pmaX4ojIOfej6lhvZbOIK7Z6C-Go%2Fedit%3Fusp%3Dsharing" target="_blank">详情查看完整报告</a></em>。</p>
<blockquote>
<p><strong>阅读更多</strong></p>
<p><a href="https://www.oschina.net/news/262155/state-of-ai-2023-report" target="_blank">2023 年度人工智能现状报告</a><br> <a href="https://www.oschina.net/news/319118" target="_blank">State of AI：2024 人工智能报告</a></p>
</blockquote>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>stateof.ai发布了2025年度人工智能现状报告 (State of AI Report 2025)。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-5fc353d2f1.png"></p>
<p>这个系列报告每年更新一次，今年值得关注的亮点：<br> ---------------------<br> 🌟OpenAI在前沿领域保持微弱领先， 但随着Meta让出领先地位，竞争日益激烈。中国的DeepSeek、Qwen和Kimi在推理和编码任务上缩小了差距，使中国成为可靠的第二名。</p>
<p>🌟推理能力定义了这一年， 前沿实验室将强化学习、基于评分标准（rubric-based）的奖励和可验证推理与新颖的环境相结合，创造出能够规划、反思、自我纠正，并在更长时间跨度上工作的模型。</p>
<p>🌟人工智能正成为科学合作者， 像DeepMind的Co-Scientist和斯坦福的Virtual Lab等系统能够自主生成、测试和验证假说。在生物学领域，Profluent的ProGen3表明，规模法则（scaling laws）现在也适用于蛋白质。</p>
<p>🌟结构化推理通过“行动链”（Chain-of-Action）规划进入物理世界， 像AI2的Molmo-Act和谷歌的Gemini Robotics 1.5等具身AI系统开始在行动前进行逐步推理。</p>
<p>🌟商业应用急剧加速。 根据Ramp和Standard Metrics的数据，44%的美国企业现在为AI工具付费（2023年为5%），平均合同金额达到53万美元，而以AI为先的初创公司比同行增长快1.5倍。</p>
<p>🌟我们的首届AI从业者调查 吸引了超过1200名受访者，结果显示95%的专业人士现在在工作或家庭中使用AI，76%的人自费购买AI工具，大多数人报告生产力持续提升，这表明AI的实际应用已成为主流。</p>
<p>🌟人工智能的工业时代已经开启。 像Stargate这样的数吉瓦（Multi-GW）数据中心标志着新一轮计算基础设施浪潮的到来，这些设施由美国、阿联酋和中国的主权基金支持，而电力供应正成为新的制约因素。</p>
<p>🌟人工智能政治进一步固化。 美国倾向于“美国优先的AI”政策，欧洲的《人工智能法案》遭遇挫折，而中国则扩大了其开源权重生态系统和国内芯片的雄心。</p>
<p>🌟安全研究进入了一个新的、更务实的阶段。 模型现在可以在监督下模仿对齐（alignment），这引发了一场关于透明度与能力之间取舍的辩论。与此同时，外部安全组织的运营预算甚至低于一个前沿实验室的单日消耗。</p>
<p>🌟关于存在性风险的辩论已经降温， 取而代之的是关于可靠性、网络韧性以及日益自主的系统的长期治理等具体问题。</p>
<p><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.google.com%2Fpresentation%2Fd%2F1xiLl0VdrlNMAei8pmaX4ojIOfej6lhvZbOIK7Z6C-Go%2Fedit%3Fusp%3Dsharing" target="_blank">详情查看完整报告</a></em>。</p>
<blockquote>
<p><strong>阅读更多</strong></p>
<p><a href="https://www.oschina.net/news/262155/state-of-ai-2023-report" target="_blank">2023 年度人工智能现状报告</a><br> <a href="https://www.oschina.net/news/319118" target="_blank">State of AI：2024 人工智能报告</a></p>
</blockquote>]]>
    </description>
    <content:encoded><![CDATA[<p>stateof.ai发布了2025年度人工智能现状报告 (State of AI Report 2025)。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-5fc353d2f1.png"></p>
<p>这个系列报告每年更新一次，今年值得关注的亮点：<br> ---------------------<br> 🌟OpenAI在前沿领域保持微弱领先， 但随着Meta让出领先地位，竞争日益激烈。中国的DeepSeek、Qwen和Kimi在推理和编码任务上缩小了差距，使中国成为可靠的第二名。</p>
<p>🌟推理能力定义了这一年， 前沿实验室将强化学习、基于评分标准（rubric-based）的奖励和可验证推理与新颖的环境相结合，创造出能够规划、反思、自我纠正，并在更长时间跨度上工作的模型。</p>
<p>🌟人工智能正成为科学合作者， 像DeepMind的Co-Scientist和斯坦福的Virtual Lab等系统能够自主生成、测试和验证假说。在生物学领域，Profluent的ProGen3表明，规模法则（scaling laws）现在也适用于蛋白质。</p>
<p>🌟结构化推理通过“行动链”（Chain-of-Action）规划进入物理世界， 像AI2的Molmo-Act和谷歌的Gemini Robotics 1.5等具身AI系统开始在行动前进行逐步推理。</p>
<p>🌟商业应用急剧加速。 根据Ramp和Standard Metrics的数据，44%的美国企业现在为AI工具付费（2023年为5%），平均合同金额达到53万美元，而以AI为先的初创公司比同行增长快1.5倍。</p>
<p>🌟我们的首届AI从业者调查 吸引了超过1200名受访者，结果显示95%的专业人士现在在工作或家庭中使用AI，76%的人自费购买AI工具，大多数人报告生产力持续提升，这表明AI的实际应用已成为主流。</p>
<p>🌟人工智能的工业时代已经开启。 像Stargate这样的数吉瓦（Multi-GW）数据中心标志着新一轮计算基础设施浪潮的到来，这些设施由美国、阿联酋和中国的主权基金支持，而电力供应正成为新的制约因素。</p>
<p>🌟人工智能政治进一步固化。 美国倾向于“美国优先的AI”政策，欧洲的《人工智能法案》遭遇挫折，而中国则扩大了其开源权重生态系统和国内芯片的雄心。</p>
<p>🌟安全研究进入了一个新的、更务实的阶段。 模型现在可以在监督下模仿对齐（alignment），这引发了一场关于透明度与能力之间取舍的辩论。与此同时，外部安全组织的运营预算甚至低于一个前沿实验室的单日消耗。</p>
<p>🌟关于存在性风险的辩论已经降温， 取而代之的是关于可靠性、网络韧性以及日益自主的系统的长期治理等具体问题。</p>
<p><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.google.com%2Fpresentation%2Fd%2F1xiLl0VdrlNMAei8pmaX4ojIOfej6lhvZbOIK7Z6C-Go%2Fedit%3Fusp%3Dsharing" target="_blank">详情查看完整报告</a></em>。</p>
<blockquote>
<p><strong>阅读更多</strong></p>
<p><a href="https://www.oschina.net/news/262155/state-of-ai-2023-report" target="_blank">2023 年度人工智能现状报告</a><br> <a href="https://www.oschina.net/news/319118" target="_blank">State of AI：2024 人工智能报告</a></p>
</blockquote>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-5fc353d2f1.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-5fc353d2f1.png" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 14:53:26 +0800</pubDate>
  </item><item>
    <title><![CDATA[美国军方高层开始依赖 ChatGPT 辅助决策]]></title>
    <link>https://www.oschina.net/news/377558</link>
    <itunes:title><![CDATA[美国军方高层开始依赖 ChatGPT 辅助决策]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>美国驻韩国的<span>最高</span>军事指挥官泰勒少将（William "Hank" Taylor）在与记者交流时透露，他和人工智能工具 ChatGPT 之间的关系变得越来越密切。他表示，自己正在利用 ChatGPT 来帮助做出军 事和个人决策，这些决策直接影响到他所指挥的士兵们。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-0082c38442.png"></p>
<p>泰勒少将目前担任驻韩美军第八集团军指挥官，同时也是联合国指挥部的首席参谋。他指出，作为一名指挥官，他希望能做出更好的决策，并在适当的时机采取行动，以获得战略上的优势。</p>
<p>然而，依赖于 ChatGPT 作出决策的做法引发了不少担忧。ChatGPT 因其偏向于提供顺从性答案而受到批评，有时甚至在极端情况下对用户的心理健康问题提供不当建议。虽然 OpenAI 尝试通过推出更严谨的版本 GPT-5来解决这些问题，但其短暂的实施后又因用户的强烈反对而恢复了原有的特性。</p>
<p>此外，GPT-5在生成基本事实信息时的准确率也遭到质疑，常常出现超过一半的错误，这在军 事决策中是一个不可忽视的风险。在当前美军驻韩的背景下，这种情况尤其令人不安，尤其是在面对朝鲜长期以来的地缘政治紧张局势时。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>美国驻韩国的<span>最高</span>军事指挥官泰勒少将（William "Hank" Taylor）在与记者交流时透露，他和人工智能工具 ChatGPT 之间的关系变得越来越密切。他表示，自己正在利用 ChatGPT 来帮助做出军 事和个人决策，这些决策直接影响到他所指挥的士兵们。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-0082c38442.png"></p>
<p>泰勒少将目前担任驻韩美军第八集团军指挥官，同时也是联合国指挥部的首席参谋。他指出，作为一名指挥官，他希望能做出更好的决策，并在适当的时机采取行动，以获得战略上的优势。</p>
<p>然而，依赖于 ChatGPT 作出决策的做法引发了不少担忧。ChatGPT 因其偏向于提供顺从性答案而受到批评，有时甚至在极端情况下对用户的心理健康问题提供不当建议。虽然 OpenAI 尝试通过推出更严谨的版本 GPT-5来解决这些问题，但其短暂的实施后又因用户的强烈反对而恢复了原有的特性。</p>
<p>此外，GPT-5在生成基本事实信息时的准确率也遭到质疑，常常出现超过一半的错误，这在军 事决策中是一个不可忽视的风险。在当前美军驻韩的背景下，这种情况尤其令人不安，尤其是在面对朝鲜长期以来的地缘政治紧张局势时。</p>]]>
    </description>
    <content:encoded><![CDATA[<p>美国驻韩国的<span>最高</span>军事指挥官泰勒少将（William "Hank" Taylor）在与记者交流时透露，他和人工智能工具 ChatGPT 之间的关系变得越来越密切。他表示，自己正在利用 ChatGPT 来帮助做出军 事和个人决策，这些决策直接影响到他所指挥的士兵们。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-0082c38442.png"></p>
<p>泰勒少将目前担任驻韩美军第八集团军指挥官，同时也是联合国指挥部的首席参谋。他指出，作为一名指挥官，他希望能做出更好的决策，并在适当的时机采取行动，以获得战略上的优势。</p>
<p>然而，依赖于 ChatGPT 作出决策的做法引发了不少担忧。ChatGPT 因其偏向于提供顺从性答案而受到批评，有时甚至在极端情况下对用户的心理健康问题提供不当建议。虽然 OpenAI 尝试通过推出更严谨的版本 GPT-5来解决这些问题，但其短暂的实施后又因用户的强烈反对而恢复了原有的特性。</p>
<p>此外，GPT-5在生成基本事实信息时的准确率也遭到质疑，常常出现超过一半的错误，这在军 事决策中是一个不可忽视的风险。在当前美军驻韩的背景下，这种情况尤其令人不安，尤其是在面对朝鲜长期以来的地缘政治紧张局势时。</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-0082c38442.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-0082c38442.png" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 14:48:17 +0800</pubDate>
  </item><item>
    <title><![CDATA[英特尔再失一位资深 Linux 驱动维护工程师]]></title>
    <link>https://www.oschina.net/news/377556</link>
    <itunes:title><![CDATA[英特尔再失一位资深 Linux 驱动维护工程师]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>英特尔资深&nbsp;Linux 内核工程师 Jarkko Nikula 已于 2025 年 9 月<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Flkml%2F20251014145905.4862-1-ilpo.jarvinen%40linux.intel.com%2FT%2F%23u" target="_blank">离职</a>，为公司近年来持续的人才流失再添一例。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-ff0c40b5ec.png"></p>
<p>Jarkko 多年来负责维护英特尔的 I²C 与 I3C 驱动子系统，他近期的一些工作包括为 Wildcat Lake U 提供支持、以及启用 Panther Lake、Arrow Lake H 等平台在 I²C / I3C 上的支持。</p>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgit.kernel.org%2Fpub%2Fscm%2Flinux%2Fkernel%2Fgit%2Ftorvalds%2Flinux.git%2Flog%2F%3Fqt%3Dauthor%26q%3Djarkko.nikula%2540linux.intel.com" target="_blank">在他最近一次提交的内核补丁中</a>，他负责 Intel QEP（Quadrature Encoder Peripheral）驱动的维护交接。Jarkko 提到自己的邮箱即将失效，并确认维护工作将由同事 Ilpo Järvinen 接手。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-3ef7bf331a.png"></p>
<p>Jarkko 曾在 Jolla 参与 Sailfish OS 开发，加入英特尔后成为 Linux 内核社区的重要成员。</p>
<blockquote>
<p>相关阅读：<em><a href="https://www.oschina.net/news/376776" target="_blank">英特尔高管：公司将重新评估对开源社区的投入</a></em></p>
</blockquote>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>英特尔资深&nbsp;Linux 内核工程师 Jarkko Nikula 已于 2025 年 9 月<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Flkml%2F20251014145905.4862-1-ilpo.jarvinen%40linux.intel.com%2FT%2F%23u" target="_blank">离职</a>，为公司近年来持续的人才流失再添一例。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-ff0c40b5ec.png"></p>
<p>Jarkko 多年来负责维护英特尔的 I²C 与 I3C 驱动子系统，他近期的一些工作包括为 Wildcat Lake U 提供支持、以及启用 Panther Lake、Arrow Lake H 等平台在 I²C / I3C 上的支持。</p>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgit.kernel.org%2Fpub%2Fscm%2Flinux%2Fkernel%2Fgit%2Ftorvalds%2Flinux.git%2Flog%2F%3Fqt%3Dauthor%26q%3Djarkko.nikula%2540linux.intel.com" target="_blank">在他最近一次提交的内核补丁中</a>，他负责 Intel QEP（Quadrature Encoder Peripheral）驱动的维护交接。Jarkko 提到自己的邮箱即将失效，并确认维护工作将由同事 Ilpo Järvinen 接手。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-3ef7bf331a.png"></p>
<p>Jarkko 曾在 Jolla 参与 Sailfish OS 开发，加入英特尔后成为 Linux 内核社区的重要成员。</p>
<blockquote>
<p>相关阅读：<em><a href="https://www.oschina.net/news/376776" target="_blank">英特尔高管：公司将重新评估对开源社区的投入</a></em></p>
</blockquote>]]>
    </description>
    <content:encoded><![CDATA[<p>英特尔资深&nbsp;Linux 内核工程师 Jarkko Nikula 已于 2025 年 9 月<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Flkml%2F20251014145905.4862-1-ilpo.jarvinen%40linux.intel.com%2FT%2F%23u" target="_blank">离职</a>，为公司近年来持续的人才流失再添一例。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-ff0c40b5ec.png"></p>
<p>Jarkko 多年来负责维护英特尔的 I²C 与 I3C 驱动子系统，他近期的一些工作包括为 Wildcat Lake U 提供支持、以及启用 Panther Lake、Arrow Lake H 等平台在 I²C / I3C 上的支持。</p>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgit.kernel.org%2Fpub%2Fscm%2Flinux%2Fkernel%2Fgit%2Ftorvalds%2Flinux.git%2Flog%2F%3Fqt%3Dauthor%26q%3Djarkko.nikula%2540linux.intel.com" target="_blank">在他最近一次提交的内核补丁中</a>，他负责 Intel QEP（Quadrature Encoder Peripheral）驱动的维护交接。Jarkko 提到自己的邮箱即将失效，并确认维护工作将由同事 Ilpo Järvinen 接手。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-3ef7bf331a.png"></p>
<p>Jarkko 曾在 Jolla 参与 Sailfish OS 开发，加入英特尔后成为 Linux 内核社区的重要成员。</p>
<blockquote>
<p>相关阅读：<em><a href="https://www.oschina.net/news/376776" target="_blank">英特尔高管：公司将重新评估对开源社区的投入</a></em></p>
</blockquote>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-ff0c40b5ec.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-ff0c40b5ec.png" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 14:39:21 +0800</pubDate>
  </item><item>
    <title><![CDATA[字体设计工具字玩 v0.3.3 发布，新增楷体和隶书笔画模板]]></title>
    <link>https://www.oschina.net/news/377555</link>
    <itunes:title><![CDATA[字体设计工具字玩 v0.3.3 发布，新增楷体和隶书笔画模板]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>字玩是一款开源的字体设计工具，致力于探索以参数化、脚本化的方式设计中文字库，帮助用户高效设计个性化字体。使用Vue3 + Tauri2开发，支持Web端、MacOS和Windows平台。</p>
<p>开源地址：<a href="https://gitee.com/toysmaker/fontplayer">字玩在gitee</a> | <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FHiToysMaker%2Ffontplayer" target="_blank">字玩在github</a></p>
<h4>v0.3.2版本更新说明</h4>
<ol>
<li> <p>新增字玩标准楷体笔画模板，可供用户调参</p> </li>
<li> <p>新增字玩标准隶书笔画模板，可供用户调参</p> </li>
<li> <p>优化骨架拖拽性能</p> </li>
<li> <p>修复部分仿宋笔画组件骨架拖拽bug</p> </li>
</ol>
<h4>新增笔画模板一览</h4>
<p>1. 字玩标准楷体</p>
<div>
<div>
模板包含32个可调参笔画，在模板菜单中选择相应笔画模板加载：
</div>
<div>
<img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6226531bd3.jpg">
</div> &nbsp;
<div>
在高级编辑-&gt;风格切换面板中可以预览一键替换效果（批量替换笔画后仍有诸多细节问题需要处理，可以使用脚本辅助优化细节）：
</div>
</div>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-55e6d17c5c.jpg"></p>
<p>2. 字玩标准隶书</p>
<div>
<div>
<span>模板包含33个可调参笔画，在模板菜单中选择相应笔画模板加载：</span>
</div>
<div>
<span><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-fce378efae.jpg"></span>
</div> &nbsp;
<div>
<span>在高级编辑-&gt;风格切换面板中可以预览一键替换效果（批量替换笔画后仍有诸多细节问题需要处理，可以使用脚本辅助优化细节）：</span>
</div>
</div>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-3d0a12af4f.jpg"></p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>字玩是一款开源的字体设计工具，致力于探索以参数化、脚本化的方式设计中文字库，帮助用户高效设计个性化字体。使用Vue3 + Tauri2开发，支持Web端、MacOS和Windows平台。</p>
<p>开源地址：<a href="https://gitee.com/toysmaker/fontplayer">字玩在gitee</a> | <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FHiToysMaker%2Ffontplayer" target="_blank">字玩在github</a></p>
<h4>v0.3.2版本更新说明</h4>
<ol>
<li> <p>新增字玩标准楷体笔画模板，可供用户调参</p> </li>
<li> <p>新增字玩标准隶书笔画模板，可供用户调参</p> </li>
<li> <p>优化骨架拖拽性能</p> </li>
<li> <p>修复部分仿宋笔画组件骨架拖拽bug</p> </li>
</ol>
<h4>新增笔画模板一览</h4>
<p>1. 字玩标准楷体</p>
<div>
<div>
模板包含32个可调参笔画，在模板菜单中选择相应笔画模板加载：
</div>
<div>
<img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6226531bd3.jpg">
</div> &nbsp;
<div>
在高级编辑-&gt;风格切换面板中可以预览一键替换效果（批量替换笔画后仍有诸多细节问题需要处理，可以使用脚本辅助优化细节）：
</div>
</div>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-55e6d17c5c.jpg"></p>
<p>2. 字玩标准隶书</p>
<div>
<div>
<span>模板包含33个可调参笔画，在模板菜单中选择相应笔画模板加载：</span>
</div>
<div>
<span><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-fce378efae.jpg"></span>
</div> &nbsp;
<div>
<span>在高级编辑-&gt;风格切换面板中可以预览一键替换效果（批量替换笔画后仍有诸多细节问题需要处理，可以使用脚本辅助优化细节）：</span>
</div>
</div>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-3d0a12af4f.jpg"></p>]]>
    </description>
    <content:encoded><![CDATA[<p>字玩是一款开源的字体设计工具，致力于探索以参数化、脚本化的方式设计中文字库，帮助用户高效设计个性化字体。使用Vue3 + Tauri2开发，支持Web端、MacOS和Windows平台。</p>
<p>开源地址：<a href="https://gitee.com/toysmaker/fontplayer">字玩在gitee</a> | <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FHiToysMaker%2Ffontplayer" target="_blank">字玩在github</a></p>
<h4>v0.3.2版本更新说明</h4>
<ol>
<li> <p>新增字玩标准楷体笔画模板，可供用户调参</p> </li>
<li> <p>新增字玩标准隶书笔画模板，可供用户调参</p> </li>
<li> <p>优化骨架拖拽性能</p> </li>
<li> <p>修复部分仿宋笔画组件骨架拖拽bug</p> </li>
</ol>
<h4>新增笔画模板一览</h4>
<p>1. 字玩标准楷体</p>
<div>
<div>
模板包含32个可调参笔画，在模板菜单中选择相应笔画模板加载：
</div>
<div>
<img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6226531bd3.jpg">
</div> &nbsp;
<div>
在高级编辑-&gt;风格切换面板中可以预览一键替换效果（批量替换笔画后仍有诸多细节问题需要处理，可以使用脚本辅助优化细节）：
</div>
</div>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-55e6d17c5c.jpg"></p>
<p>2. 字玩标准隶书</p>
<div>
<div>
<span>模板包含33个可调参笔画，在模板菜单中选择相应笔画模板加载：</span>
</div>
<div>
<span><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-fce378efae.jpg"></span>
</div> &nbsp;
<div>
<span>在高级编辑-&gt;风格切换面板中可以预览一键替换效果（批量替换笔画后仍有诸多细节问题需要处理，可以使用脚本辅助优化细节）：</span>
</div>
</div>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-3d0a12af4f.jpg"></p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6226531bd3.jpg"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6226531bd3.jpg" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 14:24:24 +0800</pubDate>
  </item><item>
    <title><![CDATA[OpenAI 年收入达 130 亿美元，启动五年“万亿”增长计划]]></title>
    <link>https://www.oschina.net/news/377552</link>
    <itunes:title><![CDATA[OpenAI 年收入达 130 亿美元，启动五年“万亿”增长计划]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p><span>据《金融时报》报道，人工智能巨头OpenAI目前的年化收入已达到约</span><strong>130亿美元</strong><span>，其中高达<strong> 70% </strong>的收入来自普通用户每月支付20美元的订阅费用。考虑到ChatGPT拥有8亿常规用户，但付费用户占比仅约5%，这一营收数字已相当惊人。</span></p>
<p>尽管OpenAI目前收入可观，但其目标也极为宏大。该公司承诺在未来十年内投入超过<strong>1万亿美元</strong>（即数万亿美元）用于基础设施建设。OpenAI最近已与甲骨文(Oracle)、英伟达(Nvidia)、AMD和博通(Broadcom)等巨头达成交易，旨在获取超过<strong>26千兆瓦</strong>的计算能力。这笔巨大的基础设施成本将远远超出其目前的投入水平。</p>
<p>为了弥补这一巨大的投入与产出差距，OpenAI正在寻求创新的盈利模式。据《金融时报》披露，一项<strong>五年计划</strong>已经启动，旨在多维度拓展业务，包括:</p>
<ul>
<li> <p><strong>政府合同：</strong>积极探索获取政府合同的机会。</p> </li>
<li> <p><strong>消费级服务：</strong>推出购物工具、视频服务及消费硬件。</p> </li>
<li> <p><strong>计算力供应商：</strong>通过其雄心勃勃的<strong>Stargate数据中心项目</strong>，成为主要的计算能力供应商。</p> </li>
</ul>
<p>《金融时报》指出，美国一些最具价值的公司目前正依赖OpenAI来履行重大合同，这体现了企业界对数学问题解决等AI能力日益增长的需求。行业观察人士警告，如果OpenAI的运营出现问题，可能会<strong>破坏美国整体市场的稳定</strong>，突显了该公司在当前经济生态中的关键地位。OpenAI正面临将年收入130亿美元快速转化为支撑万亿级投资的巨大挑战。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p><span>据《金融时报》报道，人工智能巨头OpenAI目前的年化收入已达到约</span><strong>130亿美元</strong><span>，其中高达<strong> 70% </strong>的收入来自普通用户每月支付20美元的订阅费用。考虑到ChatGPT拥有8亿常规用户，但付费用户占比仅约5%，这一营收数字已相当惊人。</span></p>
<p>尽管OpenAI目前收入可观，但其目标也极为宏大。该公司承诺在未来十年内投入超过<strong>1万亿美元</strong>（即数万亿美元）用于基础设施建设。OpenAI最近已与甲骨文(Oracle)、英伟达(Nvidia)、AMD和博通(Broadcom)等巨头达成交易，旨在获取超过<strong>26千兆瓦</strong>的计算能力。这笔巨大的基础设施成本将远远超出其目前的投入水平。</p>
<p>为了弥补这一巨大的投入与产出差距，OpenAI正在寻求创新的盈利模式。据《金融时报》披露，一项<strong>五年计划</strong>已经启动，旨在多维度拓展业务，包括:</p>
<ul>
<li> <p><strong>政府合同：</strong>积极探索获取政府合同的机会。</p> </li>
<li> <p><strong>消费级服务：</strong>推出购物工具、视频服务及消费硬件。</p> </li>
<li> <p><strong>计算力供应商：</strong>通过其雄心勃勃的<strong>Stargate数据中心项目</strong>，成为主要的计算能力供应商。</p> </li>
</ul>
<p>《金融时报》指出，美国一些最具价值的公司目前正依赖OpenAI来履行重大合同，这体现了企业界对数学问题解决等AI能力日益增长的需求。行业观察人士警告，如果OpenAI的运营出现问题，可能会<strong>破坏美国整体市场的稳定</strong>，突显了该公司在当前经济生态中的关键地位。OpenAI正面临将年收入130亿美元快速转化为支撑万亿级投资的巨大挑战。</p>]]>
    </description>
    <content:encoded><![CDATA[<p><span>据《金融时报》报道，人工智能巨头OpenAI目前的年化收入已达到约</span><strong>130亿美元</strong><span>，其中高达<strong> 70% </strong>的收入来自普通用户每月支付20美元的订阅费用。考虑到ChatGPT拥有8亿常规用户，但付费用户占比仅约5%，这一营收数字已相当惊人。</span></p>
<p>尽管OpenAI目前收入可观，但其目标也极为宏大。该公司承诺在未来十年内投入超过<strong>1万亿美元</strong>（即数万亿美元）用于基础设施建设。OpenAI最近已与甲骨文(Oracle)、英伟达(Nvidia)、AMD和博通(Broadcom)等巨头达成交易，旨在获取超过<strong>26千兆瓦</strong>的计算能力。这笔巨大的基础设施成本将远远超出其目前的投入水平。</p>
<p>为了弥补这一巨大的投入与产出差距，OpenAI正在寻求创新的盈利模式。据《金融时报》披露，一项<strong>五年计划</strong>已经启动，旨在多维度拓展业务，包括:</p>
<ul>
<li> <p><strong>政府合同：</strong>积极探索获取政府合同的机会。</p> </li>
<li> <p><strong>消费级服务：</strong>推出购物工具、视频服务及消费硬件。</p> </li>
<li> <p><strong>计算力供应商：</strong>通过其雄心勃勃的<strong>Stargate数据中心项目</strong>，成为主要的计算能力供应商。</p> </li>
</ul>
<p>《金融时报》指出，美国一些最具价值的公司目前正依赖OpenAI来履行重大合同，这体现了企业界对数学问题解决等AI能力日益增长的需求。行业观察人士警告，如果OpenAI的运营出现问题，可能会<strong>破坏美国整体市场的稳定</strong>，突显了该公司在当前经济生态中的关键地位。OpenAI正面临将年收入130亿美元快速转化为支撑万亿级投资的巨大挑战。</p>]]></content:encoded>
    
    <pubDate>Wed, 15 Oct 2025 14:20:02 +0800</pubDate>
  </item><item>
    <title><![CDATA[Ip2region 3.6.0 发布 - Javascript 扩展添加了 IPv6 的支持]]></title>
    <link>https://www.oschina.net/news/377548/ip2region-3-6-0-released</link>
    <itunes:title><![CDATA[Ip2region 3.6.0 发布 - Javascript 扩展添加了 IPv6 的支持]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fip2region.net" target="_blank">Ip2region</a><span> </span>是一个离线的 IP 数据管理框架和定位库，同时支持 IPv4 和 IPv6，支持亿级别的 IP 断管理，10 微秒级别的查询性能，提供了很多主流编程语言的 xdb 数据格式的生成和查询实现。</p>
<p>ip2region 官方社区已正式上线旨提强化 IP 相关的工具链和数据服务，目前提供了稳定的<span> </span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fip2region.net%2Fproducts%2Foffline" target="_blank">商用离线数据</a>、<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fip2region.net%2Fsearch%2Fdemo" target="_blank">在线查询测试</a>、<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fip2region.net%2Fdoc%2F" target="_blank">xdb 使用 / 技术文档</a>。</p>
<p>ip2region 3.6.0 详细更新如下：</p>
<p>1，ip2region.js npm 包支持，适用于 Nodejs / Typescript：</p>
<pre><code>npm install ip2region.js --save</code></pre>
<p>2，javascript binding (nodejs / typescript) 提供了对 IPv6 的查询支持，具体使用文档请参考 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Flionsoul2014%2Fip2region%2Ftree%2Fmaster%2Fbinding%2Fjavascript" target="_blank">javascript Binding</a>，测试方式如下：</p>
<pre><code>➜  javascript git:(master) node tests/search.app.js --db=../../data/ip2region_v6.xdb
ip2region xdb searcher test program
source xdb: ../../data/ip2region_v6.xdb (IPv6, vectorIndex)
type 'quit' to exit
ip2region&gt;&gt; ::
{region: |||, ioCount: 2, took: 158.64 μs}
ip2region&gt;&gt; 240e:3b7:3272:d8d0:3b7b:3ee0:1d39:848
{region: 中国|广东省|深圳市|家庭宽带, ioCount: 14, took: 256.98 μs}
ip2region&gt;&gt; 2001:3:ffff:ffff:ffff:ffff:ffff:ffff
{region: 美国|加利福尼亚州|洛杉矶|专线用户, ioCount: 21, took: 241.755 μs}
ip2region&gt;&gt;</code></pre>
<p>3，查询平均耗时：Razer 笔记本 / Ubuntu (电源均衡模式) + SATA SSD / VectorIndex 缓存，bench 结果如下：</p>
<pre><code>➜  javascript git:(master) node tests/bench.app.js --db=../../data/ip2region_v6.xdb --src=../../data/ipv6_source.txt
Searcher: {"version": IPv6, "dbPath": ../../data/ip2region_v6.xdb, "handle": 21, "vectorIndex": 524288 "cBuffer": null}
Bench finished, {cachePolicy: vectorIndex, total: 34159862, took: 963.9443019528878 s, cost: 28.21862400828457 μs/op}</code></pre>
<p>3415.9 万个 IPv6 平均查询耗时为 <code>28.2</code>&nbsp;微秒/次。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fip2region.net" target="_blank">Ip2region</a><span> </span>是一个离线的 IP 数据管理框架和定位库，同时支持 IPv4 和 IPv6，支持亿级别的 IP 断管理，10 微秒级别的查询性能，提供了很多主流编程语言的 xdb 数据格式的生成和查询实现。</p>
<p>ip2region 官方社区已正式上线旨提强化 IP 相关的工具链和数据服务，目前提供了稳定的<span> </span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fip2region.net%2Fproducts%2Foffline" target="_blank">商用离线数据</a>、<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fip2region.net%2Fsearch%2Fdemo" target="_blank">在线查询测试</a>、<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fip2region.net%2Fdoc%2F" target="_blank">xdb 使用 / 技术文档</a>。</p>
<p>ip2region 3.6.0 详细更新如下：</p>
<p>1，ip2region.js npm 包支持，适用于 Nodejs / Typescript：</p>
<pre><code>npm install ip2region.js --save</code></pre>
<p>2，javascript binding (nodejs / typescript) 提供了对 IPv6 的查询支持，具体使用文档请参考 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Flionsoul2014%2Fip2region%2Ftree%2Fmaster%2Fbinding%2Fjavascript" target="_blank">javascript Binding</a>，测试方式如下：</p>
<pre><code>➜  javascript git:(master) node tests/search.app.js --db=../../data/ip2region_v6.xdb
ip2region xdb searcher test program
source xdb: ../../data/ip2region_v6.xdb (IPv6, vectorIndex)
type 'quit' to exit
ip2region&gt;&gt; ::
{region: |||, ioCount: 2, took: 158.64 μs}
ip2region&gt;&gt; 240e:3b7:3272:d8d0:3b7b:3ee0:1d39:848
{region: 中国|广东省|深圳市|家庭宽带, ioCount: 14, took: 256.98 μs}
ip2region&gt;&gt; 2001:3:ffff:ffff:ffff:ffff:ffff:ffff
{region: 美国|加利福尼亚州|洛杉矶|专线用户, ioCount: 21, took: 241.755 μs}
ip2region&gt;&gt;</code></pre>
<p>3，查询平均耗时：Razer 笔记本 / Ubuntu (电源均衡模式) + SATA SSD / VectorIndex 缓存，bench 结果如下：</p>
<pre><code>➜  javascript git:(master) node tests/bench.app.js --db=../../data/ip2region_v6.xdb --src=../../data/ipv6_source.txt
Searcher: {"version": IPv6, "dbPath": ../../data/ip2region_v6.xdb, "handle": 21, "vectorIndex": 524288 "cBuffer": null}
Bench finished, {cachePolicy: vectorIndex, total: 34159862, took: 963.9443019528878 s, cost: 28.21862400828457 μs/op}</code></pre>
<p>3415.9 万个 IPv6 平均查询耗时为 <code>28.2</code>&nbsp;微秒/次。</p>]]>
    </description>
    <content:encoded><![CDATA[<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fip2region.net" target="_blank">Ip2region</a><span> </span>是一个离线的 IP 数据管理框架和定位库，同时支持 IPv4 和 IPv6，支持亿级别的 IP 断管理，10 微秒级别的查询性能，提供了很多主流编程语言的 xdb 数据格式的生成和查询实现。</p>
<p>ip2region 官方社区已正式上线旨提强化 IP 相关的工具链和数据服务，目前提供了稳定的<span> </span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fip2region.net%2Fproducts%2Foffline" target="_blank">商用离线数据</a>、<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fip2region.net%2Fsearch%2Fdemo" target="_blank">在线查询测试</a>、<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fip2region.net%2Fdoc%2F" target="_blank">xdb 使用 / 技术文档</a>。</p>
<p>ip2region 3.6.0 详细更新如下：</p>
<p>1，ip2region.js npm 包支持，适用于 Nodejs / Typescript：</p>
<pre><code>npm install ip2region.js --save</code></pre>
<p>2，javascript binding (nodejs / typescript) 提供了对 IPv6 的查询支持，具体使用文档请参考 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Flionsoul2014%2Fip2region%2Ftree%2Fmaster%2Fbinding%2Fjavascript" target="_blank">javascript Binding</a>，测试方式如下：</p>
<pre><code>➜  javascript git:(master) node tests/search.app.js --db=../../data/ip2region_v6.xdb
ip2region xdb searcher test program
source xdb: ../../data/ip2region_v6.xdb (IPv6, vectorIndex)
type 'quit' to exit
ip2region&gt;&gt; ::
{region: |||, ioCount: 2, took: 158.64 μs}
ip2region&gt;&gt; 240e:3b7:3272:d8d0:3b7b:3ee0:1d39:848
{region: 中国|广东省|深圳市|家庭宽带, ioCount: 14, took: 256.98 μs}
ip2region&gt;&gt; 2001:3:ffff:ffff:ffff:ffff:ffff:ffff
{region: 美国|加利福尼亚州|洛杉矶|专线用户, ioCount: 21, took: 241.755 μs}
ip2region&gt;&gt;</code></pre>
<p>3，查询平均耗时：Razer 笔记本 / Ubuntu (电源均衡模式) + SATA SSD / VectorIndex 缓存，bench 结果如下：</p>
<pre><code>➜  javascript git:(master) node tests/bench.app.js --db=../../data/ip2region_v6.xdb --src=../../data/ipv6_source.txt
Searcher: {"version": IPv6, "dbPath": ../../data/ip2region_v6.xdb, "handle": 21, "vectorIndex": 524288 "cBuffer": null}
Bench finished, {cachePolicy: vectorIndex, total: 34159862, took: 963.9443019528878 s, cost: 28.21862400828457 μs/op}</code></pre>
<p>3415.9 万个 IPv6 平均查询耗时为 <code>28.2</code>&nbsp;微秒/次。</p>]]></content:encoded>
    
    <pubDate>Wed, 15 Oct 2025 14:10:10 +0800</pubDate>
  </item><item>
    <title><![CDATA[Firefox 添加 Perplexity AI 答案引擎作为新的搜索选项]]></title>
    <link>https://www.oschina.net/news/377523</link>
    <itunes:title><![CDATA[Firefox 添加 Perplexity AI 答案引擎作为新的搜索选项]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>Mozilla宣布，其Firefox浏览器现已支持将AI驱动的Perplexity答案引擎作为默认搜索选项集成，让用户能够在原有浏览器中自由选择是否使用AI进行网络搜索与信息查找。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-b6b8167e0a.png"></p>
<p>Firefox用户现在无需更换浏览器，即可在设置中更改默认搜索引擎，将Perplexity与Google、必应、DuckDuckGo等传统搜索引擎一同列为可选项。</p>
<p>此前，Mozilla曾宣布对这一集成方案进行测试，但仅向美国、英国和德国等部分市场开放，尚未确定Perplexity能否成为Firefox搜索引擎列表中的常驻选项。</p>
<p>根据官方表述，正是由于试点地区用户的积极反馈，Mozilla现决定向全球桌面用户全面提供此功能，并计划在未来数月内推广至移动端。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-fa68d9c932.png"></p>
<p>启用后，Perplexity可为用户带来对话式搜索体验，提供带有权威引用的直接答案，而非如Google等搜索引擎所显示的网页链接列表。该选项将出现在地址栏的统一搜索按钮内，用户可随时切换为Perplexity搜索，也可在设置中设为默认搜索引擎。</p>
<p>Mozilla还表示，未来有望引入更多AI答案引擎，以丰富搜索体验（选择Perplexity的原因之一是其强调不会共享或出售用户个人数据）。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>Mozilla宣布，其Firefox浏览器现已支持将AI驱动的Perplexity答案引擎作为默认搜索选项集成，让用户能够在原有浏览器中自由选择是否使用AI进行网络搜索与信息查找。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-b6b8167e0a.png"></p>
<p>Firefox用户现在无需更换浏览器，即可在设置中更改默认搜索引擎，将Perplexity与Google、必应、DuckDuckGo等传统搜索引擎一同列为可选项。</p>
<p>此前，Mozilla曾宣布对这一集成方案进行测试，但仅向美国、英国和德国等部分市场开放，尚未确定Perplexity能否成为Firefox搜索引擎列表中的常驻选项。</p>
<p>根据官方表述，正是由于试点地区用户的积极反馈，Mozilla现决定向全球桌面用户全面提供此功能，并计划在未来数月内推广至移动端。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-fa68d9c932.png"></p>
<p>启用后，Perplexity可为用户带来对话式搜索体验，提供带有权威引用的直接答案，而非如Google等搜索引擎所显示的网页链接列表。该选项将出现在地址栏的统一搜索按钮内，用户可随时切换为Perplexity搜索，也可在设置中设为默认搜索引擎。</p>
<p>Mozilla还表示，未来有望引入更多AI答案引擎，以丰富搜索体验（选择Perplexity的原因之一是其强调不会共享或出售用户个人数据）。</p>]]>
    </description>
    <content:encoded><![CDATA[<p>Mozilla宣布，其Firefox浏览器现已支持将AI驱动的Perplexity答案引擎作为默认搜索选项集成，让用户能够在原有浏览器中自由选择是否使用AI进行网络搜索与信息查找。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-b6b8167e0a.png"></p>
<p>Firefox用户现在无需更换浏览器，即可在设置中更改默认搜索引擎，将Perplexity与Google、必应、DuckDuckGo等传统搜索引擎一同列为可选项。</p>
<p>此前，Mozilla曾宣布对这一集成方案进行测试，但仅向美国、英国和德国等部分市场开放，尚未确定Perplexity能否成为Firefox搜索引擎列表中的常驻选项。</p>
<p>根据官方表述，正是由于试点地区用户的积极反馈，Mozilla现决定向全球桌面用户全面提供此功能，并计划在未来数月内推广至移动端。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-fa68d9c932.png"></p>
<p>启用后，Perplexity可为用户带来对话式搜索体验，提供带有权威引用的直接答案，而非如Google等搜索引擎所显示的网页链接列表。该选项将出现在地址栏的统一搜索按钮内，用户可随时切换为Perplexity搜索，也可在设置中设为默认搜索引擎。</p>
<p>Mozilla还表示，未来有望引入更多AI答案引擎，以丰富搜索体验（选择Perplexity的原因之一是其强调不会共享或出售用户个人数据）。</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-b6b8167e0a.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-b6b8167e0a.png" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 12:09:00 +0800</pubDate>
  </item><item>
    <title><![CDATA[谷歌 NotebookLM 视频概览功能升级：引入“Nano Banana”]]></title>
    <link>https://www.oschina.net/news/377509</link>
    <itunes:title><![CDATA[谷歌 NotebookLM 视频概览功能升级：引入“Nano Banana”]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>谷歌<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Ftechnology%2Fai%2Fnano-banana-google-products%2F" target="_blank">宣布</a>为NotebookLM的视频概览功能推出重大升级，借助Gemini最新图像生成技术“Nano Banana”，实现基于文档内容的自动视频创作能力。</p>
<p>此次更新为用户提供水彩、纸艺、动漫等六种视觉风格选项，并新增“Brief”格式与原有“Explainer”格式形成互补，分别满足快速提取文档要点与深度内容阐释需求。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-47ac782124.png"></p>
<p>用户在NotebookLM中选择源文件后，点击“视频概览”按钮即可自定义视频风格、格式及旁白等元素。</p>
<p>该功能将于本周率先向NotebookLM Pro用户开放，未来几周逐步向所有用户推送。谷歌表示，此次升级旨在通过AI技术降低视频内容创作门槛，为教育、办公等场景提供更直观的信息呈现方式，进一步拓展Gemini多模态能力的应用边界。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>谷歌<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Ftechnology%2Fai%2Fnano-banana-google-products%2F" target="_blank">宣布</a>为NotebookLM的视频概览功能推出重大升级，借助Gemini最新图像生成技术“Nano Banana”，实现基于文档内容的自动视频创作能力。</p>
<p>此次更新为用户提供水彩、纸艺、动漫等六种视觉风格选项，并新增“Brief”格式与原有“Explainer”格式形成互补，分别满足快速提取文档要点与深度内容阐释需求。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-47ac782124.png"></p>
<p>用户在NotebookLM中选择源文件后，点击“视频概览”按钮即可自定义视频风格、格式及旁白等元素。</p>
<p>该功能将于本周率先向NotebookLM Pro用户开放，未来几周逐步向所有用户推送。谷歌表示，此次升级旨在通过AI技术降低视频内容创作门槛，为教育、办公等场景提供更直观的信息呈现方式，进一步拓展Gemini多模态能力的应用边界。</p>]]>
    </description>
    <content:encoded><![CDATA[<p>谷歌<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Ftechnology%2Fai%2Fnano-banana-google-products%2F" target="_blank">宣布</a>为NotebookLM的视频概览功能推出重大升级，借助Gemini最新图像生成技术“Nano Banana”，实现基于文档内容的自动视频创作能力。</p>
<p>此次更新为用户提供水彩、纸艺、动漫等六种视觉风格选项，并新增“Brief”格式与原有“Explainer”格式形成互补，分别满足快速提取文档要点与深度内容阐释需求。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-47ac782124.png"></p>
<p>用户在NotebookLM中选择源文件后，点击“视频概览”按钮即可自定义视频风格、格式及旁白等元素。</p>
<p>该功能将于本周率先向NotebookLM Pro用户开放，未来几周逐步向所有用户推送。谷歌表示，此次升级旨在通过AI技术降低视频内容创作门槛，为教育、办公等场景提供更直观的信息呈现方式，进一步拓展Gemini多模态能力的应用边界。</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-47ac782124.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-47ac782124.png" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 11:28:06 +0800</pubDate>
  </item><item>
    <title><![CDATA[马斯克：X 平台本周将发布 AI 算法更新，信息流全面转向 AI 推荐]]></title>
    <link>https://www.oschina.net/news/377508</link>
    <itunes:title><![CDATA[马斯克：X 平台本周将发布 AI 算法更新，信息流全面转向 AI 推荐]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p><span>埃隆·马斯克（Elon Musk）周二在X上发帖预告，该平台将于</span><strong>本周晚些时候</strong><span>发布更新后的算法，以实现</span><strong>完全人工智能推荐</strong><span>。</span></p>
<p>马斯克表示，此次算法革新将使得用户的信息流（feed）改善不再是由于特定用户的行为改变了启发式（heuristics），而是<strong>完全归因于Grok和其他人工智能工具的使用增加</strong>。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-2d9336758f.png"></p>
<p>据马斯克透露，X平台将于<strong>下月全面切换至由Grok驱动的AI推荐系统</strong>，并将一并发布<strong>模型权重的新算法</strong>。</p>
<p>这一重大转变的核心在于利用先进的AI技术精准分发内容。每天将有<strong>超过1亿条内容</strong>由Grok进行评估，并推荐给用户<strong>最可能引起他们兴趣的内容</strong>，旨在显著提升整体信息流的质量和用户体验。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p><span>埃隆·马斯克（Elon Musk）周二在X上发帖预告，该平台将于</span><strong>本周晚些时候</strong><span>发布更新后的算法，以实现</span><strong>完全人工智能推荐</strong><span>。</span></p>
<p>马斯克表示，此次算法革新将使得用户的信息流（feed）改善不再是由于特定用户的行为改变了启发式（heuristics），而是<strong>完全归因于Grok和其他人工智能工具的使用增加</strong>。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-2d9336758f.png"></p>
<p>据马斯克透露，X平台将于<strong>下月全面切换至由Grok驱动的AI推荐系统</strong>，并将一并发布<strong>模型权重的新算法</strong>。</p>
<p>这一重大转变的核心在于利用先进的AI技术精准分发内容。每天将有<strong>超过1亿条内容</strong>由Grok进行评估，并推荐给用户<strong>最可能引起他们兴趣的内容</strong>，旨在显著提升整体信息流的质量和用户体验。</p>]]>
    </description>
    <content:encoded><![CDATA[<p><span>埃隆·马斯克（Elon Musk）周二在X上发帖预告，该平台将于</span><strong>本周晚些时候</strong><span>发布更新后的算法，以实现</span><strong>完全人工智能推荐</strong><span>。</span></p>
<p>马斯克表示，此次算法革新将使得用户的信息流（feed）改善不再是由于特定用户的行为改变了启发式（heuristics），而是<strong>完全归因于Grok和其他人工智能工具的使用增加</strong>。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-2d9336758f.png"></p>
<p>据马斯克透露，X平台将于<strong>下月全面切换至由Grok驱动的AI推荐系统</strong>，并将一并发布<strong>模型权重的新算法</strong>。</p>
<p>这一重大转变的核心在于利用先进的AI技术精准分发内容。每天将有<strong>超过1亿条内容</strong>由Grok进行评估，并推荐给用户<strong>最可能引起他们兴趣的内容</strong>，旨在显著提升整体信息流的质量和用户体验。</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-2d9336758f.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-2d9336758f.png" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 11:27:11 +0800</pubDate>
  </item><item>
    <title><![CDATA[SQLE 4.2509.0 正式版发布！SQL 工作台焕新升级！]]></title>
    <link>https://www.oschina.net/news/377499</link>
    <itunes:title><![CDATA[SQLE 4.2509.0 正式版发布！SQL 工作台焕新升级！]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<h2><span><span><span>🎈 新功能</span></span></span></h2>
<p><strong><strong><span><strong><span><span>社区版</span></span></strong></span></strong></strong></p>
<p><span><strong><strong><strong><span><u>🚀</u></span><span><u>&nbsp;</u></span><span><u>SQL 工作台焕新升级，体验更丝滑！</u></span></strong></strong></strong></span></p>
<p><span><span>根据社区的长期反馈，我们关注到旧版&nbsp;</span><strong>SQL 工作台</strong><strong>&nbsp;</strong><span>在界面设计和功能支持上存在一些不足。为了改善使用体验，我们进行了一次有针对性的重要更新。</span></span></p>
<p><span><span>本次更新主要集中在两个方面：</span><strong>界面现代化&nbsp;</strong><span>和&nbsp;</span><strong>核心功能增强</strong><span>。</span></span></p>
<p><span><strong>1. 更现代化的工作界面</strong><span>&nbsp;</span></span></p>
<p><span><span>新的用户界面更符合当下的设计标准。</span></span></p>
<p><span><strong>布局更清晰</strong><span>：优化了整体布局，减少了视觉上的干扰，帮助你更快定位到所需功能。</span></span></p>
<p><span><strong>操作更顺畅</strong><span>：调整了交互流程，使得常用操作的路径更短，响应也更为流畅。</span></span></p>
<p><span><strong>2.&nbsp;</strong></span><span><strong>更强大的内置功能</strong></span></p>
<p><span><strong>集成工单状态追踪：</strong><span>对于从 SQL 工作台触发的审批工单，你现在可以直接在工作台内查看其进展状态。无需再切换页面，让 SQL 开发与审批流程的衔接更紧密。</span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-2c4c657563.png"></p>
<p><strong>SQL 脚本保存与复用：</strong><span>&nbsp;你可以将常用或复杂的 SQL 脚本保存在工作台中，方便随时查找和复用。这能有效减少重复编写的工作，并帮助你沉淀和管理常用的查询逻辑。</span></p>
<p><span><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-c1f4490313.png"></span></p>
<p><span><strong>我们相信，这些改进将为你的日常数据工作带来切实的帮助。</strong></span></p>
<h2><span><span>📜 版本日志</span></span></h2>
<p><strong><span><strong><span>社区版</span></strong></span></strong></p>
<p><strong><span>新特性</span></strong></p>
<ul>
<li> <p><span>[/issues/3133] SQLE 支持 ODC SQL 工作台</span></p> </li>
</ul>
<p><strong><span>Bug 修复</span></strong></p>
<ul>
<li> <p><span>[/issues/3138] 分析页面未能获取 SQL 相关的表信息</span></p> </li>
</ul>
<p><span><strong><span><strong><strong><span>企业版</span></strong></strong></span></strong></span></p>
<p><strong><span>新特性</span></strong></p>
<ul>
<li> <p><span>[actiontech/sqle-ee/issues/2533] 新增 TopSQL 智能扫描</span></p> </li>
</ul>
<p><strong><span>Bug 修复</span></strong></p>
<ul>
<li> <p><span>[actiontech/dms-ee/issues/671] 通过 OAuth2 登录后，用户表上次登录时间未更新</span></p> </li>
</ul>
<h2><span><span>🧩 版本选择</span></span></h2>
<p><span><strong><span><span>社区版：</span></span></strong><span>轻量级 MySQL 开发治理工具，满足个人和小团队的基础 SQL 开发需求。</span></span></p>
<p><span><strong><span>专业版：</span></strong><span>多数据源开发治理平台，为中小团队提供更丰富的数据库变更管控能力。</span></span></p>
<p><span><strong><span>企业版：</span></strong><span>企业级数据资产合规平台，满足大型企业的数据安全与管控要求。</span></span></p>
<p><span><span>🤗 我们为&nbsp;</span></span><span><strong><span>社区版&nbsp;</span></strong></span><span><span>和&nbsp;</span></span><span><strong><span>企业版&nbsp;</span></strong></span><span><span>准备了在线体验环境，欢迎体验。</span></span></p>
<p><span><span>👉&nbsp;</span></span><strong><span><span>社区版：</span></span></strong><span><span>http://demo.sqle.actionsky.com/</span></span></p>
<p><span>👉&nbsp;</span><span><strong><span>企业版：</span></strong></span><span>http://demo.sqle.actionsky.com:8889/</span></p>
<p><span>🙋‍♂️</span><strong><span>&nbsp;用户名：</span></strong><span>admin</span></p>
<p><span><span>🔑&nbsp;</span></span><strong><span>密 &nbsp; 码：</span></strong><span><span>admin</span></span></p>
<p><span><span>👉&nbsp;</span></span><span><strong><span>专业版：</span></strong></span><span><span>调填写调研问卷（扫码或点击&nbsp;</span></span><strong><span>原文链接</span></strong><span><span>）获取安装包。</span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-22dae3ccc9.jpg"></p>
<p><strong><span>SQLE 4.2509.0</span></strong><span><span>&nbsp;专业版获取</span></span></p>
<p><strong><span><span>🔗&nbsp;</span></span><span>企业版获取：</span></strong><span><span>可通过海报下方的小程序进行商务咨询或预约演示。</span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-64da689ccd.png"></p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<h2><span><span><span>🎈 新功能</span></span></span></h2>
<p><strong><strong><span><strong><span><span>社区版</span></span></strong></span></strong></strong></p>
<p><span><strong><strong><strong><span><u>🚀</u></span><span><u>&nbsp;</u></span><span><u>SQL 工作台焕新升级，体验更丝滑！</u></span></strong></strong></strong></span></p>
<p><span><span>根据社区的长期反馈，我们关注到旧版&nbsp;</span><strong>SQL 工作台</strong><strong>&nbsp;</strong><span>在界面设计和功能支持上存在一些不足。为了改善使用体验，我们进行了一次有针对性的重要更新。</span></span></p>
<p><span><span>本次更新主要集中在两个方面：</span><strong>界面现代化&nbsp;</strong><span>和&nbsp;</span><strong>核心功能增强</strong><span>。</span></span></p>
<p><span><strong>1. 更现代化的工作界面</strong><span>&nbsp;</span></span></p>
<p><span><span>新的用户界面更符合当下的设计标准。</span></span></p>
<p><span><strong>布局更清晰</strong><span>：优化了整体布局，减少了视觉上的干扰，帮助你更快定位到所需功能。</span></span></p>
<p><span><strong>操作更顺畅</strong><span>：调整了交互流程，使得常用操作的路径更短，响应也更为流畅。</span></span></p>
<p><span><strong>2.&nbsp;</strong></span><span><strong>更强大的内置功能</strong></span></p>
<p><span><strong>集成工单状态追踪：</strong><span>对于从 SQL 工作台触发的审批工单，你现在可以直接在工作台内查看其进展状态。无需再切换页面，让 SQL 开发与审批流程的衔接更紧密。</span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-2c4c657563.png"></p>
<p><strong>SQL 脚本保存与复用：</strong><span>&nbsp;你可以将常用或复杂的 SQL 脚本保存在工作台中，方便随时查找和复用。这能有效减少重复编写的工作，并帮助你沉淀和管理常用的查询逻辑。</span></p>
<p><span><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-c1f4490313.png"></span></p>
<p><span><strong>我们相信，这些改进将为你的日常数据工作带来切实的帮助。</strong></span></p>
<h2><span><span>📜 版本日志</span></span></h2>
<p><strong><span><strong><span>社区版</span></strong></span></strong></p>
<p><strong><span>新特性</span></strong></p>
<ul>
<li> <p><span>[/issues/3133] SQLE 支持 ODC SQL 工作台</span></p> </li>
</ul>
<p><strong><span>Bug 修复</span></strong></p>
<ul>
<li> <p><span>[/issues/3138] 分析页面未能获取 SQL 相关的表信息</span></p> </li>
</ul>
<p><span><strong><span><strong><strong><span>企业版</span></strong></strong></span></strong></span></p>
<p><strong><span>新特性</span></strong></p>
<ul>
<li> <p><span>[actiontech/sqle-ee/issues/2533] 新增 TopSQL 智能扫描</span></p> </li>
</ul>
<p><strong><span>Bug 修复</span></strong></p>
<ul>
<li> <p><span>[actiontech/dms-ee/issues/671] 通过 OAuth2 登录后，用户表上次登录时间未更新</span></p> </li>
</ul>
<h2><span><span>🧩 版本选择</span></span></h2>
<p><span><strong><span><span>社区版：</span></span></strong><span>轻量级 MySQL 开发治理工具，满足个人和小团队的基础 SQL 开发需求。</span></span></p>
<p><span><strong><span>专业版：</span></strong><span>多数据源开发治理平台，为中小团队提供更丰富的数据库变更管控能力。</span></span></p>
<p><span><strong><span>企业版：</span></strong><span>企业级数据资产合规平台，满足大型企业的数据安全与管控要求。</span></span></p>
<p><span><span>🤗 我们为&nbsp;</span></span><span><strong><span>社区版&nbsp;</span></strong></span><span><span>和&nbsp;</span></span><span><strong><span>企业版&nbsp;</span></strong></span><span><span>准备了在线体验环境，欢迎体验。</span></span></p>
<p><span><span>👉&nbsp;</span></span><strong><span><span>社区版：</span></span></strong><span><span>http://demo.sqle.actionsky.com/</span></span></p>
<p><span>👉&nbsp;</span><span><strong><span>企业版：</span></strong></span><span>http://demo.sqle.actionsky.com:8889/</span></p>
<p><span>🙋‍♂️</span><strong><span>&nbsp;用户名：</span></strong><span>admin</span></p>
<p><span><span>🔑&nbsp;</span></span><strong><span>密 &nbsp; 码：</span></strong><span><span>admin</span></span></p>
<p><span><span>👉&nbsp;</span></span><span><strong><span>专业版：</span></strong></span><span><span>调填写调研问卷（扫码或点击&nbsp;</span></span><strong><span>原文链接</span></strong><span><span>）获取安装包。</span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-22dae3ccc9.jpg"></p>
<p><strong><span>SQLE 4.2509.0</span></strong><span><span>&nbsp;专业版获取</span></span></p>
<p><strong><span><span>🔗&nbsp;</span></span><span>企业版获取：</span></strong><span><span>可通过海报下方的小程序进行商务咨询或预约演示。</span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-64da689ccd.png"></p>]]>
    </description>
    <content:encoded><![CDATA[<h2><span><span><span>🎈 新功能</span></span></span></h2>
<p><strong><strong><span><strong><span><span>社区版</span></span></strong></span></strong></strong></p>
<p><span><strong><strong><strong><span><u>🚀</u></span><span><u>&nbsp;</u></span><span><u>SQL 工作台焕新升级，体验更丝滑！</u></span></strong></strong></strong></span></p>
<p><span><span>根据社区的长期反馈，我们关注到旧版&nbsp;</span><strong>SQL 工作台</strong><strong>&nbsp;</strong><span>在界面设计和功能支持上存在一些不足。为了改善使用体验，我们进行了一次有针对性的重要更新。</span></span></p>
<p><span><span>本次更新主要集中在两个方面：</span><strong>界面现代化&nbsp;</strong><span>和&nbsp;</span><strong>核心功能增强</strong><span>。</span></span></p>
<p><span><strong>1. 更现代化的工作界面</strong><span>&nbsp;</span></span></p>
<p><span><span>新的用户界面更符合当下的设计标准。</span></span></p>
<p><span><strong>布局更清晰</strong><span>：优化了整体布局，减少了视觉上的干扰，帮助你更快定位到所需功能。</span></span></p>
<p><span><strong>操作更顺畅</strong><span>：调整了交互流程，使得常用操作的路径更短，响应也更为流畅。</span></span></p>
<p><span><strong>2.&nbsp;</strong></span><span><strong>更强大的内置功能</strong></span></p>
<p><span><strong>集成工单状态追踪：</strong><span>对于从 SQL 工作台触发的审批工单，你现在可以直接在工作台内查看其进展状态。无需再切换页面，让 SQL 开发与审批流程的衔接更紧密。</span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-2c4c657563.png"></p>
<p><strong>SQL 脚本保存与复用：</strong><span>&nbsp;你可以将常用或复杂的 SQL 脚本保存在工作台中，方便随时查找和复用。这能有效减少重复编写的工作，并帮助你沉淀和管理常用的查询逻辑。</span></p>
<p><span><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-c1f4490313.png"></span></p>
<p><span><strong>我们相信，这些改进将为你的日常数据工作带来切实的帮助。</strong></span></p>
<h2><span><span>📜 版本日志</span></span></h2>
<p><strong><span><strong><span>社区版</span></strong></span></strong></p>
<p><strong><span>新特性</span></strong></p>
<ul>
<li> <p><span>[/issues/3133] SQLE 支持 ODC SQL 工作台</span></p> </li>
</ul>
<p><strong><span>Bug 修复</span></strong></p>
<ul>
<li> <p><span>[/issues/3138] 分析页面未能获取 SQL 相关的表信息</span></p> </li>
</ul>
<p><span><strong><span><strong><strong><span>企业版</span></strong></strong></span></strong></span></p>
<p><strong><span>新特性</span></strong></p>
<ul>
<li> <p><span>[actiontech/sqle-ee/issues/2533] 新增 TopSQL 智能扫描</span></p> </li>
</ul>
<p><strong><span>Bug 修复</span></strong></p>
<ul>
<li> <p><span>[actiontech/dms-ee/issues/671] 通过 OAuth2 登录后，用户表上次登录时间未更新</span></p> </li>
</ul>
<h2><span><span>🧩 版本选择</span></span></h2>
<p><span><strong><span><span>社区版：</span></span></strong><span>轻量级 MySQL 开发治理工具，满足个人和小团队的基础 SQL 开发需求。</span></span></p>
<p><span><strong><span>专业版：</span></strong><span>多数据源开发治理平台，为中小团队提供更丰富的数据库变更管控能力。</span></span></p>
<p><span><strong><span>企业版：</span></strong><span>企业级数据资产合规平台，满足大型企业的数据安全与管控要求。</span></span></p>
<p><span><span>🤗 我们为&nbsp;</span></span><span><strong><span>社区版&nbsp;</span></strong></span><span><span>和&nbsp;</span></span><span><strong><span>企业版&nbsp;</span></strong></span><span><span>准备了在线体验环境，欢迎体验。</span></span></p>
<p><span><span>👉&nbsp;</span></span><strong><span><span>社区版：</span></span></strong><span><span>http://demo.sqle.actionsky.com/</span></span></p>
<p><span>👉&nbsp;</span><span><strong><span>企业版：</span></strong></span><span>http://demo.sqle.actionsky.com:8889/</span></p>
<p><span>🙋‍♂️</span><strong><span>&nbsp;用户名：</span></strong><span>admin</span></p>
<p><span><span>🔑&nbsp;</span></span><strong><span>密 &nbsp; 码：</span></strong><span><span>admin</span></span></p>
<p><span><span>👉&nbsp;</span></span><span><strong><span>专业版：</span></strong></span><span><span>调填写调研问卷（扫码或点击&nbsp;</span></span><strong><span>原文链接</span></strong><span><span>）获取安装包。</span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-22dae3ccc9.jpg"></p>
<p><strong><span>SQLE 4.2509.0</span></strong><span><span>&nbsp;专业版获取</span></span></p>
<p><strong><span><span>🔗&nbsp;</span></span><span>企业版获取：</span></strong><span><span>可通过海报下方的小程序进行商务咨询或预约演示。</span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-64da689ccd.png"></p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-2c4c657563.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-2c4c657563.png" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 11:07:38 +0800</pubDate>
  </item><item>
    <title><![CDATA[宾夕法尼亚大学研究发现：对 AI 越“粗鲁”回答准确率越高]]></title>
    <link>https://www.oschina.net/news/377497</link>
    <itunes:title><![CDATA[宾夕法尼亚大学研究发现：对 AI 越“粗鲁”回答准确率越高]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>宾夕法尼亚州立大学<span>最新</span>发表的研究论文《Mind Your Tone》揭示了一个反常识的现象:在与大语言模型交互时，使用直白甚至粗鲁的语气，可能比礼貌用语获得更准确的答案。这项研究<span>首次</span>系统性地验证了提问语气对AI模型表现的实际影响。</p>
<p>研究团队构建了一个包含50道中等难度选择题的测试集，题目覆盖数学、科学和历史等多个领域。针对每道题目，研究人员设计了五种不同语气的提问方式，从"您能好心帮我解这道题吗"这样的客套表达，到"请回答这道题"的中性陈述，再到"直接给答案"的简洁指令，直至"你要是不笨就回答"和"你个没用的，会解这道题吗"等带有攻击性的表述。</p>
<p>测试对象为OpenAI<span>最新</span>的GPT-4o模型。为确保实验的独立性，研究人员要求模型忘记先前对话内容，仅输出选项字母作为答案。统计结果显示，使用粗鲁语气提问时，GPT-4o的正确率达到84.8%，而过分客气的提问方式反而使准确率降至80.8%，两者差距达到4个百分点。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-1095780092.png"></p>
<p>研究团队对这一现象的解释是，过度礼貌的表达往往包含大量客套话和修饰性语言，这些与核心问题无关的信息反而干扰了模型对关键内容的提取。相比之下，直接的命令式表达虽然缺乏礼貌，但能让模型更专注于问题本身，减少了信息处理过程中的噪音。</p>
<p>值得注意的是，这一规律并非对所有AI模型普遍适用。研究人员在GPT-3.5和Llama2-70B等较早期模型上进行的对比测试显示，这些模型对礼貌提问的响应效果更好，粗鲁语气反而会降低回答质量。研究者推测，新一代模型在训练阶段接触了更多样化的语气数据，使其具备了更强的无关信息过滤能力，因此能够在非礼貌语境下保持甚至提升表现。</p>
<p>尽管实验结果提供了有趣的技术洞察，但从实际应用角度看，用户在日常使用AI工具时仍需根据具体模型特性和场景需求来调整交互方式。这项研究更重要的意义在于提醒开发者和用户：提示词的设计不仅关乎礼貌与否，更关乎信息密度和指令清晰度。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>宾夕法尼亚州立大学<span>最新</span>发表的研究论文《Mind Your Tone》揭示了一个反常识的现象:在与大语言模型交互时，使用直白甚至粗鲁的语气，可能比礼貌用语获得更准确的答案。这项研究<span>首次</span>系统性地验证了提问语气对AI模型表现的实际影响。</p>
<p>研究团队构建了一个包含50道中等难度选择题的测试集，题目覆盖数学、科学和历史等多个领域。针对每道题目，研究人员设计了五种不同语气的提问方式，从"您能好心帮我解这道题吗"这样的客套表达，到"请回答这道题"的中性陈述，再到"直接给答案"的简洁指令，直至"你要是不笨就回答"和"你个没用的，会解这道题吗"等带有攻击性的表述。</p>
<p>测试对象为OpenAI<span>最新</span>的GPT-4o模型。为确保实验的独立性，研究人员要求模型忘记先前对话内容，仅输出选项字母作为答案。统计结果显示，使用粗鲁语气提问时，GPT-4o的正确率达到84.8%，而过分客气的提问方式反而使准确率降至80.8%，两者差距达到4个百分点。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-1095780092.png"></p>
<p>研究团队对这一现象的解释是，过度礼貌的表达往往包含大量客套话和修饰性语言，这些与核心问题无关的信息反而干扰了模型对关键内容的提取。相比之下，直接的命令式表达虽然缺乏礼貌，但能让模型更专注于问题本身，减少了信息处理过程中的噪音。</p>
<p>值得注意的是，这一规律并非对所有AI模型普遍适用。研究人员在GPT-3.5和Llama2-70B等较早期模型上进行的对比测试显示，这些模型对礼貌提问的响应效果更好，粗鲁语气反而会降低回答质量。研究者推测，新一代模型在训练阶段接触了更多样化的语气数据，使其具备了更强的无关信息过滤能力，因此能够在非礼貌语境下保持甚至提升表现。</p>
<p>尽管实验结果提供了有趣的技术洞察，但从实际应用角度看，用户在日常使用AI工具时仍需根据具体模型特性和场景需求来调整交互方式。这项研究更重要的意义在于提醒开发者和用户：提示词的设计不仅关乎礼貌与否，更关乎信息密度和指令清晰度。</p>]]>
    </description>
    <content:encoded><![CDATA[<p>宾夕法尼亚州立大学<span>最新</span>发表的研究论文《Mind Your Tone》揭示了一个反常识的现象:在与大语言模型交互时，使用直白甚至粗鲁的语气，可能比礼貌用语获得更准确的答案。这项研究<span>首次</span>系统性地验证了提问语气对AI模型表现的实际影响。</p>
<p>研究团队构建了一个包含50道中等难度选择题的测试集，题目覆盖数学、科学和历史等多个领域。针对每道题目，研究人员设计了五种不同语气的提问方式，从"您能好心帮我解这道题吗"这样的客套表达，到"请回答这道题"的中性陈述，再到"直接给答案"的简洁指令，直至"你要是不笨就回答"和"你个没用的，会解这道题吗"等带有攻击性的表述。</p>
<p>测试对象为OpenAI<span>最新</span>的GPT-4o模型。为确保实验的独立性，研究人员要求模型忘记先前对话内容，仅输出选项字母作为答案。统计结果显示，使用粗鲁语气提问时，GPT-4o的正确率达到84.8%，而过分客气的提问方式反而使准确率降至80.8%，两者差距达到4个百分点。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-1095780092.png"></p>
<p>研究团队对这一现象的解释是，过度礼貌的表达往往包含大量客套话和修饰性语言，这些与核心问题无关的信息反而干扰了模型对关键内容的提取。相比之下，直接的命令式表达虽然缺乏礼貌，但能让模型更专注于问题本身，减少了信息处理过程中的噪音。</p>
<p>值得注意的是，这一规律并非对所有AI模型普遍适用。研究人员在GPT-3.5和Llama2-70B等较早期模型上进行的对比测试显示，这些模型对礼貌提问的响应效果更好，粗鲁语气反而会降低回答质量。研究者推测，新一代模型在训练阶段接触了更多样化的语气数据，使其具备了更强的无关信息过滤能力，因此能够在非礼貌语境下保持甚至提升表现。</p>
<p>尽管实验结果提供了有趣的技术洞察，但从实际应用角度看，用户在日常使用AI工具时仍需根据具体模型特性和场景需求来调整交互方式。这项研究更重要的意义在于提醒开发者和用户：提示词的设计不仅关乎礼貌与否，更关乎信息密度和指令清晰度。</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-1095780092.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-1095780092.png" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 10:59:07 +0800</pubDate>
  </item><item>
    <title><![CDATA[百度 APP 日志处理框架升级之路]]></title>
    <link>https://my.oschina.net/u/4939618/blog/18695530</link>
    <itunes:title><![CDATA[百度 APP 日志处理框架升级之路]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<h1>导读</h1>
<p>面对百度APP日均数千亿PV、超百PB数据规模带来的巨大挑战，我们完成了数据仓库的系统性升级。本文详细阐述了通过"两步走"策略解决资源压力、处理延迟和架构瓶颈的全过程：第一阶段聚焦日志清洗环节的稳定性与成本优化，第二阶段实现实时离线链路解耦、核心数据隔离及计算框架容错能力提升。此次升级显著提升了数据处理时效性、系统稳定性和成本效益，为业务发展提供了更坚实的数据支撑。</p>
<h1>背景</h1>
<p>百度APP及其产品矩阵作为百度体量最大的C端业务线，在数据处理全链路面临规模与架构的双重挑战。日志清洗环节因日均几千亿PV、超百PB的庞大数据规模，导致计算资源持续承压、处理延迟频发，加之历史遗留的复杂日志格式，清洗稳定性与时效性逐步下降，存储成本高昂。与此同时上游日志数据仍存在实时与离线链路耦合、核心与边缘数据未有效隔离、计算框架容错能力不足等结构性问题，影响关键数据产出的稳定与时效。整体系统切换与优化面临高额的历史负担和技术重构成本，下游业务的数据可用性、决策及时性及深度运营分析均受到显著制约。</p>
<p>基于以上问题，我们制定了“两步走”的升级策略：第一阶段优先解决日志清洗环节的稳定性和存储成本问题；第二阶段在此基础上，重点推进数仓上层架构优化，包括实时与离线链路解耦、核心数据隔离处理以及计算框架容错能力提升，逐步实现整体数据仓库的高效、稳定与可持续升级。</p>
<h1>01 第一阶段：多日志源整合</h1>
<h2><strong>1. 2023年之前架构</strong></h2>
<p>在百度APP及其产品矩阵的数据体系建设过程中，日志清洗作为整个数据流水线的起始环节，其处理稳定性和产出时效性始终处于关键地位，是保障下游业务数据可用性与决策及时性的重中之重。然而，随着业务规模持续扩大和用户体量快速增长，每日产生的日志量急剧上升，由此带来的巨大计算压力使得整个清洗链路频繁面临资源瓶颈与处理延迟，稳定性和时效性均逐步下滑，难以满足下游各业务方对数据交付时间和质量的要求。与此同时，数据入口的分散催生了大量烟囱式的开发与冗余的计算逻辑，不仅推高了运维成本，更在源头形成了数据孤岛。下游基于此类数据构建的数仓架构必然复杂化，多表的 JOIN 与理解成本高昂，使得整个数据建设环节背负着日趋沉重的成本与协作压力。</p>
<h2><strong>2. 问题分析</strong></h2>
<h3>2.1 旧架构分析</h3>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-41f3e39809.jpg"></p>
<h4>2.1.1 <strong><strong>数据孤岛化加剧，认知与使用成本高昂</strong></strong></h4>
<p>现有架构对每类日志采用独立落表方式，导致数据存储呈现碎片化状态。这种设计造成同一业务实体的相关信息分散在不同表中，形成严重的数据割裂。下游用户在使用数据时，不得不通过多表关联才能获取完整信息，不仅大幅增加了技术实现难度，更带来了沉重的认知负担。用户需要理解多张表的结构和关联关系，极易产生理解偏差，进而影响数据分析的准确性和可靠性。</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-abbc8cbb5f.jpg"></p>
<h4>2.1.2 <strong><strong>关联查询性能瓶颈，制约数据价值释放</strong></strong></h4>
<p>与此同时，多表关联查询模式给系统带来了巨大的性能压力。随着数据量的持续增长，表连接操作的成本呈指数级上升，查询响应时间显著延长。特别是在需要跨多个表进行关联分析的场景下，系统往往需要耗费大量计算资源和时间，无法满足业务对高效数据分析和快速决策的需求，严重制约了数据价值的及时释放。</p>
<p>此外，原始日志结构中普遍存在的复杂嵌套格式（如多层JSON、数组结构等）大幅增加了数据清洗和解析的复杂度。大量业务自定义字段缺乏统一规范，导致解析逻辑冗余且低效，进一步降低了整体处理性能。这些因素共同加剧了数据处理的延迟与资源消耗，形成系统性瓶颈。</p>
<h4>2.1.3 <strong><strong>维护复杂度与脆弱性并存，系统稳定性堪忧</strong></strong></h4>
<p>独立的数据处理流水线，导致系统维护点分散。任何逻辑变更或schema调整都需要在多处同步实施，极大地增加了维护工作量。这种架构的脆弱性也显著提高了出错风险，单个任务修改的错误可能引发连锁反应，影响整个数据链路的稳定性。</p>
<p>特别需要指出的是，当前采用的UDW数仓及配套ETL框架仍是2012年上线的技术方案，已明显落后于业界主流水平。该框架存在诸多局限性：首先，其兼容性差，难以与现有开源生态工具链高效集成；其次，基于C++的MR计算框架稳定性不足，日常运行中容易出现各种异常；最后，开发调试效率低下，严重制约了数据需求的迭代速度。这些技术债务不仅增加了系统的维护复杂度，更成为制约数据平台发展的关键瓶颈。</p>
<h3>2.2 重构思路分析</h3>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-bc837c97b5.jpg"></p>
<p><strong>理想状态</strong>：从数据架构的理想设计来看，基于通用宽表数据建模方法论，采用“一步到位”的方式直接产出高度整合、面向主题的Turing宽表，是最为高效和优雅的解决方案。它能够减少中间冗余加工环节，提升数据一致性和复用度。</p>
<p><strong>升级成本</strong>：下游业务方因历史原因，数据应用架构高度依赖传统UDW模式的数据组织与服务方式，迁移至Turing宽表体系涉及大量脚本改造、逻辑核对与业务适配工作，技术切换和数据迁移成本极高，导致架构升级短期难以实施。</p>
<p><strong>思考</strong>：为实现数据架构的平滑升级，本次重构方案采用渐进式过渡策略，在着力解决现有架构核心痛点的同时，必须充分考虑百度业务数据链路长、历史包袱重的现实情况，审慎平衡技术先进性与落地可行性。方案设计严格遵循"平滑过渡、风险可控、成本最优"三大原则。</p>
<p>需要特别指出的是，由于现有数据体系深度嵌入各业务线的策略计算与离线分析环节，其紧密的耦合关系导致配套升级难度极大、周期长。这不仅涉及底层数据表的更替、依赖路径修改，更要求对依赖原有数据模型的下游业务进行协同改造和全面适配，沟通和推进难度极大。所以在保障业务连续性的前提下，如何有序推进全链路的升级切换是本次升级的重中之重。</p>
<p><strong><strong>建模思路：</strong></strong></p>
<p><strong><strong>（1）降低迁移成本</strong></strong></p>
<p>在数据中间层设计上，方案延续使用<strong><strong>刻钟级UDW</strong></strong>表作为缓冲层，通过将多个离散的UDW表整合为统一的宽表模型，进一步降低下游的使用和理解成本。同时，对表schema实施精细化改造，包括消除冗余字段、统一数据标准、优化存储格式，并重构字段逻辑以提升数据一致性。这种设计既保持了与现有下游系统的兼容性，又显著降低了数据使用复杂度。</p>
<p><strong><strong>（2）双轨输出机制</strong></strong></p>
<p>为确保迁移过程的平稳性，方案采用双轨输出机制：一方面继续提供优化后的UDW宽表，保障现有作业的无缝运行；另一方面通过聚合加工生成小时级Turing表，作为统一对外输出的日志宽表。这种渐进式迁移路径使下游用户可根据自身情况灵活选择切换时机，最大限度降低升级成本。</p>
<p><strong><strong>（3）兼顾历史和未来</strong></strong></p>
<p>此次架构优化为后续全面升级奠定了坚实基础。通过UDW层的预处理和Turing表的逐步推广，最终将实现架构的完全过渡，在提升系统性能的同时确保业务连续性，达成技术演进与业务稳定之间的最佳平衡。</p>
<h2><strong>3. 解决方案</strong></h2>
<p><strong><strong>过渡方案设计与实施：稳时效、降成本、提效率的综合治理</strong></strong></p>
<p>面对日志清洗环节日益严峻的稳定性、时效性及成本压力，我们制定并实施了一套详尽的过渡性解决方案。该方案并未激进地推行一步到位的Turing宽表迁移，而是立足于现有技术生态，以快速解决下游业务最迫切的痛点为目标，重点攻坚“产出时效不稳定”、“存储计算成本高”及“明细数据查询效率低下”三大核心问题。</p>
<h3>3.1 优化处理粒度与逻辑沉淀，保障时效与复用性</h3>
<p>为彻底扭转小时级任务积压与延迟的局面，我们首先对调度周期进行了粒度细化，将日志清洗任务从<strong><strong>小时级调度全面提升至刻钟级（15分钟）</strong></strong>。这一调整显著降低了单次任务的处理数据量和计算压力，使数据产出的延迟大幅减少，稳定性和时效性得到了根本保障。在技术选型上，我们并未盲目更换计算框架，而是继续沿用成熟稳定的<strong><strong>C++/MR框架</strong></strong>，确保了迁移过程的平稳性与可靠性。</p>
<p>同时，我们致力于提升数据的易用性与标准化程度。针对下游业务方需要反复从复杂JSON、Map等嵌套字段中解析提取关键信息的痛点，我们进行了大规模的<strong><strong>业务通用逻辑下沉</strong></strong>工作。将超过100个高频访问的埋点属性进行预解析、扁平化处理，转化为单独的标准化字段。这不仅极大减轻了下游的数据预处理负担，更直接提升了基于这些字段的<strong><strong>查询过滤与聚合分析效率</strong></strong>，为下游开发节省了大量时间。</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-3ad183e1e7.jpg"></p>
<h3>3.2 <strong><strong>兼顾历史依赖与未来演进，提供平滑迁移路径</strong></strong></h3>
<p>我们充分认识到下游业务对原有UDW数仓体系的强依赖性。为保障业务的连续性，我们并未强制要求所有方立即迁移，而是采取了<strong><strong>双轨并行</strong></strong>的支撑策略。在产出新一代数据模型的同时，我们<strong><strong>继续提供UDW中间表</strong></strong>，确保那些尚未准备好迁移至Turing宽表的业务方能够无缝对接，无需修改现有代码，极大降低了方案的落地门槛和风险。</p>
<h3>3.3 深度优化存储与查询，实现性能跨越式提升</h3>
<p>为进一步降低存储成本并提升Turing宽表的查询性能，我们对其存储结构进行了深度优化。</p>
<ul>
<li><strong><strong>合并小文件与高效压缩</strong></strong>：海量小文件是制约查询性能的首要元凶。我们通过按<strong><strong>设备ID、点位ID、时间戳</strong></strong>等关键字段进行精细排序，将数据写入为连续有序的大文件，从而将<strong><strong>单天高达800万个小文件合并至60万左右</strong></strong>，文件数量减少了近<strong><strong>93%</strong></strong>。在存储格式上，我们选用Parquet列式存储，并经过充分调研测试，采用了<strong><strong>ZSTD压缩算法</strong></strong>。ZSTD在压缩比、压缩/解压速度上取得了最佳平衡，且完美支持多线程，最终实现了每天<strong><strong>节省超过420TB</strong></strong>的巨大存储开销，成本效益极其显著。</li>
</ul>
<h2><strong>4. 新的问题&amp;解决策略</strong></h2>
<p>问题1：宽表数据量膨胀导致的查询性能下降</p>
<p>解决策略：为应对宽表数据量激增对查询性能带来的挑战，我们实施了体系化的查询加速方案，显著提升海量数据下的检索效率</p>
<ul>
<li> <p><strong><strong>强制分区限制策略</strong></strong>：在查询引擎层上线了强制要求限制分区条件的规则，避免了全表扫描带来的巨额元数据开销，大幅提升元数据检索效率。</p> </li>
<li> <p><strong><strong>查询结果缓存</strong></strong>：对常见的热点查询结果进行缓存，对于重复性查询实现了秒级响应。</p> </li>
<li> <p><strong><strong>智能资源调度</strong></strong>：根据查询的计算复杂度，系统自动将其调度到不同配置的资源池中执行，简单查询快速返回，复杂查询获得充足资源，实现了集群资源的高效利用。</p> </li>
</ul>
<p>问题2：分区数量增多导致点位所在的分区变得困难</p>
<p>解决策略：针对分区维度增加后，数据定位难度加大的问题，我们通过元数据管理与平台化集成提供解决方案：</p>
<ul>
<li> <p>新建分区元数据集，以天为粒度预先计算并存储所有点位与分区的映射关系，形成高效的点位分区定位查询，为点位所在分区快速检索提供基础支撑。</p> </li>
<li> <p>与现有点位管理平台深度集成，在其点位查询界面新增【查一查】功能。用户可通过界面化操作直接获取精准的数据分区信息及查询SQL模板，极大提升了用户使用的效率，降低了用户使用成本。</p> </li>
</ul>
<h1>02 第二阶段：全面提速</h1>
<h2><strong>1. 2023→2024年架构</strong></h2>
<p>随着业务发展，该数仓已完成由UDW（统一数据工作台）向Turing（新数据工作台）的改造，并初步建立起体系化的数据模型与分层数据集，显著提升了数据复用性和分析效率。基于这些宽表与数据集，大部分常规分析场景已能够快速响应。然而，在数据加工的最上游，即明细数据宽表的生产环节之前依旧包含缓冲的刻钟级udw表，因此仍存在若干架构性瓶颈。首先，实时数据处理链路与离线批处理链路相互耦合，资源竞争与依赖关系复杂，影响了整体任务的稳定性和时效性；其次，核心业务指标与非核心附属数据未被有效拆分处理，导致关键数据产出易受边缘数据波动或延迟的干扰；此外，当前的计算框架对于数据迟到、重复、异常值等复杂情况的处理灵活度不足，容错与自适应能力有待加强。</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-14db3809be.jpg"></p>
<p>为彻底解决这些问题，进一步提升数据产出的时效性、准确性和稳定性，以更好地赋能百度APP及其产品矩阵及各下游业务的数据分析与决策，亟需结合各数据点位的实际使用情况和业务优先级，对最上游的日志ETL（抽取、转换、加载）处理流程进行系统性的优化与重构。</p>
<h2><strong>2. 问题分析</strong></h2>
<p>当前数据ETL处理流程面临以下几个核心挑战，这些问题不仅影响数据产出的效率与稳定性，也为下游业务数据的准确性和及时性带来风险。</p>
<h3>2.1 开发框架灵活性不足，资源协调与弹性扩展能力受限</h3>
<p>目前的ETL任务仍沿用原有UDW大表处理框架，通过单机Hadoop Client提交任务，并依赖QE（底层为mapreduce引擎）进行计算。该框架在资源调度和权限管理方面已逐渐暴露出瓶颈。同时udw是2012年提出的数仓建设方案，随着开源计算、存储技术的发展，udw性能逐步落后业界，部分功能不具备继续升级迭代可行性。一旦出现上游数据延迟、队列资源拥塞或系统异常，容易导致任务大规模积压。由于缺乏跨队列或跨资源的调度容灾能力，无法协调其他计算资源执行任务回溯与补偿，最终将直接影响整体数据产出时效，甚至波及下游多条业务线的核心数据应用。</p>
<h3>2.2 核心与非核心数据处理耦合，异常影响范围扩散</h3>
<p>在日志清洗ETL环节中，核心业务数据点位与非核心业务数据点位、以及实时与离线数据流目前尚未进行有效拆分处理。这种架构层面的耦合导致一旦上游数据源或计算过程中发生异常，其影响面会迅速扩大，不仅关键业务指标受到冲击，非核心业务数据的问题也可能反向干扰核心链路的稳定性。缺乏业务优先级识别和隔离机制，降低了计算链路的整体容错能力和故障隔离水平。</p>
<h3>2.3 计算链路冗长复杂，维护困难且稳定性面临挑战</h3>
<p>当前处理流程中包含UDW中间缓冲层，导致计算环节增多、链路层级深化。较长的依赖链不仅增加了数据产出的端到端延迟，也显著提高了运维监控和故障定位的复杂度。任何环节出现性能波动或失败都易引起连锁反应，威胁整体任务的稳定性和时效性，同时也带来较高的人力维护成本。</p>
<h3>2.4 实时与离线数据源不一致，存在冗余计算与口径偏差</h3>
<p>百度APP及其产品矩阵业务当前使用的实时计算链路和离线数据链路在核心指标上并未实现数据源统一，两条链路独立处理且并行存在。这导致相同指标需要在不同流程中重复计算，既造成资源浪费，也增加了数据口径对齐的难度。长期来看，此类架构问题会直接影响关键指标的一致性和可信度，对业务决策准确性构成潜在风险。</p>
<h3>2.5 存储无序增长，数据冗余和存储成本与日俱增</h3>
<p>随着业务规模的持续扩张和流量快速增长，支撑核心业务的明细数据宽表总量已达到百PB级别，存储与计算成本压力日益凸显。然而，不同业务域对数据的保留周期和使用频率存在显著差异，全部数据长期存储既不经济也无必要。</p>
<h2><strong>3. 解决方案</strong></h2>
<h3>3.1 ETL框架升级</h3>
<p>在完成由多张udw表到Turing表的优化工作完成后，数据处理的时效性与稳定性虽然取得了一定改善，但仍存在进一步提升的空间。具体而言，原有的C++ MR计算框架在任务运行过程中逐渐暴露出两类典型问题：一是容易发生计算长尾现象，个别任务实例处理缓慢，拖慢整个作业完成进度；二是基于单机调度的模式存在可靠性瓶颈，整体资源协调和任务容错能力有限。这些问题导致数据产出的延迟风险依然较高，难以完全满足业务对数据时效日益提升的要求。</p>
<p>为解决上述痛点，经过充分的技术调研与架构评估，我们决定将计算框架升级为TM+Spark的组合方案。其中，TM（Task Manager）作为厂内自研的高性能流式处理框架，在多个关键维度上显著优于原有的C++ MR架构。</p>
<p>TM（Task Manager）：更高的容错性和更强的稳定性</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-29892c55bf.jpg"></p>
<p>首先，在容错性方面，TM具备更为智能和敏捷的错误恢复机制。当某个计算实例发生故障或执行缓慢时，TM调度系统能够迅速感知并主动发起抢占操作，将当前Task动态迁移至新的实例继续处理，从而有效避免传统MR框架中由于个别长尾任务导致的整体作业延迟。这一机制极大提升了作业的稳健性和执行效率。</p>
<p>其次，在调度稳定性方面，TM基于Opera调度系统进行资源管理与任务分配，这一调度架构具有高度解耦和资源隔离的特点。每个任务实例独立运行，互不干扰，有效避免了在MR模式下由于同一队列中其他高负载或异常作业所带来的负面冲击，从而保障关键数据处理任务的稳定性和可预期性。</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-19d7ad2f0d.jpg"></p>
<p>此外，TM框架也在输出存储效率方面做出了重要升级。它原生支持输出Parquet列式存储格式，并集成ZSTD压缩算法，在减少存储空间占用的同时大幅提升了后续查询操作的I/O效率。这一改进使得数据在写入阶段就具备更优的列组织结构和压缩特性，为下游分析提供了高性能的数据基础。</p>
<p><strong><strong>主流开源框架Flink和TM的对比如下：</strong></strong></p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-b9aca2ae4f.png"></p>
<p><strong><strong>Spark：通过构建DAG，计算更高效；利用RDD或者DataFrame减少IO耗时；多线程机制，执行速度更快。</strong></strong></p>
<p><strong><strong>Spark对比MR的核心优势：</strong></strong></p>
<ul>
<li> <p>速度：基于内存计算，无需反复做读写操作，更加高效</p> </li>
<li> <p>高度集成：spark丰富的API和高级抽象的函数可以轻松实现复杂的逻辑计算和处理，无需和MR一般需要编写复杂的处理逻辑</p> </li>
<li> <p>计算模型：内置的RDD数据结构可以提高数据计算的容错性；查询优化和执行优化可以适应复杂数据的处理和查询</p> </li>
</ul>
<p>结合Spark通用计算引擎强大的分布式内存计算能力和丰富的生态组件，新框架不仅解决了之前C++ MR模式中的长尾与调度瓶颈，还进一步实现了处理链路的统一与优化。Spark的高扩展性和TM的流式稳健性相结合，共同构建出一个容错能力强、资源利用高效、运维负担低的新一代数据处理架构，为业务提供更低延迟、更高可靠性的数据服务。</p>
<h3>3.2 日志分类分级</h3>
<h4>3.2.1 埋点<strong><strong>上线不规范，被动兼容推高处理成本</strong></strong></h4>
<p>在当前百度APP及其产品矩阵业务高速发展的背景下，日均处理日志量已达3000亿PV的庞大规模，数据流的稳定、高效与成本可控变得至关重要。</p>
<p>原有的埋点分类和校验存在两个突出的问题：</p>
<ul>
<li> <p><strong>上报不规范</strong>：存在大量不经过日志中台统一校验而直接上线的业务打点，这些“非规范”打点格式各异、质量参差不齐，极易引发解析异常。</p> </li>
<li> <p><strong>处理成本高</strong>：下游的日志清洗ETL环节被迫陷入“被动兼容”的循环中，需要频繁地跟进制订适配规则以解析这些非标数据，不仅带来了极高的运维成本，更因计算资源的无效消耗而加剧了整体处理链路的负担，严重制约了数据产出的时效性与稳定性。</p> </li>
</ul>
<h4>3.2.2 <strong><strong>通过协同治理实现日志中台全流量覆盖</strong></strong></h4>
<p>为从根本上破解这一难题，我们基于对百度APP及其产品矩阵数据全链路的深入洞察，发起了一项跨体系的协同治理工程。联合了日志中台团队、各业务研发团队、QA质量保障团队及PMO项目管理团队，形成了强有力的专项工作组。</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-fdbd5629b9.jpg"></p>
<p>第一阶段的核心任务是对所有日志模块进行全域梳理。我们共同制定了统一的《新增业务模块接入日志中台规范》<strong><strong>与</strong></strong>《日志埋点规范》<strong><strong>，明确了从数据采集、上报到校验的完整标准流程，并强力推动百度APP及其产品矩阵（包括主客户端及相关创新业务）的全量需求空间、代码仓库及日志模块，完成向日志中台的标准化接入迁移。这一举措将日志中台的流量覆盖能力从治理前的约</strong></strong>80%<strong><strong>一举提升至</strong></strong>100%****，实现了<strong>全流量管控。</strong></p>
<p>更重要的是，我们在日志中台增强了多项主动校验能力：包括日志长度校验、关键公共参数完整性校验、以及精确到需求ID的粒度校验。这使得任何不合规的打点企图在测试和上线阶段就能被即时发现和拦截，实现了“问题早发现、早解决”的闭环管理，从而构筑起覆盖全场景的打点需求上线质量保障体系，从源头上杜绝了异常日志的产生。</p>
<h4>3.2.3 <strong><strong>打破“只上不下”僵局，建立埋点生命周期管理</strong></strong></h4>
<p>在成功建立起“入口”管控机制后，我们将治理重心转向对历史存量埋点的“出口”梳理与优化。长期以来，由于缺乏有效的评估手段，点位数据存在着“只增不减”的痼疾，大量废弃或无效点位持续消耗着巨额的计算和存储资源。为此，我们创新性地从鉴权信息入手，通过对十几类不同下游使用场景（包括内部报表、算法模型、RDC数据转发服务等）的全面调研与信息收集，并对相关日志解析链路进行深度分析，首次精准地绘制出以百度APP及其产品矩阵全量15000多个点位为起点的、覆盖所有下游应用场景的“点位全链路使用地图”。</p>
<p>基于这张价值地图，我们清晰地识别出超过10000个点位已无任何下游业务使用或价值极低。通过严格的评估与协作流程，我们果断对这些埋点进行了下线处理，下线比例高达存量点位的71%。此次大规模治理行动，不仅直接释放了海量的计算和存储资源，有效缓解了系统瓶颈，更打破了长达多年的“埋点只上不敢下”的历史僵局，建立了点位的全生命周期管理模式，为后续数据的精细化管理与成本优化奠定了坚实基础。</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-083cf2a3a5.jpg"></p>
<h3>3.3 AB实验数据扇出处理</h3>
<h4>3.3.1 现状与问题</h4>
<p>在数据驱动的业务迭代中，A/B实验平台的指标建设和效果评估能力至关重要。然而，随着业务快速扩张和实验复杂度的提升，原有的实验数仓架构逐渐显露出严重瓶颈。平台最初是在通用数仓分层模型的基础上，采用“每个指标单独计算”的模式进行建设。这种设计在初期虽然灵活，但随着实验数量和指标数量的急剧增长，计算链路变得异常复杂、冗余且难以维护。由于缺少与公司数据中台团队的深度协同和标准化约束，每次新增实验指标都需要大量重复开发，导致实验数据需求的交付周期不断延长，严重拖慢了业务迭代速度，引发了业务团队的负反馈。</p>
<h4>3.3.2 解决方案</h4>
<p><strong><strong>（1）分析过程</strong></strong></p>
<p>理想的解决方案是直接复用百度APP及其产品矩阵已有的标准化大宽表进行实验指标配置。即基于一张集成所有关键维度与指标的大宽表，快速定义和产出实验分析所需的数据集。然而，现实情况却更为复杂：百度APP及其产品矩阵客户端同时线上进行的实验数量极多，平均每个cuid（用户唯一标识）对应的实验ID（sid）字符长度已超过2400字符。这个长度几乎相当于单条日志原始存储容量的40%，如果直接将实验ID维度接入宽表，将导致每条日志存储膨胀近一倍。这不仅会带来极高的存储成本，也会大幅增加下游所有数据应用的数据扫描量和传输开销，严重拖慢查询性能，进而影响整个数据链路的效率。</p>
<p><strong><strong>（2）设计思路</strong></strong></p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-413cd36ad9.jpg"></p>
<p>面对这一独特挑战，我们并未选择传统的宽表集成方案，而是从数据生成的源头实施了更根本的架构优化。我们重点对实验ID映射关系进行了拆分和重构：<strong><strong>将sid与核心行为数据解耦，设计并建设了独立的sid维表</strong></strong>。该维表直接从日志源头统一生成，整合了来自客户端的实验曝光及分组信息，并实现了对业务方、评估方各自独立建设的多套映射关系的全面统一。这一举措不仅从本质上避免了主宽表的存储膨胀，还彻底解决了因数据来源不一致而导致的实验效果评估diff问题，显著提高了实验数据的准确性和可信度。</p>
<p><strong><strong>（3）成果与收益</strong></strong></p>
<p>在此基础上，A/B实验平台的分析查询不再依赖于对超大宽表的直接扫描，而是通过<strong><strong>sid维表与核心行为宽表进行动态拼接</strong></strong>的方式实现指标计算。</p>
<p>在指标口径对齐方面，已完成实验类指标与OKR指标的口径统一工作，累计对齐上线指标2000余个，覆盖多个主题和维度。实验指标改由数据中心宽表统一生产，显著减少了以往在指标口径沟通与对齐方面的成本；在实验效率提升显著，指标开发环节通过复用宽表及数仓下沉逻辑，并升级计算框架，使常规需求开发周期从原先2周以上缩短至1周内，开发效率提升超50%。同时核心指标计算SLA由T+14小时提升至T+10小时，处理时效明显提高；在计算资源成本方面，通过整体数据流复用和抽样日志整合优化，实现了计算资源成本的有效降低。另外，联动产品及策略团队治理并下线无效实验指标超1800+，释放的资源进一步支撑了新场景的指标建设需求。</p>
<h2><strong>4. 分级存储治理</strong></h2>
<p>随着业务规模的持续扩张与产品矩阵的不断丰富，百度APP及其产品矩阵业务的日志数据量呈现指数级增长，单张核心Turing数据表的存储量已达到百PB级别，面临巨大的存储与成本压力。传统的统一存储周期策略难以适应当前复杂的使用场景：一方面，大量短期数据被无效保留，占用巨额存储资源；另一方面，部分核心业务场景仍需依赖长周期历史数据进行跨年指标对比、关键数据需求回溯与深度建模分析。</p>
<p>为解决这一矛盾，我们针对Turing表启动了多维度的精细化存储治理工作。通过深入分析业务使用特征与数据访问频率，我们建立了差异化的数据生命周期管理机制，实施**“热-&gt;温-&gt;冷”**三级数据分层存储策略。对高频访问的近期数据全部保留，对访问频率较低的长期历史数据自动进行转储、压缩或者裁剪等，并配套建立完备的数据取回与回溯流程。</p>
<p>该项治理在充分保障核心业务长周期数据使用需求的前提下，显著压缩了整体存储规模，实现了存储成本的大幅优化，为未来数据的可持续增长与高效管理奠定了坚实基础。</p>
<p>具体实施策略：</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-9c87a2818c.png"></p>
<h1>03 总结与展望</h1>
<p>随着业务规模的持续扩张和产品矩阵的不断丰富，数据量呈现指数级增长，这一趋势持续驱动着数据处理架构与模型的演进与迭代，同时也对数据分析的敏捷性、易用性和可靠性提出了更高要求。在数仓系统全面升级的过程中，我们着力优化数据处理全链路，通过改进调度机制、减少计算环节、强化故障自动恢复能力，显著缩短了整个数据处理流程的时长，有效识别并排除多项潜在稳定性风险。此外，依托于对全端埋点体系的系统化梳理与标准化规范，构建了高质量、可复用的数据资产底座。</p>
<p>本次整体架构的升级为业务提供了坚实的数据支撑，在数据时效性、准确性和使用便捷性方面均实现显著提升。作为百度体系内最核心且数据规模最大的业务板块，百度APP仍面临数据持续激增带来的诸多挑战，包括埋点规范统一难度高、技术栈兼容与选型约束多、日志解析复杂度高、存储结构灵活多变以及成本控制压力增大等问题。</p>
<p>面向未来，我们将持续推进数仓架构的深度优化，重点围绕埋点治理、架构升级、效能提升、存储模型优化和资源精细化管理等方面展开工作。目标是构建一套具备更高时效性、更优数据模型、更低存储与计算成本的全新一代数仓链路，为业务创新与决策提供高效、可靠、低成本的数据服务能力。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<h1>导读</h1>
<p>面对百度APP日均数千亿PV、超百PB数据规模带来的巨大挑战，我们完成了数据仓库的系统性升级。本文详细阐述了通过"两步走"策略解决资源压力、处理延迟和架构瓶颈的全过程：第一阶段聚焦日志清洗环节的稳定性与成本优化，第二阶段实现实时离线链路解耦、核心数据隔离及计算框架容错能力提升。此次升级显著提升了数据处理时效性、系统稳定性和成本效益，为业务发展提供了更坚实的数据支撑。</p>
<h1>背景</h1>
<p>百度APP及其产品矩阵作为百度体量最大的C端业务线，在数据处理全链路面临规模与架构的双重挑战。日志清洗环节因日均几千亿PV、超百PB的庞大数据规模，导致计算资源持续承压、处理延迟频发，加之历史遗留的复杂日志格式，清洗稳定性与时效性逐步下降，存储成本高昂。与此同时上游日志数据仍存在实时与离线链路耦合、核心与边缘数据未有效隔离、计算框架容错能力不足等结构性问题，影响关键数据产出的稳定与时效。整体系统切换与优化面临高额的历史负担和技术重构成本，下游业务的数据可用性、决策及时性及深度运营分析均受到显著制约。</p>
<p>基于以上问题，我们制定了“两步走”的升级策略：第一阶段优先解决日志清洗环节的稳定性和存储成本问题；第二阶段在此基础上，重点推进数仓上层架构优化，包括实时与离线链路解耦、核心数据隔离处理以及计算框架容错能力提升，逐步实现整体数据仓库的高效、稳定与可持续升级。</p>
<h1>01 第一阶段：多日志源整合</h1>
<h2><strong>1. 2023年之前架构</strong></h2>
<p>在百度APP及其产品矩阵的数据体系建设过程中，日志清洗作为整个数据流水线的起始环节，其处理稳定性和产出时效性始终处于关键地位，是保障下游业务数据可用性与决策及时性的重中之重。然而，随着业务规模持续扩大和用户体量快速增长，每日产生的日志量急剧上升，由此带来的巨大计算压力使得整个清洗链路频繁面临资源瓶颈与处理延迟，稳定性和时效性均逐步下滑，难以满足下游各业务方对数据交付时间和质量的要求。与此同时，数据入口的分散催生了大量烟囱式的开发与冗余的计算逻辑，不仅推高了运维成本，更在源头形成了数据孤岛。下游基于此类数据构建的数仓架构必然复杂化，多表的 JOIN 与理解成本高昂，使得整个数据建设环节背负着日趋沉重的成本与协作压力。</p>
<h2><strong>2. 问题分析</strong></h2>
<h3>2.1 旧架构分析</h3>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-41f3e39809.jpg"></p>
<h4>2.1.1 <strong><strong>数据孤岛化加剧，认知与使用成本高昂</strong></strong></h4>
<p>现有架构对每类日志采用独立落表方式，导致数据存储呈现碎片化状态。这种设计造成同一业务实体的相关信息分散在不同表中，形成严重的数据割裂。下游用户在使用数据时，不得不通过多表关联才能获取完整信息，不仅大幅增加了技术实现难度，更带来了沉重的认知负担。用户需要理解多张表的结构和关联关系，极易产生理解偏差，进而影响数据分析的准确性和可靠性。</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-abbc8cbb5f.jpg"></p>
<h4>2.1.2 <strong><strong>关联查询性能瓶颈，制约数据价值释放</strong></strong></h4>
<p>与此同时，多表关联查询模式给系统带来了巨大的性能压力。随着数据量的持续增长，表连接操作的成本呈指数级上升，查询响应时间显著延长。特别是在需要跨多个表进行关联分析的场景下，系统往往需要耗费大量计算资源和时间，无法满足业务对高效数据分析和快速决策的需求，严重制约了数据价值的及时释放。</p>
<p>此外，原始日志结构中普遍存在的复杂嵌套格式（如多层JSON、数组结构等）大幅增加了数据清洗和解析的复杂度。大量业务自定义字段缺乏统一规范，导致解析逻辑冗余且低效，进一步降低了整体处理性能。这些因素共同加剧了数据处理的延迟与资源消耗，形成系统性瓶颈。</p>
<h4>2.1.3 <strong><strong>维护复杂度与脆弱性并存，系统稳定性堪忧</strong></strong></h4>
<p>独立的数据处理流水线，导致系统维护点分散。任何逻辑变更或schema调整都需要在多处同步实施，极大地增加了维护工作量。这种架构的脆弱性也显著提高了出错风险，单个任务修改的错误可能引发连锁反应，影响整个数据链路的稳定性。</p>
<p>特别需要指出的是，当前采用的UDW数仓及配套ETL框架仍是2012年上线的技术方案，已明显落后于业界主流水平。该框架存在诸多局限性：首先，其兼容性差，难以与现有开源生态工具链高效集成；其次，基于C++的MR计算框架稳定性不足，日常运行中容易出现各种异常；最后，开发调试效率低下，严重制约了数据需求的迭代速度。这些技术债务不仅增加了系统的维护复杂度，更成为制约数据平台发展的关键瓶颈。</p>
<h3>2.2 重构思路分析</h3>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-bc837c97b5.jpg"></p>
<p><strong>理想状态</strong>：从数据架构的理想设计来看，基于通用宽表数据建模方法论，采用“一步到位”的方式直接产出高度整合、面向主题的Turing宽表，是最为高效和优雅的解决方案。它能够减少中间冗余加工环节，提升数据一致性和复用度。</p>
<p><strong>升级成本</strong>：下游业务方因历史原因，数据应用架构高度依赖传统UDW模式的数据组织与服务方式，迁移至Turing宽表体系涉及大量脚本改造、逻辑核对与业务适配工作，技术切换和数据迁移成本极高，导致架构升级短期难以实施。</p>
<p><strong>思考</strong>：为实现数据架构的平滑升级，本次重构方案采用渐进式过渡策略，在着力解决现有架构核心痛点的同时，必须充分考虑百度业务数据链路长、历史包袱重的现实情况，审慎平衡技术先进性与落地可行性。方案设计严格遵循"平滑过渡、风险可控、成本最优"三大原则。</p>
<p>需要特别指出的是，由于现有数据体系深度嵌入各业务线的策略计算与离线分析环节，其紧密的耦合关系导致配套升级难度极大、周期长。这不仅涉及底层数据表的更替、依赖路径修改，更要求对依赖原有数据模型的下游业务进行协同改造和全面适配，沟通和推进难度极大。所以在保障业务连续性的前提下，如何有序推进全链路的升级切换是本次升级的重中之重。</p>
<p><strong><strong>建模思路：</strong></strong></p>
<p><strong><strong>（1）降低迁移成本</strong></strong></p>
<p>在数据中间层设计上，方案延续使用<strong><strong>刻钟级UDW</strong></strong>表作为缓冲层，通过将多个离散的UDW表整合为统一的宽表模型，进一步降低下游的使用和理解成本。同时，对表schema实施精细化改造，包括消除冗余字段、统一数据标准、优化存储格式，并重构字段逻辑以提升数据一致性。这种设计既保持了与现有下游系统的兼容性，又显著降低了数据使用复杂度。</p>
<p><strong><strong>（2）双轨输出机制</strong></strong></p>
<p>为确保迁移过程的平稳性，方案采用双轨输出机制：一方面继续提供优化后的UDW宽表，保障现有作业的无缝运行；另一方面通过聚合加工生成小时级Turing表，作为统一对外输出的日志宽表。这种渐进式迁移路径使下游用户可根据自身情况灵活选择切换时机，最大限度降低升级成本。</p>
<p><strong><strong>（3）兼顾历史和未来</strong></strong></p>
<p>此次架构优化为后续全面升级奠定了坚实基础。通过UDW层的预处理和Turing表的逐步推广，最终将实现架构的完全过渡，在提升系统性能的同时确保业务连续性，达成技术演进与业务稳定之间的最佳平衡。</p>
<h2><strong>3. 解决方案</strong></h2>
<p><strong><strong>过渡方案设计与实施：稳时效、降成本、提效率的综合治理</strong></strong></p>
<p>面对日志清洗环节日益严峻的稳定性、时效性及成本压力，我们制定并实施了一套详尽的过渡性解决方案。该方案并未激进地推行一步到位的Turing宽表迁移，而是立足于现有技术生态，以快速解决下游业务最迫切的痛点为目标，重点攻坚“产出时效不稳定”、“存储计算成本高”及“明细数据查询效率低下”三大核心问题。</p>
<h3>3.1 优化处理粒度与逻辑沉淀，保障时效与复用性</h3>
<p>为彻底扭转小时级任务积压与延迟的局面，我们首先对调度周期进行了粒度细化，将日志清洗任务从<strong><strong>小时级调度全面提升至刻钟级（15分钟）</strong></strong>。这一调整显著降低了单次任务的处理数据量和计算压力，使数据产出的延迟大幅减少，稳定性和时效性得到了根本保障。在技术选型上，我们并未盲目更换计算框架，而是继续沿用成熟稳定的<strong><strong>C++/MR框架</strong></strong>，确保了迁移过程的平稳性与可靠性。</p>
<p>同时，我们致力于提升数据的易用性与标准化程度。针对下游业务方需要反复从复杂JSON、Map等嵌套字段中解析提取关键信息的痛点，我们进行了大规模的<strong><strong>业务通用逻辑下沉</strong></strong>工作。将超过100个高频访问的埋点属性进行预解析、扁平化处理，转化为单独的标准化字段。这不仅极大减轻了下游的数据预处理负担，更直接提升了基于这些字段的<strong><strong>查询过滤与聚合分析效率</strong></strong>，为下游开发节省了大量时间。</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-3ad183e1e7.jpg"></p>
<h3>3.2 <strong><strong>兼顾历史依赖与未来演进，提供平滑迁移路径</strong></strong></h3>
<p>我们充分认识到下游业务对原有UDW数仓体系的强依赖性。为保障业务的连续性，我们并未强制要求所有方立即迁移，而是采取了<strong><strong>双轨并行</strong></strong>的支撑策略。在产出新一代数据模型的同时，我们<strong><strong>继续提供UDW中间表</strong></strong>，确保那些尚未准备好迁移至Turing宽表的业务方能够无缝对接，无需修改现有代码，极大降低了方案的落地门槛和风险。</p>
<h3>3.3 深度优化存储与查询，实现性能跨越式提升</h3>
<p>为进一步降低存储成本并提升Turing宽表的查询性能，我们对其存储结构进行了深度优化。</p>
<ul>
<li><strong><strong>合并小文件与高效压缩</strong></strong>：海量小文件是制约查询性能的首要元凶。我们通过按<strong><strong>设备ID、点位ID、时间戳</strong></strong>等关键字段进行精细排序，将数据写入为连续有序的大文件，从而将<strong><strong>单天高达800万个小文件合并至60万左右</strong></strong>，文件数量减少了近<strong><strong>93%</strong></strong>。在存储格式上，我们选用Parquet列式存储，并经过充分调研测试，采用了<strong><strong>ZSTD压缩算法</strong></strong>。ZSTD在压缩比、压缩/解压速度上取得了最佳平衡，且完美支持多线程，最终实现了每天<strong><strong>节省超过420TB</strong></strong>的巨大存储开销，成本效益极其显著。</li>
</ul>
<h2><strong>4. 新的问题&amp;解决策略</strong></h2>
<p>问题1：宽表数据量膨胀导致的查询性能下降</p>
<p>解决策略：为应对宽表数据量激增对查询性能带来的挑战，我们实施了体系化的查询加速方案，显著提升海量数据下的检索效率</p>
<ul>
<li> <p><strong><strong>强制分区限制策略</strong></strong>：在查询引擎层上线了强制要求限制分区条件的规则，避免了全表扫描带来的巨额元数据开销，大幅提升元数据检索效率。</p> </li>
<li> <p><strong><strong>查询结果缓存</strong></strong>：对常见的热点查询结果进行缓存，对于重复性查询实现了秒级响应。</p> </li>
<li> <p><strong><strong>智能资源调度</strong></strong>：根据查询的计算复杂度，系统自动将其调度到不同配置的资源池中执行，简单查询快速返回，复杂查询获得充足资源，实现了集群资源的高效利用。</p> </li>
</ul>
<p>问题2：分区数量增多导致点位所在的分区变得困难</p>
<p>解决策略：针对分区维度增加后，数据定位难度加大的问题，我们通过元数据管理与平台化集成提供解决方案：</p>
<ul>
<li> <p>新建分区元数据集，以天为粒度预先计算并存储所有点位与分区的映射关系，形成高效的点位分区定位查询，为点位所在分区快速检索提供基础支撑。</p> </li>
<li> <p>与现有点位管理平台深度集成，在其点位查询界面新增【查一查】功能。用户可通过界面化操作直接获取精准的数据分区信息及查询SQL模板，极大提升了用户使用的效率，降低了用户使用成本。</p> </li>
</ul>
<h1>02 第二阶段：全面提速</h1>
<h2><strong>1. 2023→2024年架构</strong></h2>
<p>随着业务发展，该数仓已完成由UDW（统一数据工作台）向Turing（新数据工作台）的改造，并初步建立起体系化的数据模型与分层数据集，显著提升了数据复用性和分析效率。基于这些宽表与数据集，大部分常规分析场景已能够快速响应。然而，在数据加工的最上游，即明细数据宽表的生产环节之前依旧包含缓冲的刻钟级udw表，因此仍存在若干架构性瓶颈。首先，实时数据处理链路与离线批处理链路相互耦合，资源竞争与依赖关系复杂，影响了整体任务的稳定性和时效性；其次，核心业务指标与非核心附属数据未被有效拆分处理，导致关键数据产出易受边缘数据波动或延迟的干扰；此外，当前的计算框架对于数据迟到、重复、异常值等复杂情况的处理灵活度不足，容错与自适应能力有待加强。</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-14db3809be.jpg"></p>
<p>为彻底解决这些问题，进一步提升数据产出的时效性、准确性和稳定性，以更好地赋能百度APP及其产品矩阵及各下游业务的数据分析与决策，亟需结合各数据点位的实际使用情况和业务优先级，对最上游的日志ETL（抽取、转换、加载）处理流程进行系统性的优化与重构。</p>
<h2><strong>2. 问题分析</strong></h2>
<p>当前数据ETL处理流程面临以下几个核心挑战，这些问题不仅影响数据产出的效率与稳定性，也为下游业务数据的准确性和及时性带来风险。</p>
<h3>2.1 开发框架灵活性不足，资源协调与弹性扩展能力受限</h3>
<p>目前的ETL任务仍沿用原有UDW大表处理框架，通过单机Hadoop Client提交任务，并依赖QE（底层为mapreduce引擎）进行计算。该框架在资源调度和权限管理方面已逐渐暴露出瓶颈。同时udw是2012年提出的数仓建设方案，随着开源计算、存储技术的发展，udw性能逐步落后业界，部分功能不具备继续升级迭代可行性。一旦出现上游数据延迟、队列资源拥塞或系统异常，容易导致任务大规模积压。由于缺乏跨队列或跨资源的调度容灾能力，无法协调其他计算资源执行任务回溯与补偿，最终将直接影响整体数据产出时效，甚至波及下游多条业务线的核心数据应用。</p>
<h3>2.2 核心与非核心数据处理耦合，异常影响范围扩散</h3>
<p>在日志清洗ETL环节中，核心业务数据点位与非核心业务数据点位、以及实时与离线数据流目前尚未进行有效拆分处理。这种架构层面的耦合导致一旦上游数据源或计算过程中发生异常，其影响面会迅速扩大，不仅关键业务指标受到冲击，非核心业务数据的问题也可能反向干扰核心链路的稳定性。缺乏业务优先级识别和隔离机制，降低了计算链路的整体容错能力和故障隔离水平。</p>
<h3>2.3 计算链路冗长复杂，维护困难且稳定性面临挑战</h3>
<p>当前处理流程中包含UDW中间缓冲层，导致计算环节增多、链路层级深化。较长的依赖链不仅增加了数据产出的端到端延迟，也显著提高了运维监控和故障定位的复杂度。任何环节出现性能波动或失败都易引起连锁反应，威胁整体任务的稳定性和时效性，同时也带来较高的人力维护成本。</p>
<h3>2.4 实时与离线数据源不一致，存在冗余计算与口径偏差</h3>
<p>百度APP及其产品矩阵业务当前使用的实时计算链路和离线数据链路在核心指标上并未实现数据源统一，两条链路独立处理且并行存在。这导致相同指标需要在不同流程中重复计算，既造成资源浪费，也增加了数据口径对齐的难度。长期来看，此类架构问题会直接影响关键指标的一致性和可信度，对业务决策准确性构成潜在风险。</p>
<h3>2.5 存储无序增长，数据冗余和存储成本与日俱增</h3>
<p>随着业务规模的持续扩张和流量快速增长，支撑核心业务的明细数据宽表总量已达到百PB级别，存储与计算成本压力日益凸显。然而，不同业务域对数据的保留周期和使用频率存在显著差异，全部数据长期存储既不经济也无必要。</p>
<h2><strong>3. 解决方案</strong></h2>
<h3>3.1 ETL框架升级</h3>
<p>在完成由多张udw表到Turing表的优化工作完成后，数据处理的时效性与稳定性虽然取得了一定改善，但仍存在进一步提升的空间。具体而言，原有的C++ MR计算框架在任务运行过程中逐渐暴露出两类典型问题：一是容易发生计算长尾现象，个别任务实例处理缓慢，拖慢整个作业完成进度；二是基于单机调度的模式存在可靠性瓶颈，整体资源协调和任务容错能力有限。这些问题导致数据产出的延迟风险依然较高，难以完全满足业务对数据时效日益提升的要求。</p>
<p>为解决上述痛点，经过充分的技术调研与架构评估，我们决定将计算框架升级为TM+Spark的组合方案。其中，TM（Task Manager）作为厂内自研的高性能流式处理框架，在多个关键维度上显著优于原有的C++ MR架构。</p>
<p>TM（Task Manager）：更高的容错性和更强的稳定性</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-29892c55bf.jpg"></p>
<p>首先，在容错性方面，TM具备更为智能和敏捷的错误恢复机制。当某个计算实例发生故障或执行缓慢时，TM调度系统能够迅速感知并主动发起抢占操作，将当前Task动态迁移至新的实例继续处理，从而有效避免传统MR框架中由于个别长尾任务导致的整体作业延迟。这一机制极大提升了作业的稳健性和执行效率。</p>
<p>其次，在调度稳定性方面，TM基于Opera调度系统进行资源管理与任务分配，这一调度架构具有高度解耦和资源隔离的特点。每个任务实例独立运行，互不干扰，有效避免了在MR模式下由于同一队列中其他高负载或异常作业所带来的负面冲击，从而保障关键数据处理任务的稳定性和可预期性。</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-19d7ad2f0d.jpg"></p>
<p>此外，TM框架也在输出存储效率方面做出了重要升级。它原生支持输出Parquet列式存储格式，并集成ZSTD压缩算法，在减少存储空间占用的同时大幅提升了后续查询操作的I/O效率。这一改进使得数据在写入阶段就具备更优的列组织结构和压缩特性，为下游分析提供了高性能的数据基础。</p>
<p><strong><strong>主流开源框架Flink和TM的对比如下：</strong></strong></p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-b9aca2ae4f.png"></p>
<p><strong><strong>Spark：通过构建DAG，计算更高效；利用RDD或者DataFrame减少IO耗时；多线程机制，执行速度更快。</strong></strong></p>
<p><strong><strong>Spark对比MR的核心优势：</strong></strong></p>
<ul>
<li> <p>速度：基于内存计算，无需反复做读写操作，更加高效</p> </li>
<li> <p>高度集成：spark丰富的API和高级抽象的函数可以轻松实现复杂的逻辑计算和处理，无需和MR一般需要编写复杂的处理逻辑</p> </li>
<li> <p>计算模型：内置的RDD数据结构可以提高数据计算的容错性；查询优化和执行优化可以适应复杂数据的处理和查询</p> </li>
</ul>
<p>结合Spark通用计算引擎强大的分布式内存计算能力和丰富的生态组件，新框架不仅解决了之前C++ MR模式中的长尾与调度瓶颈，还进一步实现了处理链路的统一与优化。Spark的高扩展性和TM的流式稳健性相结合，共同构建出一个容错能力强、资源利用高效、运维负担低的新一代数据处理架构，为业务提供更低延迟、更高可靠性的数据服务。</p>
<h3>3.2 日志分类分级</h3>
<h4>3.2.1 埋点<strong><strong>上线不规范，被动兼容推高处理成本</strong></strong></h4>
<p>在当前百度APP及其产品矩阵业务高速发展的背景下，日均处理日志量已达3000亿PV的庞大规模，数据流的稳定、高效与成本可控变得至关重要。</p>
<p>原有的埋点分类和校验存在两个突出的问题：</p>
<ul>
<li> <p><strong>上报不规范</strong>：存在大量不经过日志中台统一校验而直接上线的业务打点，这些“非规范”打点格式各异、质量参差不齐，极易引发解析异常。</p> </li>
<li> <p><strong>处理成本高</strong>：下游的日志清洗ETL环节被迫陷入“被动兼容”的循环中，需要频繁地跟进制订适配规则以解析这些非标数据，不仅带来了极高的运维成本，更因计算资源的无效消耗而加剧了整体处理链路的负担，严重制约了数据产出的时效性与稳定性。</p> </li>
</ul>
<h4>3.2.2 <strong><strong>通过协同治理实现日志中台全流量覆盖</strong></strong></h4>
<p>为从根本上破解这一难题，我们基于对百度APP及其产品矩阵数据全链路的深入洞察，发起了一项跨体系的协同治理工程。联合了日志中台团队、各业务研发团队、QA质量保障团队及PMO项目管理团队，形成了强有力的专项工作组。</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-fdbd5629b9.jpg"></p>
<p>第一阶段的核心任务是对所有日志模块进行全域梳理。我们共同制定了统一的《新增业务模块接入日志中台规范》<strong><strong>与</strong></strong>《日志埋点规范》<strong><strong>，明确了从数据采集、上报到校验的完整标准流程，并强力推动百度APP及其产品矩阵（包括主客户端及相关创新业务）的全量需求空间、代码仓库及日志模块，完成向日志中台的标准化接入迁移。这一举措将日志中台的流量覆盖能力从治理前的约</strong></strong>80%<strong><strong>一举提升至</strong></strong>100%****，实现了<strong>全流量管控。</strong></p>
<p>更重要的是，我们在日志中台增强了多项主动校验能力：包括日志长度校验、关键公共参数完整性校验、以及精确到需求ID的粒度校验。这使得任何不合规的打点企图在测试和上线阶段就能被即时发现和拦截，实现了“问题早发现、早解决”的闭环管理，从而构筑起覆盖全场景的打点需求上线质量保障体系，从源头上杜绝了异常日志的产生。</p>
<h4>3.2.3 <strong><strong>打破“只上不下”僵局，建立埋点生命周期管理</strong></strong></h4>
<p>在成功建立起“入口”管控机制后，我们将治理重心转向对历史存量埋点的“出口”梳理与优化。长期以来，由于缺乏有效的评估手段，点位数据存在着“只增不减”的痼疾，大量废弃或无效点位持续消耗着巨额的计算和存储资源。为此，我们创新性地从鉴权信息入手，通过对十几类不同下游使用场景（包括内部报表、算法模型、RDC数据转发服务等）的全面调研与信息收集，并对相关日志解析链路进行深度分析，首次精准地绘制出以百度APP及其产品矩阵全量15000多个点位为起点的、覆盖所有下游应用场景的“点位全链路使用地图”。</p>
<p>基于这张价值地图，我们清晰地识别出超过10000个点位已无任何下游业务使用或价值极低。通过严格的评估与协作流程，我们果断对这些埋点进行了下线处理，下线比例高达存量点位的71%。此次大规模治理行动，不仅直接释放了海量的计算和存储资源，有效缓解了系统瓶颈，更打破了长达多年的“埋点只上不敢下”的历史僵局，建立了点位的全生命周期管理模式，为后续数据的精细化管理与成本优化奠定了坚实基础。</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-083cf2a3a5.jpg"></p>
<h3>3.3 AB实验数据扇出处理</h3>
<h4>3.3.1 现状与问题</h4>
<p>在数据驱动的业务迭代中，A/B实验平台的指标建设和效果评估能力至关重要。然而，随着业务快速扩张和实验复杂度的提升，原有的实验数仓架构逐渐显露出严重瓶颈。平台最初是在通用数仓分层模型的基础上，采用“每个指标单独计算”的模式进行建设。这种设计在初期虽然灵活，但随着实验数量和指标数量的急剧增长，计算链路变得异常复杂、冗余且难以维护。由于缺少与公司数据中台团队的深度协同和标准化约束，每次新增实验指标都需要大量重复开发，导致实验数据需求的交付周期不断延长，严重拖慢了业务迭代速度，引发了业务团队的负反馈。</p>
<h4>3.3.2 解决方案</h4>
<p><strong><strong>（1）分析过程</strong></strong></p>
<p>理想的解决方案是直接复用百度APP及其产品矩阵已有的标准化大宽表进行实验指标配置。即基于一张集成所有关键维度与指标的大宽表，快速定义和产出实验分析所需的数据集。然而，现实情况却更为复杂：百度APP及其产品矩阵客户端同时线上进行的实验数量极多，平均每个cuid（用户唯一标识）对应的实验ID（sid）字符长度已超过2400字符。这个长度几乎相当于单条日志原始存储容量的40%，如果直接将实验ID维度接入宽表，将导致每条日志存储膨胀近一倍。这不仅会带来极高的存储成本，也会大幅增加下游所有数据应用的数据扫描量和传输开销，严重拖慢查询性能，进而影响整个数据链路的效率。</p>
<p><strong><strong>（2）设计思路</strong></strong></p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-413cd36ad9.jpg"></p>
<p>面对这一独特挑战，我们并未选择传统的宽表集成方案，而是从数据生成的源头实施了更根本的架构优化。我们重点对实验ID映射关系进行了拆分和重构：<strong><strong>将sid与核心行为数据解耦，设计并建设了独立的sid维表</strong></strong>。该维表直接从日志源头统一生成，整合了来自客户端的实验曝光及分组信息，并实现了对业务方、评估方各自独立建设的多套映射关系的全面统一。这一举措不仅从本质上避免了主宽表的存储膨胀，还彻底解决了因数据来源不一致而导致的实验效果评估diff问题，显著提高了实验数据的准确性和可信度。</p>
<p><strong><strong>（3）成果与收益</strong></strong></p>
<p>在此基础上，A/B实验平台的分析查询不再依赖于对超大宽表的直接扫描，而是通过<strong><strong>sid维表与核心行为宽表进行动态拼接</strong></strong>的方式实现指标计算。</p>
<p>在指标口径对齐方面，已完成实验类指标与OKR指标的口径统一工作，累计对齐上线指标2000余个，覆盖多个主题和维度。实验指标改由数据中心宽表统一生产，显著减少了以往在指标口径沟通与对齐方面的成本；在实验效率提升显著，指标开发环节通过复用宽表及数仓下沉逻辑，并升级计算框架，使常规需求开发周期从原先2周以上缩短至1周内，开发效率提升超50%。同时核心指标计算SLA由T+14小时提升至T+10小时，处理时效明显提高；在计算资源成本方面，通过整体数据流复用和抽样日志整合优化，实现了计算资源成本的有效降低。另外，联动产品及策略团队治理并下线无效实验指标超1800+，释放的资源进一步支撑了新场景的指标建设需求。</p>
<h2><strong>4. 分级存储治理</strong></h2>
<p>随着业务规模的持续扩张与产品矩阵的不断丰富，百度APP及其产品矩阵业务的日志数据量呈现指数级增长，单张核心Turing数据表的存储量已达到百PB级别，面临巨大的存储与成本压力。传统的统一存储周期策略难以适应当前复杂的使用场景：一方面，大量短期数据被无效保留，占用巨额存储资源；另一方面，部分核心业务场景仍需依赖长周期历史数据进行跨年指标对比、关键数据需求回溯与深度建模分析。</p>
<p>为解决这一矛盾，我们针对Turing表启动了多维度的精细化存储治理工作。通过深入分析业务使用特征与数据访问频率，我们建立了差异化的数据生命周期管理机制，实施**“热-&gt;温-&gt;冷”**三级数据分层存储策略。对高频访问的近期数据全部保留，对访问频率较低的长期历史数据自动进行转储、压缩或者裁剪等，并配套建立完备的数据取回与回溯流程。</p>
<p>该项治理在充分保障核心业务长周期数据使用需求的前提下，显著压缩了整体存储规模，实现了存储成本的大幅优化，为未来数据的可持续增长与高效管理奠定了坚实基础。</p>
<p>具体实施策略：</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-9c87a2818c.png"></p>
<h1>03 总结与展望</h1>
<p>随着业务规模的持续扩张和产品矩阵的不断丰富，数据量呈现指数级增长，这一趋势持续驱动着数据处理架构与模型的演进与迭代，同时也对数据分析的敏捷性、易用性和可靠性提出了更高要求。在数仓系统全面升级的过程中，我们着力优化数据处理全链路，通过改进调度机制、减少计算环节、强化故障自动恢复能力，显著缩短了整个数据处理流程的时长，有效识别并排除多项潜在稳定性风险。此外，依托于对全端埋点体系的系统化梳理与标准化规范，构建了高质量、可复用的数据资产底座。</p>
<p>本次整体架构的升级为业务提供了坚实的数据支撑，在数据时效性、准确性和使用便捷性方面均实现显著提升。作为百度体系内最核心且数据规模最大的业务板块，百度APP仍面临数据持续激增带来的诸多挑战，包括埋点规范统一难度高、技术栈兼容与选型约束多、日志解析复杂度高、存储结构灵活多变以及成本控制压力增大等问题。</p>
<p>面向未来，我们将持续推进数仓架构的深度优化，重点围绕埋点治理、架构升级、效能提升、存储模型优化和资源精细化管理等方面展开工作。目标是构建一套具备更高时效性、更优数据模型、更低存储与计算成本的全新一代数仓链路，为业务创新与决策提供高效、可靠、低成本的数据服务能力。</p>]]>
    </description>
    <content:encoded><![CDATA[<h1>导读</h1>
<p>面对百度APP日均数千亿PV、超百PB数据规模带来的巨大挑战，我们完成了数据仓库的系统性升级。本文详细阐述了通过"两步走"策略解决资源压力、处理延迟和架构瓶颈的全过程：第一阶段聚焦日志清洗环节的稳定性与成本优化，第二阶段实现实时离线链路解耦、核心数据隔离及计算框架容错能力提升。此次升级显著提升了数据处理时效性、系统稳定性和成本效益，为业务发展提供了更坚实的数据支撑。</p>
<h1>背景</h1>
<p>百度APP及其产品矩阵作为百度体量最大的C端业务线，在数据处理全链路面临规模与架构的双重挑战。日志清洗环节因日均几千亿PV、超百PB的庞大数据规模，导致计算资源持续承压、处理延迟频发，加之历史遗留的复杂日志格式，清洗稳定性与时效性逐步下降，存储成本高昂。与此同时上游日志数据仍存在实时与离线链路耦合、核心与边缘数据未有效隔离、计算框架容错能力不足等结构性问题，影响关键数据产出的稳定与时效。整体系统切换与优化面临高额的历史负担和技术重构成本，下游业务的数据可用性、决策及时性及深度运营分析均受到显著制约。</p>
<p>基于以上问题，我们制定了“两步走”的升级策略：第一阶段优先解决日志清洗环节的稳定性和存储成本问题；第二阶段在此基础上，重点推进数仓上层架构优化，包括实时与离线链路解耦、核心数据隔离处理以及计算框架容错能力提升，逐步实现整体数据仓库的高效、稳定与可持续升级。</p>
<h1>01 第一阶段：多日志源整合</h1>
<h2><strong>1. 2023年之前架构</strong></h2>
<p>在百度APP及其产品矩阵的数据体系建设过程中，日志清洗作为整个数据流水线的起始环节，其处理稳定性和产出时效性始终处于关键地位，是保障下游业务数据可用性与决策及时性的重中之重。然而，随着业务规模持续扩大和用户体量快速增长，每日产生的日志量急剧上升，由此带来的巨大计算压力使得整个清洗链路频繁面临资源瓶颈与处理延迟，稳定性和时效性均逐步下滑，难以满足下游各业务方对数据交付时间和质量的要求。与此同时，数据入口的分散催生了大量烟囱式的开发与冗余的计算逻辑，不仅推高了运维成本，更在源头形成了数据孤岛。下游基于此类数据构建的数仓架构必然复杂化，多表的 JOIN 与理解成本高昂，使得整个数据建设环节背负着日趋沉重的成本与协作压力。</p>
<h2><strong>2. 问题分析</strong></h2>
<h3>2.1 旧架构分析</h3>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-41f3e39809.jpg"></p>
<h4>2.1.1 <strong><strong>数据孤岛化加剧，认知与使用成本高昂</strong></strong></h4>
<p>现有架构对每类日志采用独立落表方式，导致数据存储呈现碎片化状态。这种设计造成同一业务实体的相关信息分散在不同表中，形成严重的数据割裂。下游用户在使用数据时，不得不通过多表关联才能获取完整信息，不仅大幅增加了技术实现难度，更带来了沉重的认知负担。用户需要理解多张表的结构和关联关系，极易产生理解偏差，进而影响数据分析的准确性和可靠性。</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-abbc8cbb5f.jpg"></p>
<h4>2.1.2 <strong><strong>关联查询性能瓶颈，制约数据价值释放</strong></strong></h4>
<p>与此同时，多表关联查询模式给系统带来了巨大的性能压力。随着数据量的持续增长，表连接操作的成本呈指数级上升，查询响应时间显著延长。特别是在需要跨多个表进行关联分析的场景下，系统往往需要耗费大量计算资源和时间，无法满足业务对高效数据分析和快速决策的需求，严重制约了数据价值的及时释放。</p>
<p>此外，原始日志结构中普遍存在的复杂嵌套格式（如多层JSON、数组结构等）大幅增加了数据清洗和解析的复杂度。大量业务自定义字段缺乏统一规范，导致解析逻辑冗余且低效，进一步降低了整体处理性能。这些因素共同加剧了数据处理的延迟与资源消耗，形成系统性瓶颈。</p>
<h4>2.1.3 <strong><strong>维护复杂度与脆弱性并存，系统稳定性堪忧</strong></strong></h4>
<p>独立的数据处理流水线，导致系统维护点分散。任何逻辑变更或schema调整都需要在多处同步实施，极大地增加了维护工作量。这种架构的脆弱性也显著提高了出错风险，单个任务修改的错误可能引发连锁反应，影响整个数据链路的稳定性。</p>
<p>特别需要指出的是，当前采用的UDW数仓及配套ETL框架仍是2012年上线的技术方案，已明显落后于业界主流水平。该框架存在诸多局限性：首先，其兼容性差，难以与现有开源生态工具链高效集成；其次，基于C++的MR计算框架稳定性不足，日常运行中容易出现各种异常；最后，开发调试效率低下，严重制约了数据需求的迭代速度。这些技术债务不仅增加了系统的维护复杂度，更成为制约数据平台发展的关键瓶颈。</p>
<h3>2.2 重构思路分析</h3>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-bc837c97b5.jpg"></p>
<p><strong>理想状态</strong>：从数据架构的理想设计来看，基于通用宽表数据建模方法论，采用“一步到位”的方式直接产出高度整合、面向主题的Turing宽表，是最为高效和优雅的解决方案。它能够减少中间冗余加工环节，提升数据一致性和复用度。</p>
<p><strong>升级成本</strong>：下游业务方因历史原因，数据应用架构高度依赖传统UDW模式的数据组织与服务方式，迁移至Turing宽表体系涉及大量脚本改造、逻辑核对与业务适配工作，技术切换和数据迁移成本极高，导致架构升级短期难以实施。</p>
<p><strong>思考</strong>：为实现数据架构的平滑升级，本次重构方案采用渐进式过渡策略，在着力解决现有架构核心痛点的同时，必须充分考虑百度业务数据链路长、历史包袱重的现实情况，审慎平衡技术先进性与落地可行性。方案设计严格遵循"平滑过渡、风险可控、成本最优"三大原则。</p>
<p>需要特别指出的是，由于现有数据体系深度嵌入各业务线的策略计算与离线分析环节，其紧密的耦合关系导致配套升级难度极大、周期长。这不仅涉及底层数据表的更替、依赖路径修改，更要求对依赖原有数据模型的下游业务进行协同改造和全面适配，沟通和推进难度极大。所以在保障业务连续性的前提下，如何有序推进全链路的升级切换是本次升级的重中之重。</p>
<p><strong><strong>建模思路：</strong></strong></p>
<p><strong><strong>（1）降低迁移成本</strong></strong></p>
<p>在数据中间层设计上，方案延续使用<strong><strong>刻钟级UDW</strong></strong>表作为缓冲层，通过将多个离散的UDW表整合为统一的宽表模型，进一步降低下游的使用和理解成本。同时，对表schema实施精细化改造，包括消除冗余字段、统一数据标准、优化存储格式，并重构字段逻辑以提升数据一致性。这种设计既保持了与现有下游系统的兼容性，又显著降低了数据使用复杂度。</p>
<p><strong><strong>（2）双轨输出机制</strong></strong></p>
<p>为确保迁移过程的平稳性，方案采用双轨输出机制：一方面继续提供优化后的UDW宽表，保障现有作业的无缝运行；另一方面通过聚合加工生成小时级Turing表，作为统一对外输出的日志宽表。这种渐进式迁移路径使下游用户可根据自身情况灵活选择切换时机，最大限度降低升级成本。</p>
<p><strong><strong>（3）兼顾历史和未来</strong></strong></p>
<p>此次架构优化为后续全面升级奠定了坚实基础。通过UDW层的预处理和Turing表的逐步推广，最终将实现架构的完全过渡，在提升系统性能的同时确保业务连续性，达成技术演进与业务稳定之间的最佳平衡。</p>
<h2><strong>3. 解决方案</strong></h2>
<p><strong><strong>过渡方案设计与实施：稳时效、降成本、提效率的综合治理</strong></strong></p>
<p>面对日志清洗环节日益严峻的稳定性、时效性及成本压力，我们制定并实施了一套详尽的过渡性解决方案。该方案并未激进地推行一步到位的Turing宽表迁移，而是立足于现有技术生态，以快速解决下游业务最迫切的痛点为目标，重点攻坚“产出时效不稳定”、“存储计算成本高”及“明细数据查询效率低下”三大核心问题。</p>
<h3>3.1 优化处理粒度与逻辑沉淀，保障时效与复用性</h3>
<p>为彻底扭转小时级任务积压与延迟的局面，我们首先对调度周期进行了粒度细化，将日志清洗任务从<strong><strong>小时级调度全面提升至刻钟级（15分钟）</strong></strong>。这一调整显著降低了单次任务的处理数据量和计算压力，使数据产出的延迟大幅减少，稳定性和时效性得到了根本保障。在技术选型上，我们并未盲目更换计算框架，而是继续沿用成熟稳定的<strong><strong>C++/MR框架</strong></strong>，确保了迁移过程的平稳性与可靠性。</p>
<p>同时，我们致力于提升数据的易用性与标准化程度。针对下游业务方需要反复从复杂JSON、Map等嵌套字段中解析提取关键信息的痛点，我们进行了大规模的<strong><strong>业务通用逻辑下沉</strong></strong>工作。将超过100个高频访问的埋点属性进行预解析、扁平化处理，转化为单独的标准化字段。这不仅极大减轻了下游的数据预处理负担，更直接提升了基于这些字段的<strong><strong>查询过滤与聚合分析效率</strong></strong>，为下游开发节省了大量时间。</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-3ad183e1e7.jpg"></p>
<h3>3.2 <strong><strong>兼顾历史依赖与未来演进，提供平滑迁移路径</strong></strong></h3>
<p>我们充分认识到下游业务对原有UDW数仓体系的强依赖性。为保障业务的连续性，我们并未强制要求所有方立即迁移，而是采取了<strong><strong>双轨并行</strong></strong>的支撑策略。在产出新一代数据模型的同时，我们<strong><strong>继续提供UDW中间表</strong></strong>，确保那些尚未准备好迁移至Turing宽表的业务方能够无缝对接，无需修改现有代码，极大降低了方案的落地门槛和风险。</p>
<h3>3.3 深度优化存储与查询，实现性能跨越式提升</h3>
<p>为进一步降低存储成本并提升Turing宽表的查询性能，我们对其存储结构进行了深度优化。</p>
<ul>
<li><strong><strong>合并小文件与高效压缩</strong></strong>：海量小文件是制约查询性能的首要元凶。我们通过按<strong><strong>设备ID、点位ID、时间戳</strong></strong>等关键字段进行精细排序，将数据写入为连续有序的大文件，从而将<strong><strong>单天高达800万个小文件合并至60万左右</strong></strong>，文件数量减少了近<strong><strong>93%</strong></strong>。在存储格式上，我们选用Parquet列式存储，并经过充分调研测试，采用了<strong><strong>ZSTD压缩算法</strong></strong>。ZSTD在压缩比、压缩/解压速度上取得了最佳平衡，且完美支持多线程，最终实现了每天<strong><strong>节省超过420TB</strong></strong>的巨大存储开销，成本效益极其显著。</li>
</ul>
<h2><strong>4. 新的问题&amp;解决策略</strong></h2>
<p>问题1：宽表数据量膨胀导致的查询性能下降</p>
<p>解决策略：为应对宽表数据量激增对查询性能带来的挑战，我们实施了体系化的查询加速方案，显著提升海量数据下的检索效率</p>
<ul>
<li> <p><strong><strong>强制分区限制策略</strong></strong>：在查询引擎层上线了强制要求限制分区条件的规则，避免了全表扫描带来的巨额元数据开销，大幅提升元数据检索效率。</p> </li>
<li> <p><strong><strong>查询结果缓存</strong></strong>：对常见的热点查询结果进行缓存，对于重复性查询实现了秒级响应。</p> </li>
<li> <p><strong><strong>智能资源调度</strong></strong>：根据查询的计算复杂度，系统自动将其调度到不同配置的资源池中执行，简单查询快速返回，复杂查询获得充足资源，实现了集群资源的高效利用。</p> </li>
</ul>
<p>问题2：分区数量增多导致点位所在的分区变得困难</p>
<p>解决策略：针对分区维度增加后，数据定位难度加大的问题，我们通过元数据管理与平台化集成提供解决方案：</p>
<ul>
<li> <p>新建分区元数据集，以天为粒度预先计算并存储所有点位与分区的映射关系，形成高效的点位分区定位查询，为点位所在分区快速检索提供基础支撑。</p> </li>
<li> <p>与现有点位管理平台深度集成，在其点位查询界面新增【查一查】功能。用户可通过界面化操作直接获取精准的数据分区信息及查询SQL模板，极大提升了用户使用的效率，降低了用户使用成本。</p> </li>
</ul>
<h1>02 第二阶段：全面提速</h1>
<h2><strong>1. 2023→2024年架构</strong></h2>
<p>随着业务发展，该数仓已完成由UDW（统一数据工作台）向Turing（新数据工作台）的改造，并初步建立起体系化的数据模型与分层数据集，显著提升了数据复用性和分析效率。基于这些宽表与数据集，大部分常规分析场景已能够快速响应。然而，在数据加工的最上游，即明细数据宽表的生产环节之前依旧包含缓冲的刻钟级udw表，因此仍存在若干架构性瓶颈。首先，实时数据处理链路与离线批处理链路相互耦合，资源竞争与依赖关系复杂，影响了整体任务的稳定性和时效性；其次，核心业务指标与非核心附属数据未被有效拆分处理，导致关键数据产出易受边缘数据波动或延迟的干扰；此外，当前的计算框架对于数据迟到、重复、异常值等复杂情况的处理灵活度不足，容错与自适应能力有待加强。</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-14db3809be.jpg"></p>
<p>为彻底解决这些问题，进一步提升数据产出的时效性、准确性和稳定性，以更好地赋能百度APP及其产品矩阵及各下游业务的数据分析与决策，亟需结合各数据点位的实际使用情况和业务优先级，对最上游的日志ETL（抽取、转换、加载）处理流程进行系统性的优化与重构。</p>
<h2><strong>2. 问题分析</strong></h2>
<p>当前数据ETL处理流程面临以下几个核心挑战，这些问题不仅影响数据产出的效率与稳定性，也为下游业务数据的准确性和及时性带来风险。</p>
<h3>2.1 开发框架灵活性不足，资源协调与弹性扩展能力受限</h3>
<p>目前的ETL任务仍沿用原有UDW大表处理框架，通过单机Hadoop Client提交任务，并依赖QE（底层为mapreduce引擎）进行计算。该框架在资源调度和权限管理方面已逐渐暴露出瓶颈。同时udw是2012年提出的数仓建设方案，随着开源计算、存储技术的发展，udw性能逐步落后业界，部分功能不具备继续升级迭代可行性。一旦出现上游数据延迟、队列资源拥塞或系统异常，容易导致任务大规模积压。由于缺乏跨队列或跨资源的调度容灾能力，无法协调其他计算资源执行任务回溯与补偿，最终将直接影响整体数据产出时效，甚至波及下游多条业务线的核心数据应用。</p>
<h3>2.2 核心与非核心数据处理耦合，异常影响范围扩散</h3>
<p>在日志清洗ETL环节中，核心业务数据点位与非核心业务数据点位、以及实时与离线数据流目前尚未进行有效拆分处理。这种架构层面的耦合导致一旦上游数据源或计算过程中发生异常，其影响面会迅速扩大，不仅关键业务指标受到冲击，非核心业务数据的问题也可能反向干扰核心链路的稳定性。缺乏业务优先级识别和隔离机制，降低了计算链路的整体容错能力和故障隔离水平。</p>
<h3>2.3 计算链路冗长复杂，维护困难且稳定性面临挑战</h3>
<p>当前处理流程中包含UDW中间缓冲层，导致计算环节增多、链路层级深化。较长的依赖链不仅增加了数据产出的端到端延迟，也显著提高了运维监控和故障定位的复杂度。任何环节出现性能波动或失败都易引起连锁反应，威胁整体任务的稳定性和时效性，同时也带来较高的人力维护成本。</p>
<h3>2.4 实时与离线数据源不一致，存在冗余计算与口径偏差</h3>
<p>百度APP及其产品矩阵业务当前使用的实时计算链路和离线数据链路在核心指标上并未实现数据源统一，两条链路独立处理且并行存在。这导致相同指标需要在不同流程中重复计算，既造成资源浪费，也增加了数据口径对齐的难度。长期来看，此类架构问题会直接影响关键指标的一致性和可信度，对业务决策准确性构成潜在风险。</p>
<h3>2.5 存储无序增长，数据冗余和存储成本与日俱增</h3>
<p>随着业务规模的持续扩张和流量快速增长，支撑核心业务的明细数据宽表总量已达到百PB级别，存储与计算成本压力日益凸显。然而，不同业务域对数据的保留周期和使用频率存在显著差异，全部数据长期存储既不经济也无必要。</p>
<h2><strong>3. 解决方案</strong></h2>
<h3>3.1 ETL框架升级</h3>
<p>在完成由多张udw表到Turing表的优化工作完成后，数据处理的时效性与稳定性虽然取得了一定改善，但仍存在进一步提升的空间。具体而言，原有的C++ MR计算框架在任务运行过程中逐渐暴露出两类典型问题：一是容易发生计算长尾现象，个别任务实例处理缓慢，拖慢整个作业完成进度；二是基于单机调度的模式存在可靠性瓶颈，整体资源协调和任务容错能力有限。这些问题导致数据产出的延迟风险依然较高，难以完全满足业务对数据时效日益提升的要求。</p>
<p>为解决上述痛点，经过充分的技术调研与架构评估，我们决定将计算框架升级为TM+Spark的组合方案。其中，TM（Task Manager）作为厂内自研的高性能流式处理框架，在多个关键维度上显著优于原有的C++ MR架构。</p>
<p>TM（Task Manager）：更高的容错性和更强的稳定性</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-29892c55bf.jpg"></p>
<p>首先，在容错性方面，TM具备更为智能和敏捷的错误恢复机制。当某个计算实例发生故障或执行缓慢时，TM调度系统能够迅速感知并主动发起抢占操作，将当前Task动态迁移至新的实例继续处理，从而有效避免传统MR框架中由于个别长尾任务导致的整体作业延迟。这一机制极大提升了作业的稳健性和执行效率。</p>
<p>其次，在调度稳定性方面，TM基于Opera调度系统进行资源管理与任务分配，这一调度架构具有高度解耦和资源隔离的特点。每个任务实例独立运行，互不干扰，有效避免了在MR模式下由于同一队列中其他高负载或异常作业所带来的负面冲击，从而保障关键数据处理任务的稳定性和可预期性。</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-19d7ad2f0d.jpg"></p>
<p>此外，TM框架也在输出存储效率方面做出了重要升级。它原生支持输出Parquet列式存储格式，并集成ZSTD压缩算法，在减少存储空间占用的同时大幅提升了后续查询操作的I/O效率。这一改进使得数据在写入阶段就具备更优的列组织结构和压缩特性，为下游分析提供了高性能的数据基础。</p>
<p><strong><strong>主流开源框架Flink和TM的对比如下：</strong></strong></p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-b9aca2ae4f.png"></p>
<p><strong><strong>Spark：通过构建DAG，计算更高效；利用RDD或者DataFrame减少IO耗时；多线程机制，执行速度更快。</strong></strong></p>
<p><strong><strong>Spark对比MR的核心优势：</strong></strong></p>
<ul>
<li> <p>速度：基于内存计算，无需反复做读写操作，更加高效</p> </li>
<li> <p>高度集成：spark丰富的API和高级抽象的函数可以轻松实现复杂的逻辑计算和处理，无需和MR一般需要编写复杂的处理逻辑</p> </li>
<li> <p>计算模型：内置的RDD数据结构可以提高数据计算的容错性；查询优化和执行优化可以适应复杂数据的处理和查询</p> </li>
</ul>
<p>结合Spark通用计算引擎强大的分布式内存计算能力和丰富的生态组件，新框架不仅解决了之前C++ MR模式中的长尾与调度瓶颈，还进一步实现了处理链路的统一与优化。Spark的高扩展性和TM的流式稳健性相结合，共同构建出一个容错能力强、资源利用高效、运维负担低的新一代数据处理架构，为业务提供更低延迟、更高可靠性的数据服务。</p>
<h3>3.2 日志分类分级</h3>
<h4>3.2.1 埋点<strong><strong>上线不规范，被动兼容推高处理成本</strong></strong></h4>
<p>在当前百度APP及其产品矩阵业务高速发展的背景下，日均处理日志量已达3000亿PV的庞大规模，数据流的稳定、高效与成本可控变得至关重要。</p>
<p>原有的埋点分类和校验存在两个突出的问题：</p>
<ul>
<li> <p><strong>上报不规范</strong>：存在大量不经过日志中台统一校验而直接上线的业务打点，这些“非规范”打点格式各异、质量参差不齐，极易引发解析异常。</p> </li>
<li> <p><strong>处理成本高</strong>：下游的日志清洗ETL环节被迫陷入“被动兼容”的循环中，需要频繁地跟进制订适配规则以解析这些非标数据，不仅带来了极高的运维成本，更因计算资源的无效消耗而加剧了整体处理链路的负担，严重制约了数据产出的时效性与稳定性。</p> </li>
</ul>
<h4>3.2.2 <strong><strong>通过协同治理实现日志中台全流量覆盖</strong></strong></h4>
<p>为从根本上破解这一难题，我们基于对百度APP及其产品矩阵数据全链路的深入洞察，发起了一项跨体系的协同治理工程。联合了日志中台团队、各业务研发团队、QA质量保障团队及PMO项目管理团队，形成了强有力的专项工作组。</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-fdbd5629b9.jpg"></p>
<p>第一阶段的核心任务是对所有日志模块进行全域梳理。我们共同制定了统一的《新增业务模块接入日志中台规范》<strong><strong>与</strong></strong>《日志埋点规范》<strong><strong>，明确了从数据采集、上报到校验的完整标准流程，并强力推动百度APP及其产品矩阵（包括主客户端及相关创新业务）的全量需求空间、代码仓库及日志模块，完成向日志中台的标准化接入迁移。这一举措将日志中台的流量覆盖能力从治理前的约</strong></strong>80%<strong><strong>一举提升至</strong></strong>100%****，实现了<strong>全流量管控。</strong></p>
<p>更重要的是，我们在日志中台增强了多项主动校验能力：包括日志长度校验、关键公共参数完整性校验、以及精确到需求ID的粒度校验。这使得任何不合规的打点企图在测试和上线阶段就能被即时发现和拦截，实现了“问题早发现、早解决”的闭环管理，从而构筑起覆盖全场景的打点需求上线质量保障体系，从源头上杜绝了异常日志的产生。</p>
<h4>3.2.3 <strong><strong>打破“只上不下”僵局，建立埋点生命周期管理</strong></strong></h4>
<p>在成功建立起“入口”管控机制后，我们将治理重心转向对历史存量埋点的“出口”梳理与优化。长期以来，由于缺乏有效的评估手段，点位数据存在着“只增不减”的痼疾，大量废弃或无效点位持续消耗着巨额的计算和存储资源。为此，我们创新性地从鉴权信息入手，通过对十几类不同下游使用场景（包括内部报表、算法模型、RDC数据转发服务等）的全面调研与信息收集，并对相关日志解析链路进行深度分析，首次精准地绘制出以百度APP及其产品矩阵全量15000多个点位为起点的、覆盖所有下游应用场景的“点位全链路使用地图”。</p>
<p>基于这张价值地图，我们清晰地识别出超过10000个点位已无任何下游业务使用或价值极低。通过严格的评估与协作流程，我们果断对这些埋点进行了下线处理，下线比例高达存量点位的71%。此次大规模治理行动，不仅直接释放了海量的计算和存储资源，有效缓解了系统瓶颈，更打破了长达多年的“埋点只上不敢下”的历史僵局，建立了点位的全生命周期管理模式，为后续数据的精细化管理与成本优化奠定了坚实基础。</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-083cf2a3a5.jpg"></p>
<h3>3.3 AB实验数据扇出处理</h3>
<h4>3.3.1 现状与问题</h4>
<p>在数据驱动的业务迭代中，A/B实验平台的指标建设和效果评估能力至关重要。然而，随着业务快速扩张和实验复杂度的提升，原有的实验数仓架构逐渐显露出严重瓶颈。平台最初是在通用数仓分层模型的基础上，采用“每个指标单独计算”的模式进行建设。这种设计在初期虽然灵活，但随着实验数量和指标数量的急剧增长，计算链路变得异常复杂、冗余且难以维护。由于缺少与公司数据中台团队的深度协同和标准化约束，每次新增实验指标都需要大量重复开发，导致实验数据需求的交付周期不断延长，严重拖慢了业务迭代速度，引发了业务团队的负反馈。</p>
<h4>3.3.2 解决方案</h4>
<p><strong><strong>（1）分析过程</strong></strong></p>
<p>理想的解决方案是直接复用百度APP及其产品矩阵已有的标准化大宽表进行实验指标配置。即基于一张集成所有关键维度与指标的大宽表，快速定义和产出实验分析所需的数据集。然而，现实情况却更为复杂：百度APP及其产品矩阵客户端同时线上进行的实验数量极多，平均每个cuid（用户唯一标识）对应的实验ID（sid）字符长度已超过2400字符。这个长度几乎相当于单条日志原始存储容量的40%，如果直接将实验ID维度接入宽表，将导致每条日志存储膨胀近一倍。这不仅会带来极高的存储成本，也会大幅增加下游所有数据应用的数据扫描量和传输开销，严重拖慢查询性能，进而影响整个数据链路的效率。</p>
<p><strong><strong>（2）设计思路</strong></strong></p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-413cd36ad9.jpg"></p>
<p>面对这一独特挑战，我们并未选择传统的宽表集成方案，而是从数据生成的源头实施了更根本的架构优化。我们重点对实验ID映射关系进行了拆分和重构：<strong><strong>将sid与核心行为数据解耦，设计并建设了独立的sid维表</strong></strong>。该维表直接从日志源头统一生成，整合了来自客户端的实验曝光及分组信息，并实现了对业务方、评估方各自独立建设的多套映射关系的全面统一。这一举措不仅从本质上避免了主宽表的存储膨胀，还彻底解决了因数据来源不一致而导致的实验效果评估diff问题，显著提高了实验数据的准确性和可信度。</p>
<p><strong><strong>（3）成果与收益</strong></strong></p>
<p>在此基础上，A/B实验平台的分析查询不再依赖于对超大宽表的直接扫描，而是通过<strong><strong>sid维表与核心行为宽表进行动态拼接</strong></strong>的方式实现指标计算。</p>
<p>在指标口径对齐方面，已完成实验类指标与OKR指标的口径统一工作，累计对齐上线指标2000余个，覆盖多个主题和维度。实验指标改由数据中心宽表统一生产，显著减少了以往在指标口径沟通与对齐方面的成本；在实验效率提升显著，指标开发环节通过复用宽表及数仓下沉逻辑，并升级计算框架，使常规需求开发周期从原先2周以上缩短至1周内，开发效率提升超50%。同时核心指标计算SLA由T+14小时提升至T+10小时，处理时效明显提高；在计算资源成本方面，通过整体数据流复用和抽样日志整合优化，实现了计算资源成本的有效降低。另外，联动产品及策略团队治理并下线无效实验指标超1800+，释放的资源进一步支撑了新场景的指标建设需求。</p>
<h2><strong>4. 分级存储治理</strong></h2>
<p>随着业务规模的持续扩张与产品矩阵的不断丰富，百度APP及其产品矩阵业务的日志数据量呈现指数级增长，单张核心Turing数据表的存储量已达到百PB级别，面临巨大的存储与成本压力。传统的统一存储周期策略难以适应当前复杂的使用场景：一方面，大量短期数据被无效保留，占用巨额存储资源；另一方面，部分核心业务场景仍需依赖长周期历史数据进行跨年指标对比、关键数据需求回溯与深度建模分析。</p>
<p>为解决这一矛盾，我们针对Turing表启动了多维度的精细化存储治理工作。通过深入分析业务使用特征与数据访问频率，我们建立了差异化的数据生命周期管理机制，实施**“热-&gt;温-&gt;冷”**三级数据分层存储策略。对高频访问的近期数据全部保留，对访问频率较低的长期历史数据自动进行转储、压缩或者裁剪等，并配套建立完备的数据取回与回溯流程。</p>
<p>该项治理在充分保障核心业务长周期数据使用需求的前提下，显著压缩了整体存储规模，实现了存储成本的大幅优化，为未来数据的可持续增长与高效管理奠定了坚实基础。</p>
<p>具体实施策略：</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-9c87a2818c.png"></p>
<h1>03 总结与展望</h1>
<p>随着业务规模的持续扩张和产品矩阵的不断丰富，数据量呈现指数级增长，这一趋势持续驱动着数据处理架构与模型的演进与迭代，同时也对数据分析的敏捷性、易用性和可靠性提出了更高要求。在数仓系统全面升级的过程中，我们着力优化数据处理全链路，通过改进调度机制、减少计算环节、强化故障自动恢复能力，显著缩短了整个数据处理流程的时长，有效识别并排除多项潜在稳定性风险。此外，依托于对全端埋点体系的系统化梳理与标准化规范，构建了高质量、可复用的数据资产底座。</p>
<p>本次整体架构的升级为业务提供了坚实的数据支撑，在数据时效性、准确性和使用便捷性方面均实现显著提升。作为百度体系内最核心且数据规模最大的业务板块，百度APP仍面临数据持续激增带来的诸多挑战，包括埋点规范统一难度高、技术栈兼容与选型约束多、日志解析复杂度高、存储结构灵活多变以及成本控制压力增大等问题。</p>
<p>面向未来，我们将持续推进数仓架构的深度优化，重点围绕埋点治理、架构升级、效能提升、存储模型优化和资源精细化管理等方面展开工作。目标是构建一套具备更高时效性、更优数据模型、更低存储与计算成本的全新一代数仓链路，为业务创新与决策提供高效、可靠、低成本的数据服务能力。</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-41f3e39809.jpg"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-41f3e39809.jpg" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 10:54:39 +0800</pubDate>
  </item><item>
    <title><![CDATA[AMD 与甲骨文携手打造超大型 AI 芯片集群，年内最大算力合作落地]]></title>
    <link>https://www.oschina.net/news/377494</link>
    <itunes:title><![CDATA[AMD 与甲骨文携手打造超大型 AI 芯片集群，年内最大算力合作落地]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>10 月 14 日，芯片设计商超微半导体公司（AMD）宣布与甲骨文（Oracle）<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblogs.oracle.com%2Fcloud-infrastructure%2Fpost%2Fannouncing-general-availability-of-oci-amd-mi355x" target="_blank">达成合作</a>，AMD 将在后者的数据中心部署约 5 万颗最新 AI 芯片 MI450，标志着双方在人工智能算力领域的深度绑定。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-6d6572bd3d.png"></p>
<p>根据计划，自 2025 年第三季度起，AMD 将在甲骨文旗下数据中心投用这一集群，总算力相当于 200 兆瓦电力负荷。双方表示，合作将在 2027 年后进一步扩展。消息公布后，AMD 股价盘前上涨逾 2%，甲骨文下跌约 1%。双方未披露交易金额。</p>
<p>市场人士认为，该项目将成为继英伟达之后 AI 算力市场的又一重要竞争力量。MI450 为 AMD 迄今最先进的 GPU（图形处理器），将搭载在公司自主研发的 Helios 服务器机架系统中，结合 AMD 自研中央处理器（CPU），直指英伟达下一代「Vera Rubin」系列 AI 芯片。</p>
<p>业内分析认为，此次合作标志着 AMD 的 MI450 首次在公共云场景中大规模应用，意味着更多客户可租用其 AI 算力资源，有望推动 AMD 在数据中心市场进一步缩小与英伟达的差距</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>10 月 14 日，芯片设计商超微半导体公司（AMD）宣布与甲骨文（Oracle）<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblogs.oracle.com%2Fcloud-infrastructure%2Fpost%2Fannouncing-general-availability-of-oci-amd-mi355x" target="_blank">达成合作</a>，AMD 将在后者的数据中心部署约 5 万颗最新 AI 芯片 MI450，标志着双方在人工智能算力领域的深度绑定。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-6d6572bd3d.png"></p>
<p>根据计划，自 2025 年第三季度起，AMD 将在甲骨文旗下数据中心投用这一集群，总算力相当于 200 兆瓦电力负荷。双方表示，合作将在 2027 年后进一步扩展。消息公布后，AMD 股价盘前上涨逾 2%，甲骨文下跌约 1%。双方未披露交易金额。</p>
<p>市场人士认为，该项目将成为继英伟达之后 AI 算力市场的又一重要竞争力量。MI450 为 AMD 迄今最先进的 GPU（图形处理器），将搭载在公司自主研发的 Helios 服务器机架系统中，结合 AMD 自研中央处理器（CPU），直指英伟达下一代「Vera Rubin」系列 AI 芯片。</p>
<p>业内分析认为，此次合作标志着 AMD 的 MI450 首次在公共云场景中大规模应用，意味着更多客户可租用其 AI 算力资源，有望推动 AMD 在数据中心市场进一步缩小与英伟达的差距</p>]]>
    </description>
    <content:encoded><![CDATA[<p>10 月 14 日，芯片设计商超微半导体公司（AMD）宣布与甲骨文（Oracle）<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblogs.oracle.com%2Fcloud-infrastructure%2Fpost%2Fannouncing-general-availability-of-oci-amd-mi355x" target="_blank">达成合作</a>，AMD 将在后者的数据中心部署约 5 万颗最新 AI 芯片 MI450，标志着双方在人工智能算力领域的深度绑定。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-6d6572bd3d.png"></p>
<p>根据计划，自 2025 年第三季度起，AMD 将在甲骨文旗下数据中心投用这一集群，总算力相当于 200 兆瓦电力负荷。双方表示，合作将在 2027 年后进一步扩展。消息公布后，AMD 股价盘前上涨逾 2%，甲骨文下跌约 1%。双方未披露交易金额。</p>
<p>市场人士认为，该项目将成为继英伟达之后 AI 算力市场的又一重要竞争力量。MI450 为 AMD 迄今最先进的 GPU（图形处理器），将搭载在公司自主研发的 Helios 服务器机架系统中，结合 AMD 自研中央处理器（CPU），直指英伟达下一代「Vera Rubin」系列 AI 芯片。</p>
<p>业内分析认为，此次合作标志着 AMD 的 MI450 首次在公共云场景中大规模应用，意味着更多客户可租用其 AI 算力资源，有望推动 AMD 在数据中心市场进一步缩小与英伟达的差距</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-6d6572bd3d.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-6d6572bd3d.png" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 10:43:45 +0800</pubDate>
  </item><item>
    <title><![CDATA[英特尔发布新一代数据中心 GPU 代号“Crescent Island”]]></title>
    <link>https://www.oschina.net/news/377492</link>
    <itunes:title><![CDATA[英特尔发布新一代数据中心 GPU 代号“Crescent Island”]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p><span>英特尔周二公布了一款搭载160GB内存、具备高能效的数据中心GPU，并将其加入该公司的AI加速器组合，旨在推动英特尔以开放系统与软件架构为核心的新AI战略。</span></p>
<p><span>这款GPU代号为“Crescent Island（新月岛）”，根据英特尔介绍，它专为运行推理工作负载的风冷企业级服务器而设计，强调“功耗与成本优化”。<strong>Crescent Island采用英特尔的Xe3P微架构，该架构主打单位功耗下的高性能表现，配备160GB LPDDR5X内存，并支持多种数据类型，为大语言模型（LLM）提供充足的运行空间。</strong></span></p>
<p><span>英特尔的公告还指出，Crescent Island将支持多种数据类型，并被定位为“非常适合”提供tokens-as-a-service服务的厂商和AI推理使用场景。</span></p>
<p><span>除了强调能效表现，Crescent Island还将采用风冷散热设计，并以成本优化为目标。英特尔目前正通过现有的Arc Pro B系列GPU推进其开源软件栈，为Crescent Island做准备。</span></p>
<p><span>英特尔表示，计划于2026年下半年开始向客户提供样品。不过英特尔并未公布正式上市时间——是否会赶在2026年内发布尚不清楚，更可能的情况是要等到2027年才正式大规模推出。目前也没有发布任何产品幻灯片、原型图或更多技术细节。</span></p>
<p><span>英特尔此次并未公布关于“Jaguar Shores”的最新进展。Jaguar Shores是英特尔今年早些时候宣布的一款面向机架级平台的下一代GPU。</span></p>
<p><span>在上个月的一次记者简报会上，英特尔首席AI与技术官Sachin Katti表示，Crescent Island具备“增强的内存带宽”和“大量内存容量”，这让它成为“token云服务和企业级推理场景的理想选择”。</span></p>
<p><span>Crescent Island是在2025年OCP全球峰会上正式亮相的，标志着英特尔正式开启了每年发布新GPU的节奏。此前一周，英特尔刚刚围绕即将推出的“Panther Lake”和“Clearwater Forest”两款CPU大力宣传，这次发布GPU也属同一系列动作。</span></p>
<p><span>媒体表示，在过去两年中，英伟达和AMD已先后转向每年发布新产品的节奏，英特尔此举也意在追赶步伐。过去15年间，英特尔在加速芯片领域经历了多次失败，历经四任CEO，始终未能在这个由英伟达主导的AI基础设施市场中站稳脚跟。</span></p>
<p><span>Sachin Katti是由英特尔CEO陈立武在今年4月任命，负责领导公司的新AI战略。他表示，英特尔正在围绕“开放系统与软件架构”构建AI硬件市场的新愿景，目标是提供“适配合理规模与成本”的算力，以支撑未来的自主型AI工作负载。</span></p>
<p><span>他说：“我们将构建可扩展的异构系统，为agentic AI（自主型AI）工作负载提供无摩擦的使用体验，同时借助开放异构架构，实现这些工作负载在每美元性能表现上的最优解。”</span></p>
<p><span>Katti表示，这种开放策略将为客户和合作伙伴在系统层和硬件层提供更多选择，让多家厂商都能参与进来。他补充说：“随着我们不断带来更多颠覆性的技术，这些新技术都可以被无缝嵌入到这个开放的异构架构中。”</span></p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p><span>英特尔周二公布了一款搭载160GB内存、具备高能效的数据中心GPU，并将其加入该公司的AI加速器组合，旨在推动英特尔以开放系统与软件架构为核心的新AI战略。</span></p>
<p><span>这款GPU代号为“Crescent Island（新月岛）”，根据英特尔介绍，它专为运行推理工作负载的风冷企业级服务器而设计，强调“功耗与成本优化”。<strong>Crescent Island采用英特尔的Xe3P微架构，该架构主打单位功耗下的高性能表现，配备160GB LPDDR5X内存，并支持多种数据类型，为大语言模型（LLM）提供充足的运行空间。</strong></span></p>
<p><span>英特尔的公告还指出，Crescent Island将支持多种数据类型，并被定位为“非常适合”提供tokens-as-a-service服务的厂商和AI推理使用场景。</span></p>
<p><span>除了强调能效表现，Crescent Island还将采用风冷散热设计，并以成本优化为目标。英特尔目前正通过现有的Arc Pro B系列GPU推进其开源软件栈，为Crescent Island做准备。</span></p>
<p><span>英特尔表示，计划于2026年下半年开始向客户提供样品。不过英特尔并未公布正式上市时间——是否会赶在2026年内发布尚不清楚，更可能的情况是要等到2027年才正式大规模推出。目前也没有发布任何产品幻灯片、原型图或更多技术细节。</span></p>
<p><span>英特尔此次并未公布关于“Jaguar Shores”的最新进展。Jaguar Shores是英特尔今年早些时候宣布的一款面向机架级平台的下一代GPU。</span></p>
<p><span>在上个月的一次记者简报会上，英特尔首席AI与技术官Sachin Katti表示，Crescent Island具备“增强的内存带宽”和“大量内存容量”，这让它成为“token云服务和企业级推理场景的理想选择”。</span></p>
<p><span>Crescent Island是在2025年OCP全球峰会上正式亮相的，标志着英特尔正式开启了每年发布新GPU的节奏。此前一周，英特尔刚刚围绕即将推出的“Panther Lake”和“Clearwater Forest”两款CPU大力宣传，这次发布GPU也属同一系列动作。</span></p>
<p><span>媒体表示，在过去两年中，英伟达和AMD已先后转向每年发布新产品的节奏，英特尔此举也意在追赶步伐。过去15年间，英特尔在加速芯片领域经历了多次失败，历经四任CEO，始终未能在这个由英伟达主导的AI基础设施市场中站稳脚跟。</span></p>
<p><span>Sachin Katti是由英特尔CEO陈立武在今年4月任命，负责领导公司的新AI战略。他表示，英特尔正在围绕“开放系统与软件架构”构建AI硬件市场的新愿景，目标是提供“适配合理规模与成本”的算力，以支撑未来的自主型AI工作负载。</span></p>
<p><span>他说：“我们将构建可扩展的异构系统，为agentic AI（自主型AI）工作负载提供无摩擦的使用体验，同时借助开放异构架构，实现这些工作负载在每美元性能表现上的最优解。”</span></p>
<p><span>Katti表示，这种开放策略将为客户和合作伙伴在系统层和硬件层提供更多选择，让多家厂商都能参与进来。他补充说：“随着我们不断带来更多颠覆性的技术，这些新技术都可以被无缝嵌入到这个开放的异构架构中。”</span></p>]]>
    </description>
    <content:encoded><![CDATA[<p><span>英特尔周二公布了一款搭载160GB内存、具备高能效的数据中心GPU，并将其加入该公司的AI加速器组合，旨在推动英特尔以开放系统与软件架构为核心的新AI战略。</span></p>
<p><span>这款GPU代号为“Crescent Island（新月岛）”，根据英特尔介绍，它专为运行推理工作负载的风冷企业级服务器而设计，强调“功耗与成本优化”。<strong>Crescent Island采用英特尔的Xe3P微架构，该架构主打单位功耗下的高性能表现，配备160GB LPDDR5X内存，并支持多种数据类型，为大语言模型（LLM）提供充足的运行空间。</strong></span></p>
<p><span>英特尔的公告还指出，Crescent Island将支持多种数据类型，并被定位为“非常适合”提供tokens-as-a-service服务的厂商和AI推理使用场景。</span></p>
<p><span>除了强调能效表现，Crescent Island还将采用风冷散热设计，并以成本优化为目标。英特尔目前正通过现有的Arc Pro B系列GPU推进其开源软件栈，为Crescent Island做准备。</span></p>
<p><span>英特尔表示，计划于2026年下半年开始向客户提供样品。不过英特尔并未公布正式上市时间——是否会赶在2026年内发布尚不清楚，更可能的情况是要等到2027年才正式大规模推出。目前也没有发布任何产品幻灯片、原型图或更多技术细节。</span></p>
<p><span>英特尔此次并未公布关于“Jaguar Shores”的最新进展。Jaguar Shores是英特尔今年早些时候宣布的一款面向机架级平台的下一代GPU。</span></p>
<p><span>在上个月的一次记者简报会上，英特尔首席AI与技术官Sachin Katti表示，Crescent Island具备“增强的内存带宽”和“大量内存容量”，这让它成为“token云服务和企业级推理场景的理想选择”。</span></p>
<p><span>Crescent Island是在2025年OCP全球峰会上正式亮相的，标志着英特尔正式开启了每年发布新GPU的节奏。此前一周，英特尔刚刚围绕即将推出的“Panther Lake”和“Clearwater Forest”两款CPU大力宣传，这次发布GPU也属同一系列动作。</span></p>
<p><span>媒体表示，在过去两年中，英伟达和AMD已先后转向每年发布新产品的节奏，英特尔此举也意在追赶步伐。过去15年间，英特尔在加速芯片领域经历了多次失败，历经四任CEO，始终未能在这个由英伟达主导的AI基础设施市场中站稳脚跟。</span></p>
<p><span>Sachin Katti是由英特尔CEO陈立武在今年4月任命，负责领导公司的新AI战略。他表示，英特尔正在围绕“开放系统与软件架构”构建AI硬件市场的新愿景，目标是提供“适配合理规模与成本”的算力，以支撑未来的自主型AI工作负载。</span></p>
<p><span>他说：“我们将构建可扩展的异构系统，为agentic AI（自主型AI）工作负载提供无摩擦的使用体验，同时借助开放异构架构，实现这些工作负载在每美元性能表现上的最优解。”</span></p>
<p><span>Katti表示，这种开放策略将为客户和合作伙伴在系统层和硬件层提供更多选择，让多家厂商都能参与进来。他补充说：“随着我们不断带来更多颠覆性的技术，这些新技术都可以被无缝嵌入到这个开放的异构架构中。”</span></p>]]></content:encoded>
    
    <pubDate>Wed, 15 Oct 2025 10:37:33 +0800</pubDate>
  </item><item>
    <title><![CDATA[Firefox 144.0 发布]]></title>
    <link>https://www.oschina.net/news/377489/firefox-144-0-released</link>
    <itunes:title><![CDATA[Firefox 144.0 发布]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>Firefox 144.0 现已发布，具体更新内容如下：</p>
<p><strong>New</strong></p>
<ul>
<li> <p>专注于组中的单个标签页，告别杂乱。现在，活动标签页仍会保留在视图中，即使折叠标签组也能保持界面整洁。</p> <p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6722c234bd.png"></p> </li>
<li> <p>标签页组更新。现在，可以将标签页拖放到折叠的组中，而不会自动展开。这既能快速保持界面整洁，又能最大限度减少视觉干扰。</p> </li>
<li>  <p><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsupport.mozilla.org%2Fkb%2Fprofile-management" target="_blank">Profile management 功能</a>将在未来几周内逐步面向全球用户推出，它将你的在线生活划分为不同的个人资料，涵盖工作、学习、度假计划或其他任何你喜欢的用途，从而帮助保护隐私并保持专注。用户可以命名，并使用头像和颜色主题进行自定义，以便于识别；在不同资料间切换时，书签、标签页和浏览历史记录将完全独立保存。全新的个人资料功能适用于 Windows 11、Mac 和 Linux 用户，Windows 10 即将支持。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p> <p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-0fae6a9eeb.png"></p> </li>
<li>
<p>现在，可以关闭<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsupport.mozilla.org%2Fkb%2Fabout-picture-picture-firefox" target="_blank">画中画</a>窗口而无需暂停视频。按下<code>Shift + Click</code>关闭按钮或使用<code>Shift + Esc</code>退出，同时保持播放不间断。</p>
</li>
<li>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsupport.mozilla.org%2Fkb%2Fmanage-your-logins-firefox-password-manager" target="_blank">Firefox Password Manager</a>&nbsp;中存储的登录信息现在使用现代加密方案 (AES-256-CBC) 在磁盘上加密，取代了旧版的 3DES-CBC。此更改增强了本地数据保护。通过 Firefox Sync 同步的登录信息仍保持端到端加密，并且已使用 AES-256-GCM。</p>
</li>
<li>
<p><strong>Visual search powered by Google Lens</strong></p>
<p>只需右键单击任意图像，现在就可以：</p>
<ul>
<li>查找类似的产品、地点或物品</li>
<li>从图像中复制、翻译或搜索文本</li>
<li>获取学习、旅行或购物的灵感</li>
</ul>
<p>在右键菜单中找到新的“<strong>Search Image with Google Lens</strong>”选项（初始显示为带<strong>“NEW”</strong>标识的选项）。 此<strong>功能仅限桌面端</strong>，并已在全球范围内推出。<strong>必须将默认搜索引擎设置为 Google&nbsp;</strong>才能使用此功能。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-e163684ac8.png"></p>
</li>
<li><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><strong>Firefox 中的 Perplexity AI 搜索</strong></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>&nbsp;<span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>在桌面版 Firefox 中，现已集成&nbsp;<strong>Perplexity</strong>。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></li>
<li> <p><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>现可翻译以下语言：</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p>
<ul>
<li>阿塞拜疆</li>
<li>孟加拉语</li>
<li>冰岛语</li>
</ul> </li>
</ul>
<p><strong>Fixed</strong></p>
<ul>
<li>各种<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.mozilla.org%2Fsecurity%2Fadvisories%2Fmfsa2025-81" target="_blank">安全修复</a>。</li>
<li> <p><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>以下语言的翻译质量已得到提高：</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p>
<ul>
<li>阿拉伯</li>
<li>保加利亚语</li>
<li>加泰罗尼亚语</li>
<li>简体中文</li>
<li>捷克语</li>
<li>荷兰语</li>
<li>爱沙尼亚语</li>
<li>芬兰</li>
<li>法语</li>
<li>德语</li>
<li>匈牙利</li>
<li>意大利语</li>
<li>日语</li>
<li>葡萄牙语</li>
<li>波斯语</li>
<li>西班牙语</li>
<li>乌克兰语</li>
</ul> </li>
</ul>
<p><strong>Changed</strong></p>
<ul>
<li><span>在 Windows 上，当从另一个应用程序打开链接时，Firefox 将仅使用当前虚拟桌面上的窗口或在需要时打开一个新窗口。</span></li>
</ul>
<p><strong>Developer</strong></p>
<ul>
<li>
<p>现在可以从样式规则中的<code>var()</code>函数内跳转到 CSS 自定义属性的定义。</p>
</li>
<li>
<p>现在，检查器中的事件工具提示会在自定义事件旁边显示一个标识，从而更容易将它们与内置事件区分开来。</p>
</li>
</ul>
<p><strong>Web Platform</strong></p>
<ul>
<li>
<p>Firefox 现在支持<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FElement%2FmoveBefore" target="_blank">Element.moveBefore</a>&nbsp;API。</p>
</li>
<li>
<p>Firefox 现在支持<code>math-shift</code>&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FCSS%2Fmath-shift%23compact" target="_blank">compact</a>。</p>
</li>
<li>
<p>Firefox 现已支持<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FPerformanceEventTiming%2FinteractionId" target="_blank">PerformanceEventTiming.interactionId</a>，允许开发者对相关输入事件进行分组。这为 Interaction to Next Paint (INP) responsiveness metric 提供了支持。</p>
</li>
<li>
<p>Firefox 现在支持<code>command</code>和<code>commandfor</code>属性。</p>
</li>
<li>
<p>Firefox 现在支持&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FView_Transition_API" target="_blank">View Transitions</a>&nbsp;API Level 1。View Transitions API 提供了一种在不同网站视图之间轻松创建动画过渡的机制。</p>
</li>
<li>
<p>现在，当使用硬件 WebRender 渲染<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FCSS%2Fgradient%2Flinear-gradient" target="_blank">线性渐变</a>、<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FCSS%2Fgradient%2Fconic-gradient" target="_blank">圆锥渐变</a>和<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FCSS%2Fgradient%2Fradial-gradient" target="_blank">径向渐变</a>时，会应用抖动。</p>
</li>
<li> <p>Firefox 现在支持&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ftc39%2Fproposal-upsert" target="_blank">upsert 提案</a>。该提案为<code>Map</code>和<code>WeakMap</code>添加<code>getOrInsert</code>和<code>getOrInsertComputed</code>方法。这些方法可返回键关联的值，或插入默认值后返回该值，简化了处理键是否存在于<code>Map</code>和<code>WeakMap</code>中的场景。</p> </li>
<li>
<p>Firefox 现已在 Windows 平板和 Android 设备上支持<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FScreenOrientation" target="_blank">ScreenOrientation</a>&nbsp;接口的<code>lock()</code>和<code>unlock()</code>方法。</p>
</li>
<li>
<p>Firefox 现在支持&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FRTCDataChannel" target="_blank">RTCDataChannel</a>&nbsp;的&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FWeb_Workers_API%2FTransferable_objects" target="_blank">worker transfer</a>。</p>
</li>
<li>
<p>Firefox 现在支持<code>resizeMode</code>&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FMediaDevices%2FgetUserMedia" target="_blank">getUserMedia</a>&nbsp;constraint，允许开发人员将从摄像头捕获的视频裁剪和缩小到他们选择的任何分辨率。</p>
</li>
<li>
<p>Firefox 现在支持 Windows 上的&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FWebGPU_API" target="_blank">WebGPU&nbsp;</a><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FGPUDevice%2FimportExternalTexture" target="_blank">GPUDevice.importExternalTexture API 。</a></p>
</li>
<li>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FWebCodecs_API" target="_blank">Windows 上的 WebCodecs</a>&nbsp;现在具有 VideoEncoder 的批量编码路径，由于默认批量大小较大，因此吞吐量更高、提交延迟更低，从而提高了性能。</p>
</li>
<li>
<p>Gecko-specific<code>CSS2Properties</code>已重命名为<code>CSSStyleProperties</code>，以符合最新的 Web 标准并实现与其他浏览器引擎更好的互操作性。</p>
</li>
</ul>
<p>更新说明：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.firefox.com%2Fen-US%2Ffirefox%2F144.0%2Freleasenotes%2F" target="_blank">https://www.firefox.com/en-US/firefox/144.0/releasenotes/</a></p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>Firefox 144.0 现已发布，具体更新内容如下：</p>
<p><strong>New</strong></p>
<ul>
<li> <p>专注于组中的单个标签页，告别杂乱。现在，活动标签页仍会保留在视图中，即使折叠标签组也能保持界面整洁。</p> <p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6722c234bd.png"></p> </li>
<li> <p>标签页组更新。现在，可以将标签页拖放到折叠的组中，而不会自动展开。这既能快速保持界面整洁，又能最大限度减少视觉干扰。</p> </li>
<li>  <p><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsupport.mozilla.org%2Fkb%2Fprofile-management" target="_blank">Profile management 功能</a>将在未来几周内逐步面向全球用户推出，它将你的在线生活划分为不同的个人资料，涵盖工作、学习、度假计划或其他任何你喜欢的用途，从而帮助保护隐私并保持专注。用户可以命名，并使用头像和颜色主题进行自定义，以便于识别；在不同资料间切换时，书签、标签页和浏览历史记录将完全独立保存。全新的个人资料功能适用于 Windows 11、Mac 和 Linux 用户，Windows 10 即将支持。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p> <p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-0fae6a9eeb.png"></p> </li>
<li>
<p>现在，可以关闭<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsupport.mozilla.org%2Fkb%2Fabout-picture-picture-firefox" target="_blank">画中画</a>窗口而无需暂停视频。按下<code>Shift + Click</code>关闭按钮或使用<code>Shift + Esc</code>退出，同时保持播放不间断。</p>
</li>
<li>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsupport.mozilla.org%2Fkb%2Fmanage-your-logins-firefox-password-manager" target="_blank">Firefox Password Manager</a>&nbsp;中存储的登录信息现在使用现代加密方案 (AES-256-CBC) 在磁盘上加密，取代了旧版的 3DES-CBC。此更改增强了本地数据保护。通过 Firefox Sync 同步的登录信息仍保持端到端加密，并且已使用 AES-256-GCM。</p>
</li>
<li>
<p><strong>Visual search powered by Google Lens</strong></p>
<p>只需右键单击任意图像，现在就可以：</p>
<ul>
<li>查找类似的产品、地点或物品</li>
<li>从图像中复制、翻译或搜索文本</li>
<li>获取学习、旅行或购物的灵感</li>
</ul>
<p>在右键菜单中找到新的“<strong>Search Image with Google Lens</strong>”选项（初始显示为带<strong>“NEW”</strong>标识的选项）。 此<strong>功能仅限桌面端</strong>，并已在全球范围内推出。<strong>必须将默认搜索引擎设置为 Google&nbsp;</strong>才能使用此功能。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-e163684ac8.png"></p>
</li>
<li><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><strong>Firefox 中的 Perplexity AI 搜索</strong></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>&nbsp;<span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>在桌面版 Firefox 中，现已集成&nbsp;<strong>Perplexity</strong>。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></li>
<li> <p><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>现可翻译以下语言：</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p>
<ul>
<li>阿塞拜疆</li>
<li>孟加拉语</li>
<li>冰岛语</li>
</ul> </li>
</ul>
<p><strong>Fixed</strong></p>
<ul>
<li>各种<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.mozilla.org%2Fsecurity%2Fadvisories%2Fmfsa2025-81" target="_blank">安全修复</a>。</li>
<li> <p><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>以下语言的翻译质量已得到提高：</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p>
<ul>
<li>阿拉伯</li>
<li>保加利亚语</li>
<li>加泰罗尼亚语</li>
<li>简体中文</li>
<li>捷克语</li>
<li>荷兰语</li>
<li>爱沙尼亚语</li>
<li>芬兰</li>
<li>法语</li>
<li>德语</li>
<li>匈牙利</li>
<li>意大利语</li>
<li>日语</li>
<li>葡萄牙语</li>
<li>波斯语</li>
<li>西班牙语</li>
<li>乌克兰语</li>
</ul> </li>
</ul>
<p><strong>Changed</strong></p>
<ul>
<li><span>在 Windows 上，当从另一个应用程序打开链接时，Firefox 将仅使用当前虚拟桌面上的窗口或在需要时打开一个新窗口。</span></li>
</ul>
<p><strong>Developer</strong></p>
<ul>
<li>
<p>现在可以从样式规则中的<code>var()</code>函数内跳转到 CSS 自定义属性的定义。</p>
</li>
<li>
<p>现在，检查器中的事件工具提示会在自定义事件旁边显示一个标识，从而更容易将它们与内置事件区分开来。</p>
</li>
</ul>
<p><strong>Web Platform</strong></p>
<ul>
<li>
<p>Firefox 现在支持<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FElement%2FmoveBefore" target="_blank">Element.moveBefore</a>&nbsp;API。</p>
</li>
<li>
<p>Firefox 现在支持<code>math-shift</code>&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FCSS%2Fmath-shift%23compact" target="_blank">compact</a>。</p>
</li>
<li>
<p>Firefox 现已支持<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FPerformanceEventTiming%2FinteractionId" target="_blank">PerformanceEventTiming.interactionId</a>，允许开发者对相关输入事件进行分组。这为 Interaction to Next Paint (INP) responsiveness metric 提供了支持。</p>
</li>
<li>
<p>Firefox 现在支持<code>command</code>和<code>commandfor</code>属性。</p>
</li>
<li>
<p>Firefox 现在支持&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FView_Transition_API" target="_blank">View Transitions</a>&nbsp;API Level 1。View Transitions API 提供了一种在不同网站视图之间轻松创建动画过渡的机制。</p>
</li>
<li>
<p>现在，当使用硬件 WebRender 渲染<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FCSS%2Fgradient%2Flinear-gradient" target="_blank">线性渐变</a>、<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FCSS%2Fgradient%2Fconic-gradient" target="_blank">圆锥渐变</a>和<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FCSS%2Fgradient%2Fradial-gradient" target="_blank">径向渐变</a>时，会应用抖动。</p>
</li>
<li> <p>Firefox 现在支持&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ftc39%2Fproposal-upsert" target="_blank">upsert 提案</a>。该提案为<code>Map</code>和<code>WeakMap</code>添加<code>getOrInsert</code>和<code>getOrInsertComputed</code>方法。这些方法可返回键关联的值，或插入默认值后返回该值，简化了处理键是否存在于<code>Map</code>和<code>WeakMap</code>中的场景。</p> </li>
<li>
<p>Firefox 现已在 Windows 平板和 Android 设备上支持<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FScreenOrientation" target="_blank">ScreenOrientation</a>&nbsp;接口的<code>lock()</code>和<code>unlock()</code>方法。</p>
</li>
<li>
<p>Firefox 现在支持&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FRTCDataChannel" target="_blank">RTCDataChannel</a>&nbsp;的&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FWeb_Workers_API%2FTransferable_objects" target="_blank">worker transfer</a>。</p>
</li>
<li>
<p>Firefox 现在支持<code>resizeMode</code>&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FMediaDevices%2FgetUserMedia" target="_blank">getUserMedia</a>&nbsp;constraint，允许开发人员将从摄像头捕获的视频裁剪和缩小到他们选择的任何分辨率。</p>
</li>
<li>
<p>Firefox 现在支持 Windows 上的&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FWebGPU_API" target="_blank">WebGPU&nbsp;</a><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FGPUDevice%2FimportExternalTexture" target="_blank">GPUDevice.importExternalTexture API 。</a></p>
</li>
<li>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FWebCodecs_API" target="_blank">Windows 上的 WebCodecs</a>&nbsp;现在具有 VideoEncoder 的批量编码路径，由于默认批量大小较大，因此吞吐量更高、提交延迟更低，从而提高了性能。</p>
</li>
<li>
<p>Gecko-specific<code>CSS2Properties</code>已重命名为<code>CSSStyleProperties</code>，以符合最新的 Web 标准并实现与其他浏览器引擎更好的互操作性。</p>
</li>
</ul>
<p>更新说明：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.firefox.com%2Fen-US%2Ffirefox%2F144.0%2Freleasenotes%2F" target="_blank">https://www.firefox.com/en-US/firefox/144.0/releasenotes/</a></p>]]>
    </description>
    <content:encoded><![CDATA[<p>Firefox 144.0 现已发布，具体更新内容如下：</p>
<p><strong>New</strong></p>
<ul>
<li> <p>专注于组中的单个标签页，告别杂乱。现在，活动标签页仍会保留在视图中，即使折叠标签组也能保持界面整洁。</p> <p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6722c234bd.png"></p> </li>
<li> <p>标签页组更新。现在，可以将标签页拖放到折叠的组中，而不会自动展开。这既能快速保持界面整洁，又能最大限度减少视觉干扰。</p> </li>
<li>  <p><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsupport.mozilla.org%2Fkb%2Fprofile-management" target="_blank">Profile management 功能</a>将在未来几周内逐步面向全球用户推出，它将你的在线生活划分为不同的个人资料，涵盖工作、学习、度假计划或其他任何你喜欢的用途，从而帮助保护隐私并保持专注。用户可以命名，并使用头像和颜色主题进行自定义，以便于识别；在不同资料间切换时，书签、标签页和浏览历史记录将完全独立保存。全新的个人资料功能适用于 Windows 11、Mac 和 Linux 用户，Windows 10 即将支持。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p> <p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-0fae6a9eeb.png"></p> </li>
<li>
<p>现在，可以关闭<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsupport.mozilla.org%2Fkb%2Fabout-picture-picture-firefox" target="_blank">画中画</a>窗口而无需暂停视频。按下<code>Shift + Click</code>关闭按钮或使用<code>Shift + Esc</code>退出，同时保持播放不间断。</p>
</li>
<li>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsupport.mozilla.org%2Fkb%2Fmanage-your-logins-firefox-password-manager" target="_blank">Firefox Password Manager</a>&nbsp;中存储的登录信息现在使用现代加密方案 (AES-256-CBC) 在磁盘上加密，取代了旧版的 3DES-CBC。此更改增强了本地数据保护。通过 Firefox Sync 同步的登录信息仍保持端到端加密，并且已使用 AES-256-GCM。</p>
</li>
<li>
<p><strong>Visual search powered by Google Lens</strong></p>
<p>只需右键单击任意图像，现在就可以：</p>
<ul>
<li>查找类似的产品、地点或物品</li>
<li>从图像中复制、翻译或搜索文本</li>
<li>获取学习、旅行或购物的灵感</li>
</ul>
<p>在右键菜单中找到新的“<strong>Search Image with Google Lens</strong>”选项（初始显示为带<strong>“NEW”</strong>标识的选项）。 此<strong>功能仅限桌面端</strong>，并已在全球范围内推出。<strong>必须将默认搜索引擎设置为 Google&nbsp;</strong>才能使用此功能。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-e163684ac8.png"></p>
</li>
<li><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><strong>Firefox 中的 Perplexity AI 搜索</strong></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>&nbsp;<span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>在桌面版 Firefox 中，现已集成&nbsp;<strong>Perplexity</strong>。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></li>
<li> <p><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>现可翻译以下语言：</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p>
<ul>
<li>阿塞拜疆</li>
<li>孟加拉语</li>
<li>冰岛语</li>
</ul> </li>
</ul>
<p><strong>Fixed</strong></p>
<ul>
<li>各种<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.mozilla.org%2Fsecurity%2Fadvisories%2Fmfsa2025-81" target="_blank">安全修复</a>。</li>
<li> <p><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>以下语言的翻译质量已得到提高：</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p>
<ul>
<li>阿拉伯</li>
<li>保加利亚语</li>
<li>加泰罗尼亚语</li>
<li>简体中文</li>
<li>捷克语</li>
<li>荷兰语</li>
<li>爱沙尼亚语</li>
<li>芬兰</li>
<li>法语</li>
<li>德语</li>
<li>匈牙利</li>
<li>意大利语</li>
<li>日语</li>
<li>葡萄牙语</li>
<li>波斯语</li>
<li>西班牙语</li>
<li>乌克兰语</li>
</ul> </li>
</ul>
<p><strong>Changed</strong></p>
<ul>
<li><span>在 Windows 上，当从另一个应用程序打开链接时，Firefox 将仅使用当前虚拟桌面上的窗口或在需要时打开一个新窗口。</span></li>
</ul>
<p><strong>Developer</strong></p>
<ul>
<li>
<p>现在可以从样式规则中的<code>var()</code>函数内跳转到 CSS 自定义属性的定义。</p>
</li>
<li>
<p>现在，检查器中的事件工具提示会在自定义事件旁边显示一个标识，从而更容易将它们与内置事件区分开来。</p>
</li>
</ul>
<p><strong>Web Platform</strong></p>
<ul>
<li>
<p>Firefox 现在支持<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FElement%2FmoveBefore" target="_blank">Element.moveBefore</a>&nbsp;API。</p>
</li>
<li>
<p>Firefox 现在支持<code>math-shift</code>&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FCSS%2Fmath-shift%23compact" target="_blank">compact</a>。</p>
</li>
<li>
<p>Firefox 现已支持<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FPerformanceEventTiming%2FinteractionId" target="_blank">PerformanceEventTiming.interactionId</a>，允许开发者对相关输入事件进行分组。这为 Interaction to Next Paint (INP) responsiveness metric 提供了支持。</p>
</li>
<li>
<p>Firefox 现在支持<code>command</code>和<code>commandfor</code>属性。</p>
</li>
<li>
<p>Firefox 现在支持&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FView_Transition_API" target="_blank">View Transitions</a>&nbsp;API Level 1。View Transitions API 提供了一种在不同网站视图之间轻松创建动画过渡的机制。</p>
</li>
<li>
<p>现在，当使用硬件 WebRender 渲染<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FCSS%2Fgradient%2Flinear-gradient" target="_blank">线性渐变</a>、<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FCSS%2Fgradient%2Fconic-gradient" target="_blank">圆锥渐变</a>和<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FCSS%2Fgradient%2Fradial-gradient" target="_blank">径向渐变</a>时，会应用抖动。</p>
</li>
<li> <p>Firefox 现在支持&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ftc39%2Fproposal-upsert" target="_blank">upsert 提案</a>。该提案为<code>Map</code>和<code>WeakMap</code>添加<code>getOrInsert</code>和<code>getOrInsertComputed</code>方法。这些方法可返回键关联的值，或插入默认值后返回该值，简化了处理键是否存在于<code>Map</code>和<code>WeakMap</code>中的场景。</p> </li>
<li>
<p>Firefox 现已在 Windows 平板和 Android 设备上支持<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FScreenOrientation" target="_blank">ScreenOrientation</a>&nbsp;接口的<code>lock()</code>和<code>unlock()</code>方法。</p>
</li>
<li>
<p>Firefox 现在支持&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FRTCDataChannel" target="_blank">RTCDataChannel</a>&nbsp;的&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FWeb_Workers_API%2FTransferable_objects" target="_blank">worker transfer</a>。</p>
</li>
<li>
<p>Firefox 现在支持<code>resizeMode</code>&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FMediaDevices%2FgetUserMedia" target="_blank">getUserMedia</a>&nbsp;constraint，允许开发人员将从摄像头捕获的视频裁剪和缩小到他们选择的任何分辨率。</p>
</li>
<li>
<p>Firefox 现在支持 Windows 上的&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FWebGPU_API" target="_blank">WebGPU&nbsp;</a><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FGPUDevice%2FimportExternalTexture" target="_blank">GPUDevice.importExternalTexture API 。</a></p>
</li>
<li>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FWebCodecs_API" target="_blank">Windows 上的 WebCodecs</a>&nbsp;现在具有 VideoEncoder 的批量编码路径，由于默认批量大小较大，因此吞吐量更高、提交延迟更低，从而提高了性能。</p>
</li>
<li>
<p>Gecko-specific<code>CSS2Properties</code>已重命名为<code>CSSStyleProperties</code>，以符合最新的 Web 标准并实现与其他浏览器引擎更好的互操作性。</p>
</li>
</ul>
<p>更新说明：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.firefox.com%2Fen-US%2Ffirefox%2F144.0%2Freleasenotes%2F" target="_blank">https://www.firefox.com/en-US/firefox/144.0/releasenotes/</a></p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6722c234bd.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6722c234bd.png" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 10:30:38 +0800</pubDate>
  </item><item>
    <title><![CDATA[通义千问 Qwen3-VL 上新：4B &amp; 8B 稠密模型]]></title>
    <link>https://www.oschina.net/news/377479</link>
    <itunes:title><![CDATA[通义千问 Qwen3-VL 上新：4B &amp; 8B 稠密模型]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>阿里通义 Qwen 团队正式发布 Qwen3-VL 系列的全新成员 —— 4B 与 8B 模型。Qwen3-VL 系列模型于上月<a href="https://www.oschina.net/news/374093" target="_blank">发布</a>，是迄今为止 Qwen 系列中最强大的视觉语言模型。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-a3b515f16e.png"></p>
<p>本次发布包含了 4B 和 8B 两种参数规模，两个尺寸均提供&nbsp;Instruct&nbsp;与&nbsp;Thinking&nbsp;版本。</p>
<p>新模型实现了以下关键目标:</p>
<ul>
<li>更低的资源门槛：尺寸缩减显著降低 VRAM 的占用。现在，开发者可以在更广泛的硬件设备上部署和运行模型。</li>
<li>在缩减尺寸的同时，完整保留了 Qwen3-VL 的全部核心功能。</li>
<li>卓越的基准性能:&nbsp;在 STEM、VQA、OCR、视频理解及 Agent 任务等多个权威基准上，其表现不仅超越了 Gemini&nbsp;2.5&nbsp;Flash&nbsp;Lite 和 GPT-5&nbsp;Nano，在许多场景下甚至能与半年前的旗舰模型 Qwen2.5-VL-72B 相媲美。</li>
</ul>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-ef692ad5ec.jpg"></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-d0626c8c72.jpg"></p>
<p>模型地址：<em>https://huggingface.co/collections/Qwen/qwen3-vl-68d2a7c1b8a8afce4ebd2dbe</em></p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>阿里通义 Qwen 团队正式发布 Qwen3-VL 系列的全新成员 —— 4B 与 8B 模型。Qwen3-VL 系列模型于上月<a href="https://www.oschina.net/news/374093" target="_blank">发布</a>，是迄今为止 Qwen 系列中最强大的视觉语言模型。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-a3b515f16e.png"></p>
<p>本次发布包含了 4B 和 8B 两种参数规模，两个尺寸均提供&nbsp;Instruct&nbsp;与&nbsp;Thinking&nbsp;版本。</p>
<p>新模型实现了以下关键目标:</p>
<ul>
<li>更低的资源门槛：尺寸缩减显著降低 VRAM 的占用。现在，开发者可以在更广泛的硬件设备上部署和运行模型。</li>
<li>在缩减尺寸的同时，完整保留了 Qwen3-VL 的全部核心功能。</li>
<li>卓越的基准性能:&nbsp;在 STEM、VQA、OCR、视频理解及 Agent 任务等多个权威基准上，其表现不仅超越了 Gemini&nbsp;2.5&nbsp;Flash&nbsp;Lite 和 GPT-5&nbsp;Nano，在许多场景下甚至能与半年前的旗舰模型 Qwen2.5-VL-72B 相媲美。</li>
</ul>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-ef692ad5ec.jpg"></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-d0626c8c72.jpg"></p>
<p>模型地址：<em>https://huggingface.co/collections/Qwen/qwen3-vl-68d2a7c1b8a8afce4ebd2dbe</em></p>]]>
    </description>
    <content:encoded><![CDATA[<p>阿里通义 Qwen 团队正式发布 Qwen3-VL 系列的全新成员 —— 4B 与 8B 模型。Qwen3-VL 系列模型于上月<a href="https://www.oschina.net/news/374093" target="_blank">发布</a>，是迄今为止 Qwen 系列中最强大的视觉语言模型。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-a3b515f16e.png"></p>
<p>本次发布包含了 4B 和 8B 两种参数规模，两个尺寸均提供&nbsp;Instruct&nbsp;与&nbsp;Thinking&nbsp;版本。</p>
<p>新模型实现了以下关键目标:</p>
<ul>
<li>更低的资源门槛：尺寸缩减显著降低 VRAM 的占用。现在，开发者可以在更广泛的硬件设备上部署和运行模型。</li>
<li>在缩减尺寸的同时，完整保留了 Qwen3-VL 的全部核心功能。</li>
<li>卓越的基准性能:&nbsp;在 STEM、VQA、OCR、视频理解及 Agent 任务等多个权威基准上，其表现不仅超越了 Gemini&nbsp;2.5&nbsp;Flash&nbsp;Lite 和 GPT-5&nbsp;Nano，在许多场景下甚至能与半年前的旗舰模型 Qwen2.5-VL-72B 相媲美。</li>
</ul>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-ef692ad5ec.jpg"></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-d0626c8c72.jpg"></p>
<p>模型地址：<em>https://huggingface.co/collections/Qwen/qwen3-vl-68d2a7c1b8a8afce4ebd2dbe</em></p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-a3b515f16e.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-a3b515f16e.png" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 10:19:40 +0800</pubDate>
  </item><item>
    <title><![CDATA[OpenAI CEO 称 ChatGPT 将发布新版本，允许提供成人内容]]></title>
    <link>https://www.oschina.net/news/377476</link>
    <itunes:title><![CDATA[OpenAI CEO 称 ChatGPT 将发布新版本，允许提供成人内容]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>OpenAI CEO Sam Altman <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fsama%2Fstatus%2F1978129344598827128" target="_blank">宣布</a>，ChatGPT 将会在未来几周内发布新版本，<strong>并会在 12 月推出更为全面的年龄分级，允许 ChatGPT 提供成人内容</strong>。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6ddcb220a1.png"></p>
<p>Altman 表示，此前 OpenAI 对 ChatGPT 有不少内容限制，并且对心理健康问题一直保持谨慎态度。Altman 称团队意识到这使许多没有心理健康问题的用户觉得 ChatGPT 用起来“不爽”或“不愉快”，但鉴于问题的严重性，我们希望做到这一点。（指内容限制）</p>
<p>目前，针对开放内容限制，Altman 透露 OpenAI 已经能够减轻严重的心理健康问题，并且拥有了新的工具，团队将能够在大多数情况下安全地放宽限制。</p>
<p>Altman 透露，未来几周内，新版本的 ChatGPT 能够实现更有“人味”的回应方式，能用大量的 emoji，表现得像朋友一样。</p>
<p>同时，Altman 还宣布，ChatGPT 将会在今年 12 月推出更全面的年龄分级，并作为“将成年用户视为成年人”原则的一部分。具体来看，ChatGPT 将允许更多内容生成，例如能够为通过“成年验证”的成年人提供色情内容。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>OpenAI CEO Sam Altman <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fsama%2Fstatus%2F1978129344598827128" target="_blank">宣布</a>，ChatGPT 将会在未来几周内发布新版本，<strong>并会在 12 月推出更为全面的年龄分级，允许 ChatGPT 提供成人内容</strong>。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6ddcb220a1.png"></p>
<p>Altman 表示，此前 OpenAI 对 ChatGPT 有不少内容限制，并且对心理健康问题一直保持谨慎态度。Altman 称团队意识到这使许多没有心理健康问题的用户觉得 ChatGPT 用起来“不爽”或“不愉快”，但鉴于问题的严重性，我们希望做到这一点。（指内容限制）</p>
<p>目前，针对开放内容限制，Altman 透露 OpenAI 已经能够减轻严重的心理健康问题，并且拥有了新的工具，团队将能够在大多数情况下安全地放宽限制。</p>
<p>Altman 透露，未来几周内，新版本的 ChatGPT 能够实现更有“人味”的回应方式，能用大量的 emoji，表现得像朋友一样。</p>
<p>同时，Altman 还宣布，ChatGPT 将会在今年 12 月推出更全面的年龄分级，并作为“将成年用户视为成年人”原则的一部分。具体来看，ChatGPT 将允许更多内容生成，例如能够为通过“成年验证”的成年人提供色情内容。</p>]]>
    </description>
    <content:encoded><![CDATA[<p>OpenAI CEO Sam Altman <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fsama%2Fstatus%2F1978129344598827128" target="_blank">宣布</a>，ChatGPT 将会在未来几周内发布新版本，<strong>并会在 12 月推出更为全面的年龄分级，允许 ChatGPT 提供成人内容</strong>。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6ddcb220a1.png"></p>
<p>Altman 表示，此前 OpenAI 对 ChatGPT 有不少内容限制，并且对心理健康问题一直保持谨慎态度。Altman 称团队意识到这使许多没有心理健康问题的用户觉得 ChatGPT 用起来“不爽”或“不愉快”，但鉴于问题的严重性，我们希望做到这一点。（指内容限制）</p>
<p>目前，针对开放内容限制，Altman 透露 OpenAI 已经能够减轻严重的心理健康问题，并且拥有了新的工具，团队将能够在大多数情况下安全地放宽限制。</p>
<p>Altman 透露，未来几周内，新版本的 ChatGPT 能够实现更有“人味”的回应方式，能用大量的 emoji，表现得像朋友一样。</p>
<p>同时，Altman 还宣布，ChatGPT 将会在今年 12 月推出更全面的年龄分级，并作为“将成年用户视为成年人”原则的一部分。具体来看，ChatGPT 将允许更多内容生成，例如能够为通过“成年验证”的成年人提供色情内容。</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6ddcb220a1.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6ddcb220a1.png" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 10:12:30 +0800</pubDate>
  </item><item>
    <title><![CDATA[最新数据显示：网络上超过 50% 的文章是 AI 生成的]]></title>
    <link>https://www.oschina.net/news/377475</link>
    <itunes:title><![CDATA[最新数据显示：网络上超过 50% 的文章是 AI 生成的]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>根据<span>最新</span>的研究报告，网络上约有一半的新文章是由人工智能生成的。这项研究由 SEO 公司 Graphite 发布，分析了2020年1月至2025年5月间发布的65000篇英文文章。为了评估这些文章是否由 AI 撰写，研究团队使用了名为 Surfer 的 AI 检测工具，任何被判定为50% 以上内容由大型语言模型生成的文章都被视为 AI 生成的。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6a425afd08.png"></p>
<p>自从2022年11月 ChatGPT 公开推出以来，AI 生成内容的数量呈现出快速上升的趋势。根据报告的数据，AI 生成的文章比例从2022年底的约10% 迅速上升到2024年的40% 以上，之后的增长速度有所放缓。到2025年5月，AI 生成的文章所占比例达到52%，与人类写作的文章数量相当，双方呈现出五五开的局面。</p>
<p>更令人欣慰的是，AI 文章的比例似乎已达到一个平台期。在2024年11月达到高峰后，AI 和人类写作的文章比例一直在50% 左右徘徊。此外，研究者指出，实际上人类撰写的文章比例可能更高，因为许多付费网站开始阻止 Common Crawl（一个开源数据集）对其页面的索引。这意味着一些人类写作的内容可能被排除在分析之外。</p>
<p>需要注意的是，AI 检测工具的准确性也是值得怀疑的。在对 Surfer 进行测试时，Graphite 发现其将4.2% 的人工撰写文章误判为 AI 生成，而将0.6% 的 AI 生成文章误判为人类撰写。因此，尽管 AI 生成文章数量在上升，但在搜索引擎和聊天机器人响应中，人类写作的文章仍占据<span>绝对</span>优势。</p>
<p>关于 AI 文章数量停滞的原因，目前尚不明确。根据 Graphite 的第二份报告，AI 内容生成者可能意识到，劣质的 AI 生成内容在搜索引擎中的曝光率不高，因此越来越多的文章是由人类创作的，数据显示在 Google 搜索中，86% 的文章是人类撰写的，仅有14% 是 AI 生成的。</p>
<p>如今，越来越多的作家开始在创作过程中使用 AI 聊天机器人等工具，这种情况模糊了机器生成内容和人类创作内容之间的界限。正如加州大学洛杉矶分校计算机科学教授斯特凡诺・索阿托所说:“此时，机器与人类的关系更像是一种共生关系，而不是简单的对立关系。”</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>根据<span>最新</span>的研究报告，网络上约有一半的新文章是由人工智能生成的。这项研究由 SEO 公司 Graphite 发布，分析了2020年1月至2025年5月间发布的65000篇英文文章。为了评估这些文章是否由 AI 撰写，研究团队使用了名为 Surfer 的 AI 检测工具，任何被判定为50% 以上内容由大型语言模型生成的文章都被视为 AI 生成的。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6a425afd08.png"></p>
<p>自从2022年11月 ChatGPT 公开推出以来，AI 生成内容的数量呈现出快速上升的趋势。根据报告的数据，AI 生成的文章比例从2022年底的约10% 迅速上升到2024年的40% 以上，之后的增长速度有所放缓。到2025年5月，AI 生成的文章所占比例达到52%，与人类写作的文章数量相当，双方呈现出五五开的局面。</p>
<p>更令人欣慰的是，AI 文章的比例似乎已达到一个平台期。在2024年11月达到高峰后，AI 和人类写作的文章比例一直在50% 左右徘徊。此外，研究者指出，实际上人类撰写的文章比例可能更高，因为许多付费网站开始阻止 Common Crawl（一个开源数据集）对其页面的索引。这意味着一些人类写作的内容可能被排除在分析之外。</p>
<p>需要注意的是，AI 检测工具的准确性也是值得怀疑的。在对 Surfer 进行测试时，Graphite 发现其将4.2% 的人工撰写文章误判为 AI 生成，而将0.6% 的 AI 生成文章误判为人类撰写。因此，尽管 AI 生成文章数量在上升，但在搜索引擎和聊天机器人响应中，人类写作的文章仍占据<span>绝对</span>优势。</p>
<p>关于 AI 文章数量停滞的原因，目前尚不明确。根据 Graphite 的第二份报告，AI 内容生成者可能意识到，劣质的 AI 生成内容在搜索引擎中的曝光率不高，因此越来越多的文章是由人类创作的，数据显示在 Google 搜索中，86% 的文章是人类撰写的，仅有14% 是 AI 生成的。</p>
<p>如今，越来越多的作家开始在创作过程中使用 AI 聊天机器人等工具，这种情况模糊了机器生成内容和人类创作内容之间的界限。正如加州大学洛杉矶分校计算机科学教授斯特凡诺・索阿托所说:“此时，机器与人类的关系更像是一种共生关系，而不是简单的对立关系。”</p>]]>
    </description>
    <content:encoded><![CDATA[<p>根据<span>最新</span>的研究报告，网络上约有一半的新文章是由人工智能生成的。这项研究由 SEO 公司 Graphite 发布，分析了2020年1月至2025年5月间发布的65000篇英文文章。为了评估这些文章是否由 AI 撰写，研究团队使用了名为 Surfer 的 AI 检测工具，任何被判定为50% 以上内容由大型语言模型生成的文章都被视为 AI 生成的。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6a425afd08.png"></p>
<p>自从2022年11月 ChatGPT 公开推出以来，AI 生成内容的数量呈现出快速上升的趋势。根据报告的数据，AI 生成的文章比例从2022年底的约10% 迅速上升到2024年的40% 以上，之后的增长速度有所放缓。到2025年5月，AI 生成的文章所占比例达到52%，与人类写作的文章数量相当，双方呈现出五五开的局面。</p>
<p>更令人欣慰的是，AI 文章的比例似乎已达到一个平台期。在2024年11月达到高峰后，AI 和人类写作的文章比例一直在50% 左右徘徊。此外，研究者指出，实际上人类撰写的文章比例可能更高，因为许多付费网站开始阻止 Common Crawl（一个开源数据集）对其页面的索引。这意味着一些人类写作的内容可能被排除在分析之外。</p>
<p>需要注意的是，AI 检测工具的准确性也是值得怀疑的。在对 Surfer 进行测试时，Graphite 发现其将4.2% 的人工撰写文章误判为 AI 生成，而将0.6% 的 AI 生成文章误判为人类撰写。因此，尽管 AI 生成文章数量在上升，但在搜索引擎和聊天机器人响应中，人类写作的文章仍占据<span>绝对</span>优势。</p>
<p>关于 AI 文章数量停滞的原因，目前尚不明确。根据 Graphite 的第二份报告，AI 内容生成者可能意识到，劣质的 AI 生成内容在搜索引擎中的曝光率不高，因此越来越多的文章是由人类创作的，数据显示在 Google 搜索中，86% 的文章是人类撰写的，仅有14% 是 AI 生成的。</p>
<p>如今，越来越多的作家开始在创作过程中使用 AI 聊天机器人等工具，这种情况模糊了机器生成内容和人类创作内容之间的界限。正如加州大学洛杉矶分校计算机科学教授斯特凡诺・索阿托所说:“此时，机器与人类的关系更像是一种共生关系，而不是简单的对立关系。”</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6a425afd08.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6a425afd08.png" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 10:09:20 +0800</pubDate>
  </item><item>
    <title><![CDATA[GreatSQL 8.4.4-4 GA (2025-10-15)]]></title>
    <link>https://www.oschina.net/news/377461</link>
    <itunes:title><![CDATA[GreatSQL 8.4.4-4 GA (2025-10-15)]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<h1><strong>GreatSQL 8.4.4-4 GA (2025-10-15)</strong></h1>
<h2><strong>版本信息</strong></h2>
<ul>
<li> <p>发布时间：2025年10月15日</p> </li>
<li> <p>版本号：8.4.4-4, Revision d73de75905d</p> </li>
<li> <p>下载链接：https://gitee.com/GreatSQL/GreatSQL/releases/tag/GreatSQL-8.4.4-4</p> </li>
<li> <p>用户手册：https://greatsql.cn/docs/8.4.4-4/</p> </li>
</ul>
<h2><strong>特性增强</strong></h2>
<p>GreatSQL 8.4.4.-4版本在Percona Server for MySQL 8.4.4-4版本的基础上，主要在 <strong>高可用</strong>、<strong>高性能</strong>、<strong>高兼容</strong>、<strong>高安全</strong>四个方面进行了多项特性增强，使得 GreatSQL 可在普通硬件上满足金融级应用场景，可作为 MySQL 或 Percona Server for MySQL 的理想可选替换。</p>
<h3><strong>高可用</strong></h3>
<p>针对 MGR 及主从复制进行了大量改进和提升工作，支持 地理标签、仲裁节点、读写动态 VIP、快速单主模式、智能选主 等特性，并针对 流控算法、事务认证队列清理算法、节点加入&amp;退出机制、recovery机制、大事务传输压缩等多个 MGR 底层工作机制算法进行深度优化，进一步提升优化了 MGR 的高可用保障及性能稳定性。</p>
<ul>
<li>支持 地理标签 特性，提升多机房架构数据可靠性。</li>
<li>支持 仲裁节点 特性，用更低的服务器成本实现更高可用。</li>
<li>支持 读写动态 VIP 特性，高可用切换更便捷，更快实现读负载均衡。支持 当主节点切换时，主动关闭当前活跃连接，缩短应用端不可用时长。。</li>
<li>支持 快速单主模式，在单主模式下更快，性能更高。</li>
<li>支持 智能选主 特性，高可用切换选主机制更合理。</li>
<li>优化 流控算法，使得事务更平稳，避免剧烈抖动。</li>
<li>支持 记录 MGR 网络通信开销超过阈值的事件，用于进一步分析和优化。</li>
<li>支持自动选择从最新事务数据的成员节点复制数据，可有效提升 Clone 速度，提高 MGR 的服务可靠性。</li>
<li>在主从复制中，从节点向主节点发起 Binlog 读取请求时支持限速控制。</li>
<li>优化了 asynchronous connection failover 中的故障检测效率，降低主从复制链路断开的时间，提高整体可用性。
<ul>
<li>https://dev.mysql.com/doc/refman/8.0/en/replication-asynchronous-connection-failover.html</li>
</ul> </li>
<li>支持在跨机房容灾场景中的 主主双向复制防止回路 机制。</li>
<li>优化了 MGR 节点加入、退出时可能导致性能剧烈抖动的问题。</li>
<li>解决了个别节点上磁盘空间爆满时导致MGR集群整体被阻塞的问题。</li>
<li>优化了 MGR 事务认证队列清理算法，高负载下不复存在每 60 秒性能抖动问题。</li>
<li>解决了 MGR 中长事务造成无法选主的问题。</li>
<li>修复了 MGR recovery 过程中长时间等待的问题。</li>
<li>优化了MGR大事务传输时压缩超过限制的处理机制。</li>
</ul>
<p>更多信息详见文档：</p>
<ul>
<li>高可用：https://greatsql.cn/docs/8.4.4-4/5-enhance/5-2-ha.html</li>
</ul>
<h3><strong>高性能</strong></h3>
<p>相对 MySQL 及 Percona Server For MySQL 的性能表现更稳定优异，支持 Rapid 引擎、Turbo引擎、事务无锁化、并行 LOAD DATA、异步删除大表、线程池、非阻塞式 DDL、NUMA 亲和调度优化 等特性，在 TPC-C 测试中相对 MySQL 性能提升超过 30%</p>
<ul>
<li>https://greatsql.cn/docs/8.4.4-4/10-optimize/3-5-benchmark-greatsql-vs-mysql-tpcc-report.html</li>
</ul>
<p>在 TPC-H 测试中的性能表现是 MySQL 的十几倍甚至上百倍</p>
<ul>
<li> <p>https://greatsql.cn/docs/8.4.4-4/10-optimize/3-3-benchmark-greatsql-tpch-report.html</p> </li>
<li> <p>支持 大规模并行、基于内存查询、高压缩比的高性能 Rapid 引擎，可将数据分析性能提升几个数量级。</p> </li>
<li> <p>支持 高性能并行查询引擎Turbo，使GreatSQL具备多线程并发的向量化实时查询功能。</p> </li>
<li> <p>优化 InnoDB 事务系统，实现了大锁拆分及无锁化等多种优化方案，OLTP 场景整体性能提升约 20%。</p> </li>
<li> <p>支持 并行 LOAD DATA，适用于频繁导入大批量数据的应用场景，性能可提升约 20 多倍；对于无显式定义主键的场景亦有优化提升。</p> </li>
<li> <p>支持 异步删除大表，提高 InnoDB 引擎运行时性能的稳定性。</p> </li>
<li> <p>支持 线程池，降低了线程创建和销毁的代价，保证高并发下，性能稳定不会明显衰退。</p> </li>
<li> <p>支持 非阻塞式 DDL，可以避免数据库因为必须尽快完成 DDL 操作而导致业务请求大量被阻塞的问题。</p> </li>
<li> <p>支持 NUMA 亲和性优化，通过 NUMA 亲和性调度优化，将前端用户线程和后台线程绑定到固定 NUMA 节点上以提升线程处理性能。</p> </li>
</ul>
<p>更多信息详见文档：</p>
<ul>
<li>高性能：https://greatsql.cn/docs/8.4.4-4/5-enhance/5-1-highperf.html</li>
</ul>
<h3><strong>高兼容</strong></h3>
<p>GreatSQL 实现 100% 完全兼容 MySQL 及 Percona Server For MySQL 语法，支持大多数常见 Oracle 语法，包括<code>数据类型兼容</code>、<code>函数兼容</code>、<code>SQL 语法兼容</code>、<code>存储程序兼容</code>等众多兼容扩展用法。</p>
<p>更多信息详见文档：</p>
<ul>
<li>高兼容：https://greatsql.cn/docs/8.4.4-4/5-enhance/5-3-easyuse.html</li>
</ul>
<h3><strong>高安全</strong></h3>
<p>GreatSQL 支持逻辑备份加密、CLONE 备份加密、审计、表空间国密加密、敏感数据脱敏、存储登录历史等多个安全提升特性，进一步保障业务数据安全，更适用于金融级应用场景。</p>
<ul>
<li>支持 mysqldump 逻辑备份加密，提供了利用 mysqldump 逻辑备份的安全加密需求。</li>
<li>支持 Clone 备份加密，提供了利用 Clone 物理备份的安全加密需求。</li>
<li>支持 审计功能，及时记录和发现未授权或不安全行为。</li>
<li>支持 InnoDB 表空间国密加密算法，确保重要数据的加密安全。</li>
<li>支持 基于函数和策略的两种数据脱敏 工作方式，保障敏感用户数据查询结果保密性。</li>
</ul>
<p>通过上述多个安全提升特性，进一步保障业务数据安全。</p>
<p>更多信息详见文档：</p>
<ul>
<li>高安全：https://greatsql.cn/docs/8.4.4-4/5-enhance/5-4-security.html</li>
</ul>
<h3><strong>其他</strong></h3>
<ul>
<li>支持 Clone 在线全量热备、增备及恢复，结合 Binlog 可实现恢复到指定时间点。此外，Clone 备份还支持压缩功能。
<ul>
<li>https://greatsql.cn/docs/8.4.4-4/5-enhance/5-5-clone-compressed-and-incrment-backup.html</li>
</ul> </li>
<li>支持 InnoDB Page透明压缩采用Zstd算法，进一步提高数据压缩率，尤其是当有大量长文本重复数据时。
<ul>
<li>https://greatsql.cn/docs/8.4.4-4/5-enhance/5-5-innodb-page-compression.html</li>
</ul> </li>
</ul>
<h2><strong>注意事项</strong></h2>
<p>从8.0升级到8.4版本，对现有运维管控系统最大的影响是，原先包含 <code>MASTER/SLAVE</code> 关键字的指令不再可用，相应的主要改动详见下表</p>
<table>
<tbody>
<tr>
<th>旧指令</th>
<th>新指令</th>
</tr>
</tbody>
<tbody>
<tr>
<td>START SLAVE</td>
<td>START REPLICA</td>
</tr>
<tr>
<td>STOP SLAVE</td>
<td>STOP REPLICA</td>
</tr>
<tr>
<td>SHOW SLAVE STATUS</td>
<td>SHOW REPLICA STATUS</td>
</tr>
<tr>
<td>SHOW SLAVE HOSTS</td>
<td>SHOW REPLICAS</td>
</tr>
<tr>
<td>RESET SLAVE</td>
<td>RESET REPLICA</td>
</tr>
<tr>
<td>CHANGE MASTER TO</td>
<td>CHANGE REPLICATION SOURCE TO</td>
</tr>
<tr>
<td>RESET MASTER</td>
<td>RESET BINARY LOGS AND GTIDS</td>
</tr>
<tr>
<td>SHOW MASTER STATUS</td>
<td>SHOW BINARY LOG STATUS</td>
</tr>
<tr>
<td>PURGE MASTER LOGS</td>
<td>PURGE BINARY LOGS</td>
</tr>
<tr>
<td>SHOW MASTER LOGS</td>
<td>SHOW BINARY LOGS</td>
</tr>
</tbody>
</table>
<p>此外，原来在 <code>CHANGE MASTER</code>（新的指令 <code>CHANGE REPLICATION SOURCE TO</code>） 以及 <code>START SLAVE</code>（新的指令 <code>START REPLICA</code>） 中相关的参数变量也同样发生变化，详见下表</p>
<table>
<tbody>
<tr>
<th>旧参数名</th>
<th>新参数名</th>
</tr>
</tbody>
<tbody>
<tr>
<td>MASTER_AUTO_POSITION</td>
<td>SOURCE_AUTO_POSITION</td>
</tr>
<tr>
<td>MASTER_HOST</td>
<td>SOURCE_HOST</td>
</tr>
<tr>
<td>MASTER_BIND</td>
<td>SOURCE_BIND</td>
</tr>
<tr>
<td>MASTER_USER</td>
<td>SOURCE_USER</td>
</tr>
<tr>
<td>MASTER_PASSWORD</td>
<td>SOURCE_PASSWORD</td>
</tr>
<tr>
<td>MASTER_PORT</td>
<td>SOURCE_PORT</td>
</tr>
<tr>
<td>MASTER_CONNECT_RETRY</td>
<td>SOURCE_CONNECT_RETRY</td>
</tr>
<tr>
<td>MASTER_RETRY_COUNT</td>
<td>SOURCE_RETRY_COUNT</td>
</tr>
<tr>
<td>MASTER_DELAY</td>
<td>SOURCE_DELAY</td>
</tr>
<tr>
<td>MASTER_SSL</td>
<td>SOURCE_SSL</td>
</tr>
<tr>
<td>MASTER_SSL_CA</td>
<td>SOURCE_SSL_CA</td>
</tr>
<tr>
<td>MASTER_SSL_CAPATH</td>
<td>SOURCE_SSL_CAPATH</td>
</tr>
<tr>
<td>MASTER_SSL_CIPHER</td>
<td>SOURCE_SSL_CIPHER</td>
</tr>
<tr>
<td>MASTER_SSL_CRL</td>
<td>SOURCE_SSL_CRL</td>
</tr>
<tr>
<td>MASTER_SSL_CRLPATH</td>
<td>SOURCE_SSL_CRLPATH</td>
</tr>
<tr>
<td>MASTER_SSL_KEY</td>
<td>SOURCE_SSL_KEY</td>
</tr>
<tr>
<td>MASTER_SSL_VERIFY_SERVER_CERT</td>
<td>SOURCE_SSL_VERIFY_SERVER_CERT</td>
</tr>
<tr>
<td>MASTER_TLS_VERSION</td>
<td>SOURCE_TLS_VERSION</td>
</tr>
<tr>
<td>MASTER_TLS_CIPHERSUITES</td>
<td>SOURCE_TLS_CIPHERSUITES</td>
</tr>
<tr>
<td>MASTER_SSL_CERT</td>
<td>SOURCE_SSL_CERT</td>
</tr>
<tr>
<td>MASTER_PUBLIC_KEY_PATH</td>
<td>SOURCE_PUBLIC_KEY_PATH</td>
</tr>
<tr>
<td>GET_MASTER_PUBLIC_KEY</td>
<td>GET_SOURCE_PUBLIC_KEY</td>
</tr>
<tr>
<td>MASTER_HEARTBEAT_PERIOD</td>
<td>SOURCE_HEARTBEAT_PERIOD</td>
</tr>
<tr>
<td>MASTER_COMPRESSION_ALGORITHMS</td>
<td>SOURCE_COMPRESSION_ALGORITHMS</td>
</tr>
<tr>
<td>MASTER_ZSTD_COMPRESSION_LEVEL</td>
<td>SOURCE_ZSTD_COMPRESSION_LEVEL</td>
</tr>
<tr>
<td>MASTER_LOG_FILE</td>
<td>SOURCE_LOG_FILE</td>
</tr>
<tr>
<td>MASTER_LOG_POS</td>
<td>SOURCE_LOG_POS</td>
</tr>
</tbody>
</table>
<p>执行 SQL 命令 <code>SHOW [GLOBAL] STATUS</code> 的结果中，也有部分状态变量发生变化，详见下表</p>
<table>
<tbody>
<tr>
<th>旧状态变量名</th>
<th>新状态变量名</th>
</tr>
</tbody>
<tbody>
<tr>
<td>Com_slave_start</td>
<td>Com_replica_start</td>
</tr>
<tr>
<td>Com_slave_stop</td>
<td>Com_replica_stop</td>
</tr>
<tr>
<td>Com_show_slave_status</td>
<td>Com_show_replica_status</td>
</tr>
<tr>
<td>Com_show_slave_hosts</td>
<td>Com_show_replicas</td>
</tr>
<tr>
<td>Com_show_master_status</td>
<td>Com_show_binary_log_status</td>
</tr>
<tr>
<td>Com_change_master</td>
<td>Com_change_replication_source</td>
</tr>
</tbody>
</table>
<h2><strong>升级/降级到 GreatSQL 8.4.4-4</strong></h2>
<h3><strong>升级到 GreatSQL 8.4.4-4</strong></h3>
<ul>
<li> <p>如果是 GreatSQL 5.7 等系列版本，可以直接在原来的 <code>datadir</code> 基础上，修改 <code>basedir</code> 后，原地（in-place）启动 GreatSQL 8.0.32-27 版本后，先原地升级到 GreatSQL 8.0.32-27 版本。再继续在该 <code>datadir</code> 基础上升级，即修改 <code>basedir</code> 指向 GreatSQL 8.4.4-4 新版本，再次进行原地升级。需要注意的是，从 5.7 版本升级到 8.0 版本，再升级到 8.4 版本后，数据库中的账号仍采用 <code>mysql_native_password</code> 密码验证插件。当最终升级到 8.4 版本后，需要修改 <em>my.cnf</em> 配置文件，加上 <code>mysql_native_password=1</code>，以保证原有的账号能正常登录。</p> </li>
<li> <p>如果是 GreatSQL 8.0 等系列版本，并且没有使用 <strong>Rapid</strong> 引擎，则可以直接在原来的 <code>datadir</code> 基础上，修改 <code>basedir</code> 后，原地（in-place）启动 GreatSQL 8.4.4-4 后会完成自动升级。</p> </li>
<li> <p>如果旧版本是 GreatSQL 8.0.32-27 且已启用 <strong>Rapid</strong> 引擎，可以直接在原来的 <code>datadir</code> 基础上，修改 <code>basedir</code> 后，原地（in-place）启动 GreatSQL 8.4.4-4 后会完成自动升级。</p> </li>
<li> <p>如果旧版本是 GreatSQL 8.0.32-25 或 8.0.32-26 且已启用 <strong>Rapid</strong> 引擎，<strong>这种情况下无法原地升级</strong>，需要卸载所有 <strong>Rapid</strong> 引擎表，删除 <strong>Rapid</strong> 数据文件，才可以在原来的 <code>datadir</code> 基础上，修改 <code>basedir</code> 后，原地（in-place）启动 GreatSQL 8.4.4-4 后进行自动升级。新版本实例启动后，对所有 <strong>Rapid</strong> 引擎表执行 <code>ALTER TABLE SECONDARY_LOAD</code> 完成全量数据导入，再执行 <code>SELECT START_SECONDARY_ENGINE_INCREMENT_LOAD_TASK()</code> 启动增量导入任务，完成 <strong>Rapid</strong> 引擎表升级工作。下面是一个升级参考过程：</p> <pre><code>&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong style="color:#000000"&gt;1. 查询并记录所有Rapid引擎表&lt;/strong&gt;
&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;可以执行下面的SQL，查询当前有哪些表使用了Rapid引擎：
&lt;pre style="margin-left:5px; margin-right:5px; text-align:left"&gt;
</code></pre> <p><code>greatsql&gt; <span>SELECT</span> TABLE_SCHEMA, TABLE_NAME, TABLE_ROWS <span>FROM</span> information_schema.TABLES <span>WHERE</span> CREATE_OPTIONS <span>LIKE</span> <span>'%Rapid%'</span>; +<em>--------------+----------------+------------+</em> | TABLE_SCHEMA | TABLE_NAME | TABLE_ROWS | +<em>--------------+----------------+------------+</em> | tpch100g | customer | 14854987 | | tpch100g | lineitem | 582868392 | | tpch100g | nation | 25 | | tpch100g | orders | 148492582 | | tpch100g | part | 19943155 | | tpch100g | partsupp | 79832625 | | tpch100g | region | 5 | | tpch100g | supplier | 989416 | +<em>--------------+----------------+------------+</em> </code></p> <pre><code>&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong style="color:#000000"&gt;2. 正常停止GreatSQL实例进程&lt;/strong&gt;
&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;在停止GreatSQL实例进程前，先修改&lt;code&gt;innodb_fast_shutdown=0&lt;/code&gt;后再执行&lt;code&gt;SHUTDOWN&lt;/code&gt;停止实例
&lt;pre style="margin-left:5px; margin-right:5px; text-align:left"&gt;
</code></pre> <p><code>greatsql&gt; <span>SET</span> <span>GLOBAL</span> innodb_fast_shutdown=<span>0</span>; greatsql&gt; SHUTDOWN; </code></p> <pre><code>&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong style="color:#000000"&gt;3. 删除旧的Rapid引擎数据文件&lt;/strong&gt;
&lt;pre style="margin-left:5px; margin-right:5px; text-align:left"&gt;
</code></pre> <p><code><span>cd</span> /data/GreatSQL &amp;&amp; rm -f duckdb* </code></p> <pre><code>&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong style="color:#000000"&gt;4. 修改&lt;code&gt;my.cnf&lt;/code&gt;配置文件中的&lt;code&gt;basedir&lt;/code&gt;参数，指向GreatSQL 8.4.4-4新版本&lt;/strong&gt;
&lt;pre style="margin-left:5px; margin-right:5px; text-align:left"&gt;
</code></pre> <p><code>#my.cnf [mysqld] basedir=/usr/local/GreatSQL-8.4.4-4-Linux-glibc2.28-x86_64 </code></p> <pre><code>&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;并确保参数&lt;code&gt;upgrade&lt;/code&gt;不是设置为&lt;em&gt;NONE&lt;/em&gt;。
&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong style="color:#000000"&gt;5. 启动GreatSQL 8.4.4-4新版本实例&lt;/strong&gt;
&lt;pre style="margin-left:5px; margin-right:5px; text-align:left"&gt;
</code></pre> <p><code>systemctl start greatsql </code></p> <pre><code>&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong style="color:#000000"&gt;6. 重新安装Rapid引擎&lt;/strong&gt;
&lt;pre style="margin-left:5px; margin-right:5px; text-align:left"&gt;
</code></pre> <p><code>greatsql&gt; <span>INSTALL</span> <span>PLUGIN</span> rapid <span>SONAME</span> <span>'ha_rapid.so'</span>; </code></p> <pre><code>&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong style="color:#000000"&gt;7. 对Rapid引擎表做一次全量数据导入&lt;/strong&gt;
&lt;pre style="margin-left:5px; margin-right:5px; text-align:left"&gt;
</code></pre> <p><code>greatsql&gt; <span>ALTER</span> <span>TABLE</span> test.t1 SECONDARY_LOAD; </code></p> </li>
</ul>
<blockquote>
<p>tip 小贴士：由于在升级前没有去掉该表的<code>SECONDARY_ENGINE=rapid</code>属性，所以无需重新设置。如果在升级前卸载所有Rapid引擎表，则需要重新设置。</p>
</blockquote>
<p><strong>8. 再次启动增量导入任务</strong></p>
<pre><code>greatsql&gt; <span>SELECT</span> START_SECONDARY_ENGINE_INCREMENT_LOAD_TASK(<span>'test'</span>, <span>'t1'</span>);
</code></pre>
<p>这就完成Rapid引擎表的升级操作了。</p>
<ul>
<li> <p>如果是 MySQL 5.7 或 Percona Server 5.7 等系列版本，可以直接在原来的 <code>datadir</code> 基础上，修改 <code>basedir</code> 后，原地（in-place）启动 GreatSQL 8.0.32-27 版本后，确认升级成功后，再次在原来 <code>datadir</code> 基础上继续升级，即修改 <code>basedir</code> 指向 GreatSQL 8.4.4-4 新版本，之后就能完成自动升级。需要注意的是，从 5.7 版本升级到 8.0 版本，再升级到 8.4 版本后，数据库中的账号仍采用 <code>mysql_native_password</code> 密码验证插件。当最终升级到 8.4 版本后，需要修改 <em>my.cnf</em> 配置文件，加上 <code>mysql_native_password=1</code>，以保证原有的账号能正常登录。</p> </li>
<li> <p>如果是 MySQL 8.0 或 Percona Server 8.0 等系列版本，则可以直接在原来的 <code>datadir</code> 基础上，修改 <code>basedir</code> 后，原地（in-place）启动 GreatSQL 8.4.4-4 后会完成自动升级。</p> </li>
<li> <p>其他情况下，最好采用导入逻辑备份文件方式升级到 GreatSQL 8.4.4-4 版本。</p> </li>
</ul>
<p>在以上几个原地升级场景中，务必保证<code>my.cnf</code>中参数<code>upgrade</code>不能设置为<em>NONE</em>，可以设置为默认的<em>AUTO</em>或<em>FORCE</em>。例如：</p>
<pre><code>#my.cnf
[mysqld]
upgrade = AUTO
</code></pre>
<p>更多迁移升级方案请参考：</p>
<ul>
<li>迁移升级：https://greatsql.cn/docs/8.4.4-4/7-migrate-and-upgrade/0-migrate-and-upgrade.html</li>
</ul>
<h3><strong>降级到 GreatSQL 8.4.4-4</strong></h3>
<p>如果是要从 MySQL/Percona 8.4 系列较高的小版本降级到 GreatSQL 8.4.4-4 版本，可以采用原地降级方式快速完成版本降级操作。即可以直接在原来的 <code>datadir</code> 基础上，修改 <code>basedir</code> 后，并增加设置参数<code>upgrade=FORCE</code>，原地（in-place）启动 GreatSQL 8.4.4-4 后会完成自动降级。</p>
<p>如果是要从 MySQL/Percona 9.0 及之后的版本降级到 GreatSQL 8.4.4-4 版本，则需要采取逻辑备份 + 逻辑导入方式完成降级操作，并且在逻辑备份导入完成后的首次重启时，务必设置 <code>upgrade=FORCE</code> 强制升级所有数据表，包括系统表。</p>
<p>降级过程操作大致如下所示：</p>
<p><strong>1. 在高版本中逻辑备份全量数据</strong></p>
<pre><code>mysqldump -S/data/MySQL/mysql.sock -A --triggers --routines --events --single-transaction &gt; /data/backup/fulldump.sql
</code></pre>
<p><strong>2. 在GreatSQL 8.4.4-4版本环境中导入逻辑备份文件，完成逻辑恢复</strong></p>
<pre><code>mysql -S/data/GreatSQL/mysql.sock -f &lt; /data/backup/fulldump.sql
</code></pre>
<p><strong>3. 修改<code>my.cnf</code>，确保设置<code>upgrade=FORCE</code></strong></p>
<pre><code>#my.cnf
[mysqld]
upgrade = FORCE
</code></pre>
<p><strong>4. 重启GreatSQL，降级完成</strong></p>
<pre><code>systemctl restart greatsql
</code></pre>
<p>重启过程中，可以看到日志有类似下面的强制降级过程</p>
<pre><code>[Note] [MY-013387] [Server] Upgrading system table data.
[Note] [MY-013385] [Server] Upgrading the sys schema.
[Note] [MY-013400] [Server] Upgrade of help tables started.
[Note] [MY-013400] [Server] Upgrade of help tables completed.
[Note] [MY-013394] [Server] Checking 'mysql' schema.
[Note] [MY-013394] [Server] Checking 'sys' schema.
[System] [MY-014064] [Server] Server downgrade from '80406' to '80404' started.
[System] [MY-014064] [Server] Server downgrade from '80406' to '80404' completed.
</code></pre>
<p>如果不设置 <code>upgrade = FORCE</code> 强制升级所有表，有可能发生系统表 <code>mysql.procs_priv</code> 损坏错误，在创建用户时可能会报告类似下面的错误：</p>
<pre><code>greatsql&gt; <span>CREATE</span> <span>USER</span> tpch <span>IDENTIFIED</span> <span>BY</span> <span>'tpch'</span>;
ERROR 1728 (HY000): Cannot <span>load</span> <span>from</span> mysql.procs_priv. The <span>table</span> <span>is</span> probably corrupted
</code></pre>
<h2><strong>GreatSQL vs MySQL</strong></h2>
<table>
<tbody>
<tr>
<th><strong>1.主要特性</strong></th>
<th>GreatSQL 8.4.4-4</th>
<th>MySQL 8.4.4</th>
</tr>
</tbody>
<tbody>
<tr>
<td>开源</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>ACID 完整性</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>MVCC 特性</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>支持行锁</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>Crash 自动修复</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>表分区（Partitioning）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>视图（Views）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>子查询（Subqueries）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>触发器（Triggers）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>存储程序（Stored Programs）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>外键（Foreign Keys）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>窗口函数（Window Functions）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>通用表表达式 CTE</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>地理信息（GIS）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>基于 GTID 的复制</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>组复制（MGR）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>MyRocks 引擎</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>支持龙芯架构</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td><strong>2. 性能提升扩展</strong></td>
<td>GreatSQL 8.4.4-4</td>
<td>MySQL 8.4.4</td>
</tr>
<tr>
<td>Rapid 引擎</td>
<td>✔️</td>
<td>仅云上HeatWave</td>
</tr>
<tr>
<td>Turbo 引擎</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>NUMA 亲和性优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>非阻塞式 DDL</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>无主键表导入优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>并行 LOAD DATA</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>InnoDB 事务 ReadView 无锁优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>InnoDB 事务大锁拆分优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>InnoDB Page压缩支持Zstd</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>InnoDB 资源组</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>自定义 InnoDB 页大小</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>Contention-Aware Transaction Scheduling</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>InnoDB Mutexes 拆分优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MEMORY 引擎优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>InnoDB Flushing 优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>并行 Doublewrite Buffer</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>InnoDB 快速索引创建优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>VARCHAR/BLOB/JSON 类型存储单列压缩</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>数据字典中存储单列压缩信息</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td><strong>3. 面向开发者提升改进</strong></td>
<td>GreatSQL 8.4.4-4</td>
<td>MySQL 8.4.4</td>
</tr>
<tr>
<td>X API</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>JSON</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>NoSQL Socket-Level接口</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>InnoDB 全文搜索改进</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>更多 Hash/Digest 函数</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Oracle 兼容-数据类型</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Oracle 兼容-函数</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Oracle 兼容-SQL语法</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Oracle 兼容-存储程序</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td><strong>4. 基础特性提升改进</strong></td>
<td>GreatSQL 8.4.4-4</td>
<td>MySQL 8.4.4</td>
</tr>
<tr>
<td>MGR 提升-地理标签</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-仲裁节点</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-读写节点绑定VIP</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-快速单主模式</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-智能选主机制</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-全新流控算法</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-网络分区异常处理</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-节点异常退出处理</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-节点磁盘满处理</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-自动选择 donor 节点</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-大事务压缩优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Clone 增量备份</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Clone 备份压缩</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Binlog 读取限速</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>information_schema 表数量</td>
<td>95</td>
<td>65</td>
</tr>
<tr>
<td>全局性能和状态指标</td>
<td>853</td>
<td>434</td>
</tr>
<tr>
<td>优化器直方图（Histograms）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>Per-Table 性能指标</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Per-Index 性能指标</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Per-User 性能指标</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Per-Client 性能指标</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Per-Thread 性能指标</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>全局查询相应耗时统计</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>SHOW ENGINE INNODB STATUS 增强</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>回滚段信息增强</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>临时表信息增强</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>用户统计信息增强</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Slow log 信息增强</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td><strong>5.安全性提升</strong></td>
<td>GreatSQL 8.4.4-4</td>
<td>MySQL 8.4.4</td>
</tr>
<tr>
<td>国密支持</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>备份加密</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>审计</td>
<td>✔️</td>
<td>仅企业版</td>
</tr>
<tr>
<td>数据脱敏</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>SQL Roles</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>SHA-2 密码Hashing</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>密码轮换策略</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>PAM 认证插件</td>
<td>✔️</td>
<td>仅企业版</td>
</tr>
<tr>
<td>Keyring 存储在文件中</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>Keyring 存储在Hashicorp Vault中</td>
<td>✔️</td>
<td>仅企业版</td>
</tr>
<tr>
<td>InnoDB 数据加密</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>InnoDB 日志加密</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>InnoDB 各种表空间文件加密</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>二进制日志加密</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>临时文件加密</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>强制加密</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td><strong>6. 运维便利性提升</strong></td>
<td>GreatSQL 8.4.4-4</td>
<td>MySQL 8.4.4</td>
</tr>
<tr>
<td>DDL 原子性</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>数据字典存储 InnoDB 表</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>快速 DDL</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>SET PERSIST</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>不可见索引</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>线程池（Threadpool）</td>
<td>✔️</td>
<td>仅企业版</td>
</tr>
<tr>
<td>备份锁</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>SHOW GRANTS 扩展</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>表损坏动作扩展</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>杀掉不活跃事务</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>START TRANSACTION WITH CONSISTENT SNAPSHOT 扩展</td>
<td>✔️</td>
<td>❌</td>
</tr>
</tbody>
</table>
<p>GreatSQL 8.4.4-4 基于 Percona Server for MySQL 8.4.4-4 版本，它在 MySQL 8.4.4 基础上做了大量的改进和提升以及众多新特性，详情请见：</p>
<ul>
<li>Percona Server for MySQL feature comparison: https://docs.percona.com/percona-server/8.4/feature-comparison.html</li>
</ul>
<p>这其中包括线程池、审计、数据脱敏等 MySQL 企业版才有的特性，以及 performance_schema 提升、information_schema 提升、性能和可扩展性提升、用户统计增强、PROCESSLIST 增强、Slow Log 增强等大量改进和提升，这里不一一重复列出。</p>
<h2><strong>GreatSQL Release Notes</strong></h2>
<h3><strong>GreatSQL 8.4</strong></h3>
<ul>
<li>Changes in GreatSQL 8.4.4-4 (2025-10-15) https://greatsql.cn/docs/8.4.4-4/1-docs-intro/relnotes/changes-greatsql-8444.html</li>
</ul>
<h3><strong>GreatSQL 8.0</strong></h3>
<ul>
<li>Changes in GreatSQL 8.0.32-27 (2025-3-10)</li>
<li>Changes in GreatSQL 8.0.32-26 (2024-8-5)</li>
<li>Changes in GreatSQL 8.0.32-25 (2023-12-28)</li>
<li>Changes in GreatSQL 8.0.32-24 (2023-6-5)</li>
<li>Changes in GreatSQL 8.0.25-17 (2023-3-13)</li>
<li>Changes in GreatSQL 8.0.25-16 (2022-5-16)</li>
<li>Changes in GreatSQL 8.0.25-15 (2021-8-26)</li>
</ul>
<h3><strong>GreatSQL 5.7</strong></h3>
<ul>
<li>Changes in GreatSQL 5.7.36-39 (2022-4-7)</li>
</ul>]]>
    </itunes:summary>
    <description>
      <![CDATA[<h1><strong>GreatSQL 8.4.4-4 GA (2025-10-15)</strong></h1>
<h2><strong>版本信息</strong></h2>
<ul>
<li> <p>发布时间：2025年10月15日</p> </li>
<li> <p>版本号：8.4.4-4, Revision d73de75905d</p> </li>
<li> <p>下载链接：https://gitee.com/GreatSQL/GreatSQL/releases/tag/GreatSQL-8.4.4-4</p> </li>
<li> <p>用户手册：https://greatsql.cn/docs/8.4.4-4/</p> </li>
</ul>
<h2><strong>特性增强</strong></h2>
<p>GreatSQL 8.4.4.-4版本在Percona Server for MySQL 8.4.4-4版本的基础上，主要在 <strong>高可用</strong>、<strong>高性能</strong>、<strong>高兼容</strong>、<strong>高安全</strong>四个方面进行了多项特性增强，使得 GreatSQL 可在普通硬件上满足金融级应用场景，可作为 MySQL 或 Percona Server for MySQL 的理想可选替换。</p>
<h3><strong>高可用</strong></h3>
<p>针对 MGR 及主从复制进行了大量改进和提升工作，支持 地理标签、仲裁节点、读写动态 VIP、快速单主模式、智能选主 等特性，并针对 流控算法、事务认证队列清理算法、节点加入&amp;退出机制、recovery机制、大事务传输压缩等多个 MGR 底层工作机制算法进行深度优化，进一步提升优化了 MGR 的高可用保障及性能稳定性。</p>
<ul>
<li>支持 地理标签 特性，提升多机房架构数据可靠性。</li>
<li>支持 仲裁节点 特性，用更低的服务器成本实现更高可用。</li>
<li>支持 读写动态 VIP 特性，高可用切换更便捷，更快实现读负载均衡。支持 当主节点切换时，主动关闭当前活跃连接，缩短应用端不可用时长。。</li>
<li>支持 快速单主模式，在单主模式下更快，性能更高。</li>
<li>支持 智能选主 特性，高可用切换选主机制更合理。</li>
<li>优化 流控算法，使得事务更平稳，避免剧烈抖动。</li>
<li>支持 记录 MGR 网络通信开销超过阈值的事件，用于进一步分析和优化。</li>
<li>支持自动选择从最新事务数据的成员节点复制数据，可有效提升 Clone 速度，提高 MGR 的服务可靠性。</li>
<li>在主从复制中，从节点向主节点发起 Binlog 读取请求时支持限速控制。</li>
<li>优化了 asynchronous connection failover 中的故障检测效率，降低主从复制链路断开的时间，提高整体可用性。
<ul>
<li>https://dev.mysql.com/doc/refman/8.0/en/replication-asynchronous-connection-failover.html</li>
</ul> </li>
<li>支持在跨机房容灾场景中的 主主双向复制防止回路 机制。</li>
<li>优化了 MGR 节点加入、退出时可能导致性能剧烈抖动的问题。</li>
<li>解决了个别节点上磁盘空间爆满时导致MGR集群整体被阻塞的问题。</li>
<li>优化了 MGR 事务认证队列清理算法，高负载下不复存在每 60 秒性能抖动问题。</li>
<li>解决了 MGR 中长事务造成无法选主的问题。</li>
<li>修复了 MGR recovery 过程中长时间等待的问题。</li>
<li>优化了MGR大事务传输时压缩超过限制的处理机制。</li>
</ul>
<p>更多信息详见文档：</p>
<ul>
<li>高可用：https://greatsql.cn/docs/8.4.4-4/5-enhance/5-2-ha.html</li>
</ul>
<h3><strong>高性能</strong></h3>
<p>相对 MySQL 及 Percona Server For MySQL 的性能表现更稳定优异，支持 Rapid 引擎、Turbo引擎、事务无锁化、并行 LOAD DATA、异步删除大表、线程池、非阻塞式 DDL、NUMA 亲和调度优化 等特性，在 TPC-C 测试中相对 MySQL 性能提升超过 30%</p>
<ul>
<li>https://greatsql.cn/docs/8.4.4-4/10-optimize/3-5-benchmark-greatsql-vs-mysql-tpcc-report.html</li>
</ul>
<p>在 TPC-H 测试中的性能表现是 MySQL 的十几倍甚至上百倍</p>
<ul>
<li> <p>https://greatsql.cn/docs/8.4.4-4/10-optimize/3-3-benchmark-greatsql-tpch-report.html</p> </li>
<li> <p>支持 大规模并行、基于内存查询、高压缩比的高性能 Rapid 引擎，可将数据分析性能提升几个数量级。</p> </li>
<li> <p>支持 高性能并行查询引擎Turbo，使GreatSQL具备多线程并发的向量化实时查询功能。</p> </li>
<li> <p>优化 InnoDB 事务系统，实现了大锁拆分及无锁化等多种优化方案，OLTP 场景整体性能提升约 20%。</p> </li>
<li> <p>支持 并行 LOAD DATA，适用于频繁导入大批量数据的应用场景，性能可提升约 20 多倍；对于无显式定义主键的场景亦有优化提升。</p> </li>
<li> <p>支持 异步删除大表，提高 InnoDB 引擎运行时性能的稳定性。</p> </li>
<li> <p>支持 线程池，降低了线程创建和销毁的代价，保证高并发下，性能稳定不会明显衰退。</p> </li>
<li> <p>支持 非阻塞式 DDL，可以避免数据库因为必须尽快完成 DDL 操作而导致业务请求大量被阻塞的问题。</p> </li>
<li> <p>支持 NUMA 亲和性优化，通过 NUMA 亲和性调度优化，将前端用户线程和后台线程绑定到固定 NUMA 节点上以提升线程处理性能。</p> </li>
</ul>
<p>更多信息详见文档：</p>
<ul>
<li>高性能：https://greatsql.cn/docs/8.4.4-4/5-enhance/5-1-highperf.html</li>
</ul>
<h3><strong>高兼容</strong></h3>
<p>GreatSQL 实现 100% 完全兼容 MySQL 及 Percona Server For MySQL 语法，支持大多数常见 Oracle 语法，包括<code>数据类型兼容</code>、<code>函数兼容</code>、<code>SQL 语法兼容</code>、<code>存储程序兼容</code>等众多兼容扩展用法。</p>
<p>更多信息详见文档：</p>
<ul>
<li>高兼容：https://greatsql.cn/docs/8.4.4-4/5-enhance/5-3-easyuse.html</li>
</ul>
<h3><strong>高安全</strong></h3>
<p>GreatSQL 支持逻辑备份加密、CLONE 备份加密、审计、表空间国密加密、敏感数据脱敏、存储登录历史等多个安全提升特性，进一步保障业务数据安全，更适用于金融级应用场景。</p>
<ul>
<li>支持 mysqldump 逻辑备份加密，提供了利用 mysqldump 逻辑备份的安全加密需求。</li>
<li>支持 Clone 备份加密，提供了利用 Clone 物理备份的安全加密需求。</li>
<li>支持 审计功能，及时记录和发现未授权或不安全行为。</li>
<li>支持 InnoDB 表空间国密加密算法，确保重要数据的加密安全。</li>
<li>支持 基于函数和策略的两种数据脱敏 工作方式，保障敏感用户数据查询结果保密性。</li>
</ul>
<p>通过上述多个安全提升特性，进一步保障业务数据安全。</p>
<p>更多信息详见文档：</p>
<ul>
<li>高安全：https://greatsql.cn/docs/8.4.4-4/5-enhance/5-4-security.html</li>
</ul>
<h3><strong>其他</strong></h3>
<ul>
<li>支持 Clone 在线全量热备、增备及恢复，结合 Binlog 可实现恢复到指定时间点。此外，Clone 备份还支持压缩功能。
<ul>
<li>https://greatsql.cn/docs/8.4.4-4/5-enhance/5-5-clone-compressed-and-incrment-backup.html</li>
</ul> </li>
<li>支持 InnoDB Page透明压缩采用Zstd算法，进一步提高数据压缩率，尤其是当有大量长文本重复数据时。
<ul>
<li>https://greatsql.cn/docs/8.4.4-4/5-enhance/5-5-innodb-page-compression.html</li>
</ul> </li>
</ul>
<h2><strong>注意事项</strong></h2>
<p>从8.0升级到8.4版本，对现有运维管控系统最大的影响是，原先包含 <code>MASTER/SLAVE</code> 关键字的指令不再可用，相应的主要改动详见下表</p>
<table>
<tbody>
<tr>
<th>旧指令</th>
<th>新指令</th>
</tr>
</tbody>
<tbody>
<tr>
<td>START SLAVE</td>
<td>START REPLICA</td>
</tr>
<tr>
<td>STOP SLAVE</td>
<td>STOP REPLICA</td>
</tr>
<tr>
<td>SHOW SLAVE STATUS</td>
<td>SHOW REPLICA STATUS</td>
</tr>
<tr>
<td>SHOW SLAVE HOSTS</td>
<td>SHOW REPLICAS</td>
</tr>
<tr>
<td>RESET SLAVE</td>
<td>RESET REPLICA</td>
</tr>
<tr>
<td>CHANGE MASTER TO</td>
<td>CHANGE REPLICATION SOURCE TO</td>
</tr>
<tr>
<td>RESET MASTER</td>
<td>RESET BINARY LOGS AND GTIDS</td>
</tr>
<tr>
<td>SHOW MASTER STATUS</td>
<td>SHOW BINARY LOG STATUS</td>
</tr>
<tr>
<td>PURGE MASTER LOGS</td>
<td>PURGE BINARY LOGS</td>
</tr>
<tr>
<td>SHOW MASTER LOGS</td>
<td>SHOW BINARY LOGS</td>
</tr>
</tbody>
</table>
<p>此外，原来在 <code>CHANGE MASTER</code>（新的指令 <code>CHANGE REPLICATION SOURCE TO</code>） 以及 <code>START SLAVE</code>（新的指令 <code>START REPLICA</code>） 中相关的参数变量也同样发生变化，详见下表</p>
<table>
<tbody>
<tr>
<th>旧参数名</th>
<th>新参数名</th>
</tr>
</tbody>
<tbody>
<tr>
<td>MASTER_AUTO_POSITION</td>
<td>SOURCE_AUTO_POSITION</td>
</tr>
<tr>
<td>MASTER_HOST</td>
<td>SOURCE_HOST</td>
</tr>
<tr>
<td>MASTER_BIND</td>
<td>SOURCE_BIND</td>
</tr>
<tr>
<td>MASTER_USER</td>
<td>SOURCE_USER</td>
</tr>
<tr>
<td>MASTER_PASSWORD</td>
<td>SOURCE_PASSWORD</td>
</tr>
<tr>
<td>MASTER_PORT</td>
<td>SOURCE_PORT</td>
</tr>
<tr>
<td>MASTER_CONNECT_RETRY</td>
<td>SOURCE_CONNECT_RETRY</td>
</tr>
<tr>
<td>MASTER_RETRY_COUNT</td>
<td>SOURCE_RETRY_COUNT</td>
</tr>
<tr>
<td>MASTER_DELAY</td>
<td>SOURCE_DELAY</td>
</tr>
<tr>
<td>MASTER_SSL</td>
<td>SOURCE_SSL</td>
</tr>
<tr>
<td>MASTER_SSL_CA</td>
<td>SOURCE_SSL_CA</td>
</tr>
<tr>
<td>MASTER_SSL_CAPATH</td>
<td>SOURCE_SSL_CAPATH</td>
</tr>
<tr>
<td>MASTER_SSL_CIPHER</td>
<td>SOURCE_SSL_CIPHER</td>
</tr>
<tr>
<td>MASTER_SSL_CRL</td>
<td>SOURCE_SSL_CRL</td>
</tr>
<tr>
<td>MASTER_SSL_CRLPATH</td>
<td>SOURCE_SSL_CRLPATH</td>
</tr>
<tr>
<td>MASTER_SSL_KEY</td>
<td>SOURCE_SSL_KEY</td>
</tr>
<tr>
<td>MASTER_SSL_VERIFY_SERVER_CERT</td>
<td>SOURCE_SSL_VERIFY_SERVER_CERT</td>
</tr>
<tr>
<td>MASTER_TLS_VERSION</td>
<td>SOURCE_TLS_VERSION</td>
</tr>
<tr>
<td>MASTER_TLS_CIPHERSUITES</td>
<td>SOURCE_TLS_CIPHERSUITES</td>
</tr>
<tr>
<td>MASTER_SSL_CERT</td>
<td>SOURCE_SSL_CERT</td>
</tr>
<tr>
<td>MASTER_PUBLIC_KEY_PATH</td>
<td>SOURCE_PUBLIC_KEY_PATH</td>
</tr>
<tr>
<td>GET_MASTER_PUBLIC_KEY</td>
<td>GET_SOURCE_PUBLIC_KEY</td>
</tr>
<tr>
<td>MASTER_HEARTBEAT_PERIOD</td>
<td>SOURCE_HEARTBEAT_PERIOD</td>
</tr>
<tr>
<td>MASTER_COMPRESSION_ALGORITHMS</td>
<td>SOURCE_COMPRESSION_ALGORITHMS</td>
</tr>
<tr>
<td>MASTER_ZSTD_COMPRESSION_LEVEL</td>
<td>SOURCE_ZSTD_COMPRESSION_LEVEL</td>
</tr>
<tr>
<td>MASTER_LOG_FILE</td>
<td>SOURCE_LOG_FILE</td>
</tr>
<tr>
<td>MASTER_LOG_POS</td>
<td>SOURCE_LOG_POS</td>
</tr>
</tbody>
</table>
<p>执行 SQL 命令 <code>SHOW [GLOBAL] STATUS</code> 的结果中，也有部分状态变量发生变化，详见下表</p>
<table>
<tbody>
<tr>
<th>旧状态变量名</th>
<th>新状态变量名</th>
</tr>
</tbody>
<tbody>
<tr>
<td>Com_slave_start</td>
<td>Com_replica_start</td>
</tr>
<tr>
<td>Com_slave_stop</td>
<td>Com_replica_stop</td>
</tr>
<tr>
<td>Com_show_slave_status</td>
<td>Com_show_replica_status</td>
</tr>
<tr>
<td>Com_show_slave_hosts</td>
<td>Com_show_replicas</td>
</tr>
<tr>
<td>Com_show_master_status</td>
<td>Com_show_binary_log_status</td>
</tr>
<tr>
<td>Com_change_master</td>
<td>Com_change_replication_source</td>
</tr>
</tbody>
</table>
<h2><strong>升级/降级到 GreatSQL 8.4.4-4</strong></h2>
<h3><strong>升级到 GreatSQL 8.4.4-4</strong></h3>
<ul>
<li> <p>如果是 GreatSQL 5.7 等系列版本，可以直接在原来的 <code>datadir</code> 基础上，修改 <code>basedir</code> 后，原地（in-place）启动 GreatSQL 8.0.32-27 版本后，先原地升级到 GreatSQL 8.0.32-27 版本。再继续在该 <code>datadir</code> 基础上升级，即修改 <code>basedir</code> 指向 GreatSQL 8.4.4-4 新版本，再次进行原地升级。需要注意的是，从 5.7 版本升级到 8.0 版本，再升级到 8.4 版本后，数据库中的账号仍采用 <code>mysql_native_password</code> 密码验证插件。当最终升级到 8.4 版本后，需要修改 <em>my.cnf</em> 配置文件，加上 <code>mysql_native_password=1</code>，以保证原有的账号能正常登录。</p> </li>
<li> <p>如果是 GreatSQL 8.0 等系列版本，并且没有使用 <strong>Rapid</strong> 引擎，则可以直接在原来的 <code>datadir</code> 基础上，修改 <code>basedir</code> 后，原地（in-place）启动 GreatSQL 8.4.4-4 后会完成自动升级。</p> </li>
<li> <p>如果旧版本是 GreatSQL 8.0.32-27 且已启用 <strong>Rapid</strong> 引擎，可以直接在原来的 <code>datadir</code> 基础上，修改 <code>basedir</code> 后，原地（in-place）启动 GreatSQL 8.4.4-4 后会完成自动升级。</p> </li>
<li> <p>如果旧版本是 GreatSQL 8.0.32-25 或 8.0.32-26 且已启用 <strong>Rapid</strong> 引擎，<strong>这种情况下无法原地升级</strong>，需要卸载所有 <strong>Rapid</strong> 引擎表，删除 <strong>Rapid</strong> 数据文件，才可以在原来的 <code>datadir</code> 基础上，修改 <code>basedir</code> 后，原地（in-place）启动 GreatSQL 8.4.4-4 后进行自动升级。新版本实例启动后，对所有 <strong>Rapid</strong> 引擎表执行 <code>ALTER TABLE SECONDARY_LOAD</code> 完成全量数据导入，再执行 <code>SELECT START_SECONDARY_ENGINE_INCREMENT_LOAD_TASK()</code> 启动增量导入任务，完成 <strong>Rapid</strong> 引擎表升级工作。下面是一个升级参考过程：</p> <pre><code>&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong style="color:#000000"&gt;1. 查询并记录所有Rapid引擎表&lt;/strong&gt;
&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;可以执行下面的SQL，查询当前有哪些表使用了Rapid引擎：
&lt;pre style="margin-left:5px; margin-right:5px; text-align:left"&gt;
</code></pre> <p><code>greatsql&gt; <span>SELECT</span> TABLE_SCHEMA, TABLE_NAME, TABLE_ROWS <span>FROM</span> information_schema.TABLES <span>WHERE</span> CREATE_OPTIONS <span>LIKE</span> <span>'%Rapid%'</span>; +<em>--------------+----------------+------------+</em> | TABLE_SCHEMA | TABLE_NAME | TABLE_ROWS | +<em>--------------+----------------+------------+</em> | tpch100g | customer | 14854987 | | tpch100g | lineitem | 582868392 | | tpch100g | nation | 25 | | tpch100g | orders | 148492582 | | tpch100g | part | 19943155 | | tpch100g | partsupp | 79832625 | | tpch100g | region | 5 | | tpch100g | supplier | 989416 | +<em>--------------+----------------+------------+</em> </code></p> <pre><code>&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong style="color:#000000"&gt;2. 正常停止GreatSQL实例进程&lt;/strong&gt;
&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;在停止GreatSQL实例进程前，先修改&lt;code&gt;innodb_fast_shutdown=0&lt;/code&gt;后再执行&lt;code&gt;SHUTDOWN&lt;/code&gt;停止实例
&lt;pre style="margin-left:5px; margin-right:5px; text-align:left"&gt;
</code></pre> <p><code>greatsql&gt; <span>SET</span> <span>GLOBAL</span> innodb_fast_shutdown=<span>0</span>; greatsql&gt; SHUTDOWN; </code></p> <pre><code>&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong style="color:#000000"&gt;3. 删除旧的Rapid引擎数据文件&lt;/strong&gt;
&lt;pre style="margin-left:5px; margin-right:5px; text-align:left"&gt;
</code></pre> <p><code><span>cd</span> /data/GreatSQL &amp;&amp; rm -f duckdb* </code></p> <pre><code>&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong style="color:#000000"&gt;4. 修改&lt;code&gt;my.cnf&lt;/code&gt;配置文件中的&lt;code&gt;basedir&lt;/code&gt;参数，指向GreatSQL 8.4.4-4新版本&lt;/strong&gt;
&lt;pre style="margin-left:5px; margin-right:5px; text-align:left"&gt;
</code></pre> <p><code>#my.cnf [mysqld] basedir=/usr/local/GreatSQL-8.4.4-4-Linux-glibc2.28-x86_64 </code></p> <pre><code>&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;并确保参数&lt;code&gt;upgrade&lt;/code&gt;不是设置为&lt;em&gt;NONE&lt;/em&gt;。
&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong style="color:#000000"&gt;5. 启动GreatSQL 8.4.4-4新版本实例&lt;/strong&gt;
&lt;pre style="margin-left:5px; margin-right:5px; text-align:left"&gt;
</code></pre> <p><code>systemctl start greatsql </code></p> <pre><code>&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong style="color:#000000"&gt;6. 重新安装Rapid引擎&lt;/strong&gt;
&lt;pre style="margin-left:5px; margin-right:5px; text-align:left"&gt;
</code></pre> <p><code>greatsql&gt; <span>INSTALL</span> <span>PLUGIN</span> rapid <span>SONAME</span> <span>'ha_rapid.so'</span>; </code></p> <pre><code>&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong style="color:#000000"&gt;7. 对Rapid引擎表做一次全量数据导入&lt;/strong&gt;
&lt;pre style="margin-left:5px; margin-right:5px; text-align:left"&gt;
</code></pre> <p><code>greatsql&gt; <span>ALTER</span> <span>TABLE</span> test.t1 SECONDARY_LOAD; </code></p> </li>
</ul>
<blockquote>
<p>tip 小贴士：由于在升级前没有去掉该表的<code>SECONDARY_ENGINE=rapid</code>属性，所以无需重新设置。如果在升级前卸载所有Rapid引擎表，则需要重新设置。</p>
</blockquote>
<p><strong>8. 再次启动增量导入任务</strong></p>
<pre><code>greatsql&gt; <span>SELECT</span> START_SECONDARY_ENGINE_INCREMENT_LOAD_TASK(<span>'test'</span>, <span>'t1'</span>);
</code></pre>
<p>这就完成Rapid引擎表的升级操作了。</p>
<ul>
<li> <p>如果是 MySQL 5.7 或 Percona Server 5.7 等系列版本，可以直接在原来的 <code>datadir</code> 基础上，修改 <code>basedir</code> 后，原地（in-place）启动 GreatSQL 8.0.32-27 版本后，确认升级成功后，再次在原来 <code>datadir</code> 基础上继续升级，即修改 <code>basedir</code> 指向 GreatSQL 8.4.4-4 新版本，之后就能完成自动升级。需要注意的是，从 5.7 版本升级到 8.0 版本，再升级到 8.4 版本后，数据库中的账号仍采用 <code>mysql_native_password</code> 密码验证插件。当最终升级到 8.4 版本后，需要修改 <em>my.cnf</em> 配置文件，加上 <code>mysql_native_password=1</code>，以保证原有的账号能正常登录。</p> </li>
<li> <p>如果是 MySQL 8.0 或 Percona Server 8.0 等系列版本，则可以直接在原来的 <code>datadir</code> 基础上，修改 <code>basedir</code> 后，原地（in-place）启动 GreatSQL 8.4.4-4 后会完成自动升级。</p> </li>
<li> <p>其他情况下，最好采用导入逻辑备份文件方式升级到 GreatSQL 8.4.4-4 版本。</p> </li>
</ul>
<p>在以上几个原地升级场景中，务必保证<code>my.cnf</code>中参数<code>upgrade</code>不能设置为<em>NONE</em>，可以设置为默认的<em>AUTO</em>或<em>FORCE</em>。例如：</p>
<pre><code>#my.cnf
[mysqld]
upgrade = AUTO
</code></pre>
<p>更多迁移升级方案请参考：</p>
<ul>
<li>迁移升级：https://greatsql.cn/docs/8.4.4-4/7-migrate-and-upgrade/0-migrate-and-upgrade.html</li>
</ul>
<h3><strong>降级到 GreatSQL 8.4.4-4</strong></h3>
<p>如果是要从 MySQL/Percona 8.4 系列较高的小版本降级到 GreatSQL 8.4.4-4 版本，可以采用原地降级方式快速完成版本降级操作。即可以直接在原来的 <code>datadir</code> 基础上，修改 <code>basedir</code> 后，并增加设置参数<code>upgrade=FORCE</code>，原地（in-place）启动 GreatSQL 8.4.4-4 后会完成自动降级。</p>
<p>如果是要从 MySQL/Percona 9.0 及之后的版本降级到 GreatSQL 8.4.4-4 版本，则需要采取逻辑备份 + 逻辑导入方式完成降级操作，并且在逻辑备份导入完成后的首次重启时，务必设置 <code>upgrade=FORCE</code> 强制升级所有数据表，包括系统表。</p>
<p>降级过程操作大致如下所示：</p>
<p><strong>1. 在高版本中逻辑备份全量数据</strong></p>
<pre><code>mysqldump -S/data/MySQL/mysql.sock -A --triggers --routines --events --single-transaction &gt; /data/backup/fulldump.sql
</code></pre>
<p><strong>2. 在GreatSQL 8.4.4-4版本环境中导入逻辑备份文件，完成逻辑恢复</strong></p>
<pre><code>mysql -S/data/GreatSQL/mysql.sock -f &lt; /data/backup/fulldump.sql
</code></pre>
<p><strong>3. 修改<code>my.cnf</code>，确保设置<code>upgrade=FORCE</code></strong></p>
<pre><code>#my.cnf
[mysqld]
upgrade = FORCE
</code></pre>
<p><strong>4. 重启GreatSQL，降级完成</strong></p>
<pre><code>systemctl restart greatsql
</code></pre>
<p>重启过程中，可以看到日志有类似下面的强制降级过程</p>
<pre><code>[Note] [MY-013387] [Server] Upgrading system table data.
[Note] [MY-013385] [Server] Upgrading the sys schema.
[Note] [MY-013400] [Server] Upgrade of help tables started.
[Note] [MY-013400] [Server] Upgrade of help tables completed.
[Note] [MY-013394] [Server] Checking 'mysql' schema.
[Note] [MY-013394] [Server] Checking 'sys' schema.
[System] [MY-014064] [Server] Server downgrade from '80406' to '80404' started.
[System] [MY-014064] [Server] Server downgrade from '80406' to '80404' completed.
</code></pre>
<p>如果不设置 <code>upgrade = FORCE</code> 强制升级所有表，有可能发生系统表 <code>mysql.procs_priv</code> 损坏错误，在创建用户时可能会报告类似下面的错误：</p>
<pre><code>greatsql&gt; <span>CREATE</span> <span>USER</span> tpch <span>IDENTIFIED</span> <span>BY</span> <span>'tpch'</span>;
ERROR 1728 (HY000): Cannot <span>load</span> <span>from</span> mysql.procs_priv. The <span>table</span> <span>is</span> probably corrupted
</code></pre>
<h2><strong>GreatSQL vs MySQL</strong></h2>
<table>
<tbody>
<tr>
<th><strong>1.主要特性</strong></th>
<th>GreatSQL 8.4.4-4</th>
<th>MySQL 8.4.4</th>
</tr>
</tbody>
<tbody>
<tr>
<td>开源</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>ACID 完整性</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>MVCC 特性</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>支持行锁</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>Crash 自动修复</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>表分区（Partitioning）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>视图（Views）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>子查询（Subqueries）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>触发器（Triggers）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>存储程序（Stored Programs）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>外键（Foreign Keys）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>窗口函数（Window Functions）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>通用表表达式 CTE</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>地理信息（GIS）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>基于 GTID 的复制</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>组复制（MGR）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>MyRocks 引擎</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>支持龙芯架构</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td><strong>2. 性能提升扩展</strong></td>
<td>GreatSQL 8.4.4-4</td>
<td>MySQL 8.4.4</td>
</tr>
<tr>
<td>Rapid 引擎</td>
<td>✔️</td>
<td>仅云上HeatWave</td>
</tr>
<tr>
<td>Turbo 引擎</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>NUMA 亲和性优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>非阻塞式 DDL</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>无主键表导入优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>并行 LOAD DATA</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>InnoDB 事务 ReadView 无锁优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>InnoDB 事务大锁拆分优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>InnoDB Page压缩支持Zstd</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>InnoDB 资源组</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>自定义 InnoDB 页大小</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>Contention-Aware Transaction Scheduling</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>InnoDB Mutexes 拆分优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MEMORY 引擎优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>InnoDB Flushing 优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>并行 Doublewrite Buffer</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>InnoDB 快速索引创建优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>VARCHAR/BLOB/JSON 类型存储单列压缩</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>数据字典中存储单列压缩信息</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td><strong>3. 面向开发者提升改进</strong></td>
<td>GreatSQL 8.4.4-4</td>
<td>MySQL 8.4.4</td>
</tr>
<tr>
<td>X API</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>JSON</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>NoSQL Socket-Level接口</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>InnoDB 全文搜索改进</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>更多 Hash/Digest 函数</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Oracle 兼容-数据类型</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Oracle 兼容-函数</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Oracle 兼容-SQL语法</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Oracle 兼容-存储程序</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td><strong>4. 基础特性提升改进</strong></td>
<td>GreatSQL 8.4.4-4</td>
<td>MySQL 8.4.4</td>
</tr>
<tr>
<td>MGR 提升-地理标签</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-仲裁节点</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-读写节点绑定VIP</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-快速单主模式</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-智能选主机制</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-全新流控算法</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-网络分区异常处理</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-节点异常退出处理</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-节点磁盘满处理</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-自动选择 donor 节点</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-大事务压缩优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Clone 增量备份</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Clone 备份压缩</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Binlog 读取限速</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>information_schema 表数量</td>
<td>95</td>
<td>65</td>
</tr>
<tr>
<td>全局性能和状态指标</td>
<td>853</td>
<td>434</td>
</tr>
<tr>
<td>优化器直方图（Histograms）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>Per-Table 性能指标</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Per-Index 性能指标</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Per-User 性能指标</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Per-Client 性能指标</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Per-Thread 性能指标</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>全局查询相应耗时统计</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>SHOW ENGINE INNODB STATUS 增强</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>回滚段信息增强</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>临时表信息增强</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>用户统计信息增强</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Slow log 信息增强</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td><strong>5.安全性提升</strong></td>
<td>GreatSQL 8.4.4-4</td>
<td>MySQL 8.4.4</td>
</tr>
<tr>
<td>国密支持</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>备份加密</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>审计</td>
<td>✔️</td>
<td>仅企业版</td>
</tr>
<tr>
<td>数据脱敏</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>SQL Roles</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>SHA-2 密码Hashing</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>密码轮换策略</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>PAM 认证插件</td>
<td>✔️</td>
<td>仅企业版</td>
</tr>
<tr>
<td>Keyring 存储在文件中</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>Keyring 存储在Hashicorp Vault中</td>
<td>✔️</td>
<td>仅企业版</td>
</tr>
<tr>
<td>InnoDB 数据加密</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>InnoDB 日志加密</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>InnoDB 各种表空间文件加密</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>二进制日志加密</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>临时文件加密</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>强制加密</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td><strong>6. 运维便利性提升</strong></td>
<td>GreatSQL 8.4.4-4</td>
<td>MySQL 8.4.4</td>
</tr>
<tr>
<td>DDL 原子性</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>数据字典存储 InnoDB 表</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>快速 DDL</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>SET PERSIST</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>不可见索引</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>线程池（Threadpool）</td>
<td>✔️</td>
<td>仅企业版</td>
</tr>
<tr>
<td>备份锁</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>SHOW GRANTS 扩展</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>表损坏动作扩展</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>杀掉不活跃事务</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>START TRANSACTION WITH CONSISTENT SNAPSHOT 扩展</td>
<td>✔️</td>
<td>❌</td>
</tr>
</tbody>
</table>
<p>GreatSQL 8.4.4-4 基于 Percona Server for MySQL 8.4.4-4 版本，它在 MySQL 8.4.4 基础上做了大量的改进和提升以及众多新特性，详情请见：</p>
<ul>
<li>Percona Server for MySQL feature comparison: https://docs.percona.com/percona-server/8.4/feature-comparison.html</li>
</ul>
<p>这其中包括线程池、审计、数据脱敏等 MySQL 企业版才有的特性，以及 performance_schema 提升、information_schema 提升、性能和可扩展性提升、用户统计增强、PROCESSLIST 增强、Slow Log 增强等大量改进和提升，这里不一一重复列出。</p>
<h2><strong>GreatSQL Release Notes</strong></h2>
<h3><strong>GreatSQL 8.4</strong></h3>
<ul>
<li>Changes in GreatSQL 8.4.4-4 (2025-10-15) https://greatsql.cn/docs/8.4.4-4/1-docs-intro/relnotes/changes-greatsql-8444.html</li>
</ul>
<h3><strong>GreatSQL 8.0</strong></h3>
<ul>
<li>Changes in GreatSQL 8.0.32-27 (2025-3-10)</li>
<li>Changes in GreatSQL 8.0.32-26 (2024-8-5)</li>
<li>Changes in GreatSQL 8.0.32-25 (2023-12-28)</li>
<li>Changes in GreatSQL 8.0.32-24 (2023-6-5)</li>
<li>Changes in GreatSQL 8.0.25-17 (2023-3-13)</li>
<li>Changes in GreatSQL 8.0.25-16 (2022-5-16)</li>
<li>Changes in GreatSQL 8.0.25-15 (2021-8-26)</li>
</ul>
<h3><strong>GreatSQL 5.7</strong></h3>
<ul>
<li>Changes in GreatSQL 5.7.36-39 (2022-4-7)</li>
</ul>]]>
    </description>
    <content:encoded><![CDATA[<h1><strong>GreatSQL 8.4.4-4 GA (2025-10-15)</strong></h1>
<h2><strong>版本信息</strong></h2>
<ul>
<li> <p>发布时间：2025年10月15日</p> </li>
<li> <p>版本号：8.4.4-4, Revision d73de75905d</p> </li>
<li> <p>下载链接：https://gitee.com/GreatSQL/GreatSQL/releases/tag/GreatSQL-8.4.4-4</p> </li>
<li> <p>用户手册：https://greatsql.cn/docs/8.4.4-4/</p> </li>
</ul>
<h2><strong>特性增强</strong></h2>
<p>GreatSQL 8.4.4.-4版本在Percona Server for MySQL 8.4.4-4版本的基础上，主要在 <strong>高可用</strong>、<strong>高性能</strong>、<strong>高兼容</strong>、<strong>高安全</strong>四个方面进行了多项特性增强，使得 GreatSQL 可在普通硬件上满足金融级应用场景，可作为 MySQL 或 Percona Server for MySQL 的理想可选替换。</p>
<h3><strong>高可用</strong></h3>
<p>针对 MGR 及主从复制进行了大量改进和提升工作，支持 地理标签、仲裁节点、读写动态 VIP、快速单主模式、智能选主 等特性，并针对 流控算法、事务认证队列清理算法、节点加入&amp;退出机制、recovery机制、大事务传输压缩等多个 MGR 底层工作机制算法进行深度优化，进一步提升优化了 MGR 的高可用保障及性能稳定性。</p>
<ul>
<li>支持 地理标签 特性，提升多机房架构数据可靠性。</li>
<li>支持 仲裁节点 特性，用更低的服务器成本实现更高可用。</li>
<li>支持 读写动态 VIP 特性，高可用切换更便捷，更快实现读负载均衡。支持 当主节点切换时，主动关闭当前活跃连接，缩短应用端不可用时长。。</li>
<li>支持 快速单主模式，在单主模式下更快，性能更高。</li>
<li>支持 智能选主 特性，高可用切换选主机制更合理。</li>
<li>优化 流控算法，使得事务更平稳，避免剧烈抖动。</li>
<li>支持 记录 MGR 网络通信开销超过阈值的事件，用于进一步分析和优化。</li>
<li>支持自动选择从最新事务数据的成员节点复制数据，可有效提升 Clone 速度，提高 MGR 的服务可靠性。</li>
<li>在主从复制中，从节点向主节点发起 Binlog 读取请求时支持限速控制。</li>
<li>优化了 asynchronous connection failover 中的故障检测效率，降低主从复制链路断开的时间，提高整体可用性。
<ul>
<li>https://dev.mysql.com/doc/refman/8.0/en/replication-asynchronous-connection-failover.html</li>
</ul> </li>
<li>支持在跨机房容灾场景中的 主主双向复制防止回路 机制。</li>
<li>优化了 MGR 节点加入、退出时可能导致性能剧烈抖动的问题。</li>
<li>解决了个别节点上磁盘空间爆满时导致MGR集群整体被阻塞的问题。</li>
<li>优化了 MGR 事务认证队列清理算法，高负载下不复存在每 60 秒性能抖动问题。</li>
<li>解决了 MGR 中长事务造成无法选主的问题。</li>
<li>修复了 MGR recovery 过程中长时间等待的问题。</li>
<li>优化了MGR大事务传输时压缩超过限制的处理机制。</li>
</ul>
<p>更多信息详见文档：</p>
<ul>
<li>高可用：https://greatsql.cn/docs/8.4.4-4/5-enhance/5-2-ha.html</li>
</ul>
<h3><strong>高性能</strong></h3>
<p>相对 MySQL 及 Percona Server For MySQL 的性能表现更稳定优异，支持 Rapid 引擎、Turbo引擎、事务无锁化、并行 LOAD DATA、异步删除大表、线程池、非阻塞式 DDL、NUMA 亲和调度优化 等特性，在 TPC-C 测试中相对 MySQL 性能提升超过 30%</p>
<ul>
<li>https://greatsql.cn/docs/8.4.4-4/10-optimize/3-5-benchmark-greatsql-vs-mysql-tpcc-report.html</li>
</ul>
<p>在 TPC-H 测试中的性能表现是 MySQL 的十几倍甚至上百倍</p>
<ul>
<li> <p>https://greatsql.cn/docs/8.4.4-4/10-optimize/3-3-benchmark-greatsql-tpch-report.html</p> </li>
<li> <p>支持 大规模并行、基于内存查询、高压缩比的高性能 Rapid 引擎，可将数据分析性能提升几个数量级。</p> </li>
<li> <p>支持 高性能并行查询引擎Turbo，使GreatSQL具备多线程并发的向量化实时查询功能。</p> </li>
<li> <p>优化 InnoDB 事务系统，实现了大锁拆分及无锁化等多种优化方案，OLTP 场景整体性能提升约 20%。</p> </li>
<li> <p>支持 并行 LOAD DATA，适用于频繁导入大批量数据的应用场景，性能可提升约 20 多倍；对于无显式定义主键的场景亦有优化提升。</p> </li>
<li> <p>支持 异步删除大表，提高 InnoDB 引擎运行时性能的稳定性。</p> </li>
<li> <p>支持 线程池，降低了线程创建和销毁的代价，保证高并发下，性能稳定不会明显衰退。</p> </li>
<li> <p>支持 非阻塞式 DDL，可以避免数据库因为必须尽快完成 DDL 操作而导致业务请求大量被阻塞的问题。</p> </li>
<li> <p>支持 NUMA 亲和性优化，通过 NUMA 亲和性调度优化，将前端用户线程和后台线程绑定到固定 NUMA 节点上以提升线程处理性能。</p> </li>
</ul>
<p>更多信息详见文档：</p>
<ul>
<li>高性能：https://greatsql.cn/docs/8.4.4-4/5-enhance/5-1-highperf.html</li>
</ul>
<h3><strong>高兼容</strong></h3>
<p>GreatSQL 实现 100% 完全兼容 MySQL 及 Percona Server For MySQL 语法，支持大多数常见 Oracle 语法，包括<code>数据类型兼容</code>、<code>函数兼容</code>、<code>SQL 语法兼容</code>、<code>存储程序兼容</code>等众多兼容扩展用法。</p>
<p>更多信息详见文档：</p>
<ul>
<li>高兼容：https://greatsql.cn/docs/8.4.4-4/5-enhance/5-3-easyuse.html</li>
</ul>
<h3><strong>高安全</strong></h3>
<p>GreatSQL 支持逻辑备份加密、CLONE 备份加密、审计、表空间国密加密、敏感数据脱敏、存储登录历史等多个安全提升特性，进一步保障业务数据安全，更适用于金融级应用场景。</p>
<ul>
<li>支持 mysqldump 逻辑备份加密，提供了利用 mysqldump 逻辑备份的安全加密需求。</li>
<li>支持 Clone 备份加密，提供了利用 Clone 物理备份的安全加密需求。</li>
<li>支持 审计功能，及时记录和发现未授权或不安全行为。</li>
<li>支持 InnoDB 表空间国密加密算法，确保重要数据的加密安全。</li>
<li>支持 基于函数和策略的两种数据脱敏 工作方式，保障敏感用户数据查询结果保密性。</li>
</ul>
<p>通过上述多个安全提升特性，进一步保障业务数据安全。</p>
<p>更多信息详见文档：</p>
<ul>
<li>高安全：https://greatsql.cn/docs/8.4.4-4/5-enhance/5-4-security.html</li>
</ul>
<h3><strong>其他</strong></h3>
<ul>
<li>支持 Clone 在线全量热备、增备及恢复，结合 Binlog 可实现恢复到指定时间点。此外，Clone 备份还支持压缩功能。
<ul>
<li>https://greatsql.cn/docs/8.4.4-4/5-enhance/5-5-clone-compressed-and-incrment-backup.html</li>
</ul> </li>
<li>支持 InnoDB Page透明压缩采用Zstd算法，进一步提高数据压缩率，尤其是当有大量长文本重复数据时。
<ul>
<li>https://greatsql.cn/docs/8.4.4-4/5-enhance/5-5-innodb-page-compression.html</li>
</ul> </li>
</ul>
<h2><strong>注意事项</strong></h2>
<p>从8.0升级到8.4版本，对现有运维管控系统最大的影响是，原先包含 <code>MASTER/SLAVE</code> 关键字的指令不再可用，相应的主要改动详见下表</p>
<table>
<tbody>
<tr>
<th>旧指令</th>
<th>新指令</th>
</tr>
</tbody>
<tbody>
<tr>
<td>START SLAVE</td>
<td>START REPLICA</td>
</tr>
<tr>
<td>STOP SLAVE</td>
<td>STOP REPLICA</td>
</tr>
<tr>
<td>SHOW SLAVE STATUS</td>
<td>SHOW REPLICA STATUS</td>
</tr>
<tr>
<td>SHOW SLAVE HOSTS</td>
<td>SHOW REPLICAS</td>
</tr>
<tr>
<td>RESET SLAVE</td>
<td>RESET REPLICA</td>
</tr>
<tr>
<td>CHANGE MASTER TO</td>
<td>CHANGE REPLICATION SOURCE TO</td>
</tr>
<tr>
<td>RESET MASTER</td>
<td>RESET BINARY LOGS AND GTIDS</td>
</tr>
<tr>
<td>SHOW MASTER STATUS</td>
<td>SHOW BINARY LOG STATUS</td>
</tr>
<tr>
<td>PURGE MASTER LOGS</td>
<td>PURGE BINARY LOGS</td>
</tr>
<tr>
<td>SHOW MASTER LOGS</td>
<td>SHOW BINARY LOGS</td>
</tr>
</tbody>
</table>
<p>此外，原来在 <code>CHANGE MASTER</code>（新的指令 <code>CHANGE REPLICATION SOURCE TO</code>） 以及 <code>START SLAVE</code>（新的指令 <code>START REPLICA</code>） 中相关的参数变量也同样发生变化，详见下表</p>
<table>
<tbody>
<tr>
<th>旧参数名</th>
<th>新参数名</th>
</tr>
</tbody>
<tbody>
<tr>
<td>MASTER_AUTO_POSITION</td>
<td>SOURCE_AUTO_POSITION</td>
</tr>
<tr>
<td>MASTER_HOST</td>
<td>SOURCE_HOST</td>
</tr>
<tr>
<td>MASTER_BIND</td>
<td>SOURCE_BIND</td>
</tr>
<tr>
<td>MASTER_USER</td>
<td>SOURCE_USER</td>
</tr>
<tr>
<td>MASTER_PASSWORD</td>
<td>SOURCE_PASSWORD</td>
</tr>
<tr>
<td>MASTER_PORT</td>
<td>SOURCE_PORT</td>
</tr>
<tr>
<td>MASTER_CONNECT_RETRY</td>
<td>SOURCE_CONNECT_RETRY</td>
</tr>
<tr>
<td>MASTER_RETRY_COUNT</td>
<td>SOURCE_RETRY_COUNT</td>
</tr>
<tr>
<td>MASTER_DELAY</td>
<td>SOURCE_DELAY</td>
</tr>
<tr>
<td>MASTER_SSL</td>
<td>SOURCE_SSL</td>
</tr>
<tr>
<td>MASTER_SSL_CA</td>
<td>SOURCE_SSL_CA</td>
</tr>
<tr>
<td>MASTER_SSL_CAPATH</td>
<td>SOURCE_SSL_CAPATH</td>
</tr>
<tr>
<td>MASTER_SSL_CIPHER</td>
<td>SOURCE_SSL_CIPHER</td>
</tr>
<tr>
<td>MASTER_SSL_CRL</td>
<td>SOURCE_SSL_CRL</td>
</tr>
<tr>
<td>MASTER_SSL_CRLPATH</td>
<td>SOURCE_SSL_CRLPATH</td>
</tr>
<tr>
<td>MASTER_SSL_KEY</td>
<td>SOURCE_SSL_KEY</td>
</tr>
<tr>
<td>MASTER_SSL_VERIFY_SERVER_CERT</td>
<td>SOURCE_SSL_VERIFY_SERVER_CERT</td>
</tr>
<tr>
<td>MASTER_TLS_VERSION</td>
<td>SOURCE_TLS_VERSION</td>
</tr>
<tr>
<td>MASTER_TLS_CIPHERSUITES</td>
<td>SOURCE_TLS_CIPHERSUITES</td>
</tr>
<tr>
<td>MASTER_SSL_CERT</td>
<td>SOURCE_SSL_CERT</td>
</tr>
<tr>
<td>MASTER_PUBLIC_KEY_PATH</td>
<td>SOURCE_PUBLIC_KEY_PATH</td>
</tr>
<tr>
<td>GET_MASTER_PUBLIC_KEY</td>
<td>GET_SOURCE_PUBLIC_KEY</td>
</tr>
<tr>
<td>MASTER_HEARTBEAT_PERIOD</td>
<td>SOURCE_HEARTBEAT_PERIOD</td>
</tr>
<tr>
<td>MASTER_COMPRESSION_ALGORITHMS</td>
<td>SOURCE_COMPRESSION_ALGORITHMS</td>
</tr>
<tr>
<td>MASTER_ZSTD_COMPRESSION_LEVEL</td>
<td>SOURCE_ZSTD_COMPRESSION_LEVEL</td>
</tr>
<tr>
<td>MASTER_LOG_FILE</td>
<td>SOURCE_LOG_FILE</td>
</tr>
<tr>
<td>MASTER_LOG_POS</td>
<td>SOURCE_LOG_POS</td>
</tr>
</tbody>
</table>
<p>执行 SQL 命令 <code>SHOW [GLOBAL] STATUS</code> 的结果中，也有部分状态变量发生变化，详见下表</p>
<table>
<tbody>
<tr>
<th>旧状态变量名</th>
<th>新状态变量名</th>
</tr>
</tbody>
<tbody>
<tr>
<td>Com_slave_start</td>
<td>Com_replica_start</td>
</tr>
<tr>
<td>Com_slave_stop</td>
<td>Com_replica_stop</td>
</tr>
<tr>
<td>Com_show_slave_status</td>
<td>Com_show_replica_status</td>
</tr>
<tr>
<td>Com_show_slave_hosts</td>
<td>Com_show_replicas</td>
</tr>
<tr>
<td>Com_show_master_status</td>
<td>Com_show_binary_log_status</td>
</tr>
<tr>
<td>Com_change_master</td>
<td>Com_change_replication_source</td>
</tr>
</tbody>
</table>
<h2><strong>升级/降级到 GreatSQL 8.4.4-4</strong></h2>
<h3><strong>升级到 GreatSQL 8.4.4-4</strong></h3>
<ul>
<li> <p>如果是 GreatSQL 5.7 等系列版本，可以直接在原来的 <code>datadir</code> 基础上，修改 <code>basedir</code> 后，原地（in-place）启动 GreatSQL 8.0.32-27 版本后，先原地升级到 GreatSQL 8.0.32-27 版本。再继续在该 <code>datadir</code> 基础上升级，即修改 <code>basedir</code> 指向 GreatSQL 8.4.4-4 新版本，再次进行原地升级。需要注意的是，从 5.7 版本升级到 8.0 版本，再升级到 8.4 版本后，数据库中的账号仍采用 <code>mysql_native_password</code> 密码验证插件。当最终升级到 8.4 版本后，需要修改 <em>my.cnf</em> 配置文件，加上 <code>mysql_native_password=1</code>，以保证原有的账号能正常登录。</p> </li>
<li> <p>如果是 GreatSQL 8.0 等系列版本，并且没有使用 <strong>Rapid</strong> 引擎，则可以直接在原来的 <code>datadir</code> 基础上，修改 <code>basedir</code> 后，原地（in-place）启动 GreatSQL 8.4.4-4 后会完成自动升级。</p> </li>
<li> <p>如果旧版本是 GreatSQL 8.0.32-27 且已启用 <strong>Rapid</strong> 引擎，可以直接在原来的 <code>datadir</code> 基础上，修改 <code>basedir</code> 后，原地（in-place）启动 GreatSQL 8.4.4-4 后会完成自动升级。</p> </li>
<li> <p>如果旧版本是 GreatSQL 8.0.32-25 或 8.0.32-26 且已启用 <strong>Rapid</strong> 引擎，<strong>这种情况下无法原地升级</strong>，需要卸载所有 <strong>Rapid</strong> 引擎表，删除 <strong>Rapid</strong> 数据文件，才可以在原来的 <code>datadir</code> 基础上，修改 <code>basedir</code> 后，原地（in-place）启动 GreatSQL 8.4.4-4 后进行自动升级。新版本实例启动后，对所有 <strong>Rapid</strong> 引擎表执行 <code>ALTER TABLE SECONDARY_LOAD</code> 完成全量数据导入，再执行 <code>SELECT START_SECONDARY_ENGINE_INCREMENT_LOAD_TASK()</code> 启动增量导入任务，完成 <strong>Rapid</strong> 引擎表升级工作。下面是一个升级参考过程：</p> <pre><code>&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong style="color:#000000"&gt;1. 查询并记录所有Rapid引擎表&lt;/strong&gt;
&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;可以执行下面的SQL，查询当前有哪些表使用了Rapid引擎：
&lt;pre style="margin-left:5px; margin-right:5px; text-align:left"&gt;
</code></pre> <p><code>greatsql&gt; <span>SELECT</span> TABLE_SCHEMA, TABLE_NAME, TABLE_ROWS <span>FROM</span> information_schema.TABLES <span>WHERE</span> CREATE_OPTIONS <span>LIKE</span> <span>'%Rapid%'</span>; +<em>--------------+----------------+------------+</em> | TABLE_SCHEMA | TABLE_NAME | TABLE_ROWS | +<em>--------------+----------------+------------+</em> | tpch100g | customer | 14854987 | | tpch100g | lineitem | 582868392 | | tpch100g | nation | 25 | | tpch100g | orders | 148492582 | | tpch100g | part | 19943155 | | tpch100g | partsupp | 79832625 | | tpch100g | region | 5 | | tpch100g | supplier | 989416 | +<em>--------------+----------------+------------+</em> </code></p> <pre><code>&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong style="color:#000000"&gt;2. 正常停止GreatSQL实例进程&lt;/strong&gt;
&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;在停止GreatSQL实例进程前，先修改&lt;code&gt;innodb_fast_shutdown=0&lt;/code&gt;后再执行&lt;code&gt;SHUTDOWN&lt;/code&gt;停止实例
&lt;pre style="margin-left:5px; margin-right:5px; text-align:left"&gt;
</code></pre> <p><code>greatsql&gt; <span>SET</span> <span>GLOBAL</span> innodb_fast_shutdown=<span>0</span>; greatsql&gt; SHUTDOWN; </code></p> <pre><code>&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong style="color:#000000"&gt;3. 删除旧的Rapid引擎数据文件&lt;/strong&gt;
&lt;pre style="margin-left:5px; margin-right:5px; text-align:left"&gt;
</code></pre> <p><code><span>cd</span> /data/GreatSQL &amp;&amp; rm -f duckdb* </code></p> <pre><code>&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong style="color:#000000"&gt;4. 修改&lt;code&gt;my.cnf&lt;/code&gt;配置文件中的&lt;code&gt;basedir&lt;/code&gt;参数，指向GreatSQL 8.4.4-4新版本&lt;/strong&gt;
&lt;pre style="margin-left:5px; margin-right:5px; text-align:left"&gt;
</code></pre> <p><code>#my.cnf [mysqld] basedir=/usr/local/GreatSQL-8.4.4-4-Linux-glibc2.28-x86_64 </code></p> <pre><code>&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;并确保参数&lt;code&gt;upgrade&lt;/code&gt;不是设置为&lt;em&gt;NONE&lt;/em&gt;。
&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong style="color:#000000"&gt;5. 启动GreatSQL 8.4.4-4新版本实例&lt;/strong&gt;
&lt;pre style="margin-left:5px; margin-right:5px; text-align:left"&gt;
</code></pre> <p><code>systemctl start greatsql </code></p> <pre><code>&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong style="color:#000000"&gt;6. 重新安装Rapid引擎&lt;/strong&gt;
&lt;pre style="margin-left:5px; margin-right:5px; text-align:left"&gt;
</code></pre> <p><code>greatsql&gt; <span>INSTALL</span> <span>PLUGIN</span> rapid <span>SONAME</span> <span>'ha_rapid.so'</span>; </code></p> <pre><code>&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong style="color:#000000"&gt;7. 对Rapid引擎表做一次全量数据导入&lt;/strong&gt;
&lt;pre style="margin-left:5px; margin-right:5px; text-align:left"&gt;
</code></pre> <p><code>greatsql&gt; <span>ALTER</span> <span>TABLE</span> test.t1 SECONDARY_LOAD; </code></p> </li>
</ul>
<blockquote>
<p>tip 小贴士：由于在升级前没有去掉该表的<code>SECONDARY_ENGINE=rapid</code>属性，所以无需重新设置。如果在升级前卸载所有Rapid引擎表，则需要重新设置。</p>
</blockquote>
<p><strong>8. 再次启动增量导入任务</strong></p>
<pre><code>greatsql&gt; <span>SELECT</span> START_SECONDARY_ENGINE_INCREMENT_LOAD_TASK(<span>'test'</span>, <span>'t1'</span>);
</code></pre>
<p>这就完成Rapid引擎表的升级操作了。</p>
<ul>
<li> <p>如果是 MySQL 5.7 或 Percona Server 5.7 等系列版本，可以直接在原来的 <code>datadir</code> 基础上，修改 <code>basedir</code> 后，原地（in-place）启动 GreatSQL 8.0.32-27 版本后，确认升级成功后，再次在原来 <code>datadir</code> 基础上继续升级，即修改 <code>basedir</code> 指向 GreatSQL 8.4.4-4 新版本，之后就能完成自动升级。需要注意的是，从 5.7 版本升级到 8.0 版本，再升级到 8.4 版本后，数据库中的账号仍采用 <code>mysql_native_password</code> 密码验证插件。当最终升级到 8.4 版本后，需要修改 <em>my.cnf</em> 配置文件，加上 <code>mysql_native_password=1</code>，以保证原有的账号能正常登录。</p> </li>
<li> <p>如果是 MySQL 8.0 或 Percona Server 8.0 等系列版本，则可以直接在原来的 <code>datadir</code> 基础上，修改 <code>basedir</code> 后，原地（in-place）启动 GreatSQL 8.4.4-4 后会完成自动升级。</p> </li>
<li> <p>其他情况下，最好采用导入逻辑备份文件方式升级到 GreatSQL 8.4.4-4 版本。</p> </li>
</ul>
<p>在以上几个原地升级场景中，务必保证<code>my.cnf</code>中参数<code>upgrade</code>不能设置为<em>NONE</em>，可以设置为默认的<em>AUTO</em>或<em>FORCE</em>。例如：</p>
<pre><code>#my.cnf
[mysqld]
upgrade = AUTO
</code></pre>
<p>更多迁移升级方案请参考：</p>
<ul>
<li>迁移升级：https://greatsql.cn/docs/8.4.4-4/7-migrate-and-upgrade/0-migrate-and-upgrade.html</li>
</ul>
<h3><strong>降级到 GreatSQL 8.4.4-4</strong></h3>
<p>如果是要从 MySQL/Percona 8.4 系列较高的小版本降级到 GreatSQL 8.4.4-4 版本，可以采用原地降级方式快速完成版本降级操作。即可以直接在原来的 <code>datadir</code> 基础上，修改 <code>basedir</code> 后，并增加设置参数<code>upgrade=FORCE</code>，原地（in-place）启动 GreatSQL 8.4.4-4 后会完成自动降级。</p>
<p>如果是要从 MySQL/Percona 9.0 及之后的版本降级到 GreatSQL 8.4.4-4 版本，则需要采取逻辑备份 + 逻辑导入方式完成降级操作，并且在逻辑备份导入完成后的首次重启时，务必设置 <code>upgrade=FORCE</code> 强制升级所有数据表，包括系统表。</p>
<p>降级过程操作大致如下所示：</p>
<p><strong>1. 在高版本中逻辑备份全量数据</strong></p>
<pre><code>mysqldump -S/data/MySQL/mysql.sock -A --triggers --routines --events --single-transaction &gt; /data/backup/fulldump.sql
</code></pre>
<p><strong>2. 在GreatSQL 8.4.4-4版本环境中导入逻辑备份文件，完成逻辑恢复</strong></p>
<pre><code>mysql -S/data/GreatSQL/mysql.sock -f &lt; /data/backup/fulldump.sql
</code></pre>
<p><strong>3. 修改<code>my.cnf</code>，确保设置<code>upgrade=FORCE</code></strong></p>
<pre><code>#my.cnf
[mysqld]
upgrade = FORCE
</code></pre>
<p><strong>4. 重启GreatSQL，降级完成</strong></p>
<pre><code>systemctl restart greatsql
</code></pre>
<p>重启过程中，可以看到日志有类似下面的强制降级过程</p>
<pre><code>[Note] [MY-013387] [Server] Upgrading system table data.
[Note] [MY-013385] [Server] Upgrading the sys schema.
[Note] [MY-013400] [Server] Upgrade of help tables started.
[Note] [MY-013400] [Server] Upgrade of help tables completed.
[Note] [MY-013394] [Server] Checking 'mysql' schema.
[Note] [MY-013394] [Server] Checking 'sys' schema.
[System] [MY-014064] [Server] Server downgrade from '80406' to '80404' started.
[System] [MY-014064] [Server] Server downgrade from '80406' to '80404' completed.
</code></pre>
<p>如果不设置 <code>upgrade = FORCE</code> 强制升级所有表，有可能发生系统表 <code>mysql.procs_priv</code> 损坏错误，在创建用户时可能会报告类似下面的错误：</p>
<pre><code>greatsql&gt; <span>CREATE</span> <span>USER</span> tpch <span>IDENTIFIED</span> <span>BY</span> <span>'tpch'</span>;
ERROR 1728 (HY000): Cannot <span>load</span> <span>from</span> mysql.procs_priv. The <span>table</span> <span>is</span> probably corrupted
</code></pre>
<h2><strong>GreatSQL vs MySQL</strong></h2>
<table>
<tbody>
<tr>
<th><strong>1.主要特性</strong></th>
<th>GreatSQL 8.4.4-4</th>
<th>MySQL 8.4.4</th>
</tr>
</tbody>
<tbody>
<tr>
<td>开源</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>ACID 完整性</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>MVCC 特性</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>支持行锁</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>Crash 自动修复</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>表分区（Partitioning）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>视图（Views）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>子查询（Subqueries）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>触发器（Triggers）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>存储程序（Stored Programs）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>外键（Foreign Keys）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>窗口函数（Window Functions）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>通用表表达式 CTE</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>地理信息（GIS）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>基于 GTID 的复制</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>组复制（MGR）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>MyRocks 引擎</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>支持龙芯架构</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td><strong>2. 性能提升扩展</strong></td>
<td>GreatSQL 8.4.4-4</td>
<td>MySQL 8.4.4</td>
</tr>
<tr>
<td>Rapid 引擎</td>
<td>✔️</td>
<td>仅云上HeatWave</td>
</tr>
<tr>
<td>Turbo 引擎</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>NUMA 亲和性优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>非阻塞式 DDL</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>无主键表导入优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>并行 LOAD DATA</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>InnoDB 事务 ReadView 无锁优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>InnoDB 事务大锁拆分优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>InnoDB Page压缩支持Zstd</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>InnoDB 资源组</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>自定义 InnoDB 页大小</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>Contention-Aware Transaction Scheduling</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>InnoDB Mutexes 拆分优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MEMORY 引擎优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>InnoDB Flushing 优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>并行 Doublewrite Buffer</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>InnoDB 快速索引创建优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>VARCHAR/BLOB/JSON 类型存储单列压缩</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>数据字典中存储单列压缩信息</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td><strong>3. 面向开发者提升改进</strong></td>
<td>GreatSQL 8.4.4-4</td>
<td>MySQL 8.4.4</td>
</tr>
<tr>
<td>X API</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>JSON</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>NoSQL Socket-Level接口</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>InnoDB 全文搜索改进</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>更多 Hash/Digest 函数</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Oracle 兼容-数据类型</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Oracle 兼容-函数</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Oracle 兼容-SQL语法</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Oracle 兼容-存储程序</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td><strong>4. 基础特性提升改进</strong></td>
<td>GreatSQL 8.4.4-4</td>
<td>MySQL 8.4.4</td>
</tr>
<tr>
<td>MGR 提升-地理标签</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-仲裁节点</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-读写节点绑定VIP</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-快速单主模式</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-智能选主机制</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-全新流控算法</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-网络分区异常处理</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-节点异常退出处理</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-节点磁盘满处理</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-自动选择 donor 节点</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-大事务压缩优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Clone 增量备份</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Clone 备份压缩</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Binlog 读取限速</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>information_schema 表数量</td>
<td>95</td>
<td>65</td>
</tr>
<tr>
<td>全局性能和状态指标</td>
<td>853</td>
<td>434</td>
</tr>
<tr>
<td>优化器直方图（Histograms）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>Per-Table 性能指标</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Per-Index 性能指标</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Per-User 性能指标</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Per-Client 性能指标</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Per-Thread 性能指标</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>全局查询相应耗时统计</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>SHOW ENGINE INNODB STATUS 增强</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>回滚段信息增强</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>临时表信息增强</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>用户统计信息增强</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Slow log 信息增强</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td><strong>5.安全性提升</strong></td>
<td>GreatSQL 8.4.4-4</td>
<td>MySQL 8.4.4</td>
</tr>
<tr>
<td>国密支持</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>备份加密</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>审计</td>
<td>✔️</td>
<td>仅企业版</td>
</tr>
<tr>
<td>数据脱敏</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>SQL Roles</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>SHA-2 密码Hashing</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>密码轮换策略</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>PAM 认证插件</td>
<td>✔️</td>
<td>仅企业版</td>
</tr>
<tr>
<td>Keyring 存储在文件中</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>Keyring 存储在Hashicorp Vault中</td>
<td>✔️</td>
<td>仅企业版</td>
</tr>
<tr>
<td>InnoDB 数据加密</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>InnoDB 日志加密</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>InnoDB 各种表空间文件加密</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>二进制日志加密</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>临时文件加密</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>强制加密</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td><strong>6. 运维便利性提升</strong></td>
<td>GreatSQL 8.4.4-4</td>
<td>MySQL 8.4.4</td>
</tr>
<tr>
<td>DDL 原子性</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>数据字典存储 InnoDB 表</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>快速 DDL</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>SET PERSIST</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>不可见索引</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>线程池（Threadpool）</td>
<td>✔️</td>
<td>仅企业版</td>
</tr>
<tr>
<td>备份锁</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>SHOW GRANTS 扩展</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>表损坏动作扩展</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>杀掉不活跃事务</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>START TRANSACTION WITH CONSISTENT SNAPSHOT 扩展</td>
<td>✔️</td>
<td>❌</td>
</tr>
</tbody>
</table>
<p>GreatSQL 8.4.4-4 基于 Percona Server for MySQL 8.4.4-4 版本，它在 MySQL 8.4.4 基础上做了大量的改进和提升以及众多新特性，详情请见：</p>
<ul>
<li>Percona Server for MySQL feature comparison: https://docs.percona.com/percona-server/8.4/feature-comparison.html</li>
</ul>
<p>这其中包括线程池、审计、数据脱敏等 MySQL 企业版才有的特性，以及 performance_schema 提升、information_schema 提升、性能和可扩展性提升、用户统计增强、PROCESSLIST 增强、Slow Log 增强等大量改进和提升，这里不一一重复列出。</p>
<h2><strong>GreatSQL Release Notes</strong></h2>
<h3><strong>GreatSQL 8.4</strong></h3>
<ul>
<li>Changes in GreatSQL 8.4.4-4 (2025-10-15) https://greatsql.cn/docs/8.4.4-4/1-docs-intro/relnotes/changes-greatsql-8444.html</li>
</ul>
<h3><strong>GreatSQL 8.0</strong></h3>
<ul>
<li>Changes in GreatSQL 8.0.32-27 (2025-3-10)</li>
<li>Changes in GreatSQL 8.0.32-26 (2024-8-5)</li>
<li>Changes in GreatSQL 8.0.32-25 (2023-12-28)</li>
<li>Changes in GreatSQL 8.0.32-24 (2023-6-5)</li>
<li>Changes in GreatSQL 8.0.25-17 (2023-3-13)</li>
<li>Changes in GreatSQL 8.0.25-16 (2022-5-16)</li>
<li>Changes in GreatSQL 8.0.25-15 (2021-8-26)</li>
</ul>
<h3><strong>GreatSQL 5.7</strong></h3>
<ul>
<li>Changes in GreatSQL 5.7.36-39 (2022-4-7)</li>
</ul>]]></content:encoded>
    
    <pubDate>Wed, 15 Oct 2025 09:26:31 +0800</pubDate>
  </item><item>
    <title><![CDATA[高性能跨平台网络通信框架 HP-Socket v6.0.7 发布]]></title>
    <link>https://www.oschina.net/news/377453</link>
    <itunes:title><![CDATA[高性能跨平台网络通信框架 HP-Socket v6.0.7 发布]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fldcsaa%2FHP-Socket" target="_blank"><img alt="HP-Socket" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-68508a98b0.png"></a></p>
<ul>
<li>项目主页&nbsp;:&nbsp;<a href="http://www.oschina.net/p/hp-socket" target="_blank">http://www.oschina.net/p/hp-socket</a></li>
<li>开发文档&nbsp;: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.docin.com%2Fp-4592706661.html" target="_blank">https://www.docin.com/p-4592706661.html</a></li>
<li>下载地址&nbsp;: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fldcsaa%2FHP-Socket" target="_blank">https://github.com/ldcsaa/HP-Socket</a></li>
<li>QQ Group: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjq.qq.com%2F%3F_wv%3D1027%26k%3D3UAbrhTG" target="_blank">44636872</a>, <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjq.qq.com%2F%3F_wv%3D1027%26k%3DuYBpc6bG" target="_blank">663903943</a></li>
</ul>
<hr>
<h2><span><strong>v6.0.7 更新</strong></span></h2>
<p><strong>一、主要更新</strong></p>
<ol>
<li>优化Linux通信组件多路复用处理架构，避免“惊群”问题，提升性能。</li>
<li>自动为 HP-Socket 工作线程设置唯一线程名称，方便跟踪调试。</li>
<li>TCP Client/Agent 以同步方式连接服务端时，支持通过 <em>SetSyncConnectTimeout()</em> 设置连接超时时间。</li>
<li>TcpServer/UdpServer/UdpNode 支持通过 SetDualStack() 方法设置是否支持 IPv4/IPv6 双协议栈。</li>
<li>客户端组件（Client/Agent）手工绑定本地地址的情况下，会根据连接的远程地址自动绑定本地的IPv4或IPv6地址。</li>
<li>支持定时回收垃圾内存和被动回收垃圾内存（默认使用定时回收，回收间隔 15 秒）。</li>
<li>Windows版本支持在没有安装 MFC 的环境下编译。</li>
</ol>
<p><strong>二、第三方库更新</strong></p>
<ol>
<li>openssl 升级到 3.0.18 版本</li>
<li>mimalloc 升级到 2.2.4 版本</li>
</ol>
<hr>
<h2><span><strong>HP-Socket 组件列表</strong></span></h2>
<ol>
<li><span><strong>基础组件<br> <img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-1a71c07c2e.png"></strong></span></li>
<li><span><strong>SSL 组件<br> <img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-fa2fd83cad.png"></strong></span></li>
<li><span><strong>HTTP 组件<br> <img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-979c3f87aa.png"></strong></span></li>
</ol>
<hr>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fldcsaa%2FHP-Socket" target="_blank"><img alt="HP-Socket" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-68508a98b0.png"></a></p>
<ul>
<li>项目主页&nbsp;:&nbsp;<a href="http://www.oschina.net/p/hp-socket" target="_blank">http://www.oschina.net/p/hp-socket</a></li>
<li>开发文档&nbsp;: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.docin.com%2Fp-4592706661.html" target="_blank">https://www.docin.com/p-4592706661.html</a></li>
<li>下载地址&nbsp;: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fldcsaa%2FHP-Socket" target="_blank">https://github.com/ldcsaa/HP-Socket</a></li>
<li>QQ Group: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjq.qq.com%2F%3F_wv%3D1027%26k%3D3UAbrhTG" target="_blank">44636872</a>, <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjq.qq.com%2F%3F_wv%3D1027%26k%3DuYBpc6bG" target="_blank">663903943</a></li>
</ul>
<hr>
<h2><span><strong>v6.0.7 更新</strong></span></h2>
<p><strong>一、主要更新</strong></p>
<ol>
<li>优化Linux通信组件多路复用处理架构，避免“惊群”问题，提升性能。</li>
<li>自动为 HP-Socket 工作线程设置唯一线程名称，方便跟踪调试。</li>
<li>TCP Client/Agent 以同步方式连接服务端时，支持通过 <em>SetSyncConnectTimeout()</em> 设置连接超时时间。</li>
<li>TcpServer/UdpServer/UdpNode 支持通过 SetDualStack() 方法设置是否支持 IPv4/IPv6 双协议栈。</li>
<li>客户端组件（Client/Agent）手工绑定本地地址的情况下，会根据连接的远程地址自动绑定本地的IPv4或IPv6地址。</li>
<li>支持定时回收垃圾内存和被动回收垃圾内存（默认使用定时回收，回收间隔 15 秒）。</li>
<li>Windows版本支持在没有安装 MFC 的环境下编译。</li>
</ol>
<p><strong>二、第三方库更新</strong></p>
<ol>
<li>openssl 升级到 3.0.18 版本</li>
<li>mimalloc 升级到 2.2.4 版本</li>
</ol>
<hr>
<h2><span><strong>HP-Socket 组件列表</strong></span></h2>
<ol>
<li><span><strong>基础组件<br> <img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-1a71c07c2e.png"></strong></span></li>
<li><span><strong>SSL 组件<br> <img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-fa2fd83cad.png"></strong></span></li>
<li><span><strong>HTTP 组件<br> <img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-979c3f87aa.png"></strong></span></li>
</ol>
<hr>]]>
    </description>
    <content:encoded><![CDATA[<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fldcsaa%2FHP-Socket" target="_blank"><img alt="HP-Socket" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-68508a98b0.png"></a></p>
<ul>
<li>项目主页&nbsp;:&nbsp;<a href="http://www.oschina.net/p/hp-socket" target="_blank">http://www.oschina.net/p/hp-socket</a></li>
<li>开发文档&nbsp;: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.docin.com%2Fp-4592706661.html" target="_blank">https://www.docin.com/p-4592706661.html</a></li>
<li>下载地址&nbsp;: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fldcsaa%2FHP-Socket" target="_blank">https://github.com/ldcsaa/HP-Socket</a></li>
<li>QQ Group: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjq.qq.com%2F%3F_wv%3D1027%26k%3D3UAbrhTG" target="_blank">44636872</a>, <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjq.qq.com%2F%3F_wv%3D1027%26k%3DuYBpc6bG" target="_blank">663903943</a></li>
</ul>
<hr>
<h2><span><strong>v6.0.7 更新</strong></span></h2>
<p><strong>一、主要更新</strong></p>
<ol>
<li>优化Linux通信组件多路复用处理架构，避免“惊群”问题，提升性能。</li>
<li>自动为 HP-Socket 工作线程设置唯一线程名称，方便跟踪调试。</li>
<li>TCP Client/Agent 以同步方式连接服务端时，支持通过 <em>SetSyncConnectTimeout()</em> 设置连接超时时间。</li>
<li>TcpServer/UdpServer/UdpNode 支持通过 SetDualStack() 方法设置是否支持 IPv4/IPv6 双协议栈。</li>
<li>客户端组件（Client/Agent）手工绑定本地地址的情况下，会根据连接的远程地址自动绑定本地的IPv4或IPv6地址。</li>
<li>支持定时回收垃圾内存和被动回收垃圾内存（默认使用定时回收，回收间隔 15 秒）。</li>
<li>Windows版本支持在没有安装 MFC 的环境下编译。</li>
</ol>
<p><strong>二、第三方库更新</strong></p>
<ol>
<li>openssl 升级到 3.0.18 版本</li>
<li>mimalloc 升级到 2.2.4 版本</li>
</ol>
<hr>
<h2><span><strong>HP-Socket 组件列表</strong></span></h2>
<ol>
<li><span><strong>基础组件<br> <img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-1a71c07c2e.png"></strong></span></li>
<li><span><strong>SSL 组件<br> <img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-fa2fd83cad.png"></strong></span></li>
<li><span><strong>HTTP 组件<br> <img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-979c3f87aa.png"></strong></span></li>
</ol>
<hr>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-68508a98b0.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-68508a98b0.png" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 03:28:54 +0800</pubDate>
  </item><item>
    <title><![CDATA[GNOME Flatpak 运行时不再兼容 32 位扩展]]></title>
    <link>https://www.oschina.net/news/377416</link>
    <itunes:title><![CDATA[GNOME Flatpak 运行时不再兼容 32 位扩展]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>GNOME 团队近日<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblogs.gnome.org%2Falatiera%2F2025%2F10%2F13%2Fflatpak-32bit%2F" target="_blank">宣布</a>，在最新的 <strong>GNOME 49</strong> 中，Flatpak 运行时正式移除用于 32 位环境的兼容扩展（<code>org.gnome.Platform.i386.Compat</code>），意味着 GNOME 平台今后将仅支持 <strong>x86_64</strong> 和 <strong>AArch64</strong> 架构。</p>
<p>更早之前，GNOME 已经移除了对 <strong>ARMv7（32 位 ARM）</strong> 的支持，以及对 i386（传统的 32 位 x86） 构建的支持。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-deeab67562.png"></p>
<p>这一扩展最初用于支持如 Wine 等依赖 32 位库的应用，但由于维护资源有限，GNOME 开发者决定放弃该功能。据称，这一调整部分原因是<span><strong>项目失去了持续集成环境中的捐赠硬件</strong></span>，32 位兼容模块因此成为首个被精简的目标。</p>
<p>在官方公告中（由 Jordan Petridis 发布）提到，如果有发行版或用户还依赖于 32 位 GNOME 构建，那么他们将需要自行维护、调试这些版本，或直接参与上游（GNOME 社区）的工作，以避免 32 位版本逐渐“腐蚀”（bit rot）。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>GNOME 团队近日<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblogs.gnome.org%2Falatiera%2F2025%2F10%2F13%2Fflatpak-32bit%2F" target="_blank">宣布</a>，在最新的 <strong>GNOME 49</strong> 中，Flatpak 运行时正式移除用于 32 位环境的兼容扩展（<code>org.gnome.Platform.i386.Compat</code>），意味着 GNOME 平台今后将仅支持 <strong>x86_64</strong> 和 <strong>AArch64</strong> 架构。</p>
<p>更早之前，GNOME 已经移除了对 <strong>ARMv7（32 位 ARM）</strong> 的支持，以及对 i386（传统的 32 位 x86） 构建的支持。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-deeab67562.png"></p>
<p>这一扩展最初用于支持如 Wine 等依赖 32 位库的应用，但由于维护资源有限，GNOME 开发者决定放弃该功能。据称，这一调整部分原因是<span><strong>项目失去了持续集成环境中的捐赠硬件</strong></span>，32 位兼容模块因此成为首个被精简的目标。</p>
<p>在官方公告中（由 Jordan Petridis 发布）提到，如果有发行版或用户还依赖于 32 位 GNOME 构建，那么他们将需要自行维护、调试这些版本，或直接参与上游（GNOME 社区）的工作，以避免 32 位版本逐渐“腐蚀”（bit rot）。</p>]]>
    </description>
    <content:encoded><![CDATA[<p>GNOME 团队近日<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblogs.gnome.org%2Falatiera%2F2025%2F10%2F13%2Fflatpak-32bit%2F" target="_blank">宣布</a>，在最新的 <strong>GNOME 49</strong> 中，Flatpak 运行时正式移除用于 32 位环境的兼容扩展（<code>org.gnome.Platform.i386.Compat</code>），意味着 GNOME 平台今后将仅支持 <strong>x86_64</strong> 和 <strong>AArch64</strong> 架构。</p>
<p>更早之前，GNOME 已经移除了对 <strong>ARMv7（32 位 ARM）</strong> 的支持，以及对 i386（传统的 32 位 x86） 构建的支持。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-deeab67562.png"></p>
<p>这一扩展最初用于支持如 Wine 等依赖 32 位库的应用，但由于维护资源有限，GNOME 开发者决定放弃该功能。据称，这一调整部分原因是<span><strong>项目失去了持续集成环境中的捐赠硬件</strong></span>，32 位兼容模块因此成为首个被精简的目标。</p>
<p>在官方公告中（由 Jordan Petridis 发布）提到，如果有发行版或用户还依赖于 32 位 GNOME 构建，那么他们将需要自行维护、调试这些版本，或直接参与上游（GNOME 社区）的工作，以避免 32 位版本逐渐“腐蚀”（bit rot）。</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-deeab67562.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-deeab67562.png" medium="image"/>
    <pubDate>Tue, 14 Oct 2025 19:26:44 +0800</pubDate>
  </item><item>
    <title><![CDATA[WinBoat - 在 Linux 上运行 Windows 应用]]></title>
    <link>https://www.oschina.net/p/winboat</link>
    <itunes:title><![CDATA[WinBoat - 在 Linux 上运行 Windows 应用]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>WinBoat 是一款 Electron 应用，它允许你使用容器化方法在 Linux 上运行 Windows 应用。Windows 以虚拟机的形式在 Docker 容器内运行，使用&nbsp;<span><span>&nbsp;</span></span><a href="https://github.com/TibixDev/winboat/tree/main/guest_server">WinBoat Guest Server</a><span><span>&nbsp;</span></span>与其通信，从 Windows 中检索所需的数据。为了将应用程序合成为原生操作系统级窗口，将 FreeRDP 与 Windows 的 RemoteApp 协议结合使用。</p>
<p><span>WinBoat 目前处于测试阶段。</span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-17332fb737.png"></p>
<p><strong>特性：</strong></p>
<ul>
<li><strong>优雅的界面</strong>：时尚直观的界面，将 Windows 无缝集成到你的 Linux 桌面环境中，让你感觉像原生体验</li>
<li><strong>自动安装</strong>：通过界面进行简单的安装过程 - 选择你的偏好和规格，然后自动处理其余部分</li>
<li><strong>运行任何应用程序</strong>：只要能在 Windows 上运行，就能在 WinBoat 上运行。在 Linux 环境中，像原生操作系统级窗口一样畅享各种 Windows 应用程序。</li>
<li><strong>完整的 Windows 桌面</strong>：在需要时访问完整的 Windows 桌面体验，或运行无缝集成到 Linux 工作流程中的单个应用程序</li>
<li><strong>文件系统集成</strong>：主目录安装在 Windows 中，允许在两个系统之间轻松共享文件，没有任何麻烦</li>
<li><strong>还有更多</strong>：智能卡直通、资源监控以及定期添加的更多功能</li>
</ul>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>WinBoat 是一款 Electron 应用，它允许你使用容器化方法在 Linux 上运行 Windows 应用。Windows 以虚拟机的形式在 Docker 容器内运行，使用&nbsp;<span><span>&nbsp;</span></span><a href="https://github.com/TibixDev/winboat/tree/main/guest_server">WinBoat Guest Server</a><span><span>&nbsp;</span></span>与其通信，从 Windows 中检索所需的数据。为了将应用程序合成为原生操作系统级窗口，将 FreeRDP 与 Windows 的 RemoteApp 协议结合使用。</p>
<p><span>WinBoat 目前处于测试阶段。</span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-17332fb737.png"></p>
<p><strong>特性：</strong></p>
<ul>
<li><strong>优雅的界面</strong>：时尚直观的界面，将 Windows 无缝集成到你的 Linux 桌面环境中，让你感觉像原生体验</li>
<li><strong>自动安装</strong>：通过界面进行简单的安装过程 - 选择你的偏好和规格，然后自动处理其余部分</li>
<li><strong>运行任何应用程序</strong>：只要能在 Windows 上运行，就能在 WinBoat 上运行。在 Linux 环境中，像原生操作系统级窗口一样畅享各种 Windows 应用程序。</li>
<li><strong>完整的 Windows 桌面</strong>：在需要时访问完整的 Windows 桌面体验，或运行无缝集成到 Linux 工作流程中的单个应用程序</li>
<li><strong>文件系统集成</strong>：主目录安装在 Windows 中，允许在两个系统之间轻松共享文件，没有任何麻烦</li>
<li><strong>还有更多</strong>：智能卡直通、资源监控以及定期添加的更多功能</li>
</ul>]]>
    </description>
    <content:encoded><![CDATA[<p>WinBoat 是一款 Electron 应用，它允许你使用容器化方法在 Linux 上运行 Windows 应用。Windows 以虚拟机的形式在 Docker 容器内运行，使用&nbsp;<span><span>&nbsp;</span></span><a href="https://github.com/TibixDev/winboat/tree/main/guest_server">WinBoat Guest Server</a><span><span>&nbsp;</span></span>与其通信，从 Windows 中检索所需的数据。为了将应用程序合成为原生操作系统级窗口，将 FreeRDP 与 Windows 的 RemoteApp 协议结合使用。</p>
<p><span>WinBoat 目前处于测试阶段。</span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-17332fb737.png"></p>
<p><strong>特性：</strong></p>
<ul>
<li><strong>优雅的界面</strong>：时尚直观的界面，将 Windows 无缝集成到你的 Linux 桌面环境中，让你感觉像原生体验</li>
<li><strong>自动安装</strong>：通过界面进行简单的安装过程 - 选择你的偏好和规格，然后自动处理其余部分</li>
<li><strong>运行任何应用程序</strong>：只要能在 Windows 上运行，就能在 WinBoat 上运行。在 Linux 环境中，像原生操作系统级窗口一样畅享各种 Windows 应用程序。</li>
<li><strong>完整的 Windows 桌面</strong>：在需要时访问完整的 Windows 桌面体验，或运行无缝集成到 Linux 工作流程中的单个应用程序</li>
<li><strong>文件系统集成</strong>：主目录安装在 Windows 中，允许在两个系统之间轻松共享文件，没有任何麻烦</li>
<li><strong>还有更多</strong>：智能卡直通、资源监控以及定期添加的更多功能</li>
</ul>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-17332fb737.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-17332fb737.png" medium="image"/>
    <pubDate>Tue, 14 Oct 2025 18:37:46 +0800</pubDate>
  </item><item>
    <title><![CDATA[抖音与 LV-NUS 联合推出 SAIL-VL2 模型]]></title>
    <link>https://www.oschina.net/news/377404</link>
    <itunes:title><![CDATA[抖音与 LV-NUS 联合推出 SAIL-VL2 模型]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>抖音 SAIL 团队与 LV-NUS Lab 联手推出了一款名为 SAIL-VL2 的多模态大模型，并已开源。这个新模型在保持较小参数规模的同时，还在复杂推理任务中超过了许多同类模型，甚至能与更大型的闭源模型相抗衡。</p>
<p>SAIL-VL2的参数设置分为2B 和8B，在106个数据集上实现了性能的突破，尤其在 MMMU、MathVista 等复杂推理基准测试中表现优异。SAIL-VL2在数据、训练及架构设计上进行了三大方面的创新。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-3cfa38b868.png"></p>
<p>在架构设计上，SAIL-VL2引入了稀疏混合专家（MoE），以优化性能和计算效率。其视觉编码器 SAIL-ViT 采用渐进式优化，逐步提升视觉 - 语言的对齐能力。这种创新设计使得 SAIL-VL2在推理时仅需激活部分参数，大幅度提升了模型的计算效率。</p>
<p>数据层面上，SAIL-VL2构建了高质量的多模态语料库，通过评分过滤和合成增强手段，确保数据的准确性和多样性。同时，团队还设计了一套渐进式的训练框架，从基础感知逐步过渡到复杂推理，使得模型在不同任务中的表现更加出色。</p>
<p>通过全链路优化，SAIL-VL2在基础模型的性能上取得了显著进展。数据显示，该模型在多项基准测试中脱颖而出，其8B 规模的模型在推理能力上，已然与<span>最新</span>的 GPT-4o 不相上下。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>抖音 SAIL 团队与 LV-NUS Lab 联手推出了一款名为 SAIL-VL2 的多模态大模型，并已开源。这个新模型在保持较小参数规模的同时，还在复杂推理任务中超过了许多同类模型，甚至能与更大型的闭源模型相抗衡。</p>
<p>SAIL-VL2的参数设置分为2B 和8B，在106个数据集上实现了性能的突破，尤其在 MMMU、MathVista 等复杂推理基准测试中表现优异。SAIL-VL2在数据、训练及架构设计上进行了三大方面的创新。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-3cfa38b868.png"></p>
<p>在架构设计上，SAIL-VL2引入了稀疏混合专家（MoE），以优化性能和计算效率。其视觉编码器 SAIL-ViT 采用渐进式优化，逐步提升视觉 - 语言的对齐能力。这种创新设计使得 SAIL-VL2在推理时仅需激活部分参数，大幅度提升了模型的计算效率。</p>
<p>数据层面上，SAIL-VL2构建了高质量的多模态语料库，通过评分过滤和合成增强手段，确保数据的准确性和多样性。同时，团队还设计了一套渐进式的训练框架，从基础感知逐步过渡到复杂推理，使得模型在不同任务中的表现更加出色。</p>
<p>通过全链路优化，SAIL-VL2在基础模型的性能上取得了显著进展。数据显示，该模型在多项基准测试中脱颖而出，其8B 规模的模型在推理能力上，已然与<span>最新</span>的 GPT-4o 不相上下。</p>]]>
    </description>
    <content:encoded><![CDATA[<p>抖音 SAIL 团队与 LV-NUS Lab 联手推出了一款名为 SAIL-VL2 的多模态大模型，并已开源。这个新模型在保持较小参数规模的同时，还在复杂推理任务中超过了许多同类模型，甚至能与更大型的闭源模型相抗衡。</p>
<p>SAIL-VL2的参数设置分为2B 和8B，在106个数据集上实现了性能的突破，尤其在 MMMU、MathVista 等复杂推理基准测试中表现优异。SAIL-VL2在数据、训练及架构设计上进行了三大方面的创新。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-3cfa38b868.png"></p>
<p>在架构设计上，SAIL-VL2引入了稀疏混合专家（MoE），以优化性能和计算效率。其视觉编码器 SAIL-ViT 采用渐进式优化，逐步提升视觉 - 语言的对齐能力。这种创新设计使得 SAIL-VL2在推理时仅需激活部分参数，大幅度提升了模型的计算效率。</p>
<p>数据层面上，SAIL-VL2构建了高质量的多模态语料库，通过评分过滤和合成增强手段，确保数据的准确性和多样性。同时，团队还设计了一套渐进式的训练框架，从基础感知逐步过渡到复杂推理，使得模型在不同任务中的表现更加出色。</p>
<p>通过全链路优化，SAIL-VL2在基础模型的性能上取得了显著进展。数据显示，该模型在多项基准测试中脱颖而出，其8B 规模的模型在推理能力上，已然与<span>最新</span>的 GPT-4o 不相上下。</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-3cfa38b868.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-3cfa38b868.png" medium="image"/>
    <pubDate>Tue, 14 Oct 2025 18:13:21 +0800</pubDate>
  </item></channel>
</rss>