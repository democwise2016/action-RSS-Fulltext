<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:itunes="http://www.itunes.com/dtds/podcast-1.0.dtd" xmlns:googleplay="http://www.google.com/schemas/play-podcasts/1.0" xmlns:media="http://www.rssboard.org/media-rss" version="2.0">
  <channel>
    <title><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></title>
    <link>undefined</link>
    <image>
      <url>https://www.oschina.net/img/logo.gif</url>
      <title>OSCHINA 社区最新新闻[RSS+]</title>
      <link>undefined</link>
    </image>
    <language>zh-CN</language>
    <atom:link href="https://www.oschina.net/news/rss" rel="self" type="application/rss+xml"/>
    <copyright><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></copyright>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[
      OSCHINA - 中文开源技术交流社区<br />
<br />
<a href="https://www.oschina.net/news/rss" target="_blank">https://www.oschina.net/news/rss</a>
      ]]>
    </itunes:summary>
    <description>
      <![CDATA[
      OSCHINA - 中文开源技术交流社区<br />
<br />
<a href="https://www.oschina.net/news/rss" target="_blank">https://www.oschina.net/news/rss</a>
      ]]>
    </description>
    <itunes:owner>
      <itunes:name><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:name>
    </itunes:owner>
    <itunes:image href="https://www.oschina.net/img/logo.gif"/>
<item>
    <title><![CDATA[字节跳动开源 FaceCLIP：文本驱动的高保真人脸生成技术上线]]></title>
    <link>https://www.oschina.net/news/377587</link>
    <itunes:title><![CDATA[字节跳动开源 FaceCLIP：文本驱动的高保真人脸生成技术上线]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>字节跳动近日发布了FaceCLIP，一款专注于人脸理解与生成的视觉-语言模型。该工具通过文本提示和参考图像即可生成保持身份一致性的多样化人脸图像，在多模态AI的人脸语义处理领域实现了新的技术突破。</p>
<p>FaceCLIP的核心技术在于其身份保持型图像生成框架。用户输入一张参考人脸照片和文本描述后，模型能够生成保留原始身份特征的新图像，同时根据文本指令调整表情、姿态和风格等属性。与传统方法不同，FaceCLIP摒弃了适配器模块，转而采用多模态编码策略同步捕获身份信息和文本语义，实现了人脸特征与文本提示的深度融合。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-873a461c5a.png"></p>
<p>从技术架构来看，FaceCLIP基于开源基础模型构建，提供了两个主要版本。FaceCLIP-SDXL版本采用FaceCLIP-L-14和FaceCLIP-bigG-14编码器训练，而FaceT5-FLUX版本则集成了FaceT5编码器，进一步增强了文本到图像的转换精度。这些设计使模型在处理复杂场景描述时具备更强的灵活性，例如能够准确生成"戴眼镜的老年男性在咖啡厅阅读"等具体场景，同时保持参考人脸的核心识别特征。</p>
<p>在性能表现方面，官方数据显示FaceCLIP在真实感、身份保持度和文本对齐等指标上优于现有同类方法。模型采用解耦学习方案，能够将风格特征与内容特征分离处理，从而在保证身份一致性的同时实现风格的灵活变化。不过，早期测试也暴露出一些局限性，包括对特定族裔面部特征的细微偏差，以及30GB以上显存的硬件要求。</p>
<p>应用场景方面，FaceCLIP可用于游戏角色设计、数字漫画创作、广告视觉制作等领域。开发者可以通过GitHub仓库获取代码，按照文档指引进行本地部署和集成。目前该模型在低分辨率训练条件下已能达到接近专业水准的输出质量，未来对高分辨率生成的优化将进一步拓展其商业应用价值。</p>
<p>字节跳动明确表示，FaceCLIP采用Creative Commons Attribution-NonCommercial4.0许可协议，仅限学术研究使用，并提醒用户注意AI生成内容的伦理规范。开发者社区对该模型的发布反响积极，但也有声音指出其在硬件门槛和特定场景适配上仍有改进空间。从技术演进角度看，这类身份一致性生成工具正在成为文本到图像模型发展的重要方向之一。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>字节跳动近日发布了FaceCLIP，一款专注于人脸理解与生成的视觉-语言模型。该工具通过文本提示和参考图像即可生成保持身份一致性的多样化人脸图像，在多模态AI的人脸语义处理领域实现了新的技术突破。</p>
<p>FaceCLIP的核心技术在于其身份保持型图像生成框架。用户输入一张参考人脸照片和文本描述后，模型能够生成保留原始身份特征的新图像，同时根据文本指令调整表情、姿态和风格等属性。与传统方法不同，FaceCLIP摒弃了适配器模块，转而采用多模态编码策略同步捕获身份信息和文本语义，实现了人脸特征与文本提示的深度融合。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-873a461c5a.png"></p>
<p>从技术架构来看，FaceCLIP基于开源基础模型构建，提供了两个主要版本。FaceCLIP-SDXL版本采用FaceCLIP-L-14和FaceCLIP-bigG-14编码器训练，而FaceT5-FLUX版本则集成了FaceT5编码器，进一步增强了文本到图像的转换精度。这些设计使模型在处理复杂场景描述时具备更强的灵活性，例如能够准确生成"戴眼镜的老年男性在咖啡厅阅读"等具体场景，同时保持参考人脸的核心识别特征。</p>
<p>在性能表现方面，官方数据显示FaceCLIP在真实感、身份保持度和文本对齐等指标上优于现有同类方法。模型采用解耦学习方案，能够将风格特征与内容特征分离处理，从而在保证身份一致性的同时实现风格的灵活变化。不过，早期测试也暴露出一些局限性，包括对特定族裔面部特征的细微偏差，以及30GB以上显存的硬件要求。</p>
<p>应用场景方面，FaceCLIP可用于游戏角色设计、数字漫画创作、广告视觉制作等领域。开发者可以通过GitHub仓库获取代码，按照文档指引进行本地部署和集成。目前该模型在低分辨率训练条件下已能达到接近专业水准的输出质量，未来对高分辨率生成的优化将进一步拓展其商业应用价值。</p>
<p>字节跳动明确表示，FaceCLIP采用Creative Commons Attribution-NonCommercial4.0许可协议，仅限学术研究使用，并提醒用户注意AI生成内容的伦理规范。开发者社区对该模型的发布反响积极，但也有声音指出其在硬件门槛和特定场景适配上仍有改进空间。从技术演进角度看，这类身份一致性生成工具正在成为文本到图像模型发展的重要方向之一。</p>]]>
    </description>
    <content:encoded><![CDATA[<p>字节跳动近日发布了FaceCLIP，一款专注于人脸理解与生成的视觉-语言模型。该工具通过文本提示和参考图像即可生成保持身份一致性的多样化人脸图像，在多模态AI的人脸语义处理领域实现了新的技术突破。</p>
<p>FaceCLIP的核心技术在于其身份保持型图像生成框架。用户输入一张参考人脸照片和文本描述后，模型能够生成保留原始身份特征的新图像，同时根据文本指令调整表情、姿态和风格等属性。与传统方法不同，FaceCLIP摒弃了适配器模块，转而采用多模态编码策略同步捕获身份信息和文本语义，实现了人脸特征与文本提示的深度融合。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-873a461c5a.png"></p>
<p>从技术架构来看，FaceCLIP基于开源基础模型构建，提供了两个主要版本。FaceCLIP-SDXL版本采用FaceCLIP-L-14和FaceCLIP-bigG-14编码器训练，而FaceT5-FLUX版本则集成了FaceT5编码器，进一步增强了文本到图像的转换精度。这些设计使模型在处理复杂场景描述时具备更强的灵活性，例如能够准确生成"戴眼镜的老年男性在咖啡厅阅读"等具体场景，同时保持参考人脸的核心识别特征。</p>
<p>在性能表现方面，官方数据显示FaceCLIP在真实感、身份保持度和文本对齐等指标上优于现有同类方法。模型采用解耦学习方案，能够将风格特征与内容特征分离处理，从而在保证身份一致性的同时实现风格的灵活变化。不过，早期测试也暴露出一些局限性，包括对特定族裔面部特征的细微偏差，以及30GB以上显存的硬件要求。</p>
<p>应用场景方面，FaceCLIP可用于游戏角色设计、数字漫画创作、广告视觉制作等领域。开发者可以通过GitHub仓库获取代码，按照文档指引进行本地部署和集成。目前该模型在低分辨率训练条件下已能达到接近专业水准的输出质量，未来对高分辨率生成的优化将进一步拓展其商业应用价值。</p>
<p>字节跳动明确表示，FaceCLIP采用Creative Commons Attribution-NonCommercial4.0许可协议，仅限学术研究使用，并提醒用户注意AI生成内容的伦理规范。开发者社区对该模型的发布反响积极，但也有声音指出其在硬件门槛和特定场景适配上仍有改进空间。从技术演进角度看，这类身份一致性生成工具正在成为文本到图像模型发展的重要方向之一。</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-873a461c5a.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-873a461c5a.png" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 16:35:18 +0800</pubDate>
  </item><item>
    <title><![CDATA[驳 “AI 泡沫论”：一场被误读的、正在进行中的产业结构性调整]]></title>
    <link>https://my.oschina.net/IDP/blog/18695597</link>
    <itunes:title><![CDATA[驳 “AI 泡沫论”：一场被误读的、正在进行中的产业结构性调整]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>&gt; <strong>编者按：</strong> 当&nbsp;GPT-5&nbsp;的表现未达预期，当众多&nbsp;AI&nbsp;应用试点项目收效甚微，当市场开始质疑人工智能的发展前景时，我们是否正在经历一场&nbsp;AI&nbsp;泡沫的破裂？还是说，这些表面现象背后隐藏着更深层次的产业逻辑？ &gt; &gt; 我们今天为大家带来的这篇文章，作者的观点是：当前 AI 市场并非陷入停滞或崩溃，而是进入了一个必要的“消化阶段”，这一过程虽伴随阵痛，却蕴含着持续的发展动能。 &gt; &gt; 文章通过四个层次的分析框架，系统性地解构了当前 AI 市场的真实状况：首先厘清了产品体验设计与技术能力上限的区别，指出用户对 GPT-5 的失望更多源于产品策略而非能力倒退；第二，应用层回报不明朗的根源在于组织流程滞后于技术能力，真正有价值的垂直整合方案正在悄然建立护城河；第三，基础设施投资正从粗放扩张转向精细化运营，算力合约结构化、算力利用率优化和电力资源争夺成为新焦点；最后阐述了技术演进已超越“规模至上”的初级阶段，转向测试时计算、工具调用、数据质量与智能体系统等更深层次的创新。作者还提供了判断行业是否真正崩溃的具体指标，并为资金配置方、应用层创业者和基础设施构建者提供了清晰的战略建议。</p>
<p><strong>作者 | Dave Friedman</strong></p>
<p><strong>编译 | 岳扬</strong></p>
<p>目前流传着一种看似合理的说法：GPT-5 表现未达预期，因此 AI 泡沫正在破裂。这个观点看似顺理成章，实则是错误的。这个说法将四个不同维度的事情强行捆绑，硬是揉成了一个整体：（1）产品体验的设计选择；（2）应用层的投资回报；（3）基础设施投入与供应链；（4）科研进展与规模化应用。当你拆解这层层架构时，看似崩盘的态势其实正转化为一个“消化阶段” —— 既有可预见的阵痛，也伴随着同样可预见的持续动能。</p>
<p>以下是一个用于厘清思路的清晰框架。</p>
<h1><strong>01 Layer 1：产品体验 ≠ 能力上限</strong></h1>
<p>围绕 GPT-5 的争议大多聚焦于使用感受：语气转变、拒绝机制，以及有时将用户导向更安全但乏味的交互模式。<strong>这些属于产品决策（模型对齐过程中的参数选择、安全护栏、模型路由配置、默认设置），而非技术能力的倒退。</strong> 安全调校的悖论在于：当交互界面改变“对话风格”或严格限制高风险场景时，即便能力略有提升，用户仍可能感知为性能倒退。</p>
<p>三大常见认知误区：</p>
<p>1）<strong>对齐策略与核心能力</strong>：若模型规避特定输出或在高风险领域缩短推理链条，用户就会判断“模型变差”。此时衡量的实则为安全策略，而非底层能力。</p>
<p>2）<strong>路由系统与核心模型</strong>：AI 助手类产品常采用多个模型混合调用方案。若路由系统误将请求导向更保守的小模型，用户体验到的性能波动会被错误归于旗舰模型。</p>
<p>3）<strong>大家的心理预期比较高</strong>：被冠以“划时代”称号的发布版本会设定参照标准，而实际改进幅度往往难以匹配这种预期。但即便不如宣传片震撼，这些改进（尤其在编程、长程任务和工具调用领域）仍然具有重要意义。</p>
<p>本层结论：这是产品管理策略引发的争议，并非能力停滞的证据。</p>
<h1><strong>02 Layer 2：应用层投资回报混沌不清，且与基础设施需求背道而驰</strong></h1>
<p>的确，很多企业试点项目都没有达到预期目标。但原因很简单：数据管道尚未就绪；工作流未重新设计；激励机制阻碍落地；风控措施拖慢部署；套壳应用同质化严重。当技术普及速度超过组织流程改造速度时，市场必然会出现应用层淘汰洗牌。</p>
<p>关键差异点：</p>
<p>1）<strong>套壳应用与系统重构</strong>：基于 API 的套壳聊天应用会快速同质化，而重构工作流的系统（如智能体、工具调用、私有数据检索、知识图谱）虽见效慢，却能建立更持久的优势。</p>
<p>2）<strong>横向与纵向方案之别</strong>：横向通用助手的市场声量大，但深度融合领域工具的垂直方案才真正能产生回报。后者需与一线操作者共同设计且销售周期更长，但正是护城河所在。</p>
<p>3）<strong>核心评估指标</strong>：节省工时数量和客户满意度这类脱离利润的虚荣指标毫无意义。应关注误差调整后的吞吐量、营运资金周转率或事件率变化值。若无法将成效折算为财务收益，下一轮预算审议时项目必然被否决。</p>
<p>这一层的低迷与基础设施层的蓬勃发展并不矛盾：边缘应用的弱产品市场匹配度，不会削弱对训练迭代、模型升级或智能体框架的需求，只会重新分配价值捕获的主体。</p>
<h1><strong>03 Layer 3：基础设施资本支出正从冲刺期转向消化期，而非断崖式下跌</strong></h1>
<p>基础设施领域并非“投资枯竭”，而是进入了一个新阶段：资源配置结构与利用效率将成为决胜关键。三个同时存在的事实：</p>
<p>1）<strong>产能持续扩张</strong>：电力、高频宽存储器（HBM）与先进封装（CoWoS 级）仍是关键制约因素。即便积极扩产，2026 年前多数地区的供应仍将紧张。这支撑着定价并持续激励基建投入。</p>
<p>2）<strong>算力闲置风险是局部性的而非系统性的</strong>：拥有全栈需求（搜索、广告、云服务、办公软件、消费应用）的超大规模厂商可通过模型轮替与吸纳测试时计算阶段的算力消耗保持 GPU 满载。风险主要集中在独立的 AI 云服务商和专项供应商 —— 它们面临租赁成本攀升、客户集中度高和短期采购协议的压力。即便总体需求增长，这类企业仍可能遭遇阶段性的困境。</p>
<p>3）<strong>从粗放式短期算力租赁向精细化长期商业协议</strong>：随着市场逐渐成熟，短期的算力现货租赁将减少，结构化的采购协议将成为主流（包括更长的合约期限、最低采购量承诺以及指数化定价机制）。算力金融化工具（期货/远期合约、容量预留、风险对冲）将平滑市场的消化过程，同时降低建设方与采购方的资金成本。</p>
<p>“资本支出消化期”意味着：在供应增速超越短期客户需求的领域将出现价格体系调整。行业重点正转向电力采购、互联技术、散热系统和可用性保障，并对 GPU 利用率管理赋予更高溢价 —— 这与市场崩溃的论调截然不同。</p>
<h1><strong>04 Layer 4：“规模即王道”从来就不是严肃的理论命题</strong></h1>
<p>有一种夸张的片面观点宣称：“我们已经扩大了预训练规模，现在就此止步”。<strong>而真正严谨的技术演进路径实则是：规模 × 算法创新 × 测试时计算 × 工具调用 × 高质量数据。</strong> 技术前沿正在发生范式转移：</p>
<p>1）<strong>测试时计算与规划能力</strong>：更多思维链、外部记忆、验证机制以及搜索/规划循环的运用。这方面的突破不需要更大的基础模型，而更依赖更智能的推理计算。</p>
<p>2）<strong>工具调用与智能体</strong>：将代码执行、数据库操作和服务调用作为默认运行模式（而非演示功能），使模型从文本预测器升级为行动系统。</p>
<p>3）<strong>数据质量与课程学习</strong>：当粗暴的数据规模扩张效益递减时，数据精加工、合成数据方案、基于结果指标的强化学习以及针对特定任务设计的课程学习将成为突破性能瓶颈的关键。</p>
<p>单纯扩张预训练规模的收益递减并不意味进步终结，而是改变了规模化的方向。</p>
<p>结合这四个层面来看：AI 助手默认设置的重设计带来了不好的用户体验；大量应用型初创公司遭遇试点价值的转化困境；基础设施投入正在进行结构化调整与专业化升级；研究重点从无序的规模扩张转向结构化推理。这些内容无一指向 AI 泡沫破裂，而是符合幂律分布特征的技术走向成熟的必然形态。</p>
<h1><strong>05 需要出现怎样的证据，才能真正推翻“行业处于消化期”的判断？</strong></h1>
<p>请关注下面这个简单明了的核查清单：</p>
<p>1）多家超大规模厂商连续两轮以上资本支出下调（非仅投资结构调整），且明确推迟数据中心建设（而非仅重新排序工期）</p>
<p>2）顶级 GPU 集群出现价格战（通过公开价目表可量化），同时披露闲置产能或明显延长 GPU 闲置周期。</p>
<p>3）需连续多代模型版本在复杂推理基准测试和智能体工作流中出现平台期，工具使用可靠性（如代码执行成功率）停止提升。</p>
<p>4）电网互联排队周期长和变电站扩容项目延期导致项目大规模取消（非仅工期延后），联邦能源监管委员会/公用事业约束硬性限制建设规模。</p>
<p>5）两个及以上客户群在经过深度工作流整合后，AI 套件/助手的续约率显著低于试点期表现。</p>
<p><strong>若同时触发 2-3 项指标则需重新评估“行业处于消化期”这一判断。否则应预期行业处于结构性调整而非崩溃状态。</strong></p>
<h1><strong>06 战略要点</strong></h1>
<h2><strong>6.1 资金配置方</strong></h2>
<ul>
<li><strong>优先布局瓶颈环节，而非追逐品牌光环。</strong> 高频宽存储器（HBM）、芯片基板、先进封装、电网升级、变压器/变电站设备以及散热系统。这些领域的供给制约持续时间将远超市场预期。</li>
<li><strong>审慎评估独立厂商的资本结构。</strong> 关注租赁费用递增条款与收入条款的匹配度、客户集中度及合同期限。用仅持续 90 天的收入流去支撑长达 36 个月的债务责任，便是在重演硅谷版的 WeWork 式危机。</li>
<li><strong>优先选择与约定期限关联的风险敞口。</strong> 优先选择包含阶梯价格、保底/封顶机制和电力成本传导条款的容量预留与算力采购协议。此类合约正在快速完善风控体系。</li>
</ul>
<h2><strong>6.2 应用层创业者</strong></h2>
<ul>
<li><strong>构建系统级解决方案，而非浅层套壳应用。</strong> 开发深度整合私有数据与领域工具的智能体工作流，用财务收益衡量成效而非使用演示效果衡量。</li>
<li><strong>掌控评估体系。</strong> 评估能力是产品的核心模块而不是纯研究属性的功能。若无法基于客户自有指标证明成果差异，则终将沦为附属功能。</li>
<li><strong>善用测试时计算（test-time compute）。</strong> 部署轻量基础模型搭配强大的规划/搜索框架，可在成本与质量上超越暴力扩展方案。</li>
</ul>
<h2><strong>6.3 基础设施构建者</strong></h2>
<ul>
<li><strong>优先获取电力资源。</strong> 土地易得，充足的电力难求。变电站的交付周期与等待电网公司审批接入的排队时间对项目进度的影响，远超过芯片供应短缺。</li>
<li><strong>为算力利用率而设计。</strong> 多租户隔离、拓扑感知以及适配智能体工作流的任务调度系统，将成为差异化优势。“90%+的持续算力利用率”已成为核心销售卖点。</li>
<li><strong>对冲周期波动。</strong> 勿将市场波动视为意外。在可锁定处签订长期合约，在不可控处保持灵活选择权。</li>
</ul>
<h1><strong>07 为何“AI 崩盘论”看似可信却实非如此</strong></h1>
<ul>
<li>人们倾向于只关注那些容易被包装成故事的信息。一个旗舰产品的风格发生变化，人人都能立刻感知；但 HBM（高频宽存储器）的供应量变化，却鲜有人注意。我们总是过度重视那些显而易见、容易被讲述的事物。</li>
<li>炒作后的幻灭。人们的期望以比科学进步快得多的速度膨胀；当新产品发布时，现实达不到大家的想象，我们又立刻从狂热跌入过度失望。</li>
<li>我们把“我的 AI 助手没改变生活”这种个人体验，和“没人会买 GPU”这种市场趋势混为一谈。可这是两个完全不同的市场，运行在不同的节奏上。</li>
</ul>
<p>在这里使用消化期这个隐喻还是蛮恰当的。过去一段时间，整个行业像饕餮一样吞下产能，疯狂追逐产能扩张、快速推出原型产品，并不断制造吸引眼球的故事。但现在，热潮过去了，身体吃得太撑，需要停下来好好消化。这表现为新闻头条不再那么激动人心，进展看起来变慢了；企业采购变得更谨慎、更难；大家开始认真讨论投入产出比（ROI）：不再问“能不能做”，而是问“值不值得做”；技术进步的重点，从“往训练里砸多少算力”转向“如何更聪明地使用模型”——追求的是质的跃升，而不是量的堆砌；资本运作也回归理性：短期投机减少，长期规划增多；不再靠“感觉”和“氛围”融资，而是靠扎实的财务评估和风险控制。</p>
<p>如果你想贬低它的话，你可以称之为“回落期”或“降温阶段”。但实际上，这其实是一个关键时期：护城河正在被真正挖深，财务脆弱的公司开始崩塌，而真正持久的运营杠杆（即成本不变但产出大幅增加的优势）开始在那些不起眼的地方显现出来 —— 比如电力供应、芯片封装、互联技术，以及让智能体（agents）真正可靠干活的、枯燥却至关重要的工程细节。</p>
<p><strong>归根结底，如果你的投资或判断是基于“GPT-5 让我失望，所以 AI 泡沫要破了”这种感受，那你其实是在用情绪做决策，而不是分析真实市场。</strong> 你应该分清表层情绪和底层现实，关注那些能证伪你观点的信号（比如数据、产能、需求），并做好准备 —— 迎接的可能是一段消化调整期，而不是突然的崩盘。</p>
<p><strong>END</strong></p>
<p><strong>本期互动内容 🍻</strong></p>
<p><strong>❓如果你是一家企业的决策者，在当前的“消化期”，你会更倾向于投资基础设施，还是深耕垂直场景的 AI 应用？为什么？</strong></p>
<p><strong>原文链接：</strong></p>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdavefriedman.substack.com%2Fp%2Fthe-ai-market-isnt-collapsing-its" target="_blank">https://davefriedman.substack.com/p/the-ai-market-isnt-collapsing-its</a></p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>&gt; <strong>编者按：</strong> 当&nbsp;GPT-5&nbsp;的表现未达预期，当众多&nbsp;AI&nbsp;应用试点项目收效甚微，当市场开始质疑人工智能的发展前景时，我们是否正在经历一场&nbsp;AI&nbsp;泡沫的破裂？还是说，这些表面现象背后隐藏着更深层次的产业逻辑？ &gt; &gt; 我们今天为大家带来的这篇文章，作者的观点是：当前 AI 市场并非陷入停滞或崩溃，而是进入了一个必要的“消化阶段”，这一过程虽伴随阵痛，却蕴含着持续的发展动能。 &gt; &gt; 文章通过四个层次的分析框架，系统性地解构了当前 AI 市场的真实状况：首先厘清了产品体验设计与技术能力上限的区别，指出用户对 GPT-5 的失望更多源于产品策略而非能力倒退；第二，应用层回报不明朗的根源在于组织流程滞后于技术能力，真正有价值的垂直整合方案正在悄然建立护城河；第三，基础设施投资正从粗放扩张转向精细化运营，算力合约结构化、算力利用率优化和电力资源争夺成为新焦点；最后阐述了技术演进已超越“规模至上”的初级阶段，转向测试时计算、工具调用、数据质量与智能体系统等更深层次的创新。作者还提供了判断行业是否真正崩溃的具体指标，并为资金配置方、应用层创业者和基础设施构建者提供了清晰的战略建议。</p>
<p><strong>作者 | Dave Friedman</strong></p>
<p><strong>编译 | 岳扬</strong></p>
<p>目前流传着一种看似合理的说法：GPT-5 表现未达预期，因此 AI 泡沫正在破裂。这个观点看似顺理成章，实则是错误的。这个说法将四个不同维度的事情强行捆绑，硬是揉成了一个整体：（1）产品体验的设计选择；（2）应用层的投资回报；（3）基础设施投入与供应链；（4）科研进展与规模化应用。当你拆解这层层架构时，看似崩盘的态势其实正转化为一个“消化阶段” —— 既有可预见的阵痛，也伴随着同样可预见的持续动能。</p>
<p>以下是一个用于厘清思路的清晰框架。</p>
<h1><strong>01 Layer 1：产品体验 ≠ 能力上限</strong></h1>
<p>围绕 GPT-5 的争议大多聚焦于使用感受：语气转变、拒绝机制，以及有时将用户导向更安全但乏味的交互模式。<strong>这些属于产品决策（模型对齐过程中的参数选择、安全护栏、模型路由配置、默认设置），而非技术能力的倒退。</strong> 安全调校的悖论在于：当交互界面改变“对话风格”或严格限制高风险场景时，即便能力略有提升，用户仍可能感知为性能倒退。</p>
<p>三大常见认知误区：</p>
<p>1）<strong>对齐策略与核心能力</strong>：若模型规避特定输出或在高风险领域缩短推理链条，用户就会判断“模型变差”。此时衡量的实则为安全策略，而非底层能力。</p>
<p>2）<strong>路由系统与核心模型</strong>：AI 助手类产品常采用多个模型混合调用方案。若路由系统误将请求导向更保守的小模型，用户体验到的性能波动会被错误归于旗舰模型。</p>
<p>3）<strong>大家的心理预期比较高</strong>：被冠以“划时代”称号的发布版本会设定参照标准，而实际改进幅度往往难以匹配这种预期。但即便不如宣传片震撼，这些改进（尤其在编程、长程任务和工具调用领域）仍然具有重要意义。</p>
<p>本层结论：这是产品管理策略引发的争议，并非能力停滞的证据。</p>
<h1><strong>02 Layer 2：应用层投资回报混沌不清，且与基础设施需求背道而驰</strong></h1>
<p>的确，很多企业试点项目都没有达到预期目标。但原因很简单：数据管道尚未就绪；工作流未重新设计；激励机制阻碍落地；风控措施拖慢部署；套壳应用同质化严重。当技术普及速度超过组织流程改造速度时，市场必然会出现应用层淘汰洗牌。</p>
<p>关键差异点：</p>
<p>1）<strong>套壳应用与系统重构</strong>：基于 API 的套壳聊天应用会快速同质化，而重构工作流的系统（如智能体、工具调用、私有数据检索、知识图谱）虽见效慢，却能建立更持久的优势。</p>
<p>2）<strong>横向与纵向方案之别</strong>：横向通用助手的市场声量大，但深度融合领域工具的垂直方案才真正能产生回报。后者需与一线操作者共同设计且销售周期更长，但正是护城河所在。</p>
<p>3）<strong>核心评估指标</strong>：节省工时数量和客户满意度这类脱离利润的虚荣指标毫无意义。应关注误差调整后的吞吐量、营运资金周转率或事件率变化值。若无法将成效折算为财务收益，下一轮预算审议时项目必然被否决。</p>
<p>这一层的低迷与基础设施层的蓬勃发展并不矛盾：边缘应用的弱产品市场匹配度，不会削弱对训练迭代、模型升级或智能体框架的需求，只会重新分配价值捕获的主体。</p>
<h1><strong>03 Layer 3：基础设施资本支出正从冲刺期转向消化期，而非断崖式下跌</strong></h1>
<p>基础设施领域并非“投资枯竭”，而是进入了一个新阶段：资源配置结构与利用效率将成为决胜关键。三个同时存在的事实：</p>
<p>1）<strong>产能持续扩张</strong>：电力、高频宽存储器（HBM）与先进封装（CoWoS 级）仍是关键制约因素。即便积极扩产，2026 年前多数地区的供应仍将紧张。这支撑着定价并持续激励基建投入。</p>
<p>2）<strong>算力闲置风险是局部性的而非系统性的</strong>：拥有全栈需求（搜索、广告、云服务、办公软件、消费应用）的超大规模厂商可通过模型轮替与吸纳测试时计算阶段的算力消耗保持 GPU 满载。风险主要集中在独立的 AI 云服务商和专项供应商 —— 它们面临租赁成本攀升、客户集中度高和短期采购协议的压力。即便总体需求增长，这类企业仍可能遭遇阶段性的困境。</p>
<p>3）<strong>从粗放式短期算力租赁向精细化长期商业协议</strong>：随着市场逐渐成熟，短期的算力现货租赁将减少，结构化的采购协议将成为主流（包括更长的合约期限、最低采购量承诺以及指数化定价机制）。算力金融化工具（期货/远期合约、容量预留、风险对冲）将平滑市场的消化过程，同时降低建设方与采购方的资金成本。</p>
<p>“资本支出消化期”意味着：在供应增速超越短期客户需求的领域将出现价格体系调整。行业重点正转向电力采购、互联技术、散热系统和可用性保障，并对 GPU 利用率管理赋予更高溢价 —— 这与市场崩溃的论调截然不同。</p>
<h1><strong>04 Layer 4：“规模即王道”从来就不是严肃的理论命题</strong></h1>
<p>有一种夸张的片面观点宣称：“我们已经扩大了预训练规模，现在就此止步”。<strong>而真正严谨的技术演进路径实则是：规模 × 算法创新 × 测试时计算 × 工具调用 × 高质量数据。</strong> 技术前沿正在发生范式转移：</p>
<p>1）<strong>测试时计算与规划能力</strong>：更多思维链、外部记忆、验证机制以及搜索/规划循环的运用。这方面的突破不需要更大的基础模型，而更依赖更智能的推理计算。</p>
<p>2）<strong>工具调用与智能体</strong>：将代码执行、数据库操作和服务调用作为默认运行模式（而非演示功能），使模型从文本预测器升级为行动系统。</p>
<p>3）<strong>数据质量与课程学习</strong>：当粗暴的数据规模扩张效益递减时，数据精加工、合成数据方案、基于结果指标的强化学习以及针对特定任务设计的课程学习将成为突破性能瓶颈的关键。</p>
<p>单纯扩张预训练规模的收益递减并不意味进步终结，而是改变了规模化的方向。</p>
<p>结合这四个层面来看：AI 助手默认设置的重设计带来了不好的用户体验；大量应用型初创公司遭遇试点价值的转化困境；基础设施投入正在进行结构化调整与专业化升级；研究重点从无序的规模扩张转向结构化推理。这些内容无一指向 AI 泡沫破裂，而是符合幂律分布特征的技术走向成熟的必然形态。</p>
<h1><strong>05 需要出现怎样的证据，才能真正推翻“行业处于消化期”的判断？</strong></h1>
<p>请关注下面这个简单明了的核查清单：</p>
<p>1）多家超大规模厂商连续两轮以上资本支出下调（非仅投资结构调整），且明确推迟数据中心建设（而非仅重新排序工期）</p>
<p>2）顶级 GPU 集群出现价格战（通过公开价目表可量化），同时披露闲置产能或明显延长 GPU 闲置周期。</p>
<p>3）需连续多代模型版本在复杂推理基准测试和智能体工作流中出现平台期，工具使用可靠性（如代码执行成功率）停止提升。</p>
<p>4）电网互联排队周期长和变电站扩容项目延期导致项目大规模取消（非仅工期延后），联邦能源监管委员会/公用事业约束硬性限制建设规模。</p>
<p>5）两个及以上客户群在经过深度工作流整合后，AI 套件/助手的续约率显著低于试点期表现。</p>
<p><strong>若同时触发 2-3 项指标则需重新评估“行业处于消化期”这一判断。否则应预期行业处于结构性调整而非崩溃状态。</strong></p>
<h1><strong>06 战略要点</strong></h1>
<h2><strong>6.1 资金配置方</strong></h2>
<ul>
<li><strong>优先布局瓶颈环节，而非追逐品牌光环。</strong> 高频宽存储器（HBM）、芯片基板、先进封装、电网升级、变压器/变电站设备以及散热系统。这些领域的供给制约持续时间将远超市场预期。</li>
<li><strong>审慎评估独立厂商的资本结构。</strong> 关注租赁费用递增条款与收入条款的匹配度、客户集中度及合同期限。用仅持续 90 天的收入流去支撑长达 36 个月的债务责任，便是在重演硅谷版的 WeWork 式危机。</li>
<li><strong>优先选择与约定期限关联的风险敞口。</strong> 优先选择包含阶梯价格、保底/封顶机制和电力成本传导条款的容量预留与算力采购协议。此类合约正在快速完善风控体系。</li>
</ul>
<h2><strong>6.2 应用层创业者</strong></h2>
<ul>
<li><strong>构建系统级解决方案，而非浅层套壳应用。</strong> 开发深度整合私有数据与领域工具的智能体工作流，用财务收益衡量成效而非使用演示效果衡量。</li>
<li><strong>掌控评估体系。</strong> 评估能力是产品的核心模块而不是纯研究属性的功能。若无法基于客户自有指标证明成果差异，则终将沦为附属功能。</li>
<li><strong>善用测试时计算（test-time compute）。</strong> 部署轻量基础模型搭配强大的规划/搜索框架，可在成本与质量上超越暴力扩展方案。</li>
</ul>
<h2><strong>6.3 基础设施构建者</strong></h2>
<ul>
<li><strong>优先获取电力资源。</strong> 土地易得，充足的电力难求。变电站的交付周期与等待电网公司审批接入的排队时间对项目进度的影响，远超过芯片供应短缺。</li>
<li><strong>为算力利用率而设计。</strong> 多租户隔离、拓扑感知以及适配智能体工作流的任务调度系统，将成为差异化优势。“90%+的持续算力利用率”已成为核心销售卖点。</li>
<li><strong>对冲周期波动。</strong> 勿将市场波动视为意外。在可锁定处签订长期合约，在不可控处保持灵活选择权。</li>
</ul>
<h1><strong>07 为何“AI 崩盘论”看似可信却实非如此</strong></h1>
<ul>
<li>人们倾向于只关注那些容易被包装成故事的信息。一个旗舰产品的风格发生变化，人人都能立刻感知；但 HBM（高频宽存储器）的供应量变化，却鲜有人注意。我们总是过度重视那些显而易见、容易被讲述的事物。</li>
<li>炒作后的幻灭。人们的期望以比科学进步快得多的速度膨胀；当新产品发布时，现实达不到大家的想象，我们又立刻从狂热跌入过度失望。</li>
<li>我们把“我的 AI 助手没改变生活”这种个人体验，和“没人会买 GPU”这种市场趋势混为一谈。可这是两个完全不同的市场，运行在不同的节奏上。</li>
</ul>
<p>在这里使用消化期这个隐喻还是蛮恰当的。过去一段时间，整个行业像饕餮一样吞下产能，疯狂追逐产能扩张、快速推出原型产品，并不断制造吸引眼球的故事。但现在，热潮过去了，身体吃得太撑，需要停下来好好消化。这表现为新闻头条不再那么激动人心，进展看起来变慢了；企业采购变得更谨慎、更难；大家开始认真讨论投入产出比（ROI）：不再问“能不能做”，而是问“值不值得做”；技术进步的重点，从“往训练里砸多少算力”转向“如何更聪明地使用模型”——追求的是质的跃升，而不是量的堆砌；资本运作也回归理性：短期投机减少，长期规划增多；不再靠“感觉”和“氛围”融资，而是靠扎实的财务评估和风险控制。</p>
<p>如果你想贬低它的话，你可以称之为“回落期”或“降温阶段”。但实际上，这其实是一个关键时期：护城河正在被真正挖深，财务脆弱的公司开始崩塌，而真正持久的运营杠杆（即成本不变但产出大幅增加的优势）开始在那些不起眼的地方显现出来 —— 比如电力供应、芯片封装、互联技术，以及让智能体（agents）真正可靠干活的、枯燥却至关重要的工程细节。</p>
<p><strong>归根结底，如果你的投资或判断是基于“GPT-5 让我失望，所以 AI 泡沫要破了”这种感受，那你其实是在用情绪做决策，而不是分析真实市场。</strong> 你应该分清表层情绪和底层现实，关注那些能证伪你观点的信号（比如数据、产能、需求），并做好准备 —— 迎接的可能是一段消化调整期，而不是突然的崩盘。</p>
<p><strong>END</strong></p>
<p><strong>本期互动内容 🍻</strong></p>
<p><strong>❓如果你是一家企业的决策者，在当前的“消化期”，你会更倾向于投资基础设施，还是深耕垂直场景的 AI 应用？为什么？</strong></p>
<p><strong>原文链接：</strong></p>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdavefriedman.substack.com%2Fp%2Fthe-ai-market-isnt-collapsing-its" target="_blank">https://davefriedman.substack.com/p/the-ai-market-isnt-collapsing-its</a></p>]]>
    </description>
    <content:encoded><![CDATA[<p>&gt; <strong>编者按：</strong> 当&nbsp;GPT-5&nbsp;的表现未达预期，当众多&nbsp;AI&nbsp;应用试点项目收效甚微，当市场开始质疑人工智能的发展前景时，我们是否正在经历一场&nbsp;AI&nbsp;泡沫的破裂？还是说，这些表面现象背后隐藏着更深层次的产业逻辑？ &gt; &gt; 我们今天为大家带来的这篇文章，作者的观点是：当前 AI 市场并非陷入停滞或崩溃，而是进入了一个必要的“消化阶段”，这一过程虽伴随阵痛，却蕴含着持续的发展动能。 &gt; &gt; 文章通过四个层次的分析框架，系统性地解构了当前 AI 市场的真实状况：首先厘清了产品体验设计与技术能力上限的区别，指出用户对 GPT-5 的失望更多源于产品策略而非能力倒退；第二，应用层回报不明朗的根源在于组织流程滞后于技术能力，真正有价值的垂直整合方案正在悄然建立护城河；第三，基础设施投资正从粗放扩张转向精细化运营，算力合约结构化、算力利用率优化和电力资源争夺成为新焦点；最后阐述了技术演进已超越“规模至上”的初级阶段，转向测试时计算、工具调用、数据质量与智能体系统等更深层次的创新。作者还提供了判断行业是否真正崩溃的具体指标，并为资金配置方、应用层创业者和基础设施构建者提供了清晰的战略建议。</p>
<p><strong>作者 | Dave Friedman</strong></p>
<p><strong>编译 | 岳扬</strong></p>
<p>目前流传着一种看似合理的说法：GPT-5 表现未达预期，因此 AI 泡沫正在破裂。这个观点看似顺理成章，实则是错误的。这个说法将四个不同维度的事情强行捆绑，硬是揉成了一个整体：（1）产品体验的设计选择；（2）应用层的投资回报；（3）基础设施投入与供应链；（4）科研进展与规模化应用。当你拆解这层层架构时，看似崩盘的态势其实正转化为一个“消化阶段” —— 既有可预见的阵痛，也伴随着同样可预见的持续动能。</p>
<p>以下是一个用于厘清思路的清晰框架。</p>
<h1><strong>01 Layer 1：产品体验 ≠ 能力上限</strong></h1>
<p>围绕 GPT-5 的争议大多聚焦于使用感受：语气转变、拒绝机制，以及有时将用户导向更安全但乏味的交互模式。<strong>这些属于产品决策（模型对齐过程中的参数选择、安全护栏、模型路由配置、默认设置），而非技术能力的倒退。</strong> 安全调校的悖论在于：当交互界面改变“对话风格”或严格限制高风险场景时，即便能力略有提升，用户仍可能感知为性能倒退。</p>
<p>三大常见认知误区：</p>
<p>1）<strong>对齐策略与核心能力</strong>：若模型规避特定输出或在高风险领域缩短推理链条，用户就会判断“模型变差”。此时衡量的实则为安全策略，而非底层能力。</p>
<p>2）<strong>路由系统与核心模型</strong>：AI 助手类产品常采用多个模型混合调用方案。若路由系统误将请求导向更保守的小模型，用户体验到的性能波动会被错误归于旗舰模型。</p>
<p>3）<strong>大家的心理预期比较高</strong>：被冠以“划时代”称号的发布版本会设定参照标准，而实际改进幅度往往难以匹配这种预期。但即便不如宣传片震撼，这些改进（尤其在编程、长程任务和工具调用领域）仍然具有重要意义。</p>
<p>本层结论：这是产品管理策略引发的争议，并非能力停滞的证据。</p>
<h1><strong>02 Layer 2：应用层投资回报混沌不清，且与基础设施需求背道而驰</strong></h1>
<p>的确，很多企业试点项目都没有达到预期目标。但原因很简单：数据管道尚未就绪；工作流未重新设计；激励机制阻碍落地；风控措施拖慢部署；套壳应用同质化严重。当技术普及速度超过组织流程改造速度时，市场必然会出现应用层淘汰洗牌。</p>
<p>关键差异点：</p>
<p>1）<strong>套壳应用与系统重构</strong>：基于 API 的套壳聊天应用会快速同质化，而重构工作流的系统（如智能体、工具调用、私有数据检索、知识图谱）虽见效慢，却能建立更持久的优势。</p>
<p>2）<strong>横向与纵向方案之别</strong>：横向通用助手的市场声量大，但深度融合领域工具的垂直方案才真正能产生回报。后者需与一线操作者共同设计且销售周期更长，但正是护城河所在。</p>
<p>3）<strong>核心评估指标</strong>：节省工时数量和客户满意度这类脱离利润的虚荣指标毫无意义。应关注误差调整后的吞吐量、营运资金周转率或事件率变化值。若无法将成效折算为财务收益，下一轮预算审议时项目必然被否决。</p>
<p>这一层的低迷与基础设施层的蓬勃发展并不矛盾：边缘应用的弱产品市场匹配度，不会削弱对训练迭代、模型升级或智能体框架的需求，只会重新分配价值捕获的主体。</p>
<h1><strong>03 Layer 3：基础设施资本支出正从冲刺期转向消化期，而非断崖式下跌</strong></h1>
<p>基础设施领域并非“投资枯竭”，而是进入了一个新阶段：资源配置结构与利用效率将成为决胜关键。三个同时存在的事实：</p>
<p>1）<strong>产能持续扩张</strong>：电力、高频宽存储器（HBM）与先进封装（CoWoS 级）仍是关键制约因素。即便积极扩产，2026 年前多数地区的供应仍将紧张。这支撑着定价并持续激励基建投入。</p>
<p>2）<strong>算力闲置风险是局部性的而非系统性的</strong>：拥有全栈需求（搜索、广告、云服务、办公软件、消费应用）的超大规模厂商可通过模型轮替与吸纳测试时计算阶段的算力消耗保持 GPU 满载。风险主要集中在独立的 AI 云服务商和专项供应商 —— 它们面临租赁成本攀升、客户集中度高和短期采购协议的压力。即便总体需求增长，这类企业仍可能遭遇阶段性的困境。</p>
<p>3）<strong>从粗放式短期算力租赁向精细化长期商业协议</strong>：随着市场逐渐成熟，短期的算力现货租赁将减少，结构化的采购协议将成为主流（包括更长的合约期限、最低采购量承诺以及指数化定价机制）。算力金融化工具（期货/远期合约、容量预留、风险对冲）将平滑市场的消化过程，同时降低建设方与采购方的资金成本。</p>
<p>“资本支出消化期”意味着：在供应增速超越短期客户需求的领域将出现价格体系调整。行业重点正转向电力采购、互联技术、散热系统和可用性保障，并对 GPU 利用率管理赋予更高溢价 —— 这与市场崩溃的论调截然不同。</p>
<h1><strong>04 Layer 4：“规模即王道”从来就不是严肃的理论命题</strong></h1>
<p>有一种夸张的片面观点宣称：“我们已经扩大了预训练规模，现在就此止步”。<strong>而真正严谨的技术演进路径实则是：规模 × 算法创新 × 测试时计算 × 工具调用 × 高质量数据。</strong> 技术前沿正在发生范式转移：</p>
<p>1）<strong>测试时计算与规划能力</strong>：更多思维链、外部记忆、验证机制以及搜索/规划循环的运用。这方面的突破不需要更大的基础模型，而更依赖更智能的推理计算。</p>
<p>2）<strong>工具调用与智能体</strong>：将代码执行、数据库操作和服务调用作为默认运行模式（而非演示功能），使模型从文本预测器升级为行动系统。</p>
<p>3）<strong>数据质量与课程学习</strong>：当粗暴的数据规模扩张效益递减时，数据精加工、合成数据方案、基于结果指标的强化学习以及针对特定任务设计的课程学习将成为突破性能瓶颈的关键。</p>
<p>单纯扩张预训练规模的收益递减并不意味进步终结，而是改变了规模化的方向。</p>
<p>结合这四个层面来看：AI 助手默认设置的重设计带来了不好的用户体验；大量应用型初创公司遭遇试点价值的转化困境；基础设施投入正在进行结构化调整与专业化升级；研究重点从无序的规模扩张转向结构化推理。这些内容无一指向 AI 泡沫破裂，而是符合幂律分布特征的技术走向成熟的必然形态。</p>
<h1><strong>05 需要出现怎样的证据，才能真正推翻“行业处于消化期”的判断？</strong></h1>
<p>请关注下面这个简单明了的核查清单：</p>
<p>1）多家超大规模厂商连续两轮以上资本支出下调（非仅投资结构调整），且明确推迟数据中心建设（而非仅重新排序工期）</p>
<p>2）顶级 GPU 集群出现价格战（通过公开价目表可量化），同时披露闲置产能或明显延长 GPU 闲置周期。</p>
<p>3）需连续多代模型版本在复杂推理基准测试和智能体工作流中出现平台期，工具使用可靠性（如代码执行成功率）停止提升。</p>
<p>4）电网互联排队周期长和变电站扩容项目延期导致项目大规模取消（非仅工期延后），联邦能源监管委员会/公用事业约束硬性限制建设规模。</p>
<p>5）两个及以上客户群在经过深度工作流整合后，AI 套件/助手的续约率显著低于试点期表现。</p>
<p><strong>若同时触发 2-3 项指标则需重新评估“行业处于消化期”这一判断。否则应预期行业处于结构性调整而非崩溃状态。</strong></p>
<h1><strong>06 战略要点</strong></h1>
<h2><strong>6.1 资金配置方</strong></h2>
<ul>
<li><strong>优先布局瓶颈环节，而非追逐品牌光环。</strong> 高频宽存储器（HBM）、芯片基板、先进封装、电网升级、变压器/变电站设备以及散热系统。这些领域的供给制约持续时间将远超市场预期。</li>
<li><strong>审慎评估独立厂商的资本结构。</strong> 关注租赁费用递增条款与收入条款的匹配度、客户集中度及合同期限。用仅持续 90 天的收入流去支撑长达 36 个月的债务责任，便是在重演硅谷版的 WeWork 式危机。</li>
<li><strong>优先选择与约定期限关联的风险敞口。</strong> 优先选择包含阶梯价格、保底/封顶机制和电力成本传导条款的容量预留与算力采购协议。此类合约正在快速完善风控体系。</li>
</ul>
<h2><strong>6.2 应用层创业者</strong></h2>
<ul>
<li><strong>构建系统级解决方案，而非浅层套壳应用。</strong> 开发深度整合私有数据与领域工具的智能体工作流，用财务收益衡量成效而非使用演示效果衡量。</li>
<li><strong>掌控评估体系。</strong> 评估能力是产品的核心模块而不是纯研究属性的功能。若无法基于客户自有指标证明成果差异，则终将沦为附属功能。</li>
<li><strong>善用测试时计算（test-time compute）。</strong> 部署轻量基础模型搭配强大的规划/搜索框架，可在成本与质量上超越暴力扩展方案。</li>
</ul>
<h2><strong>6.3 基础设施构建者</strong></h2>
<ul>
<li><strong>优先获取电力资源。</strong> 土地易得，充足的电力难求。变电站的交付周期与等待电网公司审批接入的排队时间对项目进度的影响，远超过芯片供应短缺。</li>
<li><strong>为算力利用率而设计。</strong> 多租户隔离、拓扑感知以及适配智能体工作流的任务调度系统，将成为差异化优势。“90%+的持续算力利用率”已成为核心销售卖点。</li>
<li><strong>对冲周期波动。</strong> 勿将市场波动视为意外。在可锁定处签订长期合约，在不可控处保持灵活选择权。</li>
</ul>
<h1><strong>07 为何“AI 崩盘论”看似可信却实非如此</strong></h1>
<ul>
<li>人们倾向于只关注那些容易被包装成故事的信息。一个旗舰产品的风格发生变化，人人都能立刻感知；但 HBM（高频宽存储器）的供应量变化，却鲜有人注意。我们总是过度重视那些显而易见、容易被讲述的事物。</li>
<li>炒作后的幻灭。人们的期望以比科学进步快得多的速度膨胀；当新产品发布时，现实达不到大家的想象，我们又立刻从狂热跌入过度失望。</li>
<li>我们把“我的 AI 助手没改变生活”这种个人体验，和“没人会买 GPU”这种市场趋势混为一谈。可这是两个完全不同的市场，运行在不同的节奏上。</li>
</ul>
<p>在这里使用消化期这个隐喻还是蛮恰当的。过去一段时间，整个行业像饕餮一样吞下产能，疯狂追逐产能扩张、快速推出原型产品，并不断制造吸引眼球的故事。但现在，热潮过去了，身体吃得太撑，需要停下来好好消化。这表现为新闻头条不再那么激动人心，进展看起来变慢了；企业采购变得更谨慎、更难；大家开始认真讨论投入产出比（ROI）：不再问“能不能做”，而是问“值不值得做”；技术进步的重点，从“往训练里砸多少算力”转向“如何更聪明地使用模型”——追求的是质的跃升，而不是量的堆砌；资本运作也回归理性：短期投机减少，长期规划增多；不再靠“感觉”和“氛围”融资，而是靠扎实的财务评估和风险控制。</p>
<p>如果你想贬低它的话，你可以称之为“回落期”或“降温阶段”。但实际上，这其实是一个关键时期：护城河正在被真正挖深，财务脆弱的公司开始崩塌，而真正持久的运营杠杆（即成本不变但产出大幅增加的优势）开始在那些不起眼的地方显现出来 —— 比如电力供应、芯片封装、互联技术，以及让智能体（agents）真正可靠干活的、枯燥却至关重要的工程细节。</p>
<p><strong>归根结底，如果你的投资或判断是基于“GPT-5 让我失望，所以 AI 泡沫要破了”这种感受，那你其实是在用情绪做决策，而不是分析真实市场。</strong> 你应该分清表层情绪和底层现实，关注那些能证伪你观点的信号（比如数据、产能、需求），并做好准备 —— 迎接的可能是一段消化调整期，而不是突然的崩盘。</p>
<p><strong>END</strong></p>
<p><strong>本期互动内容 🍻</strong></p>
<p><strong>❓如果你是一家企业的决策者，在当前的“消化期”，你会更倾向于投资基础设施，还是深耕垂直场景的 AI 应用？为什么？</strong></p>
<p><strong>原文链接：</strong></p>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdavefriedman.substack.com%2Fp%2Fthe-ai-market-isnt-collapsing-its" target="_blank">https://davefriedman.substack.com/p/the-ai-market-isnt-collapsing-its</a></p>]]></content:encoded>
    
    <pubDate>Wed, 15 Oct 2025 15:51:22 +0800</pubDate>
  </item><item>
    <title><![CDATA[RustDesk 即将突破 100K stars]]></title>
    <link>https://www.oschina.net/news/377574</link>
    <itunes:title><![CDATA[RustDesk 即将突破 100K stars]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<div>
<p><span><span><span><span>截至目前，RustDesk 在 GitHub 上的 Star 数已超过&nbsp;</span></span><span><span><span><span>99.9k</span></span></span></span><span><span>，最晚明天就能达到 10 万。作为用 Rust 开发的远程桌面软件，RustDesk 有望成为继 </span></span><span><span><span><span>Rust 语言</span></span></span></span><span><span>（107k Star）和 </span></span><span><span><span><span>Deno</span></span></span></span><span><span>（104k Star）后，</span></span><span><span><span><span>第三个 10 万 Star 的 Rust 项目</span></span></span></span><span><span>。我们由衷感谢社区的每份贡献！</span></span></span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-f67db08c84.jpg"></p>
<h2>RustDesk：简单实用的开源工具</h2>
<div>
<span>RustDesk 是一款开源跨平台远程桌面软件，特点包括：</span>
</div>
<div>
<ul>
<li><span><span><span><span><span>开源透明</span></span></span></span><span><span>：AGPL-3.0 协议，代码公开，欢迎改进。</span></span></span></li>
<li><span><span><span><span><span>高效稳定</span></span></span></span><span><span>：Rust 语言确保性能和安全。</span></span></span></li>
<li><span><span><span><span><span>自托管</span></span></span></span><span><span>：支持私有服务器，保护隐私。</span></span></span></li>
<li><span><span><span><span><span>跨平台</span></span></span></span><span><span>：支持 Windows (&gt;=Win7)、macOS、Linux (X11/Wayland)、Android、iOS、 Web。</span></span></span></li>
</ul>
</div>
<p><span><span><span><span>自2021年3月开源，RustDesk 靠社区的代码、翻译和反馈不断完善。遗憾的是，它曾被诈骗分子冒用，诱导用户授予远程权限。团队已添加警告提示，提醒只与可信方共享访问，并呼吁社区加强安全意识。</span></span></span></span></p>
</div>
<h2>社区的每一步支持</h2>
<div>
10 万 Star 凝聚了社区的信任，离不开每位贡献者的努力。RustDesk 还有改进空间，我们会继续与大家一起完善：
<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Frustdesk%2Frustdesk" target="_blank">https://github.com/rustdesk/rustdesk</a>
</div>]]>
    </itunes:summary>
    <description>
      <![CDATA[<div>
<p><span><span><span><span>截至目前，RustDesk 在 GitHub 上的 Star 数已超过&nbsp;</span></span><span><span><span><span>99.9k</span></span></span></span><span><span>，最晚明天就能达到 10 万。作为用 Rust 开发的远程桌面软件，RustDesk 有望成为继 </span></span><span><span><span><span>Rust 语言</span></span></span></span><span><span>（107k Star）和 </span></span><span><span><span><span>Deno</span></span></span></span><span><span>（104k Star）后，</span></span><span><span><span><span>第三个 10 万 Star 的 Rust 项目</span></span></span></span><span><span>。我们由衷感谢社区的每份贡献！</span></span></span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-f67db08c84.jpg"></p>
<h2>RustDesk：简单实用的开源工具</h2>
<div>
<span>RustDesk 是一款开源跨平台远程桌面软件，特点包括：</span>
</div>
<div>
<ul>
<li><span><span><span><span><span>开源透明</span></span></span></span><span><span>：AGPL-3.0 协议，代码公开，欢迎改进。</span></span></span></li>
<li><span><span><span><span><span>高效稳定</span></span></span></span><span><span>：Rust 语言确保性能和安全。</span></span></span></li>
<li><span><span><span><span><span>自托管</span></span></span></span><span><span>：支持私有服务器，保护隐私。</span></span></span></li>
<li><span><span><span><span><span>跨平台</span></span></span></span><span><span>：支持 Windows (&gt;=Win7)、macOS、Linux (X11/Wayland)、Android、iOS、 Web。</span></span></span></li>
</ul>
</div>
<p><span><span><span><span>自2021年3月开源，RustDesk 靠社区的代码、翻译和反馈不断完善。遗憾的是，它曾被诈骗分子冒用，诱导用户授予远程权限。团队已添加警告提示，提醒只与可信方共享访问，并呼吁社区加强安全意识。</span></span></span></span></p>
</div>
<h2>社区的每一步支持</h2>
<div>
10 万 Star 凝聚了社区的信任，离不开每位贡献者的努力。RustDesk 还有改进空间，我们会继续与大家一起完善：
<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Frustdesk%2Frustdesk" target="_blank">https://github.com/rustdesk/rustdesk</a>
</div>]]>
    </description>
    <content:encoded><![CDATA[<div>
<p><span><span><span><span>截至目前，RustDesk 在 GitHub 上的 Star 数已超过&nbsp;</span></span><span><span><span><span>99.9k</span></span></span></span><span><span>，最晚明天就能达到 10 万。作为用 Rust 开发的远程桌面软件，RustDesk 有望成为继 </span></span><span><span><span><span>Rust 语言</span></span></span></span><span><span>（107k Star）和 </span></span><span><span><span><span>Deno</span></span></span></span><span><span>（104k Star）后，</span></span><span><span><span><span>第三个 10 万 Star 的 Rust 项目</span></span></span></span><span><span>。我们由衷感谢社区的每份贡献！</span></span></span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-f67db08c84.jpg"></p>
<h2>RustDesk：简单实用的开源工具</h2>
<div>
<span>RustDesk 是一款开源跨平台远程桌面软件，特点包括：</span>
</div>
<div>
<ul>
<li><span><span><span><span><span>开源透明</span></span></span></span><span><span>：AGPL-3.0 协议，代码公开，欢迎改进。</span></span></span></li>
<li><span><span><span><span><span>高效稳定</span></span></span></span><span><span>：Rust 语言确保性能和安全。</span></span></span></li>
<li><span><span><span><span><span>自托管</span></span></span></span><span><span>：支持私有服务器，保护隐私。</span></span></span></li>
<li><span><span><span><span><span>跨平台</span></span></span></span><span><span>：支持 Windows (&gt;=Win7)、macOS、Linux (X11/Wayland)、Android、iOS、 Web。</span></span></span></li>
</ul>
</div>
<p><span><span><span><span>自2021年3月开源，RustDesk 靠社区的代码、翻译和反馈不断完善。遗憾的是，它曾被诈骗分子冒用，诱导用户授予远程权限。团队已添加警告提示，提醒只与可信方共享访问，并呼吁社区加强安全意识。</span></span></span></span></p>
</div>
<h2>社区的每一步支持</h2>
<div>
10 万 Star 凝聚了社区的信任，离不开每位贡献者的努力。RustDesk 还有改进空间，我们会继续与大家一起完善：
<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Frustdesk%2Frustdesk" target="_blank">https://github.com/rustdesk/rustdesk</a>
</div>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-f67db08c84.jpg"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-f67db08c84.jpg" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 15:50:35 +0800</pubDate>
  </item><item>
    <title><![CDATA[巨人网络&amp;清华大学开源 DiaMoE-TTS，多方言语音合成大模型框架]]></title>
    <link>https://www.oschina.net/news/377568</link>
    <itunes:title><![CDATA[巨人网络&amp;清华大学开源 DiaMoE-TTS，多方言语音合成大模型框架]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p><span>巨人网络AI Lab与清华大学电子工程系SATLab研究团队近日联合发布一项重大突破：</span>首创多方言语音合成大模型框架DiaMoE-TTS<span>，并宣布将</span>数据、代码、方法全方位开源<span>，旨在推动方言语音合成的公平与普惠。</span></p>
<p>在当前通用TTS（文本转语音）大模型能力惊人的时代，方言TTS(Dialect TTS)仍是业界难以触及的“灰色地带”。现有的工业级方言模型过于依赖巨量的专有数据，导致方言从业者和研究者面临缺乏统一语料构建方法和端到端开源框架的困境。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-f36d8f0626.png"></p>
<p>由双方联合首创的DiaMoE-TTS框架，为这一难题提供了一套开源的完整解决方案，其性能在一定程度上可媲美工业级方言TTS模型。该方案的关键创新在于：</p>
<ol>
<li> <p>统一的IPA表达体系：基于语言学家的专业经验，构建了一个统一的国际音标（IPA）表达体系。</p> </li>
<li> <p>数据高效性：该框架仅依赖开源方言ASR（自动语音识别）数据，解决了巨量专有数据依赖的痛点。</p> </li>
</ol>
<p>在推出广东话、四川话、上海话等中文方言版本之前，该研究团队已在英语、法语、德语、荷兰比尔茨语等多语种场景中进行过验证，证明该方法具备全球范围内的多语言可扩展性与稳健性。</p>
<p>巨人网络AI Lab与清华大学电子工程系SATLab表示，希望通过DiaMoE-TTS框架的开源，让任何研究者、开发者乃至语言文化保护工作者都能自由使用、改进与扩展这一框架，确保小众语言与方言的声音不再被通用大模型的洪流所淹没，而是能通过开源的力量被更广泛地听见与传承。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p><span>巨人网络AI Lab与清华大学电子工程系SATLab研究团队近日联合发布一项重大突破：</span>首创多方言语音合成大模型框架DiaMoE-TTS<span>，并宣布将</span>数据、代码、方法全方位开源<span>，旨在推动方言语音合成的公平与普惠。</span></p>
<p>在当前通用TTS（文本转语音）大模型能力惊人的时代，方言TTS(Dialect TTS)仍是业界难以触及的“灰色地带”。现有的工业级方言模型过于依赖巨量的专有数据，导致方言从业者和研究者面临缺乏统一语料构建方法和端到端开源框架的困境。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-f36d8f0626.png"></p>
<p>由双方联合首创的DiaMoE-TTS框架，为这一难题提供了一套开源的完整解决方案，其性能在一定程度上可媲美工业级方言TTS模型。该方案的关键创新在于：</p>
<ol>
<li> <p>统一的IPA表达体系：基于语言学家的专业经验，构建了一个统一的国际音标（IPA）表达体系。</p> </li>
<li> <p>数据高效性：该框架仅依赖开源方言ASR（自动语音识别）数据，解决了巨量专有数据依赖的痛点。</p> </li>
</ol>
<p>在推出广东话、四川话、上海话等中文方言版本之前，该研究团队已在英语、法语、德语、荷兰比尔茨语等多语种场景中进行过验证，证明该方法具备全球范围内的多语言可扩展性与稳健性。</p>
<p>巨人网络AI Lab与清华大学电子工程系SATLab表示，希望通过DiaMoE-TTS框架的开源，让任何研究者、开发者乃至语言文化保护工作者都能自由使用、改进与扩展这一框架，确保小众语言与方言的声音不再被通用大模型的洪流所淹没，而是能通过开源的力量被更广泛地听见与传承。</p>]]>
    </description>
    <content:encoded><![CDATA[<p><span>巨人网络AI Lab与清华大学电子工程系SATLab研究团队近日联合发布一项重大突破：</span>首创多方言语音合成大模型框架DiaMoE-TTS<span>，并宣布将</span>数据、代码、方法全方位开源<span>，旨在推动方言语音合成的公平与普惠。</span></p>
<p>在当前通用TTS（文本转语音）大模型能力惊人的时代，方言TTS(Dialect TTS)仍是业界难以触及的“灰色地带”。现有的工业级方言模型过于依赖巨量的专有数据，导致方言从业者和研究者面临缺乏统一语料构建方法和端到端开源框架的困境。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-f36d8f0626.png"></p>
<p>由双方联合首创的DiaMoE-TTS框架，为这一难题提供了一套开源的完整解决方案，其性能在一定程度上可媲美工业级方言TTS模型。该方案的关键创新在于：</p>
<ol>
<li> <p>统一的IPA表达体系：基于语言学家的专业经验，构建了一个统一的国际音标（IPA）表达体系。</p> </li>
<li> <p>数据高效性：该框架仅依赖开源方言ASR（自动语音识别）数据，解决了巨量专有数据依赖的痛点。</p> </li>
</ol>
<p>在推出广东话、四川话、上海话等中文方言版本之前，该研究团队已在英语、法语、德语、荷兰比尔茨语等多语种场景中进行过验证，证明该方法具备全球范围内的多语言可扩展性与稳健性。</p>
<p>巨人网络AI Lab与清华大学电子工程系SATLab表示，希望通过DiaMoE-TTS框架的开源，让任何研究者、开发者乃至语言文化保护工作者都能自由使用、改进与扩展这一框架，确保小众语言与方言的声音不再被通用大模型的洪流所淹没，而是能通过开源的力量被更广泛地听见与传承。</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-f36d8f0626.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-f36d8f0626.png" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 15:33:19 +0800</pubDate>
  </item><item>
    <title><![CDATA[FSF 推出 Librephone 项目：为手机用户带来自由]]></title>
    <link>https://www.oschina.net/news/377567/fsf-librephone-project</link>
    <itunes:title><![CDATA[FSF 推出 Librephone 项目：为手机用户带来自由]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p><span>自由软件基金会 (FSF) <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.fsf.org%2Fnews%2Flibrephone-project" target="_blank">宣布</a>推出 LibrePhone 项目，旨在为移动设备打造一款完全自由的软件操作系统，并在必要时进行逆向工程，以突破障碍。</span></p>
<blockquote>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffsf.org%2Fcampaigns%2Flibrephone" target="_blank">Librephone 是</a>&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffsf.org%2F" target="_blank">FSF</a>&nbsp;<span>的一项新举措，旨在为移动计算环境带来完全的自由。全球绝大多数软件用户都使用手机作为其主要的计算设备。在倡导计算自由四十年后，FSF 现在将致力于将</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.gnu.org%2Fphilosophy%2Ffree-sw.html" target="_blank">学习、修改、共享和修改</a><span>用户日常生活所依赖的程序的权利引入手机。</span></p>
<p><span>“四十年前，FSF 成立之初，我们的重点是提供一款人们可以在台式电脑和服务器电脑上自由使用的操作系统。时代变了，技术进步了，但我们对自由的承诺却始终如一，”FSF 执行董事 Zoë Kooyman 表示。“多年来，我们在手机自由方面已经做了大量工作，我们将在此基础上继续努力。FSF 现已准备好采取一切必要措施，为手机用户带来自由。鉴于设备的复杂性，这项工作需要时间，但我们已习惯于打持久战。”</span></p>
</blockquote>
<p><span>公告称，Librephone 的目标是弥合现有 Android 操作系统发行版与软件自由之间的最后差距。FSF 已聘请 Rob Savoye（曾参与 DejaGNU、Gnash、OpenStreetMap 等项目）来领导该项目。初期工作由 FSF 董事会成员 John Gilmore 的捐款资助。</span></p>
<p><span>具体来说，FSF 方面计划第一步筛选现有软件包并根据设备兼容性找到一款自由问题最少、最易修复的手机。在此基础上，FSF 和 Savoye 的目标是对剩余的非自由软件进行逆向工程并替换掉它们。Librephone 将服务于现有的开发者和项目，帮助他们构建一个功能齐全且 free 的 Android 兼容操作系统。</span></p>
<p><span>当被要求对该项目发表评论时，Savoye 表示：“作为一名在移动设备上工作了几十年的长期嵌入式系统工程师，我期待着有机会致力于开发一款支持自由的手机，并帮助用户控制他们的手机硬件。为现代商用手机开发完全免费的软件并非易事，成本也高昂，但我们的项目受益于站在巨人的肩膀上，他们已经完成了大部分工作。请加入我们，贡献您的力量和/或捐款。”</span></p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p><span>自由软件基金会 (FSF) <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.fsf.org%2Fnews%2Flibrephone-project" target="_blank">宣布</a>推出 LibrePhone 项目，旨在为移动设备打造一款完全自由的软件操作系统，并在必要时进行逆向工程，以突破障碍。</span></p>
<blockquote>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffsf.org%2Fcampaigns%2Flibrephone" target="_blank">Librephone 是</a>&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffsf.org%2F" target="_blank">FSF</a>&nbsp;<span>的一项新举措，旨在为移动计算环境带来完全的自由。全球绝大多数软件用户都使用手机作为其主要的计算设备。在倡导计算自由四十年后，FSF 现在将致力于将</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.gnu.org%2Fphilosophy%2Ffree-sw.html" target="_blank">学习、修改、共享和修改</a><span>用户日常生活所依赖的程序的权利引入手机。</span></p>
<p><span>“四十年前，FSF 成立之初，我们的重点是提供一款人们可以在台式电脑和服务器电脑上自由使用的操作系统。时代变了，技术进步了，但我们对自由的承诺却始终如一，”FSF 执行董事 Zoë Kooyman 表示。“多年来，我们在手机自由方面已经做了大量工作，我们将在此基础上继续努力。FSF 现已准备好采取一切必要措施，为手机用户带来自由。鉴于设备的复杂性，这项工作需要时间，但我们已习惯于打持久战。”</span></p>
</blockquote>
<p><span>公告称，Librephone 的目标是弥合现有 Android 操作系统发行版与软件自由之间的最后差距。FSF 已聘请 Rob Savoye（曾参与 DejaGNU、Gnash、OpenStreetMap 等项目）来领导该项目。初期工作由 FSF 董事会成员 John Gilmore 的捐款资助。</span></p>
<p><span>具体来说，FSF 方面计划第一步筛选现有软件包并根据设备兼容性找到一款自由问题最少、最易修复的手机。在此基础上，FSF 和 Savoye 的目标是对剩余的非自由软件进行逆向工程并替换掉它们。Librephone 将服务于现有的开发者和项目，帮助他们构建一个功能齐全且 free 的 Android 兼容操作系统。</span></p>
<p><span>当被要求对该项目发表评论时，Savoye 表示：“作为一名在移动设备上工作了几十年的长期嵌入式系统工程师，我期待着有机会致力于开发一款支持自由的手机，并帮助用户控制他们的手机硬件。为现代商用手机开发完全免费的软件并非易事，成本也高昂，但我们的项目受益于站在巨人的肩膀上，他们已经完成了大部分工作。请加入我们，贡献您的力量和/或捐款。”</span></p>]]>
    </description>
    <content:encoded><![CDATA[<p><span>自由软件基金会 (FSF) <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.fsf.org%2Fnews%2Flibrephone-project" target="_blank">宣布</a>推出 LibrePhone 项目，旨在为移动设备打造一款完全自由的软件操作系统，并在必要时进行逆向工程，以突破障碍。</span></p>
<blockquote>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffsf.org%2Fcampaigns%2Flibrephone" target="_blank">Librephone 是</a>&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffsf.org%2F" target="_blank">FSF</a>&nbsp;<span>的一项新举措，旨在为移动计算环境带来完全的自由。全球绝大多数软件用户都使用手机作为其主要的计算设备。在倡导计算自由四十年后，FSF 现在将致力于将</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.gnu.org%2Fphilosophy%2Ffree-sw.html" target="_blank">学习、修改、共享和修改</a><span>用户日常生活所依赖的程序的权利引入手机。</span></p>
<p><span>“四十年前，FSF 成立之初，我们的重点是提供一款人们可以在台式电脑和服务器电脑上自由使用的操作系统。时代变了，技术进步了，但我们对自由的承诺却始终如一，”FSF 执行董事 Zoë Kooyman 表示。“多年来，我们在手机自由方面已经做了大量工作，我们将在此基础上继续努力。FSF 现已准备好采取一切必要措施，为手机用户带来自由。鉴于设备的复杂性，这项工作需要时间，但我们已习惯于打持久战。”</span></p>
</blockquote>
<p><span>公告称，Librephone 的目标是弥合现有 Android 操作系统发行版与软件自由之间的最后差距。FSF 已聘请 Rob Savoye（曾参与 DejaGNU、Gnash、OpenStreetMap 等项目）来领导该项目。初期工作由 FSF 董事会成员 John Gilmore 的捐款资助。</span></p>
<p><span>具体来说，FSF 方面计划第一步筛选现有软件包并根据设备兼容性找到一款自由问题最少、最易修复的手机。在此基础上，FSF 和 Savoye 的目标是对剩余的非自由软件进行逆向工程并替换掉它们。Librephone 将服务于现有的开发者和项目，帮助他们构建一个功能齐全且 free 的 Android 兼容操作系统。</span></p>
<p><span>当被要求对该项目发表评论时，Savoye 表示：“作为一名在移动设备上工作了几十年的长期嵌入式系统工程师，我期待着有机会致力于开发一款支持自由的手机，并帮助用户控制他们的手机硬件。为现代商用手机开发完全免费的软件并非易事，成本也高昂，但我们的项目受益于站在巨人的肩膀上，他们已经完成了大部分工作。请加入我们，贡献您的力量和/或捐款。”</span></p>]]></content:encoded>
    
    <pubDate>Wed, 15 Oct 2025 15:15:50 +0800</pubDate>
  </item><item>
    <title><![CDATA[stateof.ai 发布 2025 人工智能现状报告]]></title>
    <link>https://www.oschina.net/news/377560</link>
    <itunes:title><![CDATA[stateof.ai 发布 2025 人工智能现状报告]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>stateof.ai发布了2025年度人工智能现状报告 (State of AI Report 2025)。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-5fc353d2f1.png"></p>
<p>这个系列报告每年更新一次，今年值得关注的亮点：<br> ---------------------<br> 🌟OpenAI在前沿领域保持微弱领先， 但随着Meta让出领先地位，竞争日益激烈。中国的DeepSeek、Qwen和Kimi在推理和编码任务上缩小了差距，使中国成为可靠的第二名。</p>
<p>🌟推理能力定义了这一年， 前沿实验室将强化学习、基于评分标准（rubric-based）的奖励和可验证推理与新颖的环境相结合，创造出能够规划、反思、自我纠正，并在更长时间跨度上工作的模型。</p>
<p>🌟人工智能正成为科学合作者， 像DeepMind的Co-Scientist和斯坦福的Virtual Lab等系统能够自主生成、测试和验证假说。在生物学领域，Profluent的ProGen3表明，规模法则（scaling laws）现在也适用于蛋白质。</p>
<p>🌟结构化推理通过“行动链”（Chain-of-Action）规划进入物理世界， 像AI2的Molmo-Act和谷歌的Gemini Robotics 1.5等具身AI系统开始在行动前进行逐步推理。</p>
<p>🌟商业应用急剧加速。 根据Ramp和Standard Metrics的数据，44%的美国企业现在为AI工具付费（2023年为5%），平均合同金额达到53万美元，而以AI为先的初创公司比同行增长快1.5倍。</p>
<p>🌟我们的首届AI从业者调查 吸引了超过1200名受访者，结果显示95%的专业人士现在在工作或家庭中使用AI，76%的人自费购买AI工具，大多数人报告生产力持续提升，这表明AI的实际应用已成为主流。</p>
<p>🌟人工智能的工业时代已经开启。 像Stargate这样的数吉瓦（Multi-GW）数据中心标志着新一轮计算基础设施浪潮的到来，这些设施由美国、阿联酋和中国的主权基金支持，而电力供应正成为新的制约因素。</p>
<p>🌟人工智能政治进一步固化。 美国倾向于“美国优先的AI”政策，欧洲的《人工智能法案》遭遇挫折，而中国则扩大了其开源权重生态系统和国内芯片的雄心。</p>
<p>🌟安全研究进入了一个新的、更务实的阶段。 模型现在可以在监督下模仿对齐（alignment），这引发了一场关于透明度与能力之间取舍的辩论。与此同时，外部安全组织的运营预算甚至低于一个前沿实验室的单日消耗。</p>
<p>🌟关于存在性风险的辩论已经降温， 取而代之的是关于可靠性、网络韧性以及日益自主的系统的长期治理等具体问题。</p>
<p><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.google.com%2Fpresentation%2Fd%2F1xiLl0VdrlNMAei8pmaX4ojIOfej6lhvZbOIK7Z6C-Go%2Fedit%3Fusp%3Dsharing" target="_blank">详情查看完整报告</a></em>。</p>
<blockquote>
<p><strong>阅读更多</strong></p>
<p><a href="https://www.oschina.net/news/262155/state-of-ai-2023-report" target="_blank">2023 年度人工智能现状报告</a><br> <a href="https://www.oschina.net/news/319118" target="_blank">State of AI：2024 人工智能报告</a></p>
</blockquote>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>stateof.ai发布了2025年度人工智能现状报告 (State of AI Report 2025)。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-5fc353d2f1.png"></p>
<p>这个系列报告每年更新一次，今年值得关注的亮点：<br> ---------------------<br> 🌟OpenAI在前沿领域保持微弱领先， 但随着Meta让出领先地位，竞争日益激烈。中国的DeepSeek、Qwen和Kimi在推理和编码任务上缩小了差距，使中国成为可靠的第二名。</p>
<p>🌟推理能力定义了这一年， 前沿实验室将强化学习、基于评分标准（rubric-based）的奖励和可验证推理与新颖的环境相结合，创造出能够规划、反思、自我纠正，并在更长时间跨度上工作的模型。</p>
<p>🌟人工智能正成为科学合作者， 像DeepMind的Co-Scientist和斯坦福的Virtual Lab等系统能够自主生成、测试和验证假说。在生物学领域，Profluent的ProGen3表明，规模法则（scaling laws）现在也适用于蛋白质。</p>
<p>🌟结构化推理通过“行动链”（Chain-of-Action）规划进入物理世界， 像AI2的Molmo-Act和谷歌的Gemini Robotics 1.5等具身AI系统开始在行动前进行逐步推理。</p>
<p>🌟商业应用急剧加速。 根据Ramp和Standard Metrics的数据，44%的美国企业现在为AI工具付费（2023年为5%），平均合同金额达到53万美元，而以AI为先的初创公司比同行增长快1.5倍。</p>
<p>🌟我们的首届AI从业者调查 吸引了超过1200名受访者，结果显示95%的专业人士现在在工作或家庭中使用AI，76%的人自费购买AI工具，大多数人报告生产力持续提升，这表明AI的实际应用已成为主流。</p>
<p>🌟人工智能的工业时代已经开启。 像Stargate这样的数吉瓦（Multi-GW）数据中心标志着新一轮计算基础设施浪潮的到来，这些设施由美国、阿联酋和中国的主权基金支持，而电力供应正成为新的制约因素。</p>
<p>🌟人工智能政治进一步固化。 美国倾向于“美国优先的AI”政策，欧洲的《人工智能法案》遭遇挫折，而中国则扩大了其开源权重生态系统和国内芯片的雄心。</p>
<p>🌟安全研究进入了一个新的、更务实的阶段。 模型现在可以在监督下模仿对齐（alignment），这引发了一场关于透明度与能力之间取舍的辩论。与此同时，外部安全组织的运营预算甚至低于一个前沿实验室的单日消耗。</p>
<p>🌟关于存在性风险的辩论已经降温， 取而代之的是关于可靠性、网络韧性以及日益自主的系统的长期治理等具体问题。</p>
<p><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.google.com%2Fpresentation%2Fd%2F1xiLl0VdrlNMAei8pmaX4ojIOfej6lhvZbOIK7Z6C-Go%2Fedit%3Fusp%3Dsharing" target="_blank">详情查看完整报告</a></em>。</p>
<blockquote>
<p><strong>阅读更多</strong></p>
<p><a href="https://www.oschina.net/news/262155/state-of-ai-2023-report" target="_blank">2023 年度人工智能现状报告</a><br> <a href="https://www.oschina.net/news/319118" target="_blank">State of AI：2024 人工智能报告</a></p>
</blockquote>]]>
    </description>
    <content:encoded><![CDATA[<p>stateof.ai发布了2025年度人工智能现状报告 (State of AI Report 2025)。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-5fc353d2f1.png"></p>
<p>这个系列报告每年更新一次，今年值得关注的亮点：<br> ---------------------<br> 🌟OpenAI在前沿领域保持微弱领先， 但随着Meta让出领先地位，竞争日益激烈。中国的DeepSeek、Qwen和Kimi在推理和编码任务上缩小了差距，使中国成为可靠的第二名。</p>
<p>🌟推理能力定义了这一年， 前沿实验室将强化学习、基于评分标准（rubric-based）的奖励和可验证推理与新颖的环境相结合，创造出能够规划、反思、自我纠正，并在更长时间跨度上工作的模型。</p>
<p>🌟人工智能正成为科学合作者， 像DeepMind的Co-Scientist和斯坦福的Virtual Lab等系统能够自主生成、测试和验证假说。在生物学领域，Profluent的ProGen3表明，规模法则（scaling laws）现在也适用于蛋白质。</p>
<p>🌟结构化推理通过“行动链”（Chain-of-Action）规划进入物理世界， 像AI2的Molmo-Act和谷歌的Gemini Robotics 1.5等具身AI系统开始在行动前进行逐步推理。</p>
<p>🌟商业应用急剧加速。 根据Ramp和Standard Metrics的数据，44%的美国企业现在为AI工具付费（2023年为5%），平均合同金额达到53万美元，而以AI为先的初创公司比同行增长快1.5倍。</p>
<p>🌟我们的首届AI从业者调查 吸引了超过1200名受访者，结果显示95%的专业人士现在在工作或家庭中使用AI，76%的人自费购买AI工具，大多数人报告生产力持续提升，这表明AI的实际应用已成为主流。</p>
<p>🌟人工智能的工业时代已经开启。 像Stargate这样的数吉瓦（Multi-GW）数据中心标志着新一轮计算基础设施浪潮的到来，这些设施由美国、阿联酋和中国的主权基金支持，而电力供应正成为新的制约因素。</p>
<p>🌟人工智能政治进一步固化。 美国倾向于“美国优先的AI”政策，欧洲的《人工智能法案》遭遇挫折，而中国则扩大了其开源权重生态系统和国内芯片的雄心。</p>
<p>🌟安全研究进入了一个新的、更务实的阶段。 模型现在可以在监督下模仿对齐（alignment），这引发了一场关于透明度与能力之间取舍的辩论。与此同时，外部安全组织的运营预算甚至低于一个前沿实验室的单日消耗。</p>
<p>🌟关于存在性风险的辩论已经降温， 取而代之的是关于可靠性、网络韧性以及日益自主的系统的长期治理等具体问题。</p>
<p><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.google.com%2Fpresentation%2Fd%2F1xiLl0VdrlNMAei8pmaX4ojIOfej6lhvZbOIK7Z6C-Go%2Fedit%3Fusp%3Dsharing" target="_blank">详情查看完整报告</a></em>。</p>
<blockquote>
<p><strong>阅读更多</strong></p>
<p><a href="https://www.oschina.net/news/262155/state-of-ai-2023-report" target="_blank">2023 年度人工智能现状报告</a><br> <a href="https://www.oschina.net/news/319118" target="_blank">State of AI：2024 人工智能报告</a></p>
</blockquote>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-5fc353d2f1.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-5fc353d2f1.png" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 14:53:26 +0800</pubDate>
  </item><item>
    <title><![CDATA[美国军方高层开始依赖 ChatGPT 辅助决策]]></title>
    <link>https://www.oschina.net/news/377558</link>
    <itunes:title><![CDATA[美国军方高层开始依赖 ChatGPT 辅助决策]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>美国驻韩国的<span>最高</span>军事指挥官泰勒少将（William "Hank" Taylor）在与记者交流时透露，他和人工智能工具 ChatGPT 之间的关系变得越来越密切。他表示，自己正在利用 ChatGPT 来帮助做出军 事和个人决策，这些决策直接影响到他所指挥的士兵们。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-0082c38442.png"></p>
<p>泰勒少将目前担任驻韩美军第八集团军指挥官，同时也是联合国指挥部的首席参谋。他指出，作为一名指挥官，他希望能做出更好的决策，并在适当的时机采取行动，以获得战略上的优势。</p>
<p>然而，依赖于 ChatGPT 作出决策的做法引发了不少担忧。ChatGPT 因其偏向于提供顺从性答案而受到批评，有时甚至在极端情况下对用户的心理健康问题提供不当建议。虽然 OpenAI 尝试通过推出更严谨的版本 GPT-5来解决这些问题，但其短暂的实施后又因用户的强烈反对而恢复了原有的特性。</p>
<p>此外，GPT-5在生成基本事实信息时的准确率也遭到质疑，常常出现超过一半的错误，这在军 事决策中是一个不可忽视的风险。在当前美军驻韩的背景下，这种情况尤其令人不安，尤其是在面对朝鲜长期以来的地缘政治紧张局势时。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>美国驻韩国的<span>最高</span>军事指挥官泰勒少将（William "Hank" Taylor）在与记者交流时透露，他和人工智能工具 ChatGPT 之间的关系变得越来越密切。他表示，自己正在利用 ChatGPT 来帮助做出军 事和个人决策，这些决策直接影响到他所指挥的士兵们。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-0082c38442.png"></p>
<p>泰勒少将目前担任驻韩美军第八集团军指挥官，同时也是联合国指挥部的首席参谋。他指出，作为一名指挥官，他希望能做出更好的决策，并在适当的时机采取行动，以获得战略上的优势。</p>
<p>然而，依赖于 ChatGPT 作出决策的做法引发了不少担忧。ChatGPT 因其偏向于提供顺从性答案而受到批评，有时甚至在极端情况下对用户的心理健康问题提供不当建议。虽然 OpenAI 尝试通过推出更严谨的版本 GPT-5来解决这些问题，但其短暂的实施后又因用户的强烈反对而恢复了原有的特性。</p>
<p>此外，GPT-5在生成基本事实信息时的准确率也遭到质疑，常常出现超过一半的错误，这在军 事决策中是一个不可忽视的风险。在当前美军驻韩的背景下，这种情况尤其令人不安，尤其是在面对朝鲜长期以来的地缘政治紧张局势时。</p>]]>
    </description>
    <content:encoded><![CDATA[<p>美国驻韩国的<span>最高</span>军事指挥官泰勒少将（William "Hank" Taylor）在与记者交流时透露，他和人工智能工具 ChatGPT 之间的关系变得越来越密切。他表示，自己正在利用 ChatGPT 来帮助做出军 事和个人决策，这些决策直接影响到他所指挥的士兵们。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-0082c38442.png"></p>
<p>泰勒少将目前担任驻韩美军第八集团军指挥官，同时也是联合国指挥部的首席参谋。他指出，作为一名指挥官，他希望能做出更好的决策，并在适当的时机采取行动，以获得战略上的优势。</p>
<p>然而，依赖于 ChatGPT 作出决策的做法引发了不少担忧。ChatGPT 因其偏向于提供顺从性答案而受到批评，有时甚至在极端情况下对用户的心理健康问题提供不当建议。虽然 OpenAI 尝试通过推出更严谨的版本 GPT-5来解决这些问题，但其短暂的实施后又因用户的强烈反对而恢复了原有的特性。</p>
<p>此外，GPT-5在生成基本事实信息时的准确率也遭到质疑，常常出现超过一半的错误，这在军 事决策中是一个不可忽视的风险。在当前美军驻韩的背景下，这种情况尤其令人不安，尤其是在面对朝鲜长期以来的地缘政治紧张局势时。</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-0082c38442.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-0082c38442.png" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 14:48:17 +0800</pubDate>
  </item><item>
    <title><![CDATA[英特尔再失一位资深 Linux 驱动维护工程师]]></title>
    <link>https://www.oschina.net/news/377556</link>
    <itunes:title><![CDATA[英特尔再失一位资深 Linux 驱动维护工程师]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>英特尔资深&nbsp;Linux 内核工程师 Jarkko Nikula 已于 2025 年 9 月<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Flkml%2F20251014145905.4862-1-ilpo.jarvinen%40linux.intel.com%2FT%2F%23u" target="_blank">离职</a>，为公司近年来持续的人才流失再添一例。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-ff0c40b5ec.png"></p>
<p>Jarkko 多年来负责维护英特尔的 I²C 与 I3C 驱动子系统，他近期的一些工作包括为 Wildcat Lake U 提供支持、以及启用 Panther Lake、Arrow Lake H 等平台在 I²C / I3C 上的支持。</p>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgit.kernel.org%2Fpub%2Fscm%2Flinux%2Fkernel%2Fgit%2Ftorvalds%2Flinux.git%2Flog%2F%3Fqt%3Dauthor%26q%3Djarkko.nikula%2540linux.intel.com" target="_blank">在他最近一次提交的内核补丁中</a>，他负责 Intel QEP（Quadrature Encoder Peripheral）驱动的维护交接。Jarkko 提到自己的邮箱即将失效，并确认维护工作将由同事 Ilpo Järvinen 接手。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-3ef7bf331a.png"></p>
<p>Jarkko 曾在 Jolla 参与 Sailfish OS 开发，加入英特尔后成为 Linux 内核社区的重要成员。</p>
<blockquote>
<p>相关阅读：<em><a href="https://www.oschina.net/news/376776" target="_blank">英特尔高管：公司将重新评估对开源社区的投入</a></em></p>
</blockquote>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>英特尔资深&nbsp;Linux 内核工程师 Jarkko Nikula 已于 2025 年 9 月<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Flkml%2F20251014145905.4862-1-ilpo.jarvinen%40linux.intel.com%2FT%2F%23u" target="_blank">离职</a>，为公司近年来持续的人才流失再添一例。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-ff0c40b5ec.png"></p>
<p>Jarkko 多年来负责维护英特尔的 I²C 与 I3C 驱动子系统，他近期的一些工作包括为 Wildcat Lake U 提供支持、以及启用 Panther Lake、Arrow Lake H 等平台在 I²C / I3C 上的支持。</p>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgit.kernel.org%2Fpub%2Fscm%2Flinux%2Fkernel%2Fgit%2Ftorvalds%2Flinux.git%2Flog%2F%3Fqt%3Dauthor%26q%3Djarkko.nikula%2540linux.intel.com" target="_blank">在他最近一次提交的内核补丁中</a>，他负责 Intel QEP（Quadrature Encoder Peripheral）驱动的维护交接。Jarkko 提到自己的邮箱即将失效，并确认维护工作将由同事 Ilpo Järvinen 接手。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-3ef7bf331a.png"></p>
<p>Jarkko 曾在 Jolla 参与 Sailfish OS 开发，加入英特尔后成为 Linux 内核社区的重要成员。</p>
<blockquote>
<p>相关阅读：<em><a href="https://www.oschina.net/news/376776" target="_blank">英特尔高管：公司将重新评估对开源社区的投入</a></em></p>
</blockquote>]]>
    </description>
    <content:encoded><![CDATA[<p>英特尔资深&nbsp;Linux 内核工程师 Jarkko Nikula 已于 2025 年 9 月<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Flkml%2F20251014145905.4862-1-ilpo.jarvinen%40linux.intel.com%2FT%2F%23u" target="_blank">离职</a>，为公司近年来持续的人才流失再添一例。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-ff0c40b5ec.png"></p>
<p>Jarkko 多年来负责维护英特尔的 I²C 与 I3C 驱动子系统，他近期的一些工作包括为 Wildcat Lake U 提供支持、以及启用 Panther Lake、Arrow Lake H 等平台在 I²C / I3C 上的支持。</p>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgit.kernel.org%2Fpub%2Fscm%2Flinux%2Fkernel%2Fgit%2Ftorvalds%2Flinux.git%2Flog%2F%3Fqt%3Dauthor%26q%3Djarkko.nikula%2540linux.intel.com" target="_blank">在他最近一次提交的内核补丁中</a>，他负责 Intel QEP（Quadrature Encoder Peripheral）驱动的维护交接。Jarkko 提到自己的邮箱即将失效，并确认维护工作将由同事 Ilpo Järvinen 接手。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-3ef7bf331a.png"></p>
<p>Jarkko 曾在 Jolla 参与 Sailfish OS 开发，加入英特尔后成为 Linux 内核社区的重要成员。</p>
<blockquote>
<p>相关阅读：<em><a href="https://www.oschina.net/news/376776" target="_blank">英特尔高管：公司将重新评估对开源社区的投入</a></em></p>
</blockquote>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-ff0c40b5ec.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-ff0c40b5ec.png" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 14:39:21 +0800</pubDate>
  </item><item>
    <title><![CDATA[字体设计工具字玩 v0.3.3 发布，新增楷体和隶书笔画模板]]></title>
    <link>https://www.oschina.net/news/377555</link>
    <itunes:title><![CDATA[字体设计工具字玩 v0.3.3 发布，新增楷体和隶书笔画模板]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>字玩是一款开源的字体设计工具，致力于探索以参数化、脚本化的方式设计中文字库，帮助用户高效设计个性化字体。使用Vue3 + Tauri2开发，支持Web端、MacOS和Windows平台。</p>
<p>开源地址：<a href="https://gitee.com/toysmaker/fontplayer">字玩在gitee</a> | <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FHiToysMaker%2Ffontplayer" target="_blank">字玩在github</a></p>
<h4>v0.3.2版本更新说明</h4>
<ol>
<li> <p>新增字玩标准楷体笔画模板，可供用户调参</p> </li>
<li> <p>新增字玩标准隶书笔画模板，可供用户调参</p> </li>
<li> <p>优化骨架拖拽性能</p> </li>
<li> <p>修复部分仿宋笔画组件骨架拖拽bug</p> </li>
</ol>
<h4>新增笔画模板一览</h4>
<p>1. 字玩标准楷体</p>
<div>
<div>
模板包含32个可调参笔画，在模板菜单中选择相应笔画模板加载：
</div>
<div>
<img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6226531bd3.jpg">
</div> &nbsp;
<div>
在高级编辑-&gt;风格切换面板中可以预览一键替换效果（批量替换笔画后仍有诸多细节问题需要处理，可以使用脚本辅助优化细节）：
</div>
</div>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-55e6d17c5c.jpg"></p>
<p>2. 字玩标准隶书</p>
<div>
<div>
<span>模板包含33个可调参笔画，在模板菜单中选择相应笔画模板加载：</span>
</div>
<div>
<span><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-fce378efae.jpg"></span>
</div> &nbsp;
<div>
<span>在高级编辑-&gt;风格切换面板中可以预览一键替换效果（批量替换笔画后仍有诸多细节问题需要处理，可以使用脚本辅助优化细节）：</span>
</div>
</div>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-3d0a12af4f.jpg"></p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>字玩是一款开源的字体设计工具，致力于探索以参数化、脚本化的方式设计中文字库，帮助用户高效设计个性化字体。使用Vue3 + Tauri2开发，支持Web端、MacOS和Windows平台。</p>
<p>开源地址：<a href="https://gitee.com/toysmaker/fontplayer">字玩在gitee</a> | <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FHiToysMaker%2Ffontplayer" target="_blank">字玩在github</a></p>
<h4>v0.3.2版本更新说明</h4>
<ol>
<li> <p>新增字玩标准楷体笔画模板，可供用户调参</p> </li>
<li> <p>新增字玩标准隶书笔画模板，可供用户调参</p> </li>
<li> <p>优化骨架拖拽性能</p> </li>
<li> <p>修复部分仿宋笔画组件骨架拖拽bug</p> </li>
</ol>
<h4>新增笔画模板一览</h4>
<p>1. 字玩标准楷体</p>
<div>
<div>
模板包含32个可调参笔画，在模板菜单中选择相应笔画模板加载：
</div>
<div>
<img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6226531bd3.jpg">
</div> &nbsp;
<div>
在高级编辑-&gt;风格切换面板中可以预览一键替换效果（批量替换笔画后仍有诸多细节问题需要处理，可以使用脚本辅助优化细节）：
</div>
</div>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-55e6d17c5c.jpg"></p>
<p>2. 字玩标准隶书</p>
<div>
<div>
<span>模板包含33个可调参笔画，在模板菜单中选择相应笔画模板加载：</span>
</div>
<div>
<span><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-fce378efae.jpg"></span>
</div> &nbsp;
<div>
<span>在高级编辑-&gt;风格切换面板中可以预览一键替换效果（批量替换笔画后仍有诸多细节问题需要处理，可以使用脚本辅助优化细节）：</span>
</div>
</div>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-3d0a12af4f.jpg"></p>]]>
    </description>
    <content:encoded><![CDATA[<p>字玩是一款开源的字体设计工具，致力于探索以参数化、脚本化的方式设计中文字库，帮助用户高效设计个性化字体。使用Vue3 + Tauri2开发，支持Web端、MacOS和Windows平台。</p>
<p>开源地址：<a href="https://gitee.com/toysmaker/fontplayer">字玩在gitee</a> | <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FHiToysMaker%2Ffontplayer" target="_blank">字玩在github</a></p>
<h4>v0.3.2版本更新说明</h4>
<ol>
<li> <p>新增字玩标准楷体笔画模板，可供用户调参</p> </li>
<li> <p>新增字玩标准隶书笔画模板，可供用户调参</p> </li>
<li> <p>优化骨架拖拽性能</p> </li>
<li> <p>修复部分仿宋笔画组件骨架拖拽bug</p> </li>
</ol>
<h4>新增笔画模板一览</h4>
<p>1. 字玩标准楷体</p>
<div>
<div>
模板包含32个可调参笔画，在模板菜单中选择相应笔画模板加载：
</div>
<div>
<img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6226531bd3.jpg">
</div> &nbsp;
<div>
在高级编辑-&gt;风格切换面板中可以预览一键替换效果（批量替换笔画后仍有诸多细节问题需要处理，可以使用脚本辅助优化细节）：
</div>
</div>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-55e6d17c5c.jpg"></p>
<p>2. 字玩标准隶书</p>
<div>
<div>
<span>模板包含33个可调参笔画，在模板菜单中选择相应笔画模板加载：</span>
</div>
<div>
<span><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-fce378efae.jpg"></span>
</div> &nbsp;
<div>
<span>在高级编辑-&gt;风格切换面板中可以预览一键替换效果（批量替换笔画后仍有诸多细节问题需要处理，可以使用脚本辅助优化细节）：</span>
</div>
</div>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-3d0a12af4f.jpg"></p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6226531bd3.jpg"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6226531bd3.jpg" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 14:24:24 +0800</pubDate>
  </item><item>
    <title><![CDATA[OpenAI 年收入达 130 亿美元，启动五年“万亿”增长计划]]></title>
    <link>https://www.oschina.net/news/377552</link>
    <itunes:title><![CDATA[OpenAI 年收入达 130 亿美元，启动五年“万亿”增长计划]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p><span>据《金融时报》报道，人工智能巨头OpenAI目前的年化收入已达到约</span><strong>130亿美元</strong><span>，其中高达<strong> 70% </strong>的收入来自普通用户每月支付20美元的订阅费用。考虑到ChatGPT拥有8亿常规用户，但付费用户占比仅约5%，这一营收数字已相当惊人。</span></p>
<p>尽管OpenAI目前收入可观，但其目标也极为宏大。该公司承诺在未来十年内投入超过<strong>1万亿美元</strong>（即数万亿美元）用于基础设施建设。OpenAI最近已与甲骨文(Oracle)、英伟达(Nvidia)、AMD和博通(Broadcom)等巨头达成交易，旨在获取超过<strong>26千兆瓦</strong>的计算能力。这笔巨大的基础设施成本将远远超出其目前的投入水平。</p>
<p>为了弥补这一巨大的投入与产出差距，OpenAI正在寻求创新的盈利模式。据《金融时报》披露，一项<strong>五年计划</strong>已经启动，旨在多维度拓展业务，包括:</p>
<ul>
<li> <p><strong>政府合同：</strong>积极探索获取政府合同的机会。</p> </li>
<li> <p><strong>消费级服务：</strong>推出购物工具、视频服务及消费硬件。</p> </li>
<li> <p><strong>计算力供应商：</strong>通过其雄心勃勃的<strong>Stargate数据中心项目</strong>，成为主要的计算能力供应商。</p> </li>
</ul>
<p>《金融时报》指出，美国一些最具价值的公司目前正依赖OpenAI来履行重大合同，这体现了企业界对数学问题解决等AI能力日益增长的需求。行业观察人士警告，如果OpenAI的运营出现问题，可能会<strong>破坏美国整体市场的稳定</strong>，突显了该公司在当前经济生态中的关键地位。OpenAI正面临将年收入130亿美元快速转化为支撑万亿级投资的巨大挑战。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p><span>据《金融时报》报道，人工智能巨头OpenAI目前的年化收入已达到约</span><strong>130亿美元</strong><span>，其中高达<strong> 70% </strong>的收入来自普通用户每月支付20美元的订阅费用。考虑到ChatGPT拥有8亿常规用户，但付费用户占比仅约5%，这一营收数字已相当惊人。</span></p>
<p>尽管OpenAI目前收入可观，但其目标也极为宏大。该公司承诺在未来十年内投入超过<strong>1万亿美元</strong>（即数万亿美元）用于基础设施建设。OpenAI最近已与甲骨文(Oracle)、英伟达(Nvidia)、AMD和博通(Broadcom)等巨头达成交易，旨在获取超过<strong>26千兆瓦</strong>的计算能力。这笔巨大的基础设施成本将远远超出其目前的投入水平。</p>
<p>为了弥补这一巨大的投入与产出差距，OpenAI正在寻求创新的盈利模式。据《金融时报》披露，一项<strong>五年计划</strong>已经启动，旨在多维度拓展业务，包括:</p>
<ul>
<li> <p><strong>政府合同：</strong>积极探索获取政府合同的机会。</p> </li>
<li> <p><strong>消费级服务：</strong>推出购物工具、视频服务及消费硬件。</p> </li>
<li> <p><strong>计算力供应商：</strong>通过其雄心勃勃的<strong>Stargate数据中心项目</strong>，成为主要的计算能力供应商。</p> </li>
</ul>
<p>《金融时报》指出，美国一些最具价值的公司目前正依赖OpenAI来履行重大合同，这体现了企业界对数学问题解决等AI能力日益增长的需求。行业观察人士警告，如果OpenAI的运营出现问题，可能会<strong>破坏美国整体市场的稳定</strong>，突显了该公司在当前经济生态中的关键地位。OpenAI正面临将年收入130亿美元快速转化为支撑万亿级投资的巨大挑战。</p>]]>
    </description>
    <content:encoded><![CDATA[<p><span>据《金融时报》报道，人工智能巨头OpenAI目前的年化收入已达到约</span><strong>130亿美元</strong><span>，其中高达<strong> 70% </strong>的收入来自普通用户每月支付20美元的订阅费用。考虑到ChatGPT拥有8亿常规用户，但付费用户占比仅约5%，这一营收数字已相当惊人。</span></p>
<p>尽管OpenAI目前收入可观，但其目标也极为宏大。该公司承诺在未来十年内投入超过<strong>1万亿美元</strong>（即数万亿美元）用于基础设施建设。OpenAI最近已与甲骨文(Oracle)、英伟达(Nvidia)、AMD和博通(Broadcom)等巨头达成交易，旨在获取超过<strong>26千兆瓦</strong>的计算能力。这笔巨大的基础设施成本将远远超出其目前的投入水平。</p>
<p>为了弥补这一巨大的投入与产出差距，OpenAI正在寻求创新的盈利模式。据《金融时报》披露，一项<strong>五年计划</strong>已经启动，旨在多维度拓展业务，包括:</p>
<ul>
<li> <p><strong>政府合同：</strong>积极探索获取政府合同的机会。</p> </li>
<li> <p><strong>消费级服务：</strong>推出购物工具、视频服务及消费硬件。</p> </li>
<li> <p><strong>计算力供应商：</strong>通过其雄心勃勃的<strong>Stargate数据中心项目</strong>，成为主要的计算能力供应商。</p> </li>
</ul>
<p>《金融时报》指出，美国一些最具价值的公司目前正依赖OpenAI来履行重大合同，这体现了企业界对数学问题解决等AI能力日益增长的需求。行业观察人士警告，如果OpenAI的运营出现问题，可能会<strong>破坏美国整体市场的稳定</strong>，突显了该公司在当前经济生态中的关键地位。OpenAI正面临将年收入130亿美元快速转化为支撑万亿级投资的巨大挑战。</p>]]></content:encoded>
    
    <pubDate>Wed, 15 Oct 2025 14:20:02 +0800</pubDate>
  </item><item>
    <title><![CDATA[Ip2region 3.6.0 发布 - Javascript 扩展添加了 IPv6 的支持]]></title>
    <link>https://www.oschina.net/news/377548/ip2region-3-6-0-released</link>
    <itunes:title><![CDATA[Ip2region 3.6.0 发布 - Javascript 扩展添加了 IPv6 的支持]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fip2region.net" target="_blank">Ip2region</a><span> </span>是一个离线的 IP 数据管理框架和定位库，同时支持 IPv4 和 IPv6，支持亿级别的 IP 断管理，10 微秒级别的查询性能，提供了很多主流编程语言的 xdb 数据格式的生成和查询实现。</p>
<p>ip2region 官方社区已正式上线旨提强化 IP 相关的工具链和数据服务，目前提供了稳定的<span> </span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fip2region.net%2Fproducts%2Foffline" target="_blank">商用离线数据</a>、<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fip2region.net%2Fsearch%2Fdemo" target="_blank">在线查询测试</a>、<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fip2region.net%2Fdoc%2F" target="_blank">xdb 使用 / 技术文档</a>。</p>
<p>ip2region 3.6.0 详细更新如下：</p>
<p>1，ip2region.js npm 包支持，适用于 Nodejs / Typescript：</p>
<pre><code>npm install ip2region.js --save</code></pre>
<p>2，javascript binding (nodejs / typescript) 提供了对 IPv6 的查询支持，具体使用文档请参考 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Flionsoul2014%2Fip2region%2Ftree%2Fmaster%2Fbinding%2Fjavascript" target="_blank">javascript Binding</a>，测试方式如下：</p>
<pre><code>➜  javascript git:(master) node tests/search.app.js --db=../../data/ip2region_v6.xdb
ip2region xdb searcher test program
source xdb: ../../data/ip2region_v6.xdb (IPv6, vectorIndex)
type 'quit' to exit
ip2region&gt;&gt; ::
{region: |||, ioCount: 2, took: 158.64 μs}
ip2region&gt;&gt; 240e:3b7:3272:d8d0:3b7b:3ee0:1d39:848
{region: 中国|广东省|深圳市|家庭宽带, ioCount: 14, took: 256.98 μs}
ip2region&gt;&gt; 2001:3:ffff:ffff:ffff:ffff:ffff:ffff
{region: 美国|加利福尼亚州|洛杉矶|专线用户, ioCount: 21, took: 241.755 μs}
ip2region&gt;&gt;</code></pre>
<p>3，查询平均耗时：Razer 笔记本 / Ubuntu (电源均衡模式) + SATA SSD / VectorIndex 缓存，bench 结果如下：</p>
<pre><code>➜  javascript git:(master) node tests/bench.app.js --db=../../data/ip2region_v6.xdb --src=../../data/ipv6_source.txt
Searcher: {"version": IPv6, "dbPath": ../../data/ip2region_v6.xdb, "handle": 21, "vectorIndex": 524288 "cBuffer": null}
Bench finished, {cachePolicy: vectorIndex, total: 34159862, took: 963.9443019528878 s, cost: 28.21862400828457 μs/op}</code></pre>
<p>3415.9 万个 IPv6 平均查询耗时为 <code>28.2</code>&nbsp;微秒/次。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fip2region.net" target="_blank">Ip2region</a><span> </span>是一个离线的 IP 数据管理框架和定位库，同时支持 IPv4 和 IPv6，支持亿级别的 IP 断管理，10 微秒级别的查询性能，提供了很多主流编程语言的 xdb 数据格式的生成和查询实现。</p>
<p>ip2region 官方社区已正式上线旨提强化 IP 相关的工具链和数据服务，目前提供了稳定的<span> </span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fip2region.net%2Fproducts%2Foffline" target="_blank">商用离线数据</a>、<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fip2region.net%2Fsearch%2Fdemo" target="_blank">在线查询测试</a>、<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fip2region.net%2Fdoc%2F" target="_blank">xdb 使用 / 技术文档</a>。</p>
<p>ip2region 3.6.0 详细更新如下：</p>
<p>1，ip2region.js npm 包支持，适用于 Nodejs / Typescript：</p>
<pre><code>npm install ip2region.js --save</code></pre>
<p>2，javascript binding (nodejs / typescript) 提供了对 IPv6 的查询支持，具体使用文档请参考 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Flionsoul2014%2Fip2region%2Ftree%2Fmaster%2Fbinding%2Fjavascript" target="_blank">javascript Binding</a>，测试方式如下：</p>
<pre><code>➜  javascript git:(master) node tests/search.app.js --db=../../data/ip2region_v6.xdb
ip2region xdb searcher test program
source xdb: ../../data/ip2region_v6.xdb (IPv6, vectorIndex)
type 'quit' to exit
ip2region&gt;&gt; ::
{region: |||, ioCount: 2, took: 158.64 μs}
ip2region&gt;&gt; 240e:3b7:3272:d8d0:3b7b:3ee0:1d39:848
{region: 中国|广东省|深圳市|家庭宽带, ioCount: 14, took: 256.98 μs}
ip2region&gt;&gt; 2001:3:ffff:ffff:ffff:ffff:ffff:ffff
{region: 美国|加利福尼亚州|洛杉矶|专线用户, ioCount: 21, took: 241.755 μs}
ip2region&gt;&gt;</code></pre>
<p>3，查询平均耗时：Razer 笔记本 / Ubuntu (电源均衡模式) + SATA SSD / VectorIndex 缓存，bench 结果如下：</p>
<pre><code>➜  javascript git:(master) node tests/bench.app.js --db=../../data/ip2region_v6.xdb --src=../../data/ipv6_source.txt
Searcher: {"version": IPv6, "dbPath": ../../data/ip2region_v6.xdb, "handle": 21, "vectorIndex": 524288 "cBuffer": null}
Bench finished, {cachePolicy: vectorIndex, total: 34159862, took: 963.9443019528878 s, cost: 28.21862400828457 μs/op}</code></pre>
<p>3415.9 万个 IPv6 平均查询耗时为 <code>28.2</code>&nbsp;微秒/次。</p>]]>
    </description>
    <content:encoded><![CDATA[<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fip2region.net" target="_blank">Ip2region</a><span> </span>是一个离线的 IP 数据管理框架和定位库，同时支持 IPv4 和 IPv6，支持亿级别的 IP 断管理，10 微秒级别的查询性能，提供了很多主流编程语言的 xdb 数据格式的生成和查询实现。</p>
<p>ip2region 官方社区已正式上线旨提强化 IP 相关的工具链和数据服务，目前提供了稳定的<span> </span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fip2region.net%2Fproducts%2Foffline" target="_blank">商用离线数据</a>、<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fip2region.net%2Fsearch%2Fdemo" target="_blank">在线查询测试</a>、<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fip2region.net%2Fdoc%2F" target="_blank">xdb 使用 / 技术文档</a>。</p>
<p>ip2region 3.6.0 详细更新如下：</p>
<p>1，ip2region.js npm 包支持，适用于 Nodejs / Typescript：</p>
<pre><code>npm install ip2region.js --save</code></pre>
<p>2，javascript binding (nodejs / typescript) 提供了对 IPv6 的查询支持，具体使用文档请参考 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Flionsoul2014%2Fip2region%2Ftree%2Fmaster%2Fbinding%2Fjavascript" target="_blank">javascript Binding</a>，测试方式如下：</p>
<pre><code>➜  javascript git:(master) node tests/search.app.js --db=../../data/ip2region_v6.xdb
ip2region xdb searcher test program
source xdb: ../../data/ip2region_v6.xdb (IPv6, vectorIndex)
type 'quit' to exit
ip2region&gt;&gt; ::
{region: |||, ioCount: 2, took: 158.64 μs}
ip2region&gt;&gt; 240e:3b7:3272:d8d0:3b7b:3ee0:1d39:848
{region: 中国|广东省|深圳市|家庭宽带, ioCount: 14, took: 256.98 μs}
ip2region&gt;&gt; 2001:3:ffff:ffff:ffff:ffff:ffff:ffff
{region: 美国|加利福尼亚州|洛杉矶|专线用户, ioCount: 21, took: 241.755 μs}
ip2region&gt;&gt;</code></pre>
<p>3，查询平均耗时：Razer 笔记本 / Ubuntu (电源均衡模式) + SATA SSD / VectorIndex 缓存，bench 结果如下：</p>
<pre><code>➜  javascript git:(master) node tests/bench.app.js --db=../../data/ip2region_v6.xdb --src=../../data/ipv6_source.txt
Searcher: {"version": IPv6, "dbPath": ../../data/ip2region_v6.xdb, "handle": 21, "vectorIndex": 524288 "cBuffer": null}
Bench finished, {cachePolicy: vectorIndex, total: 34159862, took: 963.9443019528878 s, cost: 28.21862400828457 μs/op}</code></pre>
<p>3415.9 万个 IPv6 平均查询耗时为 <code>28.2</code>&nbsp;微秒/次。</p>]]></content:encoded>
    
    <pubDate>Wed, 15 Oct 2025 14:10:10 +0800</pubDate>
  </item><item>
    <title><![CDATA[Firefox 添加 Perplexity AI 答案引擎作为新的搜索选项]]></title>
    <link>https://www.oschina.net/news/377523</link>
    <itunes:title><![CDATA[Firefox 添加 Perplexity AI 答案引擎作为新的搜索选项]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>Mozilla宣布，其Firefox浏览器现已支持将AI驱动的Perplexity答案引擎作为默认搜索选项集成，让用户能够在原有浏览器中自由选择是否使用AI进行网络搜索与信息查找。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-b6b8167e0a.png"></p>
<p>Firefox用户现在无需更换浏览器，即可在设置中更改默认搜索引擎，将Perplexity与Google、必应、DuckDuckGo等传统搜索引擎一同列为可选项。</p>
<p>此前，Mozilla曾宣布对这一集成方案进行测试，但仅向美国、英国和德国等部分市场开放，尚未确定Perplexity能否成为Firefox搜索引擎列表中的常驻选项。</p>
<p>根据官方表述，正是由于试点地区用户的积极反馈，Mozilla现决定向全球桌面用户全面提供此功能，并计划在未来数月内推广至移动端。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-fa68d9c932.png"></p>
<p>启用后，Perplexity可为用户带来对话式搜索体验，提供带有权威引用的直接答案，而非如Google等搜索引擎所显示的网页链接列表。该选项将出现在地址栏的统一搜索按钮内，用户可随时切换为Perplexity搜索，也可在设置中设为默认搜索引擎。</p>
<p>Mozilla还表示，未来有望引入更多AI答案引擎，以丰富搜索体验（选择Perplexity的原因之一是其强调不会共享或出售用户个人数据）。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>Mozilla宣布，其Firefox浏览器现已支持将AI驱动的Perplexity答案引擎作为默认搜索选项集成，让用户能够在原有浏览器中自由选择是否使用AI进行网络搜索与信息查找。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-b6b8167e0a.png"></p>
<p>Firefox用户现在无需更换浏览器，即可在设置中更改默认搜索引擎，将Perplexity与Google、必应、DuckDuckGo等传统搜索引擎一同列为可选项。</p>
<p>此前，Mozilla曾宣布对这一集成方案进行测试，但仅向美国、英国和德国等部分市场开放，尚未确定Perplexity能否成为Firefox搜索引擎列表中的常驻选项。</p>
<p>根据官方表述，正是由于试点地区用户的积极反馈，Mozilla现决定向全球桌面用户全面提供此功能，并计划在未来数月内推广至移动端。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-fa68d9c932.png"></p>
<p>启用后，Perplexity可为用户带来对话式搜索体验，提供带有权威引用的直接答案，而非如Google等搜索引擎所显示的网页链接列表。该选项将出现在地址栏的统一搜索按钮内，用户可随时切换为Perplexity搜索，也可在设置中设为默认搜索引擎。</p>
<p>Mozilla还表示，未来有望引入更多AI答案引擎，以丰富搜索体验（选择Perplexity的原因之一是其强调不会共享或出售用户个人数据）。</p>]]>
    </description>
    <content:encoded><![CDATA[<p>Mozilla宣布，其Firefox浏览器现已支持将AI驱动的Perplexity答案引擎作为默认搜索选项集成，让用户能够在原有浏览器中自由选择是否使用AI进行网络搜索与信息查找。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-b6b8167e0a.png"></p>
<p>Firefox用户现在无需更换浏览器，即可在设置中更改默认搜索引擎，将Perplexity与Google、必应、DuckDuckGo等传统搜索引擎一同列为可选项。</p>
<p>此前，Mozilla曾宣布对这一集成方案进行测试，但仅向美国、英国和德国等部分市场开放，尚未确定Perplexity能否成为Firefox搜索引擎列表中的常驻选项。</p>
<p>根据官方表述，正是由于试点地区用户的积极反馈，Mozilla现决定向全球桌面用户全面提供此功能，并计划在未来数月内推广至移动端。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-fa68d9c932.png"></p>
<p>启用后，Perplexity可为用户带来对话式搜索体验，提供带有权威引用的直接答案，而非如Google等搜索引擎所显示的网页链接列表。该选项将出现在地址栏的统一搜索按钮内，用户可随时切换为Perplexity搜索，也可在设置中设为默认搜索引擎。</p>
<p>Mozilla还表示，未来有望引入更多AI答案引擎，以丰富搜索体验（选择Perplexity的原因之一是其强调不会共享或出售用户个人数据）。</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-b6b8167e0a.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-b6b8167e0a.png" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 12:09:00 +0800</pubDate>
  </item><item>
    <title><![CDATA[谷歌 NotebookLM 视频概览功能升级：引入“Nano Banana”]]></title>
    <link>https://www.oschina.net/news/377509</link>
    <itunes:title><![CDATA[谷歌 NotebookLM 视频概览功能升级：引入“Nano Banana”]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>谷歌<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Ftechnology%2Fai%2Fnano-banana-google-products%2F" target="_blank">宣布</a>为NotebookLM的视频概览功能推出重大升级，借助Gemini最新图像生成技术“Nano Banana”，实现基于文档内容的自动视频创作能力。</p>
<p>此次更新为用户提供水彩、纸艺、动漫等六种视觉风格选项，并新增“Brief”格式与原有“Explainer”格式形成互补，分别满足快速提取文档要点与深度内容阐释需求。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-47ac782124.png"></p>
<p>用户在NotebookLM中选择源文件后，点击“视频概览”按钮即可自定义视频风格、格式及旁白等元素。</p>
<p>该功能将于本周率先向NotebookLM Pro用户开放，未来几周逐步向所有用户推送。谷歌表示，此次升级旨在通过AI技术降低视频内容创作门槛，为教育、办公等场景提供更直观的信息呈现方式，进一步拓展Gemini多模态能力的应用边界。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>谷歌<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Ftechnology%2Fai%2Fnano-banana-google-products%2F" target="_blank">宣布</a>为NotebookLM的视频概览功能推出重大升级，借助Gemini最新图像生成技术“Nano Banana”，实现基于文档内容的自动视频创作能力。</p>
<p>此次更新为用户提供水彩、纸艺、动漫等六种视觉风格选项，并新增“Brief”格式与原有“Explainer”格式形成互补，分别满足快速提取文档要点与深度内容阐释需求。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-47ac782124.png"></p>
<p>用户在NotebookLM中选择源文件后，点击“视频概览”按钮即可自定义视频风格、格式及旁白等元素。</p>
<p>该功能将于本周率先向NotebookLM Pro用户开放，未来几周逐步向所有用户推送。谷歌表示，此次升级旨在通过AI技术降低视频内容创作门槛，为教育、办公等场景提供更直观的信息呈现方式，进一步拓展Gemini多模态能力的应用边界。</p>]]>
    </description>
    <content:encoded><![CDATA[<p>谷歌<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Ftechnology%2Fai%2Fnano-banana-google-products%2F" target="_blank">宣布</a>为NotebookLM的视频概览功能推出重大升级，借助Gemini最新图像生成技术“Nano Banana”，实现基于文档内容的自动视频创作能力。</p>
<p>此次更新为用户提供水彩、纸艺、动漫等六种视觉风格选项，并新增“Brief”格式与原有“Explainer”格式形成互补，分别满足快速提取文档要点与深度内容阐释需求。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-47ac782124.png"></p>
<p>用户在NotebookLM中选择源文件后，点击“视频概览”按钮即可自定义视频风格、格式及旁白等元素。</p>
<p>该功能将于本周率先向NotebookLM Pro用户开放，未来几周逐步向所有用户推送。谷歌表示，此次升级旨在通过AI技术降低视频内容创作门槛，为教育、办公等场景提供更直观的信息呈现方式，进一步拓展Gemini多模态能力的应用边界。</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-47ac782124.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-47ac782124.png" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 11:28:06 +0800</pubDate>
  </item><item>
    <title><![CDATA[马斯克：X 平台本周将发布 AI 算法更新，信息流全面转向 AI 推荐]]></title>
    <link>https://www.oschina.net/news/377508</link>
    <itunes:title><![CDATA[马斯克：X 平台本周将发布 AI 算法更新，信息流全面转向 AI 推荐]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p><span>埃隆·马斯克（Elon Musk）周二在X上发帖预告，该平台将于</span><strong>本周晚些时候</strong><span>发布更新后的算法，以实现</span><strong>完全人工智能推荐</strong><span>。</span></p>
<p>马斯克表示，此次算法革新将使得用户的信息流（feed）改善不再是由于特定用户的行为改变了启发式（heuristics），而是<strong>完全归因于Grok和其他人工智能工具的使用增加</strong>。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-2d9336758f.png"></p>
<p>据马斯克透露，X平台将于<strong>下月全面切换至由Grok驱动的AI推荐系统</strong>，并将一并发布<strong>模型权重的新算法</strong>。</p>
<p>这一重大转变的核心在于利用先进的AI技术精准分发内容。每天将有<strong>超过1亿条内容</strong>由Grok进行评估，并推荐给用户<strong>最可能引起他们兴趣的内容</strong>，旨在显著提升整体信息流的质量和用户体验。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p><span>埃隆·马斯克（Elon Musk）周二在X上发帖预告，该平台将于</span><strong>本周晚些时候</strong><span>发布更新后的算法，以实现</span><strong>完全人工智能推荐</strong><span>。</span></p>
<p>马斯克表示，此次算法革新将使得用户的信息流（feed）改善不再是由于特定用户的行为改变了启发式（heuristics），而是<strong>完全归因于Grok和其他人工智能工具的使用增加</strong>。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-2d9336758f.png"></p>
<p>据马斯克透露，X平台将于<strong>下月全面切换至由Grok驱动的AI推荐系统</strong>，并将一并发布<strong>模型权重的新算法</strong>。</p>
<p>这一重大转变的核心在于利用先进的AI技术精准分发内容。每天将有<strong>超过1亿条内容</strong>由Grok进行评估，并推荐给用户<strong>最可能引起他们兴趣的内容</strong>，旨在显著提升整体信息流的质量和用户体验。</p>]]>
    </description>
    <content:encoded><![CDATA[<p><span>埃隆·马斯克（Elon Musk）周二在X上发帖预告，该平台将于</span><strong>本周晚些时候</strong><span>发布更新后的算法，以实现</span><strong>完全人工智能推荐</strong><span>。</span></p>
<p>马斯克表示，此次算法革新将使得用户的信息流（feed）改善不再是由于特定用户的行为改变了启发式（heuristics），而是<strong>完全归因于Grok和其他人工智能工具的使用增加</strong>。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-2d9336758f.png"></p>
<p>据马斯克透露，X平台将于<strong>下月全面切换至由Grok驱动的AI推荐系统</strong>，并将一并发布<strong>模型权重的新算法</strong>。</p>
<p>这一重大转变的核心在于利用先进的AI技术精准分发内容。每天将有<strong>超过1亿条内容</strong>由Grok进行评估，并推荐给用户<strong>最可能引起他们兴趣的内容</strong>，旨在显著提升整体信息流的质量和用户体验。</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-2d9336758f.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-2d9336758f.png" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 11:27:11 +0800</pubDate>
  </item><item>
    <title><![CDATA[SQLE 4.2509.0 正式版发布！SQL 工作台焕新升级！]]></title>
    <link>https://www.oschina.net/news/377499</link>
    <itunes:title><![CDATA[SQLE 4.2509.0 正式版发布！SQL 工作台焕新升级！]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<h2><span><span><span>🎈 新功能</span></span></span></h2>
<p><strong><strong><span><strong><span><span>社区版</span></span></strong></span></strong></strong></p>
<p><span><strong><strong><strong><span><u>🚀</u></span><span><u>&nbsp;</u></span><span><u>SQL 工作台焕新升级，体验更丝滑！</u></span></strong></strong></strong></span></p>
<p><span><span>根据社区的长期反馈，我们关注到旧版&nbsp;</span><strong>SQL 工作台</strong><strong>&nbsp;</strong><span>在界面设计和功能支持上存在一些不足。为了改善使用体验，我们进行了一次有针对性的重要更新。</span></span></p>
<p><span><span>本次更新主要集中在两个方面：</span><strong>界面现代化&nbsp;</strong><span>和&nbsp;</span><strong>核心功能增强</strong><span>。</span></span></p>
<p><span><strong>1. 更现代化的工作界面</strong><span>&nbsp;</span></span></p>
<p><span><span>新的用户界面更符合当下的设计标准。</span></span></p>
<p><span><strong>布局更清晰</strong><span>：优化了整体布局，减少了视觉上的干扰，帮助你更快定位到所需功能。</span></span></p>
<p><span><strong>操作更顺畅</strong><span>：调整了交互流程，使得常用操作的路径更短，响应也更为流畅。</span></span></p>
<p><span><strong>2.&nbsp;</strong></span><span><strong>更强大的内置功能</strong></span></p>
<p><span><strong>集成工单状态追踪：</strong><span>对于从 SQL 工作台触发的审批工单，你现在可以直接在工作台内查看其进展状态。无需再切换页面，让 SQL 开发与审批流程的衔接更紧密。</span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-2c4c657563.png"></p>
<p><strong>SQL 脚本保存与复用：</strong><span>&nbsp;你可以将常用或复杂的 SQL 脚本保存在工作台中，方便随时查找和复用。这能有效减少重复编写的工作，并帮助你沉淀和管理常用的查询逻辑。</span></p>
<p><span><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-c1f4490313.png"></span></p>
<p><span><strong>我们相信，这些改进将为你的日常数据工作带来切实的帮助。</strong></span></p>
<h2><span><span>📜 版本日志</span></span></h2>
<p><strong><span><strong><span>社区版</span></strong></span></strong></p>
<p><strong><span>新特性</span></strong></p>
<ul>
<li> <p><span>[/issues/3133] SQLE 支持 ODC SQL 工作台</span></p> </li>
</ul>
<p><strong><span>Bug 修复</span></strong></p>
<ul>
<li> <p><span>[/issues/3138] 分析页面未能获取 SQL 相关的表信息</span></p> </li>
</ul>
<p><span><strong><span><strong><strong><span>企业版</span></strong></strong></span></strong></span></p>
<p><strong><span>新特性</span></strong></p>
<ul>
<li> <p><span>[actiontech/sqle-ee/issues/2533] 新增 TopSQL 智能扫描</span></p> </li>
</ul>
<p><strong><span>Bug 修复</span></strong></p>
<ul>
<li> <p><span>[actiontech/dms-ee/issues/671] 通过 OAuth2 登录后，用户表上次登录时间未更新</span></p> </li>
</ul>
<h2><span><span>🧩 版本选择</span></span></h2>
<p><span><strong><span><span>社区版：</span></span></strong><span>轻量级 MySQL 开发治理工具，满足个人和小团队的基础 SQL 开发需求。</span></span></p>
<p><span><strong><span>专业版：</span></strong><span>多数据源开发治理平台，为中小团队提供更丰富的数据库变更管控能力。</span></span></p>
<p><span><strong><span>企业版：</span></strong><span>企业级数据资产合规平台，满足大型企业的数据安全与管控要求。</span></span></p>
<p><span><span>🤗 我们为&nbsp;</span></span><span><strong><span>社区版&nbsp;</span></strong></span><span><span>和&nbsp;</span></span><span><strong><span>企业版&nbsp;</span></strong></span><span><span>准备了在线体验环境，欢迎体验。</span></span></p>
<p><span><span>👉&nbsp;</span></span><strong><span><span>社区版：</span></span></strong><span><span>http://demo.sqle.actionsky.com/</span></span></p>
<p><span>👉&nbsp;</span><span><strong><span>企业版：</span></strong></span><span>http://demo.sqle.actionsky.com:8889/</span></p>
<p><span>🙋‍♂️</span><strong><span>&nbsp;用户名：</span></strong><span>admin</span></p>
<p><span><span>🔑&nbsp;</span></span><strong><span>密 &nbsp; 码：</span></strong><span><span>admin</span></span></p>
<p><span><span>👉&nbsp;</span></span><span><strong><span>专业版：</span></strong></span><span><span>调填写调研问卷（扫码或点击&nbsp;</span></span><strong><span>原文链接</span></strong><span><span>）获取安装包。</span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-22dae3ccc9.jpg"></p>
<p><strong><span>SQLE 4.2509.0</span></strong><span><span>&nbsp;专业版获取</span></span></p>
<p><strong><span><span>🔗&nbsp;</span></span><span>企业版获取：</span></strong><span><span>可通过海报下方的小程序进行商务咨询或预约演示。</span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-64da689ccd.png"></p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<h2><span><span><span>🎈 新功能</span></span></span></h2>
<p><strong><strong><span><strong><span><span>社区版</span></span></strong></span></strong></strong></p>
<p><span><strong><strong><strong><span><u>🚀</u></span><span><u>&nbsp;</u></span><span><u>SQL 工作台焕新升级，体验更丝滑！</u></span></strong></strong></strong></span></p>
<p><span><span>根据社区的长期反馈，我们关注到旧版&nbsp;</span><strong>SQL 工作台</strong><strong>&nbsp;</strong><span>在界面设计和功能支持上存在一些不足。为了改善使用体验，我们进行了一次有针对性的重要更新。</span></span></p>
<p><span><span>本次更新主要集中在两个方面：</span><strong>界面现代化&nbsp;</strong><span>和&nbsp;</span><strong>核心功能增强</strong><span>。</span></span></p>
<p><span><strong>1. 更现代化的工作界面</strong><span>&nbsp;</span></span></p>
<p><span><span>新的用户界面更符合当下的设计标准。</span></span></p>
<p><span><strong>布局更清晰</strong><span>：优化了整体布局，减少了视觉上的干扰，帮助你更快定位到所需功能。</span></span></p>
<p><span><strong>操作更顺畅</strong><span>：调整了交互流程，使得常用操作的路径更短，响应也更为流畅。</span></span></p>
<p><span><strong>2.&nbsp;</strong></span><span><strong>更强大的内置功能</strong></span></p>
<p><span><strong>集成工单状态追踪：</strong><span>对于从 SQL 工作台触发的审批工单，你现在可以直接在工作台内查看其进展状态。无需再切换页面，让 SQL 开发与审批流程的衔接更紧密。</span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-2c4c657563.png"></p>
<p><strong>SQL 脚本保存与复用：</strong><span>&nbsp;你可以将常用或复杂的 SQL 脚本保存在工作台中，方便随时查找和复用。这能有效减少重复编写的工作，并帮助你沉淀和管理常用的查询逻辑。</span></p>
<p><span><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-c1f4490313.png"></span></p>
<p><span><strong>我们相信，这些改进将为你的日常数据工作带来切实的帮助。</strong></span></p>
<h2><span><span>📜 版本日志</span></span></h2>
<p><strong><span><strong><span>社区版</span></strong></span></strong></p>
<p><strong><span>新特性</span></strong></p>
<ul>
<li> <p><span>[/issues/3133] SQLE 支持 ODC SQL 工作台</span></p> </li>
</ul>
<p><strong><span>Bug 修复</span></strong></p>
<ul>
<li> <p><span>[/issues/3138] 分析页面未能获取 SQL 相关的表信息</span></p> </li>
</ul>
<p><span><strong><span><strong><strong><span>企业版</span></strong></strong></span></strong></span></p>
<p><strong><span>新特性</span></strong></p>
<ul>
<li> <p><span>[actiontech/sqle-ee/issues/2533] 新增 TopSQL 智能扫描</span></p> </li>
</ul>
<p><strong><span>Bug 修复</span></strong></p>
<ul>
<li> <p><span>[actiontech/dms-ee/issues/671] 通过 OAuth2 登录后，用户表上次登录时间未更新</span></p> </li>
</ul>
<h2><span><span>🧩 版本选择</span></span></h2>
<p><span><strong><span><span>社区版：</span></span></strong><span>轻量级 MySQL 开发治理工具，满足个人和小团队的基础 SQL 开发需求。</span></span></p>
<p><span><strong><span>专业版：</span></strong><span>多数据源开发治理平台，为中小团队提供更丰富的数据库变更管控能力。</span></span></p>
<p><span><strong><span>企业版：</span></strong><span>企业级数据资产合规平台，满足大型企业的数据安全与管控要求。</span></span></p>
<p><span><span>🤗 我们为&nbsp;</span></span><span><strong><span>社区版&nbsp;</span></strong></span><span><span>和&nbsp;</span></span><span><strong><span>企业版&nbsp;</span></strong></span><span><span>准备了在线体验环境，欢迎体验。</span></span></p>
<p><span><span>👉&nbsp;</span></span><strong><span><span>社区版：</span></span></strong><span><span>http://demo.sqle.actionsky.com/</span></span></p>
<p><span>👉&nbsp;</span><span><strong><span>企业版：</span></strong></span><span>http://demo.sqle.actionsky.com:8889/</span></p>
<p><span>🙋‍♂️</span><strong><span>&nbsp;用户名：</span></strong><span>admin</span></p>
<p><span><span>🔑&nbsp;</span></span><strong><span>密 &nbsp; 码：</span></strong><span><span>admin</span></span></p>
<p><span><span>👉&nbsp;</span></span><span><strong><span>专业版：</span></strong></span><span><span>调填写调研问卷（扫码或点击&nbsp;</span></span><strong><span>原文链接</span></strong><span><span>）获取安装包。</span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-22dae3ccc9.jpg"></p>
<p><strong><span>SQLE 4.2509.0</span></strong><span><span>&nbsp;专业版获取</span></span></p>
<p><strong><span><span>🔗&nbsp;</span></span><span>企业版获取：</span></strong><span><span>可通过海报下方的小程序进行商务咨询或预约演示。</span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-64da689ccd.png"></p>]]>
    </description>
    <content:encoded><![CDATA[<h2><span><span><span>🎈 新功能</span></span></span></h2>
<p><strong><strong><span><strong><span><span>社区版</span></span></strong></span></strong></strong></p>
<p><span><strong><strong><strong><span><u>🚀</u></span><span><u>&nbsp;</u></span><span><u>SQL 工作台焕新升级，体验更丝滑！</u></span></strong></strong></strong></span></p>
<p><span><span>根据社区的长期反馈，我们关注到旧版&nbsp;</span><strong>SQL 工作台</strong><strong>&nbsp;</strong><span>在界面设计和功能支持上存在一些不足。为了改善使用体验，我们进行了一次有针对性的重要更新。</span></span></p>
<p><span><span>本次更新主要集中在两个方面：</span><strong>界面现代化&nbsp;</strong><span>和&nbsp;</span><strong>核心功能增强</strong><span>。</span></span></p>
<p><span><strong>1. 更现代化的工作界面</strong><span>&nbsp;</span></span></p>
<p><span><span>新的用户界面更符合当下的设计标准。</span></span></p>
<p><span><strong>布局更清晰</strong><span>：优化了整体布局，减少了视觉上的干扰，帮助你更快定位到所需功能。</span></span></p>
<p><span><strong>操作更顺畅</strong><span>：调整了交互流程，使得常用操作的路径更短，响应也更为流畅。</span></span></p>
<p><span><strong>2.&nbsp;</strong></span><span><strong>更强大的内置功能</strong></span></p>
<p><span><strong>集成工单状态追踪：</strong><span>对于从 SQL 工作台触发的审批工单，你现在可以直接在工作台内查看其进展状态。无需再切换页面，让 SQL 开发与审批流程的衔接更紧密。</span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-2c4c657563.png"></p>
<p><strong>SQL 脚本保存与复用：</strong><span>&nbsp;你可以将常用或复杂的 SQL 脚本保存在工作台中，方便随时查找和复用。这能有效减少重复编写的工作，并帮助你沉淀和管理常用的查询逻辑。</span></p>
<p><span><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-c1f4490313.png"></span></p>
<p><span><strong>我们相信，这些改进将为你的日常数据工作带来切实的帮助。</strong></span></p>
<h2><span><span>📜 版本日志</span></span></h2>
<p><strong><span><strong><span>社区版</span></strong></span></strong></p>
<p><strong><span>新特性</span></strong></p>
<ul>
<li> <p><span>[/issues/3133] SQLE 支持 ODC SQL 工作台</span></p> </li>
</ul>
<p><strong><span>Bug 修复</span></strong></p>
<ul>
<li> <p><span>[/issues/3138] 分析页面未能获取 SQL 相关的表信息</span></p> </li>
</ul>
<p><span><strong><span><strong><strong><span>企业版</span></strong></strong></span></strong></span></p>
<p><strong><span>新特性</span></strong></p>
<ul>
<li> <p><span>[actiontech/sqle-ee/issues/2533] 新增 TopSQL 智能扫描</span></p> </li>
</ul>
<p><strong><span>Bug 修复</span></strong></p>
<ul>
<li> <p><span>[actiontech/dms-ee/issues/671] 通过 OAuth2 登录后，用户表上次登录时间未更新</span></p> </li>
</ul>
<h2><span><span>🧩 版本选择</span></span></h2>
<p><span><strong><span><span>社区版：</span></span></strong><span>轻量级 MySQL 开发治理工具，满足个人和小团队的基础 SQL 开发需求。</span></span></p>
<p><span><strong><span>专业版：</span></strong><span>多数据源开发治理平台，为中小团队提供更丰富的数据库变更管控能力。</span></span></p>
<p><span><strong><span>企业版：</span></strong><span>企业级数据资产合规平台，满足大型企业的数据安全与管控要求。</span></span></p>
<p><span><span>🤗 我们为&nbsp;</span></span><span><strong><span>社区版&nbsp;</span></strong></span><span><span>和&nbsp;</span></span><span><strong><span>企业版&nbsp;</span></strong></span><span><span>准备了在线体验环境，欢迎体验。</span></span></p>
<p><span><span>👉&nbsp;</span></span><strong><span><span>社区版：</span></span></strong><span><span>http://demo.sqle.actionsky.com/</span></span></p>
<p><span>👉&nbsp;</span><span><strong><span>企业版：</span></strong></span><span>http://demo.sqle.actionsky.com:8889/</span></p>
<p><span>🙋‍♂️</span><strong><span>&nbsp;用户名：</span></strong><span>admin</span></p>
<p><span><span>🔑&nbsp;</span></span><strong><span>密 &nbsp; 码：</span></strong><span><span>admin</span></span></p>
<p><span><span>👉&nbsp;</span></span><span><strong><span>专业版：</span></strong></span><span><span>调填写调研问卷（扫码或点击&nbsp;</span></span><strong><span>原文链接</span></strong><span><span>）获取安装包。</span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-22dae3ccc9.jpg"></p>
<p><strong><span>SQLE 4.2509.0</span></strong><span><span>&nbsp;专业版获取</span></span></p>
<p><strong><span><span>🔗&nbsp;</span></span><span>企业版获取：</span></strong><span><span>可通过海报下方的小程序进行商务咨询或预约演示。</span></span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-64da689ccd.png"></p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-2c4c657563.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-2c4c657563.png" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 11:07:38 +0800</pubDate>
  </item><item>
    <title><![CDATA[宾夕法尼亚大学研究发现：对 AI 越“粗鲁”回答准确率越高]]></title>
    <link>https://www.oschina.net/news/377497</link>
    <itunes:title><![CDATA[宾夕法尼亚大学研究发现：对 AI 越“粗鲁”回答准确率越高]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>宾夕法尼亚州立大学<span>最新</span>发表的研究论文《Mind Your Tone》揭示了一个反常识的现象:在与大语言模型交互时，使用直白甚至粗鲁的语气，可能比礼貌用语获得更准确的答案。这项研究<span>首次</span>系统性地验证了提问语气对AI模型表现的实际影响。</p>
<p>研究团队构建了一个包含50道中等难度选择题的测试集，题目覆盖数学、科学和历史等多个领域。针对每道题目，研究人员设计了五种不同语气的提问方式，从"您能好心帮我解这道题吗"这样的客套表达，到"请回答这道题"的中性陈述，再到"直接给答案"的简洁指令，直至"你要是不笨就回答"和"你个没用的，会解这道题吗"等带有攻击性的表述。</p>
<p>测试对象为OpenAI<span>最新</span>的GPT-4o模型。为确保实验的独立性，研究人员要求模型忘记先前对话内容，仅输出选项字母作为答案。统计结果显示，使用粗鲁语气提问时，GPT-4o的正确率达到84.8%，而过分客气的提问方式反而使准确率降至80.8%，两者差距达到4个百分点。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-1095780092.png"></p>
<p>研究团队对这一现象的解释是，过度礼貌的表达往往包含大量客套话和修饰性语言，这些与核心问题无关的信息反而干扰了模型对关键内容的提取。相比之下，直接的命令式表达虽然缺乏礼貌，但能让模型更专注于问题本身，减少了信息处理过程中的噪音。</p>
<p>值得注意的是，这一规律并非对所有AI模型普遍适用。研究人员在GPT-3.5和Llama2-70B等较早期模型上进行的对比测试显示，这些模型对礼貌提问的响应效果更好，粗鲁语气反而会降低回答质量。研究者推测，新一代模型在训练阶段接触了更多样化的语气数据，使其具备了更强的无关信息过滤能力，因此能够在非礼貌语境下保持甚至提升表现。</p>
<p>尽管实验结果提供了有趣的技术洞察，但从实际应用角度看，用户在日常使用AI工具时仍需根据具体模型特性和场景需求来调整交互方式。这项研究更重要的意义在于提醒开发者和用户：提示词的设计不仅关乎礼貌与否，更关乎信息密度和指令清晰度。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>宾夕法尼亚州立大学<span>最新</span>发表的研究论文《Mind Your Tone》揭示了一个反常识的现象:在与大语言模型交互时，使用直白甚至粗鲁的语气，可能比礼貌用语获得更准确的答案。这项研究<span>首次</span>系统性地验证了提问语气对AI模型表现的实际影响。</p>
<p>研究团队构建了一个包含50道中等难度选择题的测试集，题目覆盖数学、科学和历史等多个领域。针对每道题目，研究人员设计了五种不同语气的提问方式，从"您能好心帮我解这道题吗"这样的客套表达，到"请回答这道题"的中性陈述，再到"直接给答案"的简洁指令，直至"你要是不笨就回答"和"你个没用的，会解这道题吗"等带有攻击性的表述。</p>
<p>测试对象为OpenAI<span>最新</span>的GPT-4o模型。为确保实验的独立性，研究人员要求模型忘记先前对话内容，仅输出选项字母作为答案。统计结果显示，使用粗鲁语气提问时，GPT-4o的正确率达到84.8%，而过分客气的提问方式反而使准确率降至80.8%，两者差距达到4个百分点。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-1095780092.png"></p>
<p>研究团队对这一现象的解释是，过度礼貌的表达往往包含大量客套话和修饰性语言，这些与核心问题无关的信息反而干扰了模型对关键内容的提取。相比之下，直接的命令式表达虽然缺乏礼貌，但能让模型更专注于问题本身，减少了信息处理过程中的噪音。</p>
<p>值得注意的是，这一规律并非对所有AI模型普遍适用。研究人员在GPT-3.5和Llama2-70B等较早期模型上进行的对比测试显示，这些模型对礼貌提问的响应效果更好，粗鲁语气反而会降低回答质量。研究者推测，新一代模型在训练阶段接触了更多样化的语气数据，使其具备了更强的无关信息过滤能力，因此能够在非礼貌语境下保持甚至提升表现。</p>
<p>尽管实验结果提供了有趣的技术洞察，但从实际应用角度看，用户在日常使用AI工具时仍需根据具体模型特性和场景需求来调整交互方式。这项研究更重要的意义在于提醒开发者和用户：提示词的设计不仅关乎礼貌与否，更关乎信息密度和指令清晰度。</p>]]>
    </description>
    <content:encoded><![CDATA[<p>宾夕法尼亚州立大学<span>最新</span>发表的研究论文《Mind Your Tone》揭示了一个反常识的现象:在与大语言模型交互时，使用直白甚至粗鲁的语气，可能比礼貌用语获得更准确的答案。这项研究<span>首次</span>系统性地验证了提问语气对AI模型表现的实际影响。</p>
<p>研究团队构建了一个包含50道中等难度选择题的测试集，题目覆盖数学、科学和历史等多个领域。针对每道题目，研究人员设计了五种不同语气的提问方式，从"您能好心帮我解这道题吗"这样的客套表达，到"请回答这道题"的中性陈述，再到"直接给答案"的简洁指令，直至"你要是不笨就回答"和"你个没用的，会解这道题吗"等带有攻击性的表述。</p>
<p>测试对象为OpenAI<span>最新</span>的GPT-4o模型。为确保实验的独立性，研究人员要求模型忘记先前对话内容，仅输出选项字母作为答案。统计结果显示，使用粗鲁语气提问时，GPT-4o的正确率达到84.8%，而过分客气的提问方式反而使准确率降至80.8%，两者差距达到4个百分点。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-1095780092.png"></p>
<p>研究团队对这一现象的解释是，过度礼貌的表达往往包含大量客套话和修饰性语言，这些与核心问题无关的信息反而干扰了模型对关键内容的提取。相比之下，直接的命令式表达虽然缺乏礼貌，但能让模型更专注于问题本身，减少了信息处理过程中的噪音。</p>
<p>值得注意的是，这一规律并非对所有AI模型普遍适用。研究人员在GPT-3.5和Llama2-70B等较早期模型上进行的对比测试显示，这些模型对礼貌提问的响应效果更好，粗鲁语气反而会降低回答质量。研究者推测，新一代模型在训练阶段接触了更多样化的语气数据，使其具备了更强的无关信息过滤能力，因此能够在非礼貌语境下保持甚至提升表现。</p>
<p>尽管实验结果提供了有趣的技术洞察，但从实际应用角度看，用户在日常使用AI工具时仍需根据具体模型特性和场景需求来调整交互方式。这项研究更重要的意义在于提醒开发者和用户：提示词的设计不仅关乎礼貌与否，更关乎信息密度和指令清晰度。</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-1095780092.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-1095780092.png" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 10:59:07 +0800</pubDate>
  </item><item>
    <title><![CDATA[百度 APP 日志处理框架升级之路]]></title>
    <link>https://my.oschina.net/u/4939618/blog/18695530</link>
    <itunes:title><![CDATA[百度 APP 日志处理框架升级之路]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<h1>导读</h1>
<p>面对百度APP日均数千亿PV、超百PB数据规模带来的巨大挑战，我们完成了数据仓库的系统性升级。本文详细阐述了通过"两步走"策略解决资源压力、处理延迟和架构瓶颈的全过程：第一阶段聚焦日志清洗环节的稳定性与成本优化，第二阶段实现实时离线链路解耦、核心数据隔离及计算框架容错能力提升。此次升级显著提升了数据处理时效性、系统稳定性和成本效益，为业务发展提供了更坚实的数据支撑。</p>
<h1>背景</h1>
<p>百度APP及其产品矩阵作为百度体量最大的C端业务线，在数据处理全链路面临规模与架构的双重挑战。日志清洗环节因日均几千亿PV、超百PB的庞大数据规模，导致计算资源持续承压、处理延迟频发，加之历史遗留的复杂日志格式，清洗稳定性与时效性逐步下降，存储成本高昂。与此同时上游日志数据仍存在实时与离线链路耦合、核心与边缘数据未有效隔离、计算框架容错能力不足等结构性问题，影响关键数据产出的稳定与时效。整体系统切换与优化面临高额的历史负担和技术重构成本，下游业务的数据可用性、决策及时性及深度运营分析均受到显著制约。</p>
<p>基于以上问题，我们制定了“两步走”的升级策略：第一阶段优先解决日志清洗环节的稳定性和存储成本问题；第二阶段在此基础上，重点推进数仓上层架构优化，包括实时与离线链路解耦、核心数据隔离处理以及计算框架容错能力提升，逐步实现整体数据仓库的高效、稳定与可持续升级。</p>
<h1>01 第一阶段：多日志源整合</h1>
<h2><strong>1. 2023年之前架构</strong></h2>
<p>在百度APP及其产品矩阵的数据体系建设过程中，日志清洗作为整个数据流水线的起始环节，其处理稳定性和产出时效性始终处于关键地位，是保障下游业务数据可用性与决策及时性的重中之重。然而，随着业务规模持续扩大和用户体量快速增长，每日产生的日志量急剧上升，由此带来的巨大计算压力使得整个清洗链路频繁面临资源瓶颈与处理延迟，稳定性和时效性均逐步下滑，难以满足下游各业务方对数据交付时间和质量的要求。与此同时，数据入口的分散催生了大量烟囱式的开发与冗余的计算逻辑，不仅推高了运维成本，更在源头形成了数据孤岛。下游基于此类数据构建的数仓架构必然复杂化，多表的 JOIN 与理解成本高昂，使得整个数据建设环节背负着日趋沉重的成本与协作压力。</p>
<h2><strong>2. 问题分析</strong></h2>
<h3>2.1 旧架构分析</h3>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-41f3e39809.jpg"></p>
<h4>2.1.1 <strong><strong>数据孤岛化加剧，认知与使用成本高昂</strong></strong></h4>
<p>现有架构对每类日志采用独立落表方式，导致数据存储呈现碎片化状态。这种设计造成同一业务实体的相关信息分散在不同表中，形成严重的数据割裂。下游用户在使用数据时，不得不通过多表关联才能获取完整信息，不仅大幅增加了技术实现难度，更带来了沉重的认知负担。用户需要理解多张表的结构和关联关系，极易产生理解偏差，进而影响数据分析的准确性和可靠性。</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-abbc8cbb5f.jpg"></p>
<h4>2.1.2 <strong><strong>关联查询性能瓶颈，制约数据价值释放</strong></strong></h4>
<p>与此同时，多表关联查询模式给系统带来了巨大的性能压力。随着数据量的持续增长，表连接操作的成本呈指数级上升，查询响应时间显著延长。特别是在需要跨多个表进行关联分析的场景下，系统往往需要耗费大量计算资源和时间，无法满足业务对高效数据分析和快速决策的需求，严重制约了数据价值的及时释放。</p>
<p>此外，原始日志结构中普遍存在的复杂嵌套格式（如多层JSON、数组结构等）大幅增加了数据清洗和解析的复杂度。大量业务自定义字段缺乏统一规范，导致解析逻辑冗余且低效，进一步降低了整体处理性能。这些因素共同加剧了数据处理的延迟与资源消耗，形成系统性瓶颈。</p>
<h4>2.1.3 <strong><strong>维护复杂度与脆弱性并存，系统稳定性堪忧</strong></strong></h4>
<p>独立的数据处理流水线，导致系统维护点分散。任何逻辑变更或schema调整都需要在多处同步实施，极大地增加了维护工作量。这种架构的脆弱性也显著提高了出错风险，单个任务修改的错误可能引发连锁反应，影响整个数据链路的稳定性。</p>
<p>特别需要指出的是，当前采用的UDW数仓及配套ETL框架仍是2012年上线的技术方案，已明显落后于业界主流水平。该框架存在诸多局限性：首先，其兼容性差，难以与现有开源生态工具链高效集成；其次，基于C++的MR计算框架稳定性不足，日常运行中容易出现各种异常；最后，开发调试效率低下，严重制约了数据需求的迭代速度。这些技术债务不仅增加了系统的维护复杂度，更成为制约数据平台发展的关键瓶颈。</p>
<h3>2.2 重构思路分析</h3>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-bc837c97b5.jpg"></p>
<p><strong>理想状态</strong>：从数据架构的理想设计来看，基于通用宽表数据建模方法论，采用“一步到位”的方式直接产出高度整合、面向主题的Turing宽表，是最为高效和优雅的解决方案。它能够减少中间冗余加工环节，提升数据一致性和复用度。</p>
<p><strong>升级成本</strong>：下游业务方因历史原因，数据应用架构高度依赖传统UDW模式的数据组织与服务方式，迁移至Turing宽表体系涉及大量脚本改造、逻辑核对与业务适配工作，技术切换和数据迁移成本极高，导致架构升级短期难以实施。</p>
<p><strong>思考</strong>：为实现数据架构的平滑升级，本次重构方案采用渐进式过渡策略，在着力解决现有架构核心痛点的同时，必须充分考虑百度业务数据链路长、历史包袱重的现实情况，审慎平衡技术先进性与落地可行性。方案设计严格遵循"平滑过渡、风险可控、成本最优"三大原则。</p>
<p>需要特别指出的是，由于现有数据体系深度嵌入各业务线的策略计算与离线分析环节，其紧密的耦合关系导致配套升级难度极大、周期长。这不仅涉及底层数据表的更替、依赖路径修改，更要求对依赖原有数据模型的下游业务进行协同改造和全面适配，沟通和推进难度极大。所以在保障业务连续性的前提下，如何有序推进全链路的升级切换是本次升级的重中之重。</p>
<p><strong><strong>建模思路：</strong></strong></p>
<p><strong><strong>（1）降低迁移成本</strong></strong></p>
<p>在数据中间层设计上，方案延续使用<strong><strong>刻钟级UDW</strong></strong>表作为缓冲层，通过将多个离散的UDW表整合为统一的宽表模型，进一步降低下游的使用和理解成本。同时，对表schema实施精细化改造，包括消除冗余字段、统一数据标准、优化存储格式，并重构字段逻辑以提升数据一致性。这种设计既保持了与现有下游系统的兼容性，又显著降低了数据使用复杂度。</p>
<p><strong><strong>（2）双轨输出机制</strong></strong></p>
<p>为确保迁移过程的平稳性，方案采用双轨输出机制：一方面继续提供优化后的UDW宽表，保障现有作业的无缝运行；另一方面通过聚合加工生成小时级Turing表，作为统一对外输出的日志宽表。这种渐进式迁移路径使下游用户可根据自身情况灵活选择切换时机，最大限度降低升级成本。</p>
<p><strong><strong>（3）兼顾历史和未来</strong></strong></p>
<p>此次架构优化为后续全面升级奠定了坚实基础。通过UDW层的预处理和Turing表的逐步推广，最终将实现架构的完全过渡，在提升系统性能的同时确保业务连续性，达成技术演进与业务稳定之间的最佳平衡。</p>
<h2><strong>3. 解决方案</strong></h2>
<p><strong><strong>过渡方案设计与实施：稳时效、降成本、提效率的综合治理</strong></strong></p>
<p>面对日志清洗环节日益严峻的稳定性、时效性及成本压力，我们制定并实施了一套详尽的过渡性解决方案。该方案并未激进地推行一步到位的Turing宽表迁移，而是立足于现有技术生态，以快速解决下游业务最迫切的痛点为目标，重点攻坚“产出时效不稳定”、“存储计算成本高”及“明细数据查询效率低下”三大核心问题。</p>
<h3>3.1 优化处理粒度与逻辑沉淀，保障时效与复用性</h3>
<p>为彻底扭转小时级任务积压与延迟的局面，我们首先对调度周期进行了粒度细化，将日志清洗任务从<strong><strong>小时级调度全面提升至刻钟级（15分钟）</strong></strong>。这一调整显著降低了单次任务的处理数据量和计算压力，使数据产出的延迟大幅减少，稳定性和时效性得到了根本保障。在技术选型上，我们并未盲目更换计算框架，而是继续沿用成熟稳定的<strong><strong>C++/MR框架</strong></strong>，确保了迁移过程的平稳性与可靠性。</p>
<p>同时，我们致力于提升数据的易用性与标准化程度。针对下游业务方需要反复从复杂JSON、Map等嵌套字段中解析提取关键信息的痛点，我们进行了大规模的<strong><strong>业务通用逻辑下沉</strong></strong>工作。将超过100个高频访问的埋点属性进行预解析、扁平化处理，转化为单独的标准化字段。这不仅极大减轻了下游的数据预处理负担，更直接提升了基于这些字段的<strong><strong>查询过滤与聚合分析效率</strong></strong>，为下游开发节省了大量时间。</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-3ad183e1e7.jpg"></p>
<h3>3.2 <strong><strong>兼顾历史依赖与未来演进，提供平滑迁移路径</strong></strong></h3>
<p>我们充分认识到下游业务对原有UDW数仓体系的强依赖性。为保障业务的连续性，我们并未强制要求所有方立即迁移，而是采取了<strong><strong>双轨并行</strong></strong>的支撑策略。在产出新一代数据模型的同时，我们<strong><strong>继续提供UDW中间表</strong></strong>，确保那些尚未准备好迁移至Turing宽表的业务方能够无缝对接，无需修改现有代码，极大降低了方案的落地门槛和风险。</p>
<h3>3.3 深度优化存储与查询，实现性能跨越式提升</h3>
<p>为进一步降低存储成本并提升Turing宽表的查询性能，我们对其存储结构进行了深度优化。</p>
<ul>
<li><strong><strong>合并小文件与高效压缩</strong></strong>：海量小文件是制约查询性能的首要元凶。我们通过按<strong><strong>设备ID、点位ID、时间戳</strong></strong>等关键字段进行精细排序，将数据写入为连续有序的大文件，从而将<strong><strong>单天高达800万个小文件合并至60万左右</strong></strong>，文件数量减少了近<strong><strong>93%</strong></strong>。在存储格式上，我们选用Parquet列式存储，并经过充分调研测试，采用了<strong><strong>ZSTD压缩算法</strong></strong>。ZSTD在压缩比、压缩/解压速度上取得了最佳平衡，且完美支持多线程，最终实现了每天<strong><strong>节省超过420TB</strong></strong>的巨大存储开销，成本效益极其显著。</li>
</ul>
<h2><strong>4. 新的问题&amp;解决策略</strong></h2>
<p>问题1：宽表数据量膨胀导致的查询性能下降</p>
<p>解决策略：为应对宽表数据量激增对查询性能带来的挑战，我们实施了体系化的查询加速方案，显著提升海量数据下的检索效率</p>
<ul>
<li> <p><strong><strong>强制分区限制策略</strong></strong>：在查询引擎层上线了强制要求限制分区条件的规则，避免了全表扫描带来的巨额元数据开销，大幅提升元数据检索效率。</p> </li>
<li> <p><strong><strong>查询结果缓存</strong></strong>：对常见的热点查询结果进行缓存，对于重复性查询实现了秒级响应。</p> </li>
<li> <p><strong><strong>智能资源调度</strong></strong>：根据查询的计算复杂度，系统自动将其调度到不同配置的资源池中执行，简单查询快速返回，复杂查询获得充足资源，实现了集群资源的高效利用。</p> </li>
</ul>
<p>问题2：分区数量增多导致点位所在的分区变得困难</p>
<p>解决策略：针对分区维度增加后，数据定位难度加大的问题，我们通过元数据管理与平台化集成提供解决方案：</p>
<ul>
<li> <p>新建分区元数据集，以天为粒度预先计算并存储所有点位与分区的映射关系，形成高效的点位分区定位查询，为点位所在分区快速检索提供基础支撑。</p> </li>
<li> <p>与现有点位管理平台深度集成，在其点位查询界面新增【查一查】功能。用户可通过界面化操作直接获取精准的数据分区信息及查询SQL模板，极大提升了用户使用的效率，降低了用户使用成本。</p> </li>
</ul>
<h1>02 第二阶段：全面提速</h1>
<h2><strong>1. 2023→2024年架构</strong></h2>
<p>随着业务发展，该数仓已完成由UDW（统一数据工作台）向Turing（新数据工作台）的改造，并初步建立起体系化的数据模型与分层数据集，显著提升了数据复用性和分析效率。基于这些宽表与数据集，大部分常规分析场景已能够快速响应。然而，在数据加工的最上游，即明细数据宽表的生产环节之前依旧包含缓冲的刻钟级udw表，因此仍存在若干架构性瓶颈。首先，实时数据处理链路与离线批处理链路相互耦合，资源竞争与依赖关系复杂，影响了整体任务的稳定性和时效性；其次，核心业务指标与非核心附属数据未被有效拆分处理，导致关键数据产出易受边缘数据波动或延迟的干扰；此外，当前的计算框架对于数据迟到、重复、异常值等复杂情况的处理灵活度不足，容错与自适应能力有待加强。</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-14db3809be.jpg"></p>
<p>为彻底解决这些问题，进一步提升数据产出的时效性、准确性和稳定性，以更好地赋能百度APP及其产品矩阵及各下游业务的数据分析与决策，亟需结合各数据点位的实际使用情况和业务优先级，对最上游的日志ETL（抽取、转换、加载）处理流程进行系统性的优化与重构。</p>
<h2><strong>2. 问题分析</strong></h2>
<p>当前数据ETL处理流程面临以下几个核心挑战，这些问题不仅影响数据产出的效率与稳定性，也为下游业务数据的准确性和及时性带来风险。</p>
<h3>2.1 开发框架灵活性不足，资源协调与弹性扩展能力受限</h3>
<p>目前的ETL任务仍沿用原有UDW大表处理框架，通过单机Hadoop Client提交任务，并依赖QE（底层为mapreduce引擎）进行计算。该框架在资源调度和权限管理方面已逐渐暴露出瓶颈。同时udw是2012年提出的数仓建设方案，随着开源计算、存储技术的发展，udw性能逐步落后业界，部分功能不具备继续升级迭代可行性。一旦出现上游数据延迟、队列资源拥塞或系统异常，容易导致任务大规模积压。由于缺乏跨队列或跨资源的调度容灾能力，无法协调其他计算资源执行任务回溯与补偿，最终将直接影响整体数据产出时效，甚至波及下游多条业务线的核心数据应用。</p>
<h3>2.2 核心与非核心数据处理耦合，异常影响范围扩散</h3>
<p>在日志清洗ETL环节中，核心业务数据点位与非核心业务数据点位、以及实时与离线数据流目前尚未进行有效拆分处理。这种架构层面的耦合导致一旦上游数据源或计算过程中发生异常，其影响面会迅速扩大，不仅关键业务指标受到冲击，非核心业务数据的问题也可能反向干扰核心链路的稳定性。缺乏业务优先级识别和隔离机制，降低了计算链路的整体容错能力和故障隔离水平。</p>
<h3>2.3 计算链路冗长复杂，维护困难且稳定性面临挑战</h3>
<p>当前处理流程中包含UDW中间缓冲层，导致计算环节增多、链路层级深化。较长的依赖链不仅增加了数据产出的端到端延迟，也显著提高了运维监控和故障定位的复杂度。任何环节出现性能波动或失败都易引起连锁反应，威胁整体任务的稳定性和时效性，同时也带来较高的人力维护成本。</p>
<h3>2.4 实时与离线数据源不一致，存在冗余计算与口径偏差</h3>
<p>百度APP及其产品矩阵业务当前使用的实时计算链路和离线数据链路在核心指标上并未实现数据源统一，两条链路独立处理且并行存在。这导致相同指标需要在不同流程中重复计算，既造成资源浪费，也增加了数据口径对齐的难度。长期来看，此类架构问题会直接影响关键指标的一致性和可信度，对业务决策准确性构成潜在风险。</p>
<h3>2.5 存储无序增长，数据冗余和存储成本与日俱增</h3>
<p>随着业务规模的持续扩张和流量快速增长，支撑核心业务的明细数据宽表总量已达到百PB级别，存储与计算成本压力日益凸显。然而，不同业务域对数据的保留周期和使用频率存在显著差异，全部数据长期存储既不经济也无必要。</p>
<h2><strong>3. 解决方案</strong></h2>
<h3>3.1 ETL框架升级</h3>
<p>在完成由多张udw表到Turing表的优化工作完成后，数据处理的时效性与稳定性虽然取得了一定改善，但仍存在进一步提升的空间。具体而言，原有的C++ MR计算框架在任务运行过程中逐渐暴露出两类典型问题：一是容易发生计算长尾现象，个别任务实例处理缓慢，拖慢整个作业完成进度；二是基于单机调度的模式存在可靠性瓶颈，整体资源协调和任务容错能力有限。这些问题导致数据产出的延迟风险依然较高，难以完全满足业务对数据时效日益提升的要求。</p>
<p>为解决上述痛点，经过充分的技术调研与架构评估，我们决定将计算框架升级为TM+Spark的组合方案。其中，TM（Task Manager）作为厂内自研的高性能流式处理框架，在多个关键维度上显著优于原有的C++ MR架构。</p>
<p>TM（Task Manager）：更高的容错性和更强的稳定性</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-29892c55bf.jpg"></p>
<p>首先，在容错性方面，TM具备更为智能和敏捷的错误恢复机制。当某个计算实例发生故障或执行缓慢时，TM调度系统能够迅速感知并主动发起抢占操作，将当前Task动态迁移至新的实例继续处理，从而有效避免传统MR框架中由于个别长尾任务导致的整体作业延迟。这一机制极大提升了作业的稳健性和执行效率。</p>
<p>其次，在调度稳定性方面，TM基于Opera调度系统进行资源管理与任务分配，这一调度架构具有高度解耦和资源隔离的特点。每个任务实例独立运行，互不干扰，有效避免了在MR模式下由于同一队列中其他高负载或异常作业所带来的负面冲击，从而保障关键数据处理任务的稳定性和可预期性。</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-19d7ad2f0d.jpg"></p>
<p>此外，TM框架也在输出存储效率方面做出了重要升级。它原生支持输出Parquet列式存储格式，并集成ZSTD压缩算法，在减少存储空间占用的同时大幅提升了后续查询操作的I/O效率。这一改进使得数据在写入阶段就具备更优的列组织结构和压缩特性，为下游分析提供了高性能的数据基础。</p>
<p><strong><strong>主流开源框架Flink和TM的对比如下：</strong></strong></p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-b9aca2ae4f.png"></p>
<p><strong><strong>Spark：通过构建DAG，计算更高效；利用RDD或者DataFrame减少IO耗时；多线程机制，执行速度更快。</strong></strong></p>
<p><strong><strong>Spark对比MR的核心优势：</strong></strong></p>
<ul>
<li> <p>速度：基于内存计算，无需反复做读写操作，更加高效</p> </li>
<li> <p>高度集成：spark丰富的API和高级抽象的函数可以轻松实现复杂的逻辑计算和处理，无需和MR一般需要编写复杂的处理逻辑</p> </li>
<li> <p>计算模型：内置的RDD数据结构可以提高数据计算的容错性；查询优化和执行优化可以适应复杂数据的处理和查询</p> </li>
</ul>
<p>结合Spark通用计算引擎强大的分布式内存计算能力和丰富的生态组件，新框架不仅解决了之前C++ MR模式中的长尾与调度瓶颈，还进一步实现了处理链路的统一与优化。Spark的高扩展性和TM的流式稳健性相结合，共同构建出一个容错能力强、资源利用高效、运维负担低的新一代数据处理架构，为业务提供更低延迟、更高可靠性的数据服务。</p>
<h3>3.2 日志分类分级</h3>
<h4>3.2.1 埋点<strong><strong>上线不规范，被动兼容推高处理成本</strong></strong></h4>
<p>在当前百度APP及其产品矩阵业务高速发展的背景下，日均处理日志量已达3000亿PV的庞大规模，数据流的稳定、高效与成本可控变得至关重要。</p>
<p>原有的埋点分类和校验存在两个突出的问题：</p>
<ul>
<li> <p><strong>上报不规范</strong>：存在大量不经过日志中台统一校验而直接上线的业务打点，这些“非规范”打点格式各异、质量参差不齐，极易引发解析异常。</p> </li>
<li> <p><strong>处理成本高</strong>：下游的日志清洗ETL环节被迫陷入“被动兼容”的循环中，需要频繁地跟进制订适配规则以解析这些非标数据，不仅带来了极高的运维成本，更因计算资源的无效消耗而加剧了整体处理链路的负担，严重制约了数据产出的时效性与稳定性。</p> </li>
</ul>
<h4>3.2.2 <strong><strong>通过协同治理实现日志中台全流量覆盖</strong></strong></h4>
<p>为从根本上破解这一难题，我们基于对百度APP及其产品矩阵数据全链路的深入洞察，发起了一项跨体系的协同治理工程。联合了日志中台团队、各业务研发团队、QA质量保障团队及PMO项目管理团队，形成了强有力的专项工作组。</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-fdbd5629b9.jpg"></p>
<p>第一阶段的核心任务是对所有日志模块进行全域梳理。我们共同制定了统一的《新增业务模块接入日志中台规范》<strong><strong>与</strong></strong>《日志埋点规范》<strong><strong>，明确了从数据采集、上报到校验的完整标准流程，并强力推动百度APP及其产品矩阵（包括主客户端及相关创新业务）的全量需求空间、代码仓库及日志模块，完成向日志中台的标准化接入迁移。这一举措将日志中台的流量覆盖能力从治理前的约</strong></strong>80%<strong><strong>一举提升至</strong></strong>100%****，实现了<strong>全流量管控。</strong></p>
<p>更重要的是，我们在日志中台增强了多项主动校验能力：包括日志长度校验、关键公共参数完整性校验、以及精确到需求ID的粒度校验。这使得任何不合规的打点企图在测试和上线阶段就能被即时发现和拦截，实现了“问题早发现、早解决”的闭环管理，从而构筑起覆盖全场景的打点需求上线质量保障体系，从源头上杜绝了异常日志的产生。</p>
<h4>3.2.3 <strong><strong>打破“只上不下”僵局，建立埋点生命周期管理</strong></strong></h4>
<p>在成功建立起“入口”管控机制后，我们将治理重心转向对历史存量埋点的“出口”梳理与优化。长期以来，由于缺乏有效的评估手段，点位数据存在着“只增不减”的痼疾，大量废弃或无效点位持续消耗着巨额的计算和存储资源。为此，我们创新性地从鉴权信息入手，通过对十几类不同下游使用场景（包括内部报表、算法模型、RDC数据转发服务等）的全面调研与信息收集，并对相关日志解析链路进行深度分析，首次精准地绘制出以百度APP及其产品矩阵全量15000多个点位为起点的、覆盖所有下游应用场景的“点位全链路使用地图”。</p>
<p>基于这张价值地图，我们清晰地识别出超过10000个点位已无任何下游业务使用或价值极低。通过严格的评估与协作流程，我们果断对这些埋点进行了下线处理，下线比例高达存量点位的71%。此次大规模治理行动，不仅直接释放了海量的计算和存储资源，有效缓解了系统瓶颈，更打破了长达多年的“埋点只上不敢下”的历史僵局，建立了点位的全生命周期管理模式，为后续数据的精细化管理与成本优化奠定了坚实基础。</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-083cf2a3a5.jpg"></p>
<h3>3.3 AB实验数据扇出处理</h3>
<h4>3.3.1 现状与问题</h4>
<p>在数据驱动的业务迭代中，A/B实验平台的指标建设和效果评估能力至关重要。然而，随着业务快速扩张和实验复杂度的提升，原有的实验数仓架构逐渐显露出严重瓶颈。平台最初是在通用数仓分层模型的基础上，采用“每个指标单独计算”的模式进行建设。这种设计在初期虽然灵活，但随着实验数量和指标数量的急剧增长，计算链路变得异常复杂、冗余且难以维护。由于缺少与公司数据中台团队的深度协同和标准化约束，每次新增实验指标都需要大量重复开发，导致实验数据需求的交付周期不断延长，严重拖慢了业务迭代速度，引发了业务团队的负反馈。</p>
<h4>3.3.2 解决方案</h4>
<p><strong><strong>（1）分析过程</strong></strong></p>
<p>理想的解决方案是直接复用百度APP及其产品矩阵已有的标准化大宽表进行实验指标配置。即基于一张集成所有关键维度与指标的大宽表，快速定义和产出实验分析所需的数据集。然而，现实情况却更为复杂：百度APP及其产品矩阵客户端同时线上进行的实验数量极多，平均每个cuid（用户唯一标识）对应的实验ID（sid）字符长度已超过2400字符。这个长度几乎相当于单条日志原始存储容量的40%，如果直接将实验ID维度接入宽表，将导致每条日志存储膨胀近一倍。这不仅会带来极高的存储成本，也会大幅增加下游所有数据应用的数据扫描量和传输开销，严重拖慢查询性能，进而影响整个数据链路的效率。</p>
<p><strong><strong>（2）设计思路</strong></strong></p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-413cd36ad9.jpg"></p>
<p>面对这一独特挑战，我们并未选择传统的宽表集成方案，而是从数据生成的源头实施了更根本的架构优化。我们重点对实验ID映射关系进行了拆分和重构：<strong><strong>将sid与核心行为数据解耦，设计并建设了独立的sid维表</strong></strong>。该维表直接从日志源头统一生成，整合了来自客户端的实验曝光及分组信息，并实现了对业务方、评估方各自独立建设的多套映射关系的全面统一。这一举措不仅从本质上避免了主宽表的存储膨胀，还彻底解决了因数据来源不一致而导致的实验效果评估diff问题，显著提高了实验数据的准确性和可信度。</p>
<p><strong><strong>（3）成果与收益</strong></strong></p>
<p>在此基础上，A/B实验平台的分析查询不再依赖于对超大宽表的直接扫描，而是通过<strong><strong>sid维表与核心行为宽表进行动态拼接</strong></strong>的方式实现指标计算。</p>
<p>在指标口径对齐方面，已完成实验类指标与OKR指标的口径统一工作，累计对齐上线指标2000余个，覆盖多个主题和维度。实验指标改由数据中心宽表统一生产，显著减少了以往在指标口径沟通与对齐方面的成本；在实验效率提升显著，指标开发环节通过复用宽表及数仓下沉逻辑，并升级计算框架，使常规需求开发周期从原先2周以上缩短至1周内，开发效率提升超50%。同时核心指标计算SLA由T+14小时提升至T+10小时，处理时效明显提高；在计算资源成本方面，通过整体数据流复用和抽样日志整合优化，实现了计算资源成本的有效降低。另外，联动产品及策略团队治理并下线无效实验指标超1800+，释放的资源进一步支撑了新场景的指标建设需求。</p>
<h2><strong>4. 分级存储治理</strong></h2>
<p>随着业务规模的持续扩张与产品矩阵的不断丰富，百度APP及其产品矩阵业务的日志数据量呈现指数级增长，单张核心Turing数据表的存储量已达到百PB级别，面临巨大的存储与成本压力。传统的统一存储周期策略难以适应当前复杂的使用场景：一方面，大量短期数据被无效保留，占用巨额存储资源；另一方面，部分核心业务场景仍需依赖长周期历史数据进行跨年指标对比、关键数据需求回溯与深度建模分析。</p>
<p>为解决这一矛盾，我们针对Turing表启动了多维度的精细化存储治理工作。通过深入分析业务使用特征与数据访问频率，我们建立了差异化的数据生命周期管理机制，实施**“热-&gt;温-&gt;冷”**三级数据分层存储策略。对高频访问的近期数据全部保留，对访问频率较低的长期历史数据自动进行转储、压缩或者裁剪等，并配套建立完备的数据取回与回溯流程。</p>
<p>该项治理在充分保障核心业务长周期数据使用需求的前提下，显著压缩了整体存储规模，实现了存储成本的大幅优化，为未来数据的可持续增长与高效管理奠定了坚实基础。</p>
<p>具体实施策略：</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-9c87a2818c.png"></p>
<h1>03 总结与展望</h1>
<p>随着业务规模的持续扩张和产品矩阵的不断丰富，数据量呈现指数级增长，这一趋势持续驱动着数据处理架构与模型的演进与迭代，同时也对数据分析的敏捷性、易用性和可靠性提出了更高要求。在数仓系统全面升级的过程中，我们着力优化数据处理全链路，通过改进调度机制、减少计算环节、强化故障自动恢复能力，显著缩短了整个数据处理流程的时长，有效识别并排除多项潜在稳定性风险。此外，依托于对全端埋点体系的系统化梳理与标准化规范，构建了高质量、可复用的数据资产底座。</p>
<p>本次整体架构的升级为业务提供了坚实的数据支撑，在数据时效性、准确性和使用便捷性方面均实现显著提升。作为百度体系内最核心且数据规模最大的业务板块，百度APP仍面临数据持续激增带来的诸多挑战，包括埋点规范统一难度高、技术栈兼容与选型约束多、日志解析复杂度高、存储结构灵活多变以及成本控制压力增大等问题。</p>
<p>面向未来，我们将持续推进数仓架构的深度优化，重点围绕埋点治理、架构升级、效能提升、存储模型优化和资源精细化管理等方面展开工作。目标是构建一套具备更高时效性、更优数据模型、更低存储与计算成本的全新一代数仓链路，为业务创新与决策提供高效、可靠、低成本的数据服务能力。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<h1>导读</h1>
<p>面对百度APP日均数千亿PV、超百PB数据规模带来的巨大挑战，我们完成了数据仓库的系统性升级。本文详细阐述了通过"两步走"策略解决资源压力、处理延迟和架构瓶颈的全过程：第一阶段聚焦日志清洗环节的稳定性与成本优化，第二阶段实现实时离线链路解耦、核心数据隔离及计算框架容错能力提升。此次升级显著提升了数据处理时效性、系统稳定性和成本效益，为业务发展提供了更坚实的数据支撑。</p>
<h1>背景</h1>
<p>百度APP及其产品矩阵作为百度体量最大的C端业务线，在数据处理全链路面临规模与架构的双重挑战。日志清洗环节因日均几千亿PV、超百PB的庞大数据规模，导致计算资源持续承压、处理延迟频发，加之历史遗留的复杂日志格式，清洗稳定性与时效性逐步下降，存储成本高昂。与此同时上游日志数据仍存在实时与离线链路耦合、核心与边缘数据未有效隔离、计算框架容错能力不足等结构性问题，影响关键数据产出的稳定与时效。整体系统切换与优化面临高额的历史负担和技术重构成本，下游业务的数据可用性、决策及时性及深度运营分析均受到显著制约。</p>
<p>基于以上问题，我们制定了“两步走”的升级策略：第一阶段优先解决日志清洗环节的稳定性和存储成本问题；第二阶段在此基础上，重点推进数仓上层架构优化，包括实时与离线链路解耦、核心数据隔离处理以及计算框架容错能力提升，逐步实现整体数据仓库的高效、稳定与可持续升级。</p>
<h1>01 第一阶段：多日志源整合</h1>
<h2><strong>1. 2023年之前架构</strong></h2>
<p>在百度APP及其产品矩阵的数据体系建设过程中，日志清洗作为整个数据流水线的起始环节，其处理稳定性和产出时效性始终处于关键地位，是保障下游业务数据可用性与决策及时性的重中之重。然而，随着业务规模持续扩大和用户体量快速增长，每日产生的日志量急剧上升，由此带来的巨大计算压力使得整个清洗链路频繁面临资源瓶颈与处理延迟，稳定性和时效性均逐步下滑，难以满足下游各业务方对数据交付时间和质量的要求。与此同时，数据入口的分散催生了大量烟囱式的开发与冗余的计算逻辑，不仅推高了运维成本，更在源头形成了数据孤岛。下游基于此类数据构建的数仓架构必然复杂化，多表的 JOIN 与理解成本高昂，使得整个数据建设环节背负着日趋沉重的成本与协作压力。</p>
<h2><strong>2. 问题分析</strong></h2>
<h3>2.1 旧架构分析</h3>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-41f3e39809.jpg"></p>
<h4>2.1.1 <strong><strong>数据孤岛化加剧，认知与使用成本高昂</strong></strong></h4>
<p>现有架构对每类日志采用独立落表方式，导致数据存储呈现碎片化状态。这种设计造成同一业务实体的相关信息分散在不同表中，形成严重的数据割裂。下游用户在使用数据时，不得不通过多表关联才能获取完整信息，不仅大幅增加了技术实现难度，更带来了沉重的认知负担。用户需要理解多张表的结构和关联关系，极易产生理解偏差，进而影响数据分析的准确性和可靠性。</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-abbc8cbb5f.jpg"></p>
<h4>2.1.2 <strong><strong>关联查询性能瓶颈，制约数据价值释放</strong></strong></h4>
<p>与此同时，多表关联查询模式给系统带来了巨大的性能压力。随着数据量的持续增长，表连接操作的成本呈指数级上升，查询响应时间显著延长。特别是在需要跨多个表进行关联分析的场景下，系统往往需要耗费大量计算资源和时间，无法满足业务对高效数据分析和快速决策的需求，严重制约了数据价值的及时释放。</p>
<p>此外，原始日志结构中普遍存在的复杂嵌套格式（如多层JSON、数组结构等）大幅增加了数据清洗和解析的复杂度。大量业务自定义字段缺乏统一规范，导致解析逻辑冗余且低效，进一步降低了整体处理性能。这些因素共同加剧了数据处理的延迟与资源消耗，形成系统性瓶颈。</p>
<h4>2.1.3 <strong><strong>维护复杂度与脆弱性并存，系统稳定性堪忧</strong></strong></h4>
<p>独立的数据处理流水线，导致系统维护点分散。任何逻辑变更或schema调整都需要在多处同步实施，极大地增加了维护工作量。这种架构的脆弱性也显著提高了出错风险，单个任务修改的错误可能引发连锁反应，影响整个数据链路的稳定性。</p>
<p>特别需要指出的是，当前采用的UDW数仓及配套ETL框架仍是2012年上线的技术方案，已明显落后于业界主流水平。该框架存在诸多局限性：首先，其兼容性差，难以与现有开源生态工具链高效集成；其次，基于C++的MR计算框架稳定性不足，日常运行中容易出现各种异常；最后，开发调试效率低下，严重制约了数据需求的迭代速度。这些技术债务不仅增加了系统的维护复杂度，更成为制约数据平台发展的关键瓶颈。</p>
<h3>2.2 重构思路分析</h3>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-bc837c97b5.jpg"></p>
<p><strong>理想状态</strong>：从数据架构的理想设计来看，基于通用宽表数据建模方法论，采用“一步到位”的方式直接产出高度整合、面向主题的Turing宽表，是最为高效和优雅的解决方案。它能够减少中间冗余加工环节，提升数据一致性和复用度。</p>
<p><strong>升级成本</strong>：下游业务方因历史原因，数据应用架构高度依赖传统UDW模式的数据组织与服务方式，迁移至Turing宽表体系涉及大量脚本改造、逻辑核对与业务适配工作，技术切换和数据迁移成本极高，导致架构升级短期难以实施。</p>
<p><strong>思考</strong>：为实现数据架构的平滑升级，本次重构方案采用渐进式过渡策略，在着力解决现有架构核心痛点的同时，必须充分考虑百度业务数据链路长、历史包袱重的现实情况，审慎平衡技术先进性与落地可行性。方案设计严格遵循"平滑过渡、风险可控、成本最优"三大原则。</p>
<p>需要特别指出的是，由于现有数据体系深度嵌入各业务线的策略计算与离线分析环节，其紧密的耦合关系导致配套升级难度极大、周期长。这不仅涉及底层数据表的更替、依赖路径修改，更要求对依赖原有数据模型的下游业务进行协同改造和全面适配，沟通和推进难度极大。所以在保障业务连续性的前提下，如何有序推进全链路的升级切换是本次升级的重中之重。</p>
<p><strong><strong>建模思路：</strong></strong></p>
<p><strong><strong>（1）降低迁移成本</strong></strong></p>
<p>在数据中间层设计上，方案延续使用<strong><strong>刻钟级UDW</strong></strong>表作为缓冲层，通过将多个离散的UDW表整合为统一的宽表模型，进一步降低下游的使用和理解成本。同时，对表schema实施精细化改造，包括消除冗余字段、统一数据标准、优化存储格式，并重构字段逻辑以提升数据一致性。这种设计既保持了与现有下游系统的兼容性，又显著降低了数据使用复杂度。</p>
<p><strong><strong>（2）双轨输出机制</strong></strong></p>
<p>为确保迁移过程的平稳性，方案采用双轨输出机制：一方面继续提供优化后的UDW宽表，保障现有作业的无缝运行；另一方面通过聚合加工生成小时级Turing表，作为统一对外输出的日志宽表。这种渐进式迁移路径使下游用户可根据自身情况灵活选择切换时机，最大限度降低升级成本。</p>
<p><strong><strong>（3）兼顾历史和未来</strong></strong></p>
<p>此次架构优化为后续全面升级奠定了坚实基础。通过UDW层的预处理和Turing表的逐步推广，最终将实现架构的完全过渡，在提升系统性能的同时确保业务连续性，达成技术演进与业务稳定之间的最佳平衡。</p>
<h2><strong>3. 解决方案</strong></h2>
<p><strong><strong>过渡方案设计与实施：稳时效、降成本、提效率的综合治理</strong></strong></p>
<p>面对日志清洗环节日益严峻的稳定性、时效性及成本压力，我们制定并实施了一套详尽的过渡性解决方案。该方案并未激进地推行一步到位的Turing宽表迁移，而是立足于现有技术生态，以快速解决下游业务最迫切的痛点为目标，重点攻坚“产出时效不稳定”、“存储计算成本高”及“明细数据查询效率低下”三大核心问题。</p>
<h3>3.1 优化处理粒度与逻辑沉淀，保障时效与复用性</h3>
<p>为彻底扭转小时级任务积压与延迟的局面，我们首先对调度周期进行了粒度细化，将日志清洗任务从<strong><strong>小时级调度全面提升至刻钟级（15分钟）</strong></strong>。这一调整显著降低了单次任务的处理数据量和计算压力，使数据产出的延迟大幅减少，稳定性和时效性得到了根本保障。在技术选型上，我们并未盲目更换计算框架，而是继续沿用成熟稳定的<strong><strong>C++/MR框架</strong></strong>，确保了迁移过程的平稳性与可靠性。</p>
<p>同时，我们致力于提升数据的易用性与标准化程度。针对下游业务方需要反复从复杂JSON、Map等嵌套字段中解析提取关键信息的痛点，我们进行了大规模的<strong><strong>业务通用逻辑下沉</strong></strong>工作。将超过100个高频访问的埋点属性进行预解析、扁平化处理，转化为单独的标准化字段。这不仅极大减轻了下游的数据预处理负担，更直接提升了基于这些字段的<strong><strong>查询过滤与聚合分析效率</strong></strong>，为下游开发节省了大量时间。</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-3ad183e1e7.jpg"></p>
<h3>3.2 <strong><strong>兼顾历史依赖与未来演进，提供平滑迁移路径</strong></strong></h3>
<p>我们充分认识到下游业务对原有UDW数仓体系的强依赖性。为保障业务的连续性，我们并未强制要求所有方立即迁移，而是采取了<strong><strong>双轨并行</strong></strong>的支撑策略。在产出新一代数据模型的同时，我们<strong><strong>继续提供UDW中间表</strong></strong>，确保那些尚未准备好迁移至Turing宽表的业务方能够无缝对接，无需修改现有代码，极大降低了方案的落地门槛和风险。</p>
<h3>3.3 深度优化存储与查询，实现性能跨越式提升</h3>
<p>为进一步降低存储成本并提升Turing宽表的查询性能，我们对其存储结构进行了深度优化。</p>
<ul>
<li><strong><strong>合并小文件与高效压缩</strong></strong>：海量小文件是制约查询性能的首要元凶。我们通过按<strong><strong>设备ID、点位ID、时间戳</strong></strong>等关键字段进行精细排序，将数据写入为连续有序的大文件，从而将<strong><strong>单天高达800万个小文件合并至60万左右</strong></strong>，文件数量减少了近<strong><strong>93%</strong></strong>。在存储格式上，我们选用Parquet列式存储，并经过充分调研测试，采用了<strong><strong>ZSTD压缩算法</strong></strong>。ZSTD在压缩比、压缩/解压速度上取得了最佳平衡，且完美支持多线程，最终实现了每天<strong><strong>节省超过420TB</strong></strong>的巨大存储开销，成本效益极其显著。</li>
</ul>
<h2><strong>4. 新的问题&amp;解决策略</strong></h2>
<p>问题1：宽表数据量膨胀导致的查询性能下降</p>
<p>解决策略：为应对宽表数据量激增对查询性能带来的挑战，我们实施了体系化的查询加速方案，显著提升海量数据下的检索效率</p>
<ul>
<li> <p><strong><strong>强制分区限制策略</strong></strong>：在查询引擎层上线了强制要求限制分区条件的规则，避免了全表扫描带来的巨额元数据开销，大幅提升元数据检索效率。</p> </li>
<li> <p><strong><strong>查询结果缓存</strong></strong>：对常见的热点查询结果进行缓存，对于重复性查询实现了秒级响应。</p> </li>
<li> <p><strong><strong>智能资源调度</strong></strong>：根据查询的计算复杂度，系统自动将其调度到不同配置的资源池中执行，简单查询快速返回，复杂查询获得充足资源，实现了集群资源的高效利用。</p> </li>
</ul>
<p>问题2：分区数量增多导致点位所在的分区变得困难</p>
<p>解决策略：针对分区维度增加后，数据定位难度加大的问题，我们通过元数据管理与平台化集成提供解决方案：</p>
<ul>
<li> <p>新建分区元数据集，以天为粒度预先计算并存储所有点位与分区的映射关系，形成高效的点位分区定位查询，为点位所在分区快速检索提供基础支撑。</p> </li>
<li> <p>与现有点位管理平台深度集成，在其点位查询界面新增【查一查】功能。用户可通过界面化操作直接获取精准的数据分区信息及查询SQL模板，极大提升了用户使用的效率，降低了用户使用成本。</p> </li>
</ul>
<h1>02 第二阶段：全面提速</h1>
<h2><strong>1. 2023→2024年架构</strong></h2>
<p>随着业务发展，该数仓已完成由UDW（统一数据工作台）向Turing（新数据工作台）的改造，并初步建立起体系化的数据模型与分层数据集，显著提升了数据复用性和分析效率。基于这些宽表与数据集，大部分常规分析场景已能够快速响应。然而，在数据加工的最上游，即明细数据宽表的生产环节之前依旧包含缓冲的刻钟级udw表，因此仍存在若干架构性瓶颈。首先，实时数据处理链路与离线批处理链路相互耦合，资源竞争与依赖关系复杂，影响了整体任务的稳定性和时效性；其次，核心业务指标与非核心附属数据未被有效拆分处理，导致关键数据产出易受边缘数据波动或延迟的干扰；此外，当前的计算框架对于数据迟到、重复、异常值等复杂情况的处理灵活度不足，容错与自适应能力有待加强。</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-14db3809be.jpg"></p>
<p>为彻底解决这些问题，进一步提升数据产出的时效性、准确性和稳定性，以更好地赋能百度APP及其产品矩阵及各下游业务的数据分析与决策，亟需结合各数据点位的实际使用情况和业务优先级，对最上游的日志ETL（抽取、转换、加载）处理流程进行系统性的优化与重构。</p>
<h2><strong>2. 问题分析</strong></h2>
<p>当前数据ETL处理流程面临以下几个核心挑战，这些问题不仅影响数据产出的效率与稳定性，也为下游业务数据的准确性和及时性带来风险。</p>
<h3>2.1 开发框架灵活性不足，资源协调与弹性扩展能力受限</h3>
<p>目前的ETL任务仍沿用原有UDW大表处理框架，通过单机Hadoop Client提交任务，并依赖QE（底层为mapreduce引擎）进行计算。该框架在资源调度和权限管理方面已逐渐暴露出瓶颈。同时udw是2012年提出的数仓建设方案，随着开源计算、存储技术的发展，udw性能逐步落后业界，部分功能不具备继续升级迭代可行性。一旦出现上游数据延迟、队列资源拥塞或系统异常，容易导致任务大规模积压。由于缺乏跨队列或跨资源的调度容灾能力，无法协调其他计算资源执行任务回溯与补偿，最终将直接影响整体数据产出时效，甚至波及下游多条业务线的核心数据应用。</p>
<h3>2.2 核心与非核心数据处理耦合，异常影响范围扩散</h3>
<p>在日志清洗ETL环节中，核心业务数据点位与非核心业务数据点位、以及实时与离线数据流目前尚未进行有效拆分处理。这种架构层面的耦合导致一旦上游数据源或计算过程中发生异常，其影响面会迅速扩大，不仅关键业务指标受到冲击，非核心业务数据的问题也可能反向干扰核心链路的稳定性。缺乏业务优先级识别和隔离机制，降低了计算链路的整体容错能力和故障隔离水平。</p>
<h3>2.3 计算链路冗长复杂，维护困难且稳定性面临挑战</h3>
<p>当前处理流程中包含UDW中间缓冲层，导致计算环节增多、链路层级深化。较长的依赖链不仅增加了数据产出的端到端延迟，也显著提高了运维监控和故障定位的复杂度。任何环节出现性能波动或失败都易引起连锁反应，威胁整体任务的稳定性和时效性，同时也带来较高的人力维护成本。</p>
<h3>2.4 实时与离线数据源不一致，存在冗余计算与口径偏差</h3>
<p>百度APP及其产品矩阵业务当前使用的实时计算链路和离线数据链路在核心指标上并未实现数据源统一，两条链路独立处理且并行存在。这导致相同指标需要在不同流程中重复计算，既造成资源浪费，也增加了数据口径对齐的难度。长期来看，此类架构问题会直接影响关键指标的一致性和可信度，对业务决策准确性构成潜在风险。</p>
<h3>2.5 存储无序增长，数据冗余和存储成本与日俱增</h3>
<p>随着业务规模的持续扩张和流量快速增长，支撑核心业务的明细数据宽表总量已达到百PB级别，存储与计算成本压力日益凸显。然而，不同业务域对数据的保留周期和使用频率存在显著差异，全部数据长期存储既不经济也无必要。</p>
<h2><strong>3. 解决方案</strong></h2>
<h3>3.1 ETL框架升级</h3>
<p>在完成由多张udw表到Turing表的优化工作完成后，数据处理的时效性与稳定性虽然取得了一定改善，但仍存在进一步提升的空间。具体而言，原有的C++ MR计算框架在任务运行过程中逐渐暴露出两类典型问题：一是容易发生计算长尾现象，个别任务实例处理缓慢，拖慢整个作业完成进度；二是基于单机调度的模式存在可靠性瓶颈，整体资源协调和任务容错能力有限。这些问题导致数据产出的延迟风险依然较高，难以完全满足业务对数据时效日益提升的要求。</p>
<p>为解决上述痛点，经过充分的技术调研与架构评估，我们决定将计算框架升级为TM+Spark的组合方案。其中，TM（Task Manager）作为厂内自研的高性能流式处理框架，在多个关键维度上显著优于原有的C++ MR架构。</p>
<p>TM（Task Manager）：更高的容错性和更强的稳定性</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-29892c55bf.jpg"></p>
<p>首先，在容错性方面，TM具备更为智能和敏捷的错误恢复机制。当某个计算实例发生故障或执行缓慢时，TM调度系统能够迅速感知并主动发起抢占操作，将当前Task动态迁移至新的实例继续处理，从而有效避免传统MR框架中由于个别长尾任务导致的整体作业延迟。这一机制极大提升了作业的稳健性和执行效率。</p>
<p>其次，在调度稳定性方面，TM基于Opera调度系统进行资源管理与任务分配，这一调度架构具有高度解耦和资源隔离的特点。每个任务实例独立运行，互不干扰，有效避免了在MR模式下由于同一队列中其他高负载或异常作业所带来的负面冲击，从而保障关键数据处理任务的稳定性和可预期性。</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-19d7ad2f0d.jpg"></p>
<p>此外，TM框架也在输出存储效率方面做出了重要升级。它原生支持输出Parquet列式存储格式，并集成ZSTD压缩算法，在减少存储空间占用的同时大幅提升了后续查询操作的I/O效率。这一改进使得数据在写入阶段就具备更优的列组织结构和压缩特性，为下游分析提供了高性能的数据基础。</p>
<p><strong><strong>主流开源框架Flink和TM的对比如下：</strong></strong></p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-b9aca2ae4f.png"></p>
<p><strong><strong>Spark：通过构建DAG，计算更高效；利用RDD或者DataFrame减少IO耗时；多线程机制，执行速度更快。</strong></strong></p>
<p><strong><strong>Spark对比MR的核心优势：</strong></strong></p>
<ul>
<li> <p>速度：基于内存计算，无需反复做读写操作，更加高效</p> </li>
<li> <p>高度集成：spark丰富的API和高级抽象的函数可以轻松实现复杂的逻辑计算和处理，无需和MR一般需要编写复杂的处理逻辑</p> </li>
<li> <p>计算模型：内置的RDD数据结构可以提高数据计算的容错性；查询优化和执行优化可以适应复杂数据的处理和查询</p> </li>
</ul>
<p>结合Spark通用计算引擎强大的分布式内存计算能力和丰富的生态组件，新框架不仅解决了之前C++ MR模式中的长尾与调度瓶颈，还进一步实现了处理链路的统一与优化。Spark的高扩展性和TM的流式稳健性相结合，共同构建出一个容错能力强、资源利用高效、运维负担低的新一代数据处理架构，为业务提供更低延迟、更高可靠性的数据服务。</p>
<h3>3.2 日志分类分级</h3>
<h4>3.2.1 埋点<strong><strong>上线不规范，被动兼容推高处理成本</strong></strong></h4>
<p>在当前百度APP及其产品矩阵业务高速发展的背景下，日均处理日志量已达3000亿PV的庞大规模，数据流的稳定、高效与成本可控变得至关重要。</p>
<p>原有的埋点分类和校验存在两个突出的问题：</p>
<ul>
<li> <p><strong>上报不规范</strong>：存在大量不经过日志中台统一校验而直接上线的业务打点，这些“非规范”打点格式各异、质量参差不齐，极易引发解析异常。</p> </li>
<li> <p><strong>处理成本高</strong>：下游的日志清洗ETL环节被迫陷入“被动兼容”的循环中，需要频繁地跟进制订适配规则以解析这些非标数据，不仅带来了极高的运维成本，更因计算资源的无效消耗而加剧了整体处理链路的负担，严重制约了数据产出的时效性与稳定性。</p> </li>
</ul>
<h4>3.2.2 <strong><strong>通过协同治理实现日志中台全流量覆盖</strong></strong></h4>
<p>为从根本上破解这一难题，我们基于对百度APP及其产品矩阵数据全链路的深入洞察，发起了一项跨体系的协同治理工程。联合了日志中台团队、各业务研发团队、QA质量保障团队及PMO项目管理团队，形成了强有力的专项工作组。</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-fdbd5629b9.jpg"></p>
<p>第一阶段的核心任务是对所有日志模块进行全域梳理。我们共同制定了统一的《新增业务模块接入日志中台规范》<strong><strong>与</strong></strong>《日志埋点规范》<strong><strong>，明确了从数据采集、上报到校验的完整标准流程，并强力推动百度APP及其产品矩阵（包括主客户端及相关创新业务）的全量需求空间、代码仓库及日志模块，完成向日志中台的标准化接入迁移。这一举措将日志中台的流量覆盖能力从治理前的约</strong></strong>80%<strong><strong>一举提升至</strong></strong>100%****，实现了<strong>全流量管控。</strong></p>
<p>更重要的是，我们在日志中台增强了多项主动校验能力：包括日志长度校验、关键公共参数完整性校验、以及精确到需求ID的粒度校验。这使得任何不合规的打点企图在测试和上线阶段就能被即时发现和拦截，实现了“问题早发现、早解决”的闭环管理，从而构筑起覆盖全场景的打点需求上线质量保障体系，从源头上杜绝了异常日志的产生。</p>
<h4>3.2.3 <strong><strong>打破“只上不下”僵局，建立埋点生命周期管理</strong></strong></h4>
<p>在成功建立起“入口”管控机制后，我们将治理重心转向对历史存量埋点的“出口”梳理与优化。长期以来，由于缺乏有效的评估手段，点位数据存在着“只增不减”的痼疾，大量废弃或无效点位持续消耗着巨额的计算和存储资源。为此，我们创新性地从鉴权信息入手，通过对十几类不同下游使用场景（包括内部报表、算法模型、RDC数据转发服务等）的全面调研与信息收集，并对相关日志解析链路进行深度分析，首次精准地绘制出以百度APP及其产品矩阵全量15000多个点位为起点的、覆盖所有下游应用场景的“点位全链路使用地图”。</p>
<p>基于这张价值地图，我们清晰地识别出超过10000个点位已无任何下游业务使用或价值极低。通过严格的评估与协作流程，我们果断对这些埋点进行了下线处理，下线比例高达存量点位的71%。此次大规模治理行动，不仅直接释放了海量的计算和存储资源，有效缓解了系统瓶颈，更打破了长达多年的“埋点只上不敢下”的历史僵局，建立了点位的全生命周期管理模式，为后续数据的精细化管理与成本优化奠定了坚实基础。</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-083cf2a3a5.jpg"></p>
<h3>3.3 AB实验数据扇出处理</h3>
<h4>3.3.1 现状与问题</h4>
<p>在数据驱动的业务迭代中，A/B实验平台的指标建设和效果评估能力至关重要。然而，随着业务快速扩张和实验复杂度的提升，原有的实验数仓架构逐渐显露出严重瓶颈。平台最初是在通用数仓分层模型的基础上，采用“每个指标单独计算”的模式进行建设。这种设计在初期虽然灵活，但随着实验数量和指标数量的急剧增长，计算链路变得异常复杂、冗余且难以维护。由于缺少与公司数据中台团队的深度协同和标准化约束，每次新增实验指标都需要大量重复开发，导致实验数据需求的交付周期不断延长，严重拖慢了业务迭代速度，引发了业务团队的负反馈。</p>
<h4>3.3.2 解决方案</h4>
<p><strong><strong>（1）分析过程</strong></strong></p>
<p>理想的解决方案是直接复用百度APP及其产品矩阵已有的标准化大宽表进行实验指标配置。即基于一张集成所有关键维度与指标的大宽表，快速定义和产出实验分析所需的数据集。然而，现实情况却更为复杂：百度APP及其产品矩阵客户端同时线上进行的实验数量极多，平均每个cuid（用户唯一标识）对应的实验ID（sid）字符长度已超过2400字符。这个长度几乎相当于单条日志原始存储容量的40%，如果直接将实验ID维度接入宽表，将导致每条日志存储膨胀近一倍。这不仅会带来极高的存储成本，也会大幅增加下游所有数据应用的数据扫描量和传输开销，严重拖慢查询性能，进而影响整个数据链路的效率。</p>
<p><strong><strong>（2）设计思路</strong></strong></p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-413cd36ad9.jpg"></p>
<p>面对这一独特挑战，我们并未选择传统的宽表集成方案，而是从数据生成的源头实施了更根本的架构优化。我们重点对实验ID映射关系进行了拆分和重构：<strong><strong>将sid与核心行为数据解耦，设计并建设了独立的sid维表</strong></strong>。该维表直接从日志源头统一生成，整合了来自客户端的实验曝光及分组信息，并实现了对业务方、评估方各自独立建设的多套映射关系的全面统一。这一举措不仅从本质上避免了主宽表的存储膨胀，还彻底解决了因数据来源不一致而导致的实验效果评估diff问题，显著提高了实验数据的准确性和可信度。</p>
<p><strong><strong>（3）成果与收益</strong></strong></p>
<p>在此基础上，A/B实验平台的分析查询不再依赖于对超大宽表的直接扫描，而是通过<strong><strong>sid维表与核心行为宽表进行动态拼接</strong></strong>的方式实现指标计算。</p>
<p>在指标口径对齐方面，已完成实验类指标与OKR指标的口径统一工作，累计对齐上线指标2000余个，覆盖多个主题和维度。实验指标改由数据中心宽表统一生产，显著减少了以往在指标口径沟通与对齐方面的成本；在实验效率提升显著，指标开发环节通过复用宽表及数仓下沉逻辑，并升级计算框架，使常规需求开发周期从原先2周以上缩短至1周内，开发效率提升超50%。同时核心指标计算SLA由T+14小时提升至T+10小时，处理时效明显提高；在计算资源成本方面，通过整体数据流复用和抽样日志整合优化，实现了计算资源成本的有效降低。另外，联动产品及策略团队治理并下线无效实验指标超1800+，释放的资源进一步支撑了新场景的指标建设需求。</p>
<h2><strong>4. 分级存储治理</strong></h2>
<p>随着业务规模的持续扩张与产品矩阵的不断丰富，百度APP及其产品矩阵业务的日志数据量呈现指数级增长，单张核心Turing数据表的存储量已达到百PB级别，面临巨大的存储与成本压力。传统的统一存储周期策略难以适应当前复杂的使用场景：一方面，大量短期数据被无效保留，占用巨额存储资源；另一方面，部分核心业务场景仍需依赖长周期历史数据进行跨年指标对比、关键数据需求回溯与深度建模分析。</p>
<p>为解决这一矛盾，我们针对Turing表启动了多维度的精细化存储治理工作。通过深入分析业务使用特征与数据访问频率，我们建立了差异化的数据生命周期管理机制，实施**“热-&gt;温-&gt;冷”**三级数据分层存储策略。对高频访问的近期数据全部保留，对访问频率较低的长期历史数据自动进行转储、压缩或者裁剪等，并配套建立完备的数据取回与回溯流程。</p>
<p>该项治理在充分保障核心业务长周期数据使用需求的前提下，显著压缩了整体存储规模，实现了存储成本的大幅优化，为未来数据的可持续增长与高效管理奠定了坚实基础。</p>
<p>具体实施策略：</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-9c87a2818c.png"></p>
<h1>03 总结与展望</h1>
<p>随着业务规模的持续扩张和产品矩阵的不断丰富，数据量呈现指数级增长，这一趋势持续驱动着数据处理架构与模型的演进与迭代，同时也对数据分析的敏捷性、易用性和可靠性提出了更高要求。在数仓系统全面升级的过程中，我们着力优化数据处理全链路，通过改进调度机制、减少计算环节、强化故障自动恢复能力，显著缩短了整个数据处理流程的时长，有效识别并排除多项潜在稳定性风险。此外，依托于对全端埋点体系的系统化梳理与标准化规范，构建了高质量、可复用的数据资产底座。</p>
<p>本次整体架构的升级为业务提供了坚实的数据支撑，在数据时效性、准确性和使用便捷性方面均实现显著提升。作为百度体系内最核心且数据规模最大的业务板块，百度APP仍面临数据持续激增带来的诸多挑战，包括埋点规范统一难度高、技术栈兼容与选型约束多、日志解析复杂度高、存储结构灵活多变以及成本控制压力增大等问题。</p>
<p>面向未来，我们将持续推进数仓架构的深度优化，重点围绕埋点治理、架构升级、效能提升、存储模型优化和资源精细化管理等方面展开工作。目标是构建一套具备更高时效性、更优数据模型、更低存储与计算成本的全新一代数仓链路，为业务创新与决策提供高效、可靠、低成本的数据服务能力。</p>]]>
    </description>
    <content:encoded><![CDATA[<h1>导读</h1>
<p>面对百度APP日均数千亿PV、超百PB数据规模带来的巨大挑战，我们完成了数据仓库的系统性升级。本文详细阐述了通过"两步走"策略解决资源压力、处理延迟和架构瓶颈的全过程：第一阶段聚焦日志清洗环节的稳定性与成本优化，第二阶段实现实时离线链路解耦、核心数据隔离及计算框架容错能力提升。此次升级显著提升了数据处理时效性、系统稳定性和成本效益，为业务发展提供了更坚实的数据支撑。</p>
<h1>背景</h1>
<p>百度APP及其产品矩阵作为百度体量最大的C端业务线，在数据处理全链路面临规模与架构的双重挑战。日志清洗环节因日均几千亿PV、超百PB的庞大数据规模，导致计算资源持续承压、处理延迟频发，加之历史遗留的复杂日志格式，清洗稳定性与时效性逐步下降，存储成本高昂。与此同时上游日志数据仍存在实时与离线链路耦合、核心与边缘数据未有效隔离、计算框架容错能力不足等结构性问题，影响关键数据产出的稳定与时效。整体系统切换与优化面临高额的历史负担和技术重构成本，下游业务的数据可用性、决策及时性及深度运营分析均受到显著制约。</p>
<p>基于以上问题，我们制定了“两步走”的升级策略：第一阶段优先解决日志清洗环节的稳定性和存储成本问题；第二阶段在此基础上，重点推进数仓上层架构优化，包括实时与离线链路解耦、核心数据隔离处理以及计算框架容错能力提升，逐步实现整体数据仓库的高效、稳定与可持续升级。</p>
<h1>01 第一阶段：多日志源整合</h1>
<h2><strong>1. 2023年之前架构</strong></h2>
<p>在百度APP及其产品矩阵的数据体系建设过程中，日志清洗作为整个数据流水线的起始环节，其处理稳定性和产出时效性始终处于关键地位，是保障下游业务数据可用性与决策及时性的重中之重。然而，随着业务规模持续扩大和用户体量快速增长，每日产生的日志量急剧上升，由此带来的巨大计算压力使得整个清洗链路频繁面临资源瓶颈与处理延迟，稳定性和时效性均逐步下滑，难以满足下游各业务方对数据交付时间和质量的要求。与此同时，数据入口的分散催生了大量烟囱式的开发与冗余的计算逻辑，不仅推高了运维成本，更在源头形成了数据孤岛。下游基于此类数据构建的数仓架构必然复杂化，多表的 JOIN 与理解成本高昂，使得整个数据建设环节背负着日趋沉重的成本与协作压力。</p>
<h2><strong>2. 问题分析</strong></h2>
<h3>2.1 旧架构分析</h3>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-41f3e39809.jpg"></p>
<h4>2.1.1 <strong><strong>数据孤岛化加剧，认知与使用成本高昂</strong></strong></h4>
<p>现有架构对每类日志采用独立落表方式，导致数据存储呈现碎片化状态。这种设计造成同一业务实体的相关信息分散在不同表中，形成严重的数据割裂。下游用户在使用数据时，不得不通过多表关联才能获取完整信息，不仅大幅增加了技术实现难度，更带来了沉重的认知负担。用户需要理解多张表的结构和关联关系，极易产生理解偏差，进而影响数据分析的准确性和可靠性。</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-abbc8cbb5f.jpg"></p>
<h4>2.1.2 <strong><strong>关联查询性能瓶颈，制约数据价值释放</strong></strong></h4>
<p>与此同时，多表关联查询模式给系统带来了巨大的性能压力。随着数据量的持续增长，表连接操作的成本呈指数级上升，查询响应时间显著延长。特别是在需要跨多个表进行关联分析的场景下，系统往往需要耗费大量计算资源和时间，无法满足业务对高效数据分析和快速决策的需求，严重制约了数据价值的及时释放。</p>
<p>此外，原始日志结构中普遍存在的复杂嵌套格式（如多层JSON、数组结构等）大幅增加了数据清洗和解析的复杂度。大量业务自定义字段缺乏统一规范，导致解析逻辑冗余且低效，进一步降低了整体处理性能。这些因素共同加剧了数据处理的延迟与资源消耗，形成系统性瓶颈。</p>
<h4>2.1.3 <strong><strong>维护复杂度与脆弱性并存，系统稳定性堪忧</strong></strong></h4>
<p>独立的数据处理流水线，导致系统维护点分散。任何逻辑变更或schema调整都需要在多处同步实施，极大地增加了维护工作量。这种架构的脆弱性也显著提高了出错风险，单个任务修改的错误可能引发连锁反应，影响整个数据链路的稳定性。</p>
<p>特别需要指出的是，当前采用的UDW数仓及配套ETL框架仍是2012年上线的技术方案，已明显落后于业界主流水平。该框架存在诸多局限性：首先，其兼容性差，难以与现有开源生态工具链高效集成；其次，基于C++的MR计算框架稳定性不足，日常运行中容易出现各种异常；最后，开发调试效率低下，严重制约了数据需求的迭代速度。这些技术债务不仅增加了系统的维护复杂度，更成为制约数据平台发展的关键瓶颈。</p>
<h3>2.2 重构思路分析</h3>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-bc837c97b5.jpg"></p>
<p><strong>理想状态</strong>：从数据架构的理想设计来看，基于通用宽表数据建模方法论，采用“一步到位”的方式直接产出高度整合、面向主题的Turing宽表，是最为高效和优雅的解决方案。它能够减少中间冗余加工环节，提升数据一致性和复用度。</p>
<p><strong>升级成本</strong>：下游业务方因历史原因，数据应用架构高度依赖传统UDW模式的数据组织与服务方式，迁移至Turing宽表体系涉及大量脚本改造、逻辑核对与业务适配工作，技术切换和数据迁移成本极高，导致架构升级短期难以实施。</p>
<p><strong>思考</strong>：为实现数据架构的平滑升级，本次重构方案采用渐进式过渡策略，在着力解决现有架构核心痛点的同时，必须充分考虑百度业务数据链路长、历史包袱重的现实情况，审慎平衡技术先进性与落地可行性。方案设计严格遵循"平滑过渡、风险可控、成本最优"三大原则。</p>
<p>需要特别指出的是，由于现有数据体系深度嵌入各业务线的策略计算与离线分析环节，其紧密的耦合关系导致配套升级难度极大、周期长。这不仅涉及底层数据表的更替、依赖路径修改，更要求对依赖原有数据模型的下游业务进行协同改造和全面适配，沟通和推进难度极大。所以在保障业务连续性的前提下，如何有序推进全链路的升级切换是本次升级的重中之重。</p>
<p><strong><strong>建模思路：</strong></strong></p>
<p><strong><strong>（1）降低迁移成本</strong></strong></p>
<p>在数据中间层设计上，方案延续使用<strong><strong>刻钟级UDW</strong></strong>表作为缓冲层，通过将多个离散的UDW表整合为统一的宽表模型，进一步降低下游的使用和理解成本。同时，对表schema实施精细化改造，包括消除冗余字段、统一数据标准、优化存储格式，并重构字段逻辑以提升数据一致性。这种设计既保持了与现有下游系统的兼容性，又显著降低了数据使用复杂度。</p>
<p><strong><strong>（2）双轨输出机制</strong></strong></p>
<p>为确保迁移过程的平稳性，方案采用双轨输出机制：一方面继续提供优化后的UDW宽表，保障现有作业的无缝运行；另一方面通过聚合加工生成小时级Turing表，作为统一对外输出的日志宽表。这种渐进式迁移路径使下游用户可根据自身情况灵活选择切换时机，最大限度降低升级成本。</p>
<p><strong><strong>（3）兼顾历史和未来</strong></strong></p>
<p>此次架构优化为后续全面升级奠定了坚实基础。通过UDW层的预处理和Turing表的逐步推广，最终将实现架构的完全过渡，在提升系统性能的同时确保业务连续性，达成技术演进与业务稳定之间的最佳平衡。</p>
<h2><strong>3. 解决方案</strong></h2>
<p><strong><strong>过渡方案设计与实施：稳时效、降成本、提效率的综合治理</strong></strong></p>
<p>面对日志清洗环节日益严峻的稳定性、时效性及成本压力，我们制定并实施了一套详尽的过渡性解决方案。该方案并未激进地推行一步到位的Turing宽表迁移，而是立足于现有技术生态，以快速解决下游业务最迫切的痛点为目标，重点攻坚“产出时效不稳定”、“存储计算成本高”及“明细数据查询效率低下”三大核心问题。</p>
<h3>3.1 优化处理粒度与逻辑沉淀，保障时效与复用性</h3>
<p>为彻底扭转小时级任务积压与延迟的局面，我们首先对调度周期进行了粒度细化，将日志清洗任务从<strong><strong>小时级调度全面提升至刻钟级（15分钟）</strong></strong>。这一调整显著降低了单次任务的处理数据量和计算压力，使数据产出的延迟大幅减少，稳定性和时效性得到了根本保障。在技术选型上，我们并未盲目更换计算框架，而是继续沿用成熟稳定的<strong><strong>C++/MR框架</strong></strong>，确保了迁移过程的平稳性与可靠性。</p>
<p>同时，我们致力于提升数据的易用性与标准化程度。针对下游业务方需要反复从复杂JSON、Map等嵌套字段中解析提取关键信息的痛点，我们进行了大规模的<strong><strong>业务通用逻辑下沉</strong></strong>工作。将超过100个高频访问的埋点属性进行预解析、扁平化处理，转化为单独的标准化字段。这不仅极大减轻了下游的数据预处理负担，更直接提升了基于这些字段的<strong><strong>查询过滤与聚合分析效率</strong></strong>，为下游开发节省了大量时间。</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-3ad183e1e7.jpg"></p>
<h3>3.2 <strong><strong>兼顾历史依赖与未来演进，提供平滑迁移路径</strong></strong></h3>
<p>我们充分认识到下游业务对原有UDW数仓体系的强依赖性。为保障业务的连续性，我们并未强制要求所有方立即迁移，而是采取了<strong><strong>双轨并行</strong></strong>的支撑策略。在产出新一代数据模型的同时，我们<strong><strong>继续提供UDW中间表</strong></strong>，确保那些尚未准备好迁移至Turing宽表的业务方能够无缝对接，无需修改现有代码，极大降低了方案的落地门槛和风险。</p>
<h3>3.3 深度优化存储与查询，实现性能跨越式提升</h3>
<p>为进一步降低存储成本并提升Turing宽表的查询性能，我们对其存储结构进行了深度优化。</p>
<ul>
<li><strong><strong>合并小文件与高效压缩</strong></strong>：海量小文件是制约查询性能的首要元凶。我们通过按<strong><strong>设备ID、点位ID、时间戳</strong></strong>等关键字段进行精细排序，将数据写入为连续有序的大文件，从而将<strong><strong>单天高达800万个小文件合并至60万左右</strong></strong>，文件数量减少了近<strong><strong>93%</strong></strong>。在存储格式上，我们选用Parquet列式存储，并经过充分调研测试，采用了<strong><strong>ZSTD压缩算法</strong></strong>。ZSTD在压缩比、压缩/解压速度上取得了最佳平衡，且完美支持多线程，最终实现了每天<strong><strong>节省超过420TB</strong></strong>的巨大存储开销，成本效益极其显著。</li>
</ul>
<h2><strong>4. 新的问题&amp;解决策略</strong></h2>
<p>问题1：宽表数据量膨胀导致的查询性能下降</p>
<p>解决策略：为应对宽表数据量激增对查询性能带来的挑战，我们实施了体系化的查询加速方案，显著提升海量数据下的检索效率</p>
<ul>
<li> <p><strong><strong>强制分区限制策略</strong></strong>：在查询引擎层上线了强制要求限制分区条件的规则，避免了全表扫描带来的巨额元数据开销，大幅提升元数据检索效率。</p> </li>
<li> <p><strong><strong>查询结果缓存</strong></strong>：对常见的热点查询结果进行缓存，对于重复性查询实现了秒级响应。</p> </li>
<li> <p><strong><strong>智能资源调度</strong></strong>：根据查询的计算复杂度，系统自动将其调度到不同配置的资源池中执行，简单查询快速返回，复杂查询获得充足资源，实现了集群资源的高效利用。</p> </li>
</ul>
<p>问题2：分区数量增多导致点位所在的分区变得困难</p>
<p>解决策略：针对分区维度增加后，数据定位难度加大的问题，我们通过元数据管理与平台化集成提供解决方案：</p>
<ul>
<li> <p>新建分区元数据集，以天为粒度预先计算并存储所有点位与分区的映射关系，形成高效的点位分区定位查询，为点位所在分区快速检索提供基础支撑。</p> </li>
<li> <p>与现有点位管理平台深度集成，在其点位查询界面新增【查一查】功能。用户可通过界面化操作直接获取精准的数据分区信息及查询SQL模板，极大提升了用户使用的效率，降低了用户使用成本。</p> </li>
</ul>
<h1>02 第二阶段：全面提速</h1>
<h2><strong>1. 2023→2024年架构</strong></h2>
<p>随着业务发展，该数仓已完成由UDW（统一数据工作台）向Turing（新数据工作台）的改造，并初步建立起体系化的数据模型与分层数据集，显著提升了数据复用性和分析效率。基于这些宽表与数据集，大部分常规分析场景已能够快速响应。然而，在数据加工的最上游，即明细数据宽表的生产环节之前依旧包含缓冲的刻钟级udw表，因此仍存在若干架构性瓶颈。首先，实时数据处理链路与离线批处理链路相互耦合，资源竞争与依赖关系复杂，影响了整体任务的稳定性和时效性；其次，核心业务指标与非核心附属数据未被有效拆分处理，导致关键数据产出易受边缘数据波动或延迟的干扰；此外，当前的计算框架对于数据迟到、重复、异常值等复杂情况的处理灵活度不足，容错与自适应能力有待加强。</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-14db3809be.jpg"></p>
<p>为彻底解决这些问题，进一步提升数据产出的时效性、准确性和稳定性，以更好地赋能百度APP及其产品矩阵及各下游业务的数据分析与决策，亟需结合各数据点位的实际使用情况和业务优先级，对最上游的日志ETL（抽取、转换、加载）处理流程进行系统性的优化与重构。</p>
<h2><strong>2. 问题分析</strong></h2>
<p>当前数据ETL处理流程面临以下几个核心挑战，这些问题不仅影响数据产出的效率与稳定性，也为下游业务数据的准确性和及时性带来风险。</p>
<h3>2.1 开发框架灵活性不足，资源协调与弹性扩展能力受限</h3>
<p>目前的ETL任务仍沿用原有UDW大表处理框架，通过单机Hadoop Client提交任务，并依赖QE（底层为mapreduce引擎）进行计算。该框架在资源调度和权限管理方面已逐渐暴露出瓶颈。同时udw是2012年提出的数仓建设方案，随着开源计算、存储技术的发展，udw性能逐步落后业界，部分功能不具备继续升级迭代可行性。一旦出现上游数据延迟、队列资源拥塞或系统异常，容易导致任务大规模积压。由于缺乏跨队列或跨资源的调度容灾能力，无法协调其他计算资源执行任务回溯与补偿，最终将直接影响整体数据产出时效，甚至波及下游多条业务线的核心数据应用。</p>
<h3>2.2 核心与非核心数据处理耦合，异常影响范围扩散</h3>
<p>在日志清洗ETL环节中，核心业务数据点位与非核心业务数据点位、以及实时与离线数据流目前尚未进行有效拆分处理。这种架构层面的耦合导致一旦上游数据源或计算过程中发生异常，其影响面会迅速扩大，不仅关键业务指标受到冲击，非核心业务数据的问题也可能反向干扰核心链路的稳定性。缺乏业务优先级识别和隔离机制，降低了计算链路的整体容错能力和故障隔离水平。</p>
<h3>2.3 计算链路冗长复杂，维护困难且稳定性面临挑战</h3>
<p>当前处理流程中包含UDW中间缓冲层，导致计算环节增多、链路层级深化。较长的依赖链不仅增加了数据产出的端到端延迟，也显著提高了运维监控和故障定位的复杂度。任何环节出现性能波动或失败都易引起连锁反应，威胁整体任务的稳定性和时效性，同时也带来较高的人力维护成本。</p>
<h3>2.4 实时与离线数据源不一致，存在冗余计算与口径偏差</h3>
<p>百度APP及其产品矩阵业务当前使用的实时计算链路和离线数据链路在核心指标上并未实现数据源统一，两条链路独立处理且并行存在。这导致相同指标需要在不同流程中重复计算，既造成资源浪费，也增加了数据口径对齐的难度。长期来看，此类架构问题会直接影响关键指标的一致性和可信度，对业务决策准确性构成潜在风险。</p>
<h3>2.5 存储无序增长，数据冗余和存储成本与日俱增</h3>
<p>随着业务规模的持续扩张和流量快速增长，支撑核心业务的明细数据宽表总量已达到百PB级别，存储与计算成本压力日益凸显。然而，不同业务域对数据的保留周期和使用频率存在显著差异，全部数据长期存储既不经济也无必要。</p>
<h2><strong>3. 解决方案</strong></h2>
<h3>3.1 ETL框架升级</h3>
<p>在完成由多张udw表到Turing表的优化工作完成后，数据处理的时效性与稳定性虽然取得了一定改善，但仍存在进一步提升的空间。具体而言，原有的C++ MR计算框架在任务运行过程中逐渐暴露出两类典型问题：一是容易发生计算长尾现象，个别任务实例处理缓慢，拖慢整个作业完成进度；二是基于单机调度的模式存在可靠性瓶颈，整体资源协调和任务容错能力有限。这些问题导致数据产出的延迟风险依然较高，难以完全满足业务对数据时效日益提升的要求。</p>
<p>为解决上述痛点，经过充分的技术调研与架构评估，我们决定将计算框架升级为TM+Spark的组合方案。其中，TM（Task Manager）作为厂内自研的高性能流式处理框架，在多个关键维度上显著优于原有的C++ MR架构。</p>
<p>TM（Task Manager）：更高的容错性和更强的稳定性</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-29892c55bf.jpg"></p>
<p>首先，在容错性方面，TM具备更为智能和敏捷的错误恢复机制。当某个计算实例发生故障或执行缓慢时，TM调度系统能够迅速感知并主动发起抢占操作，将当前Task动态迁移至新的实例继续处理，从而有效避免传统MR框架中由于个别长尾任务导致的整体作业延迟。这一机制极大提升了作业的稳健性和执行效率。</p>
<p>其次，在调度稳定性方面，TM基于Opera调度系统进行资源管理与任务分配，这一调度架构具有高度解耦和资源隔离的特点。每个任务实例独立运行，互不干扰，有效避免了在MR模式下由于同一队列中其他高负载或异常作业所带来的负面冲击，从而保障关键数据处理任务的稳定性和可预期性。</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-19d7ad2f0d.jpg"></p>
<p>此外，TM框架也在输出存储效率方面做出了重要升级。它原生支持输出Parquet列式存储格式，并集成ZSTD压缩算法，在减少存储空间占用的同时大幅提升了后续查询操作的I/O效率。这一改进使得数据在写入阶段就具备更优的列组织结构和压缩特性，为下游分析提供了高性能的数据基础。</p>
<p><strong><strong>主流开源框架Flink和TM的对比如下：</strong></strong></p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-b9aca2ae4f.png"></p>
<p><strong><strong>Spark：通过构建DAG，计算更高效；利用RDD或者DataFrame减少IO耗时；多线程机制，执行速度更快。</strong></strong></p>
<p><strong><strong>Spark对比MR的核心优势：</strong></strong></p>
<ul>
<li> <p>速度：基于内存计算，无需反复做读写操作，更加高效</p> </li>
<li> <p>高度集成：spark丰富的API和高级抽象的函数可以轻松实现复杂的逻辑计算和处理，无需和MR一般需要编写复杂的处理逻辑</p> </li>
<li> <p>计算模型：内置的RDD数据结构可以提高数据计算的容错性；查询优化和执行优化可以适应复杂数据的处理和查询</p> </li>
</ul>
<p>结合Spark通用计算引擎强大的分布式内存计算能力和丰富的生态组件，新框架不仅解决了之前C++ MR模式中的长尾与调度瓶颈，还进一步实现了处理链路的统一与优化。Spark的高扩展性和TM的流式稳健性相结合，共同构建出一个容错能力强、资源利用高效、运维负担低的新一代数据处理架构，为业务提供更低延迟、更高可靠性的数据服务。</p>
<h3>3.2 日志分类分级</h3>
<h4>3.2.1 埋点<strong><strong>上线不规范，被动兼容推高处理成本</strong></strong></h4>
<p>在当前百度APP及其产品矩阵业务高速发展的背景下，日均处理日志量已达3000亿PV的庞大规模，数据流的稳定、高效与成本可控变得至关重要。</p>
<p>原有的埋点分类和校验存在两个突出的问题：</p>
<ul>
<li> <p><strong>上报不规范</strong>：存在大量不经过日志中台统一校验而直接上线的业务打点，这些“非规范”打点格式各异、质量参差不齐，极易引发解析异常。</p> </li>
<li> <p><strong>处理成本高</strong>：下游的日志清洗ETL环节被迫陷入“被动兼容”的循环中，需要频繁地跟进制订适配规则以解析这些非标数据，不仅带来了极高的运维成本，更因计算资源的无效消耗而加剧了整体处理链路的负担，严重制约了数据产出的时效性与稳定性。</p> </li>
</ul>
<h4>3.2.2 <strong><strong>通过协同治理实现日志中台全流量覆盖</strong></strong></h4>
<p>为从根本上破解这一难题，我们基于对百度APP及其产品矩阵数据全链路的深入洞察，发起了一项跨体系的协同治理工程。联合了日志中台团队、各业务研发团队、QA质量保障团队及PMO项目管理团队，形成了强有力的专项工作组。</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-fdbd5629b9.jpg"></p>
<p>第一阶段的核心任务是对所有日志模块进行全域梳理。我们共同制定了统一的《新增业务模块接入日志中台规范》<strong><strong>与</strong></strong>《日志埋点规范》<strong><strong>，明确了从数据采集、上报到校验的完整标准流程，并强力推动百度APP及其产品矩阵（包括主客户端及相关创新业务）的全量需求空间、代码仓库及日志模块，完成向日志中台的标准化接入迁移。这一举措将日志中台的流量覆盖能力从治理前的约</strong></strong>80%<strong><strong>一举提升至</strong></strong>100%****，实现了<strong>全流量管控。</strong></p>
<p>更重要的是，我们在日志中台增强了多项主动校验能力：包括日志长度校验、关键公共参数完整性校验、以及精确到需求ID的粒度校验。这使得任何不合规的打点企图在测试和上线阶段就能被即时发现和拦截，实现了“问题早发现、早解决”的闭环管理，从而构筑起覆盖全场景的打点需求上线质量保障体系，从源头上杜绝了异常日志的产生。</p>
<h4>3.2.3 <strong><strong>打破“只上不下”僵局，建立埋点生命周期管理</strong></strong></h4>
<p>在成功建立起“入口”管控机制后，我们将治理重心转向对历史存量埋点的“出口”梳理与优化。长期以来，由于缺乏有效的评估手段，点位数据存在着“只增不减”的痼疾，大量废弃或无效点位持续消耗着巨额的计算和存储资源。为此，我们创新性地从鉴权信息入手，通过对十几类不同下游使用场景（包括内部报表、算法模型、RDC数据转发服务等）的全面调研与信息收集，并对相关日志解析链路进行深度分析，首次精准地绘制出以百度APP及其产品矩阵全量15000多个点位为起点的、覆盖所有下游应用场景的“点位全链路使用地图”。</p>
<p>基于这张价值地图，我们清晰地识别出超过10000个点位已无任何下游业务使用或价值极低。通过严格的评估与协作流程，我们果断对这些埋点进行了下线处理，下线比例高达存量点位的71%。此次大规模治理行动，不仅直接释放了海量的计算和存储资源，有效缓解了系统瓶颈，更打破了长达多年的“埋点只上不敢下”的历史僵局，建立了点位的全生命周期管理模式，为后续数据的精细化管理与成本优化奠定了坚实基础。</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-083cf2a3a5.jpg"></p>
<h3>3.3 AB实验数据扇出处理</h3>
<h4>3.3.1 现状与问题</h4>
<p>在数据驱动的业务迭代中，A/B实验平台的指标建设和效果评估能力至关重要。然而，随着业务快速扩张和实验复杂度的提升，原有的实验数仓架构逐渐显露出严重瓶颈。平台最初是在通用数仓分层模型的基础上，采用“每个指标单独计算”的模式进行建设。这种设计在初期虽然灵活，但随着实验数量和指标数量的急剧增长，计算链路变得异常复杂、冗余且难以维护。由于缺少与公司数据中台团队的深度协同和标准化约束，每次新增实验指标都需要大量重复开发，导致实验数据需求的交付周期不断延长，严重拖慢了业务迭代速度，引发了业务团队的负反馈。</p>
<h4>3.3.2 解决方案</h4>
<p><strong><strong>（1）分析过程</strong></strong></p>
<p>理想的解决方案是直接复用百度APP及其产品矩阵已有的标准化大宽表进行实验指标配置。即基于一张集成所有关键维度与指标的大宽表，快速定义和产出实验分析所需的数据集。然而，现实情况却更为复杂：百度APP及其产品矩阵客户端同时线上进行的实验数量极多，平均每个cuid（用户唯一标识）对应的实验ID（sid）字符长度已超过2400字符。这个长度几乎相当于单条日志原始存储容量的40%，如果直接将实验ID维度接入宽表，将导致每条日志存储膨胀近一倍。这不仅会带来极高的存储成本，也会大幅增加下游所有数据应用的数据扫描量和传输开销，严重拖慢查询性能，进而影响整个数据链路的效率。</p>
<p><strong><strong>（2）设计思路</strong></strong></p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-413cd36ad9.jpg"></p>
<p>面对这一独特挑战，我们并未选择传统的宽表集成方案，而是从数据生成的源头实施了更根本的架构优化。我们重点对实验ID映射关系进行了拆分和重构：<strong><strong>将sid与核心行为数据解耦，设计并建设了独立的sid维表</strong></strong>。该维表直接从日志源头统一生成，整合了来自客户端的实验曝光及分组信息，并实现了对业务方、评估方各自独立建设的多套映射关系的全面统一。这一举措不仅从本质上避免了主宽表的存储膨胀，还彻底解决了因数据来源不一致而导致的实验效果评估diff问题，显著提高了实验数据的准确性和可信度。</p>
<p><strong><strong>（3）成果与收益</strong></strong></p>
<p>在此基础上，A/B实验平台的分析查询不再依赖于对超大宽表的直接扫描，而是通过<strong><strong>sid维表与核心行为宽表进行动态拼接</strong></strong>的方式实现指标计算。</p>
<p>在指标口径对齐方面，已完成实验类指标与OKR指标的口径统一工作，累计对齐上线指标2000余个，覆盖多个主题和维度。实验指标改由数据中心宽表统一生产，显著减少了以往在指标口径沟通与对齐方面的成本；在实验效率提升显著，指标开发环节通过复用宽表及数仓下沉逻辑，并升级计算框架，使常规需求开发周期从原先2周以上缩短至1周内，开发效率提升超50%。同时核心指标计算SLA由T+14小时提升至T+10小时，处理时效明显提高；在计算资源成本方面，通过整体数据流复用和抽样日志整合优化，实现了计算资源成本的有效降低。另外，联动产品及策略团队治理并下线无效实验指标超1800+，释放的资源进一步支撑了新场景的指标建设需求。</p>
<h2><strong>4. 分级存储治理</strong></h2>
<p>随着业务规模的持续扩张与产品矩阵的不断丰富，百度APP及其产品矩阵业务的日志数据量呈现指数级增长，单张核心Turing数据表的存储量已达到百PB级别，面临巨大的存储与成本压力。传统的统一存储周期策略难以适应当前复杂的使用场景：一方面，大量短期数据被无效保留，占用巨额存储资源；另一方面，部分核心业务场景仍需依赖长周期历史数据进行跨年指标对比、关键数据需求回溯与深度建模分析。</p>
<p>为解决这一矛盾，我们针对Turing表启动了多维度的精细化存储治理工作。通过深入分析业务使用特征与数据访问频率，我们建立了差异化的数据生命周期管理机制，实施**“热-&gt;温-&gt;冷”**三级数据分层存储策略。对高频访问的近期数据全部保留，对访问频率较低的长期历史数据自动进行转储、压缩或者裁剪等，并配套建立完备的数据取回与回溯流程。</p>
<p>该项治理在充分保障核心业务长周期数据使用需求的前提下，显著压缩了整体存储规模，实现了存储成本的大幅优化，为未来数据的可持续增长与高效管理奠定了坚实基础。</p>
<p>具体实施策略：</p>
<p><img alt="图片" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-9c87a2818c.png"></p>
<h1>03 总结与展望</h1>
<p>随着业务规模的持续扩张和产品矩阵的不断丰富，数据量呈现指数级增长，这一趋势持续驱动着数据处理架构与模型的演进与迭代，同时也对数据分析的敏捷性、易用性和可靠性提出了更高要求。在数仓系统全面升级的过程中，我们着力优化数据处理全链路，通过改进调度机制、减少计算环节、强化故障自动恢复能力，显著缩短了整个数据处理流程的时长，有效识别并排除多项潜在稳定性风险。此外，依托于对全端埋点体系的系统化梳理与标准化规范，构建了高质量、可复用的数据资产底座。</p>
<p>本次整体架构的升级为业务提供了坚实的数据支撑，在数据时效性、准确性和使用便捷性方面均实现显著提升。作为百度体系内最核心且数据规模最大的业务板块，百度APP仍面临数据持续激增带来的诸多挑战，包括埋点规范统一难度高、技术栈兼容与选型约束多、日志解析复杂度高、存储结构灵活多变以及成本控制压力增大等问题。</p>
<p>面向未来，我们将持续推进数仓架构的深度优化，重点围绕埋点治理、架构升级、效能提升、存储模型优化和资源精细化管理等方面展开工作。目标是构建一套具备更高时效性、更优数据模型、更低存储与计算成本的全新一代数仓链路，为业务创新与决策提供高效、可靠、低成本的数据服务能力。</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-41f3e39809.jpg"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-41f3e39809.jpg" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 10:54:39 +0800</pubDate>
  </item><item>
    <title><![CDATA[AMD 与甲骨文携手打造超大型 AI 芯片集群，年内最大算力合作落地]]></title>
    <link>https://www.oschina.net/news/377494</link>
    <itunes:title><![CDATA[AMD 与甲骨文携手打造超大型 AI 芯片集群，年内最大算力合作落地]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>10 月 14 日，芯片设计商超微半导体公司（AMD）宣布与甲骨文（Oracle）<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblogs.oracle.com%2Fcloud-infrastructure%2Fpost%2Fannouncing-general-availability-of-oci-amd-mi355x" target="_blank">达成合作</a>，AMD 将在后者的数据中心部署约 5 万颗最新 AI 芯片 MI450，标志着双方在人工智能算力领域的深度绑定。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-6d6572bd3d.png"></p>
<p>根据计划，自 2025 年第三季度起，AMD 将在甲骨文旗下数据中心投用这一集群，总算力相当于 200 兆瓦电力负荷。双方表示，合作将在 2027 年后进一步扩展。消息公布后，AMD 股价盘前上涨逾 2%，甲骨文下跌约 1%。双方未披露交易金额。</p>
<p>市场人士认为，该项目将成为继英伟达之后 AI 算力市场的又一重要竞争力量。MI450 为 AMD 迄今最先进的 GPU（图形处理器），将搭载在公司自主研发的 Helios 服务器机架系统中，结合 AMD 自研中央处理器（CPU），直指英伟达下一代「Vera Rubin」系列 AI 芯片。</p>
<p>业内分析认为，此次合作标志着 AMD 的 MI450 首次在公共云场景中大规模应用，意味着更多客户可租用其 AI 算力资源，有望推动 AMD 在数据中心市场进一步缩小与英伟达的差距</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>10 月 14 日，芯片设计商超微半导体公司（AMD）宣布与甲骨文（Oracle）<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblogs.oracle.com%2Fcloud-infrastructure%2Fpost%2Fannouncing-general-availability-of-oci-amd-mi355x" target="_blank">达成合作</a>，AMD 将在后者的数据中心部署约 5 万颗最新 AI 芯片 MI450，标志着双方在人工智能算力领域的深度绑定。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-6d6572bd3d.png"></p>
<p>根据计划，自 2025 年第三季度起，AMD 将在甲骨文旗下数据中心投用这一集群，总算力相当于 200 兆瓦电力负荷。双方表示，合作将在 2027 年后进一步扩展。消息公布后，AMD 股价盘前上涨逾 2%，甲骨文下跌约 1%。双方未披露交易金额。</p>
<p>市场人士认为，该项目将成为继英伟达之后 AI 算力市场的又一重要竞争力量。MI450 为 AMD 迄今最先进的 GPU（图形处理器），将搭载在公司自主研发的 Helios 服务器机架系统中，结合 AMD 自研中央处理器（CPU），直指英伟达下一代「Vera Rubin」系列 AI 芯片。</p>
<p>业内分析认为，此次合作标志着 AMD 的 MI450 首次在公共云场景中大规模应用，意味着更多客户可租用其 AI 算力资源，有望推动 AMD 在数据中心市场进一步缩小与英伟达的差距</p>]]>
    </description>
    <content:encoded><![CDATA[<p>10 月 14 日，芯片设计商超微半导体公司（AMD）宣布与甲骨文（Oracle）<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblogs.oracle.com%2Fcloud-infrastructure%2Fpost%2Fannouncing-general-availability-of-oci-amd-mi355x" target="_blank">达成合作</a>，AMD 将在后者的数据中心部署约 5 万颗最新 AI 芯片 MI450，标志着双方在人工智能算力领域的深度绑定。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-6d6572bd3d.png"></p>
<p>根据计划，自 2025 年第三季度起，AMD 将在甲骨文旗下数据中心投用这一集群，总算力相当于 200 兆瓦电力负荷。双方表示，合作将在 2027 年后进一步扩展。消息公布后，AMD 股价盘前上涨逾 2%，甲骨文下跌约 1%。双方未披露交易金额。</p>
<p>市场人士认为，该项目将成为继英伟达之后 AI 算力市场的又一重要竞争力量。MI450 为 AMD 迄今最先进的 GPU（图形处理器），将搭载在公司自主研发的 Helios 服务器机架系统中，结合 AMD 自研中央处理器（CPU），直指英伟达下一代「Vera Rubin」系列 AI 芯片。</p>
<p>业内分析认为，此次合作标志着 AMD 的 MI450 首次在公共云场景中大规模应用，意味着更多客户可租用其 AI 算力资源，有望推动 AMD 在数据中心市场进一步缩小与英伟达的差距</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-6d6572bd3d.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-6d6572bd3d.png" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 10:43:45 +0800</pubDate>
  </item><item>
    <title><![CDATA[英特尔发布新一代数据中心 GPU 代号“Crescent Island”]]></title>
    <link>https://www.oschina.net/news/377492</link>
    <itunes:title><![CDATA[英特尔发布新一代数据中心 GPU 代号“Crescent Island”]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p><span>英特尔周二公布了一款搭载160GB内存、具备高能效的数据中心GPU，并将其加入该公司的AI加速器组合，旨在推动英特尔以开放系统与软件架构为核心的新AI战略。</span></p>
<p><span>这款GPU代号为“Crescent Island（新月岛）”，根据英特尔介绍，它专为运行推理工作负载的风冷企业级服务器而设计，强调“功耗与成本优化”。<strong>Crescent Island采用英特尔的Xe3P微架构，该架构主打单位功耗下的高性能表现，配备160GB LPDDR5X内存，并支持多种数据类型，为大语言模型（LLM）提供充足的运行空间。</strong></span></p>
<p><span>英特尔的公告还指出，Crescent Island将支持多种数据类型，并被定位为“非常适合”提供tokens-as-a-service服务的厂商和AI推理使用场景。</span></p>
<p><span>除了强调能效表现，Crescent Island还将采用风冷散热设计，并以成本优化为目标。英特尔目前正通过现有的Arc Pro B系列GPU推进其开源软件栈，为Crescent Island做准备。</span></p>
<p><span>英特尔表示，计划于2026年下半年开始向客户提供样品。不过英特尔并未公布正式上市时间——是否会赶在2026年内发布尚不清楚，更可能的情况是要等到2027年才正式大规模推出。目前也没有发布任何产品幻灯片、原型图或更多技术细节。</span></p>
<p><span>英特尔此次并未公布关于“Jaguar Shores”的最新进展。Jaguar Shores是英特尔今年早些时候宣布的一款面向机架级平台的下一代GPU。</span></p>
<p><span>在上个月的一次记者简报会上，英特尔首席AI与技术官Sachin Katti表示，Crescent Island具备“增强的内存带宽”和“大量内存容量”，这让它成为“token云服务和企业级推理场景的理想选择”。</span></p>
<p><span>Crescent Island是在2025年OCP全球峰会上正式亮相的，标志着英特尔正式开启了每年发布新GPU的节奏。此前一周，英特尔刚刚围绕即将推出的“Panther Lake”和“Clearwater Forest”两款CPU大力宣传，这次发布GPU也属同一系列动作。</span></p>
<p><span>媒体表示，在过去两年中，英伟达和AMD已先后转向每年发布新产品的节奏，英特尔此举也意在追赶步伐。过去15年间，英特尔在加速芯片领域经历了多次失败，历经四任CEO，始终未能在这个由英伟达主导的AI基础设施市场中站稳脚跟。</span></p>
<p><span>Sachin Katti是由英特尔CEO陈立武在今年4月任命，负责领导公司的新AI战略。他表示，英特尔正在围绕“开放系统与软件架构”构建AI硬件市场的新愿景，目标是提供“适配合理规模与成本”的算力，以支撑未来的自主型AI工作负载。</span></p>
<p><span>他说：“我们将构建可扩展的异构系统，为agentic AI（自主型AI）工作负载提供无摩擦的使用体验，同时借助开放异构架构，实现这些工作负载在每美元性能表现上的最优解。”</span></p>
<p><span>Katti表示，这种开放策略将为客户和合作伙伴在系统层和硬件层提供更多选择，让多家厂商都能参与进来。他补充说：“随着我们不断带来更多颠覆性的技术，这些新技术都可以被无缝嵌入到这个开放的异构架构中。”</span></p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p><span>英特尔周二公布了一款搭载160GB内存、具备高能效的数据中心GPU，并将其加入该公司的AI加速器组合，旨在推动英特尔以开放系统与软件架构为核心的新AI战略。</span></p>
<p><span>这款GPU代号为“Crescent Island（新月岛）”，根据英特尔介绍，它专为运行推理工作负载的风冷企业级服务器而设计，强调“功耗与成本优化”。<strong>Crescent Island采用英特尔的Xe3P微架构，该架构主打单位功耗下的高性能表现，配备160GB LPDDR5X内存，并支持多种数据类型，为大语言模型（LLM）提供充足的运行空间。</strong></span></p>
<p><span>英特尔的公告还指出，Crescent Island将支持多种数据类型，并被定位为“非常适合”提供tokens-as-a-service服务的厂商和AI推理使用场景。</span></p>
<p><span>除了强调能效表现，Crescent Island还将采用风冷散热设计，并以成本优化为目标。英特尔目前正通过现有的Arc Pro B系列GPU推进其开源软件栈，为Crescent Island做准备。</span></p>
<p><span>英特尔表示，计划于2026年下半年开始向客户提供样品。不过英特尔并未公布正式上市时间——是否会赶在2026年内发布尚不清楚，更可能的情况是要等到2027年才正式大规模推出。目前也没有发布任何产品幻灯片、原型图或更多技术细节。</span></p>
<p><span>英特尔此次并未公布关于“Jaguar Shores”的最新进展。Jaguar Shores是英特尔今年早些时候宣布的一款面向机架级平台的下一代GPU。</span></p>
<p><span>在上个月的一次记者简报会上，英特尔首席AI与技术官Sachin Katti表示，Crescent Island具备“增强的内存带宽”和“大量内存容量”，这让它成为“token云服务和企业级推理场景的理想选择”。</span></p>
<p><span>Crescent Island是在2025年OCP全球峰会上正式亮相的，标志着英特尔正式开启了每年发布新GPU的节奏。此前一周，英特尔刚刚围绕即将推出的“Panther Lake”和“Clearwater Forest”两款CPU大力宣传，这次发布GPU也属同一系列动作。</span></p>
<p><span>媒体表示，在过去两年中，英伟达和AMD已先后转向每年发布新产品的节奏，英特尔此举也意在追赶步伐。过去15年间，英特尔在加速芯片领域经历了多次失败，历经四任CEO，始终未能在这个由英伟达主导的AI基础设施市场中站稳脚跟。</span></p>
<p><span>Sachin Katti是由英特尔CEO陈立武在今年4月任命，负责领导公司的新AI战略。他表示，英特尔正在围绕“开放系统与软件架构”构建AI硬件市场的新愿景，目标是提供“适配合理规模与成本”的算力，以支撑未来的自主型AI工作负载。</span></p>
<p><span>他说：“我们将构建可扩展的异构系统，为agentic AI（自主型AI）工作负载提供无摩擦的使用体验，同时借助开放异构架构，实现这些工作负载在每美元性能表现上的最优解。”</span></p>
<p><span>Katti表示，这种开放策略将为客户和合作伙伴在系统层和硬件层提供更多选择，让多家厂商都能参与进来。他补充说：“随着我们不断带来更多颠覆性的技术，这些新技术都可以被无缝嵌入到这个开放的异构架构中。”</span></p>]]>
    </description>
    <content:encoded><![CDATA[<p><span>英特尔周二公布了一款搭载160GB内存、具备高能效的数据中心GPU，并将其加入该公司的AI加速器组合，旨在推动英特尔以开放系统与软件架构为核心的新AI战略。</span></p>
<p><span>这款GPU代号为“Crescent Island（新月岛）”，根据英特尔介绍，它专为运行推理工作负载的风冷企业级服务器而设计，强调“功耗与成本优化”。<strong>Crescent Island采用英特尔的Xe3P微架构，该架构主打单位功耗下的高性能表现，配备160GB LPDDR5X内存，并支持多种数据类型，为大语言模型（LLM）提供充足的运行空间。</strong></span></p>
<p><span>英特尔的公告还指出，Crescent Island将支持多种数据类型，并被定位为“非常适合”提供tokens-as-a-service服务的厂商和AI推理使用场景。</span></p>
<p><span>除了强调能效表现，Crescent Island还将采用风冷散热设计，并以成本优化为目标。英特尔目前正通过现有的Arc Pro B系列GPU推进其开源软件栈，为Crescent Island做准备。</span></p>
<p><span>英特尔表示，计划于2026年下半年开始向客户提供样品。不过英特尔并未公布正式上市时间——是否会赶在2026年内发布尚不清楚，更可能的情况是要等到2027年才正式大规模推出。目前也没有发布任何产品幻灯片、原型图或更多技术细节。</span></p>
<p><span>英特尔此次并未公布关于“Jaguar Shores”的最新进展。Jaguar Shores是英特尔今年早些时候宣布的一款面向机架级平台的下一代GPU。</span></p>
<p><span>在上个月的一次记者简报会上，英特尔首席AI与技术官Sachin Katti表示，Crescent Island具备“增强的内存带宽”和“大量内存容量”，这让它成为“token云服务和企业级推理场景的理想选择”。</span></p>
<p><span>Crescent Island是在2025年OCP全球峰会上正式亮相的，标志着英特尔正式开启了每年发布新GPU的节奏。此前一周，英特尔刚刚围绕即将推出的“Panther Lake”和“Clearwater Forest”两款CPU大力宣传，这次发布GPU也属同一系列动作。</span></p>
<p><span>媒体表示，在过去两年中，英伟达和AMD已先后转向每年发布新产品的节奏，英特尔此举也意在追赶步伐。过去15年间，英特尔在加速芯片领域经历了多次失败，历经四任CEO，始终未能在这个由英伟达主导的AI基础设施市场中站稳脚跟。</span></p>
<p><span>Sachin Katti是由英特尔CEO陈立武在今年4月任命，负责领导公司的新AI战略。他表示，英特尔正在围绕“开放系统与软件架构”构建AI硬件市场的新愿景，目标是提供“适配合理规模与成本”的算力，以支撑未来的自主型AI工作负载。</span></p>
<p><span>他说：“我们将构建可扩展的异构系统，为agentic AI（自主型AI）工作负载提供无摩擦的使用体验，同时借助开放异构架构，实现这些工作负载在每美元性能表现上的最优解。”</span></p>
<p><span>Katti表示，这种开放策略将为客户和合作伙伴在系统层和硬件层提供更多选择，让多家厂商都能参与进来。他补充说：“随着我们不断带来更多颠覆性的技术，这些新技术都可以被无缝嵌入到这个开放的异构架构中。”</span></p>]]></content:encoded>
    
    <pubDate>Wed, 15 Oct 2025 10:37:33 +0800</pubDate>
  </item><item>
    <title><![CDATA[Firefox 144.0 发布]]></title>
    <link>https://www.oschina.net/news/377489/firefox-144-0-released</link>
    <itunes:title><![CDATA[Firefox 144.0 发布]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>Firefox 144.0 现已发布，具体更新内容如下：</p>
<p><strong>New</strong></p>
<ul>
<li> <p>专注于组中的单个标签页，告别杂乱。现在，活动标签页仍会保留在视图中，即使折叠标签组也能保持界面整洁。</p> <p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6722c234bd.png"></p> </li>
<li> <p>标签页组更新。现在，可以将标签页拖放到折叠的组中，而不会自动展开。这既能快速保持界面整洁，又能最大限度减少视觉干扰。</p> </li>
<li>  <p><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsupport.mozilla.org%2Fkb%2Fprofile-management" target="_blank">Profile management 功能</a>将在未来几周内逐步面向全球用户推出，它将你的在线生活划分为不同的个人资料，涵盖工作、学习、度假计划或其他任何你喜欢的用途，从而帮助保护隐私并保持专注。用户可以命名，并使用头像和颜色主题进行自定义，以便于识别；在不同资料间切换时，书签、标签页和浏览历史记录将完全独立保存。全新的个人资料功能适用于 Windows 11、Mac 和 Linux 用户，Windows 10 即将支持。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p> <p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-0fae6a9eeb.png"></p> </li>
<li>
<p>现在，可以关闭<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsupport.mozilla.org%2Fkb%2Fabout-picture-picture-firefox" target="_blank">画中画</a>窗口而无需暂停视频。按下<code>Shift + Click</code>关闭按钮或使用<code>Shift + Esc</code>退出，同时保持播放不间断。</p>
</li>
<li>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsupport.mozilla.org%2Fkb%2Fmanage-your-logins-firefox-password-manager" target="_blank">Firefox Password Manager</a>&nbsp;中存储的登录信息现在使用现代加密方案 (AES-256-CBC) 在磁盘上加密，取代了旧版的 3DES-CBC。此更改增强了本地数据保护。通过 Firefox Sync 同步的登录信息仍保持端到端加密，并且已使用 AES-256-GCM。</p>
</li>
<li>
<p><strong>Visual search powered by Google Lens</strong></p>
<p>只需右键单击任意图像，现在就可以：</p>
<ul>
<li>查找类似的产品、地点或物品</li>
<li>从图像中复制、翻译或搜索文本</li>
<li>获取学习、旅行或购物的灵感</li>
</ul>
<p>在右键菜单中找到新的“<strong>Search Image with Google Lens</strong>”选项（初始显示为带<strong>“NEW”</strong>标识的选项）。 此<strong>功能仅限桌面端</strong>，并已在全球范围内推出。<strong>必须将默认搜索引擎设置为 Google&nbsp;</strong>才能使用此功能。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-e163684ac8.png"></p>
</li>
<li><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><strong>Firefox 中的 Perplexity AI 搜索</strong></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>&nbsp;<span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>在桌面版 Firefox 中，现已集成&nbsp;<strong>Perplexity</strong>。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></li>
<li> <p><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>现可翻译以下语言：</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p>
<ul>
<li>阿塞拜疆</li>
<li>孟加拉语</li>
<li>冰岛语</li>
</ul> </li>
</ul>
<p><strong>Fixed</strong></p>
<ul>
<li>各种<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.mozilla.org%2Fsecurity%2Fadvisories%2Fmfsa2025-81" target="_blank">安全修复</a>。</li>
<li> <p><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>以下语言的翻译质量已得到提高：</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p>
<ul>
<li>阿拉伯</li>
<li>保加利亚语</li>
<li>加泰罗尼亚语</li>
<li>简体中文</li>
<li>捷克语</li>
<li>荷兰语</li>
<li>爱沙尼亚语</li>
<li>芬兰</li>
<li>法语</li>
<li>德语</li>
<li>匈牙利</li>
<li>意大利语</li>
<li>日语</li>
<li>葡萄牙语</li>
<li>波斯语</li>
<li>西班牙语</li>
<li>乌克兰语</li>
</ul> </li>
</ul>
<p><strong>Changed</strong></p>
<ul>
<li><span>在 Windows 上，当从另一个应用程序打开链接时，Firefox 将仅使用当前虚拟桌面上的窗口或在需要时打开一个新窗口。</span></li>
</ul>
<p><strong>Developer</strong></p>
<ul>
<li>
<p>现在可以从样式规则中的<code>var()</code>函数内跳转到 CSS 自定义属性的定义。</p>
</li>
<li>
<p>现在，检查器中的事件工具提示会在自定义事件旁边显示一个标识，从而更容易将它们与内置事件区分开来。</p>
</li>
</ul>
<p><strong>Web Platform</strong></p>
<ul>
<li>
<p>Firefox 现在支持<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FElement%2FmoveBefore" target="_blank">Element.moveBefore</a>&nbsp;API。</p>
</li>
<li>
<p>Firefox 现在支持<code>math-shift</code>&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FCSS%2Fmath-shift%23compact" target="_blank">compact</a>。</p>
</li>
<li>
<p>Firefox 现已支持<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FPerformanceEventTiming%2FinteractionId" target="_blank">PerformanceEventTiming.interactionId</a>，允许开发者对相关输入事件进行分组。这为 Interaction to Next Paint (INP) responsiveness metric 提供了支持。</p>
</li>
<li>
<p>Firefox 现在支持<code>command</code>和<code>commandfor</code>属性。</p>
</li>
<li>
<p>Firefox 现在支持&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FView_Transition_API" target="_blank">View Transitions</a>&nbsp;API Level 1。View Transitions API 提供了一种在不同网站视图之间轻松创建动画过渡的机制。</p>
</li>
<li>
<p>现在，当使用硬件 WebRender 渲染<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FCSS%2Fgradient%2Flinear-gradient" target="_blank">线性渐变</a>、<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FCSS%2Fgradient%2Fconic-gradient" target="_blank">圆锥渐变</a>和<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FCSS%2Fgradient%2Fradial-gradient" target="_blank">径向渐变</a>时，会应用抖动。</p>
</li>
<li> <p>Firefox 现在支持&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ftc39%2Fproposal-upsert" target="_blank">upsert 提案</a>。该提案为<code>Map</code>和<code>WeakMap</code>添加<code>getOrInsert</code>和<code>getOrInsertComputed</code>方法。这些方法可返回键关联的值，或插入默认值后返回该值，简化了处理键是否存在于<code>Map</code>和<code>WeakMap</code>中的场景。</p> </li>
<li>
<p>Firefox 现已在 Windows 平板和 Android 设备上支持<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FScreenOrientation" target="_blank">ScreenOrientation</a>&nbsp;接口的<code>lock()</code>和<code>unlock()</code>方法。</p>
</li>
<li>
<p>Firefox 现在支持&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FRTCDataChannel" target="_blank">RTCDataChannel</a>&nbsp;的&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FWeb_Workers_API%2FTransferable_objects" target="_blank">worker transfer</a>。</p>
</li>
<li>
<p>Firefox 现在支持<code>resizeMode</code>&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FMediaDevices%2FgetUserMedia" target="_blank">getUserMedia</a>&nbsp;constraint，允许开发人员将从摄像头捕获的视频裁剪和缩小到他们选择的任何分辨率。</p>
</li>
<li>
<p>Firefox 现在支持 Windows 上的&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FWebGPU_API" target="_blank">WebGPU&nbsp;</a><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FGPUDevice%2FimportExternalTexture" target="_blank">GPUDevice.importExternalTexture API 。</a></p>
</li>
<li>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FWebCodecs_API" target="_blank">Windows 上的 WebCodecs</a>&nbsp;现在具有 VideoEncoder 的批量编码路径，由于默认批量大小较大，因此吞吐量更高、提交延迟更低，从而提高了性能。</p>
</li>
<li>
<p>Gecko-specific<code>CSS2Properties</code>已重命名为<code>CSSStyleProperties</code>，以符合最新的 Web 标准并实现与其他浏览器引擎更好的互操作性。</p>
</li>
</ul>
<p>更新说明：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.firefox.com%2Fen-US%2Ffirefox%2F144.0%2Freleasenotes%2F" target="_blank">https://www.firefox.com/en-US/firefox/144.0/releasenotes/</a></p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>Firefox 144.0 现已发布，具体更新内容如下：</p>
<p><strong>New</strong></p>
<ul>
<li> <p>专注于组中的单个标签页，告别杂乱。现在，活动标签页仍会保留在视图中，即使折叠标签组也能保持界面整洁。</p> <p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6722c234bd.png"></p> </li>
<li> <p>标签页组更新。现在，可以将标签页拖放到折叠的组中，而不会自动展开。这既能快速保持界面整洁，又能最大限度减少视觉干扰。</p> </li>
<li>  <p><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsupport.mozilla.org%2Fkb%2Fprofile-management" target="_blank">Profile management 功能</a>将在未来几周内逐步面向全球用户推出，它将你的在线生活划分为不同的个人资料，涵盖工作、学习、度假计划或其他任何你喜欢的用途，从而帮助保护隐私并保持专注。用户可以命名，并使用头像和颜色主题进行自定义，以便于识别；在不同资料间切换时，书签、标签页和浏览历史记录将完全独立保存。全新的个人资料功能适用于 Windows 11、Mac 和 Linux 用户，Windows 10 即将支持。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p> <p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-0fae6a9eeb.png"></p> </li>
<li>
<p>现在，可以关闭<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsupport.mozilla.org%2Fkb%2Fabout-picture-picture-firefox" target="_blank">画中画</a>窗口而无需暂停视频。按下<code>Shift + Click</code>关闭按钮或使用<code>Shift + Esc</code>退出，同时保持播放不间断。</p>
</li>
<li>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsupport.mozilla.org%2Fkb%2Fmanage-your-logins-firefox-password-manager" target="_blank">Firefox Password Manager</a>&nbsp;中存储的登录信息现在使用现代加密方案 (AES-256-CBC) 在磁盘上加密，取代了旧版的 3DES-CBC。此更改增强了本地数据保护。通过 Firefox Sync 同步的登录信息仍保持端到端加密，并且已使用 AES-256-GCM。</p>
</li>
<li>
<p><strong>Visual search powered by Google Lens</strong></p>
<p>只需右键单击任意图像，现在就可以：</p>
<ul>
<li>查找类似的产品、地点或物品</li>
<li>从图像中复制、翻译或搜索文本</li>
<li>获取学习、旅行或购物的灵感</li>
</ul>
<p>在右键菜单中找到新的“<strong>Search Image with Google Lens</strong>”选项（初始显示为带<strong>“NEW”</strong>标识的选项）。 此<strong>功能仅限桌面端</strong>，并已在全球范围内推出。<strong>必须将默认搜索引擎设置为 Google&nbsp;</strong>才能使用此功能。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-e163684ac8.png"></p>
</li>
<li><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><strong>Firefox 中的 Perplexity AI 搜索</strong></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>&nbsp;<span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>在桌面版 Firefox 中，现已集成&nbsp;<strong>Perplexity</strong>。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></li>
<li> <p><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>现可翻译以下语言：</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p>
<ul>
<li>阿塞拜疆</li>
<li>孟加拉语</li>
<li>冰岛语</li>
</ul> </li>
</ul>
<p><strong>Fixed</strong></p>
<ul>
<li>各种<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.mozilla.org%2Fsecurity%2Fadvisories%2Fmfsa2025-81" target="_blank">安全修复</a>。</li>
<li> <p><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>以下语言的翻译质量已得到提高：</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p>
<ul>
<li>阿拉伯</li>
<li>保加利亚语</li>
<li>加泰罗尼亚语</li>
<li>简体中文</li>
<li>捷克语</li>
<li>荷兰语</li>
<li>爱沙尼亚语</li>
<li>芬兰</li>
<li>法语</li>
<li>德语</li>
<li>匈牙利</li>
<li>意大利语</li>
<li>日语</li>
<li>葡萄牙语</li>
<li>波斯语</li>
<li>西班牙语</li>
<li>乌克兰语</li>
</ul> </li>
</ul>
<p><strong>Changed</strong></p>
<ul>
<li><span>在 Windows 上，当从另一个应用程序打开链接时，Firefox 将仅使用当前虚拟桌面上的窗口或在需要时打开一个新窗口。</span></li>
</ul>
<p><strong>Developer</strong></p>
<ul>
<li>
<p>现在可以从样式规则中的<code>var()</code>函数内跳转到 CSS 自定义属性的定义。</p>
</li>
<li>
<p>现在，检查器中的事件工具提示会在自定义事件旁边显示一个标识，从而更容易将它们与内置事件区分开来。</p>
</li>
</ul>
<p><strong>Web Platform</strong></p>
<ul>
<li>
<p>Firefox 现在支持<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FElement%2FmoveBefore" target="_blank">Element.moveBefore</a>&nbsp;API。</p>
</li>
<li>
<p>Firefox 现在支持<code>math-shift</code>&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FCSS%2Fmath-shift%23compact" target="_blank">compact</a>。</p>
</li>
<li>
<p>Firefox 现已支持<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FPerformanceEventTiming%2FinteractionId" target="_blank">PerformanceEventTiming.interactionId</a>，允许开发者对相关输入事件进行分组。这为 Interaction to Next Paint (INP) responsiveness metric 提供了支持。</p>
</li>
<li>
<p>Firefox 现在支持<code>command</code>和<code>commandfor</code>属性。</p>
</li>
<li>
<p>Firefox 现在支持&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FView_Transition_API" target="_blank">View Transitions</a>&nbsp;API Level 1。View Transitions API 提供了一种在不同网站视图之间轻松创建动画过渡的机制。</p>
</li>
<li>
<p>现在，当使用硬件 WebRender 渲染<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FCSS%2Fgradient%2Flinear-gradient" target="_blank">线性渐变</a>、<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FCSS%2Fgradient%2Fconic-gradient" target="_blank">圆锥渐变</a>和<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FCSS%2Fgradient%2Fradial-gradient" target="_blank">径向渐变</a>时，会应用抖动。</p>
</li>
<li> <p>Firefox 现在支持&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ftc39%2Fproposal-upsert" target="_blank">upsert 提案</a>。该提案为<code>Map</code>和<code>WeakMap</code>添加<code>getOrInsert</code>和<code>getOrInsertComputed</code>方法。这些方法可返回键关联的值，或插入默认值后返回该值，简化了处理键是否存在于<code>Map</code>和<code>WeakMap</code>中的场景。</p> </li>
<li>
<p>Firefox 现已在 Windows 平板和 Android 设备上支持<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FScreenOrientation" target="_blank">ScreenOrientation</a>&nbsp;接口的<code>lock()</code>和<code>unlock()</code>方法。</p>
</li>
<li>
<p>Firefox 现在支持&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FRTCDataChannel" target="_blank">RTCDataChannel</a>&nbsp;的&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FWeb_Workers_API%2FTransferable_objects" target="_blank">worker transfer</a>。</p>
</li>
<li>
<p>Firefox 现在支持<code>resizeMode</code>&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FMediaDevices%2FgetUserMedia" target="_blank">getUserMedia</a>&nbsp;constraint，允许开发人员将从摄像头捕获的视频裁剪和缩小到他们选择的任何分辨率。</p>
</li>
<li>
<p>Firefox 现在支持 Windows 上的&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FWebGPU_API" target="_blank">WebGPU&nbsp;</a><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FGPUDevice%2FimportExternalTexture" target="_blank">GPUDevice.importExternalTexture API 。</a></p>
</li>
<li>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FWebCodecs_API" target="_blank">Windows 上的 WebCodecs</a>&nbsp;现在具有 VideoEncoder 的批量编码路径，由于默认批量大小较大，因此吞吐量更高、提交延迟更低，从而提高了性能。</p>
</li>
<li>
<p>Gecko-specific<code>CSS2Properties</code>已重命名为<code>CSSStyleProperties</code>，以符合最新的 Web 标准并实现与其他浏览器引擎更好的互操作性。</p>
</li>
</ul>
<p>更新说明：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.firefox.com%2Fen-US%2Ffirefox%2F144.0%2Freleasenotes%2F" target="_blank">https://www.firefox.com/en-US/firefox/144.0/releasenotes/</a></p>]]>
    </description>
    <content:encoded><![CDATA[<p>Firefox 144.0 现已发布，具体更新内容如下：</p>
<p><strong>New</strong></p>
<ul>
<li> <p>专注于组中的单个标签页，告别杂乱。现在，活动标签页仍会保留在视图中，即使折叠标签组也能保持界面整洁。</p> <p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6722c234bd.png"></p> </li>
<li> <p>标签页组更新。现在，可以将标签页拖放到折叠的组中，而不会自动展开。这既能快速保持界面整洁，又能最大限度减少视觉干扰。</p> </li>
<li>  <p><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsupport.mozilla.org%2Fkb%2Fprofile-management" target="_blank">Profile management 功能</a>将在未来几周内逐步面向全球用户推出，它将你的在线生活划分为不同的个人资料，涵盖工作、学习、度假计划或其他任何你喜欢的用途，从而帮助保护隐私并保持专注。用户可以命名，并使用头像和颜色主题进行自定义，以便于识别；在不同资料间切换时，书签、标签页和浏览历史记录将完全独立保存。全新的个人资料功能适用于 Windows 11、Mac 和 Linux 用户，Windows 10 即将支持。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p> <p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-0fae6a9eeb.png"></p> </li>
<li>
<p>现在，可以关闭<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsupport.mozilla.org%2Fkb%2Fabout-picture-picture-firefox" target="_blank">画中画</a>窗口而无需暂停视频。按下<code>Shift + Click</code>关闭按钮或使用<code>Shift + Esc</code>退出，同时保持播放不间断。</p>
</li>
<li>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsupport.mozilla.org%2Fkb%2Fmanage-your-logins-firefox-password-manager" target="_blank">Firefox Password Manager</a>&nbsp;中存储的登录信息现在使用现代加密方案 (AES-256-CBC) 在磁盘上加密，取代了旧版的 3DES-CBC。此更改增强了本地数据保护。通过 Firefox Sync 同步的登录信息仍保持端到端加密，并且已使用 AES-256-GCM。</p>
</li>
<li>
<p><strong>Visual search powered by Google Lens</strong></p>
<p>只需右键单击任意图像，现在就可以：</p>
<ul>
<li>查找类似的产品、地点或物品</li>
<li>从图像中复制、翻译或搜索文本</li>
<li>获取学习、旅行或购物的灵感</li>
</ul>
<p>在右键菜单中找到新的“<strong>Search Image with Google Lens</strong>”选项（初始显示为带<strong>“NEW”</strong>标识的选项）。 此<strong>功能仅限桌面端</strong>，并已在全球范围内推出。<strong>必须将默认搜索引擎设置为 Google&nbsp;</strong>才能使用此功能。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-e163684ac8.png"></p>
</li>
<li><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><strong>Firefox 中的 Perplexity AI 搜索</strong></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>&nbsp;<span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>在桌面版 Firefox 中，现已集成&nbsp;<strong>Perplexity</strong>。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></li>
<li> <p><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>现可翻译以下语言：</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p>
<ul>
<li>阿塞拜疆</li>
<li>孟加拉语</li>
<li>冰岛语</li>
</ul> </li>
</ul>
<p><strong>Fixed</strong></p>
<ul>
<li>各种<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.mozilla.org%2Fsecurity%2Fadvisories%2Fmfsa2025-81" target="_blank">安全修复</a>。</li>
<li> <p><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>以下语言的翻译质量已得到提高：</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p>
<ul>
<li>阿拉伯</li>
<li>保加利亚语</li>
<li>加泰罗尼亚语</li>
<li>简体中文</li>
<li>捷克语</li>
<li>荷兰语</li>
<li>爱沙尼亚语</li>
<li>芬兰</li>
<li>法语</li>
<li>德语</li>
<li>匈牙利</li>
<li>意大利语</li>
<li>日语</li>
<li>葡萄牙语</li>
<li>波斯语</li>
<li>西班牙语</li>
<li>乌克兰语</li>
</ul> </li>
</ul>
<p><strong>Changed</strong></p>
<ul>
<li><span>在 Windows 上，当从另一个应用程序打开链接时，Firefox 将仅使用当前虚拟桌面上的窗口或在需要时打开一个新窗口。</span></li>
</ul>
<p><strong>Developer</strong></p>
<ul>
<li>
<p>现在可以从样式规则中的<code>var()</code>函数内跳转到 CSS 自定义属性的定义。</p>
</li>
<li>
<p>现在，检查器中的事件工具提示会在自定义事件旁边显示一个标识，从而更容易将它们与内置事件区分开来。</p>
</li>
</ul>
<p><strong>Web Platform</strong></p>
<ul>
<li>
<p>Firefox 现在支持<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FElement%2FmoveBefore" target="_blank">Element.moveBefore</a>&nbsp;API。</p>
</li>
<li>
<p>Firefox 现在支持<code>math-shift</code>&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FCSS%2Fmath-shift%23compact" target="_blank">compact</a>。</p>
</li>
<li>
<p>Firefox 现已支持<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FPerformanceEventTiming%2FinteractionId" target="_blank">PerformanceEventTiming.interactionId</a>，允许开发者对相关输入事件进行分组。这为 Interaction to Next Paint (INP) responsiveness metric 提供了支持。</p>
</li>
<li>
<p>Firefox 现在支持<code>command</code>和<code>commandfor</code>属性。</p>
</li>
<li>
<p>Firefox 现在支持&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FView_Transition_API" target="_blank">View Transitions</a>&nbsp;API Level 1。View Transitions API 提供了一种在不同网站视图之间轻松创建动画过渡的机制。</p>
</li>
<li>
<p>现在，当使用硬件 WebRender 渲染<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FCSS%2Fgradient%2Flinear-gradient" target="_blank">线性渐变</a>、<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FCSS%2Fgradient%2Fconic-gradient" target="_blank">圆锥渐变</a>和<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FCSS%2Fgradient%2Fradial-gradient" target="_blank">径向渐变</a>时，会应用抖动。</p>
</li>
<li> <p>Firefox 现在支持&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ftc39%2Fproposal-upsert" target="_blank">upsert 提案</a>。该提案为<code>Map</code>和<code>WeakMap</code>添加<code>getOrInsert</code>和<code>getOrInsertComputed</code>方法。这些方法可返回键关联的值，或插入默认值后返回该值，简化了处理键是否存在于<code>Map</code>和<code>WeakMap</code>中的场景。</p> </li>
<li>
<p>Firefox 现已在 Windows 平板和 Android 设备上支持<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FScreenOrientation" target="_blank">ScreenOrientation</a>&nbsp;接口的<code>lock()</code>和<code>unlock()</code>方法。</p>
</li>
<li>
<p>Firefox 现在支持&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FRTCDataChannel" target="_blank">RTCDataChannel</a>&nbsp;的&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FWeb_Workers_API%2FTransferable_objects" target="_blank">worker transfer</a>。</p>
</li>
<li>
<p>Firefox 现在支持<code>resizeMode</code>&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FMediaDevices%2FgetUserMedia" target="_blank">getUserMedia</a>&nbsp;constraint，允许开发人员将从摄像头捕获的视频裁剪和缩小到他们选择的任何分辨率。</p>
</li>
<li>
<p>Firefox 现在支持 Windows 上的&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FWebGPU_API" target="_blank">WebGPU&nbsp;</a><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FGPUDevice%2FimportExternalTexture" target="_blank">GPUDevice.importExternalTexture API 。</a></p>
</li>
<li>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FWebCodecs_API" target="_blank">Windows 上的 WebCodecs</a>&nbsp;现在具有 VideoEncoder 的批量编码路径，由于默认批量大小较大，因此吞吐量更高、提交延迟更低，从而提高了性能。</p>
</li>
<li>
<p>Gecko-specific<code>CSS2Properties</code>已重命名为<code>CSSStyleProperties</code>，以符合最新的 Web 标准并实现与其他浏览器引擎更好的互操作性。</p>
</li>
</ul>
<p>更新说明：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.firefox.com%2Fen-US%2Ffirefox%2F144.0%2Freleasenotes%2F" target="_blank">https://www.firefox.com/en-US/firefox/144.0/releasenotes/</a></p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6722c234bd.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6722c234bd.png" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 10:30:38 +0800</pubDate>
  </item><item>
    <title><![CDATA[通义千问 Qwen3-VL 上新：4B &amp; 8B 稠密模型]]></title>
    <link>https://www.oschina.net/news/377479</link>
    <itunes:title><![CDATA[通义千问 Qwen3-VL 上新：4B &amp; 8B 稠密模型]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>阿里通义 Qwen 团队正式发布 Qwen3-VL 系列的全新成员 —— 4B 与 8B 模型。Qwen3-VL 系列模型于上月<a href="https://www.oschina.net/news/374093" target="_blank">发布</a>，是迄今为止 Qwen 系列中最强大的视觉语言模型。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-a3b515f16e.png"></p>
<p>本次发布包含了 4B 和 8B 两种参数规模，两个尺寸均提供&nbsp;Instruct&nbsp;与&nbsp;Thinking&nbsp;版本。</p>
<p>新模型实现了以下关键目标:</p>
<ul>
<li>更低的资源门槛：尺寸缩减显著降低 VRAM 的占用。现在，开发者可以在更广泛的硬件设备上部署和运行模型。</li>
<li>在缩减尺寸的同时，完整保留了 Qwen3-VL 的全部核心功能。</li>
<li>卓越的基准性能:&nbsp;在 STEM、VQA、OCR、视频理解及 Agent 任务等多个权威基准上，其表现不仅超越了 Gemini&nbsp;2.5&nbsp;Flash&nbsp;Lite 和 GPT-5&nbsp;Nano，在许多场景下甚至能与半年前的旗舰模型 Qwen2.5-VL-72B 相媲美。</li>
</ul>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-ef692ad5ec.jpg"></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-d0626c8c72.jpg"></p>
<p>模型地址：<em>https://huggingface.co/collections/Qwen/qwen3-vl-68d2a7c1b8a8afce4ebd2dbe</em></p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>阿里通义 Qwen 团队正式发布 Qwen3-VL 系列的全新成员 —— 4B 与 8B 模型。Qwen3-VL 系列模型于上月<a href="https://www.oschina.net/news/374093" target="_blank">发布</a>，是迄今为止 Qwen 系列中最强大的视觉语言模型。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-a3b515f16e.png"></p>
<p>本次发布包含了 4B 和 8B 两种参数规模，两个尺寸均提供&nbsp;Instruct&nbsp;与&nbsp;Thinking&nbsp;版本。</p>
<p>新模型实现了以下关键目标:</p>
<ul>
<li>更低的资源门槛：尺寸缩减显著降低 VRAM 的占用。现在，开发者可以在更广泛的硬件设备上部署和运行模型。</li>
<li>在缩减尺寸的同时，完整保留了 Qwen3-VL 的全部核心功能。</li>
<li>卓越的基准性能:&nbsp;在 STEM、VQA、OCR、视频理解及 Agent 任务等多个权威基准上，其表现不仅超越了 Gemini&nbsp;2.5&nbsp;Flash&nbsp;Lite 和 GPT-5&nbsp;Nano，在许多场景下甚至能与半年前的旗舰模型 Qwen2.5-VL-72B 相媲美。</li>
</ul>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-ef692ad5ec.jpg"></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-d0626c8c72.jpg"></p>
<p>模型地址：<em>https://huggingface.co/collections/Qwen/qwen3-vl-68d2a7c1b8a8afce4ebd2dbe</em></p>]]>
    </description>
    <content:encoded><![CDATA[<p>阿里通义 Qwen 团队正式发布 Qwen3-VL 系列的全新成员 —— 4B 与 8B 模型。Qwen3-VL 系列模型于上月<a href="https://www.oschina.net/news/374093" target="_blank">发布</a>，是迄今为止 Qwen 系列中最强大的视觉语言模型。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-a3b515f16e.png"></p>
<p>本次发布包含了 4B 和 8B 两种参数规模，两个尺寸均提供&nbsp;Instruct&nbsp;与&nbsp;Thinking&nbsp;版本。</p>
<p>新模型实现了以下关键目标:</p>
<ul>
<li>更低的资源门槛：尺寸缩减显著降低 VRAM 的占用。现在，开发者可以在更广泛的硬件设备上部署和运行模型。</li>
<li>在缩减尺寸的同时，完整保留了 Qwen3-VL 的全部核心功能。</li>
<li>卓越的基准性能:&nbsp;在 STEM、VQA、OCR、视频理解及 Agent 任务等多个权威基准上，其表现不仅超越了 Gemini&nbsp;2.5&nbsp;Flash&nbsp;Lite 和 GPT-5&nbsp;Nano，在许多场景下甚至能与半年前的旗舰模型 Qwen2.5-VL-72B 相媲美。</li>
</ul>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-ef692ad5ec.jpg"></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-d0626c8c72.jpg"></p>
<p>模型地址：<em>https://huggingface.co/collections/Qwen/qwen3-vl-68d2a7c1b8a8afce4ebd2dbe</em></p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-a3b515f16e.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-a3b515f16e.png" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 10:19:40 +0800</pubDate>
  </item><item>
    <title><![CDATA[OpenAI CEO 称 ChatGPT 将发布新版本，允许提供成人内容]]></title>
    <link>https://www.oschina.net/news/377476</link>
    <itunes:title><![CDATA[OpenAI CEO 称 ChatGPT 将发布新版本，允许提供成人内容]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>OpenAI CEO Sam Altman <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fsama%2Fstatus%2F1978129344598827128" target="_blank">宣布</a>，ChatGPT 将会在未来几周内发布新版本，<strong>并会在 12 月推出更为全面的年龄分级，允许 ChatGPT 提供成人内容</strong>。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6ddcb220a1.png"></p>
<p>Altman 表示，此前 OpenAI 对 ChatGPT 有不少内容限制，并且对心理健康问题一直保持谨慎态度。Altman 称团队意识到这使许多没有心理健康问题的用户觉得 ChatGPT 用起来“不爽”或“不愉快”，但鉴于问题的严重性，我们希望做到这一点。（指内容限制）</p>
<p>目前，针对开放内容限制，Altman 透露 OpenAI 已经能够减轻严重的心理健康问题，并且拥有了新的工具，团队将能够在大多数情况下安全地放宽限制。</p>
<p>Altman 透露，未来几周内，新版本的 ChatGPT 能够实现更有“人味”的回应方式，能用大量的 emoji，表现得像朋友一样。</p>
<p>同时，Altman 还宣布，ChatGPT 将会在今年 12 月推出更全面的年龄分级，并作为“将成年用户视为成年人”原则的一部分。具体来看，ChatGPT 将允许更多内容生成，例如能够为通过“成年验证”的成年人提供色情内容。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>OpenAI CEO Sam Altman <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fsama%2Fstatus%2F1978129344598827128" target="_blank">宣布</a>，ChatGPT 将会在未来几周内发布新版本，<strong>并会在 12 月推出更为全面的年龄分级，允许 ChatGPT 提供成人内容</strong>。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6ddcb220a1.png"></p>
<p>Altman 表示，此前 OpenAI 对 ChatGPT 有不少内容限制，并且对心理健康问题一直保持谨慎态度。Altman 称团队意识到这使许多没有心理健康问题的用户觉得 ChatGPT 用起来“不爽”或“不愉快”，但鉴于问题的严重性，我们希望做到这一点。（指内容限制）</p>
<p>目前，针对开放内容限制，Altman 透露 OpenAI 已经能够减轻严重的心理健康问题，并且拥有了新的工具，团队将能够在大多数情况下安全地放宽限制。</p>
<p>Altman 透露，未来几周内，新版本的 ChatGPT 能够实现更有“人味”的回应方式，能用大量的 emoji，表现得像朋友一样。</p>
<p>同时，Altman 还宣布，ChatGPT 将会在今年 12 月推出更全面的年龄分级，并作为“将成年用户视为成年人”原则的一部分。具体来看，ChatGPT 将允许更多内容生成，例如能够为通过“成年验证”的成年人提供色情内容。</p>]]>
    </description>
    <content:encoded><![CDATA[<p>OpenAI CEO Sam Altman <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fsama%2Fstatus%2F1978129344598827128" target="_blank">宣布</a>，ChatGPT 将会在未来几周内发布新版本，<strong>并会在 12 月推出更为全面的年龄分级，允许 ChatGPT 提供成人内容</strong>。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6ddcb220a1.png"></p>
<p>Altman 表示，此前 OpenAI 对 ChatGPT 有不少内容限制，并且对心理健康问题一直保持谨慎态度。Altman 称团队意识到这使许多没有心理健康问题的用户觉得 ChatGPT 用起来“不爽”或“不愉快”，但鉴于问题的严重性，我们希望做到这一点。（指内容限制）</p>
<p>目前，针对开放内容限制，Altman 透露 OpenAI 已经能够减轻严重的心理健康问题，并且拥有了新的工具，团队将能够在大多数情况下安全地放宽限制。</p>
<p>Altman 透露，未来几周内，新版本的 ChatGPT 能够实现更有“人味”的回应方式，能用大量的 emoji，表现得像朋友一样。</p>
<p>同时，Altman 还宣布，ChatGPT 将会在今年 12 月推出更全面的年龄分级，并作为“将成年用户视为成年人”原则的一部分。具体来看，ChatGPT 将允许更多内容生成，例如能够为通过“成年验证”的成年人提供色情内容。</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6ddcb220a1.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6ddcb220a1.png" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 10:12:30 +0800</pubDate>
  </item><item>
    <title><![CDATA[最新数据显示：网络上超过 50% 的文章是 AI 生成的]]></title>
    <link>https://www.oschina.net/news/377475</link>
    <itunes:title><![CDATA[最新数据显示：网络上超过 50% 的文章是 AI 生成的]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>根据<span>最新</span>的研究报告，网络上约有一半的新文章是由人工智能生成的。这项研究由 SEO 公司 Graphite 发布，分析了2020年1月至2025年5月间发布的65000篇英文文章。为了评估这些文章是否由 AI 撰写，研究团队使用了名为 Surfer 的 AI 检测工具，任何被判定为50% 以上内容由大型语言模型生成的文章都被视为 AI 生成的。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6a425afd08.png"></p>
<p>自从2022年11月 ChatGPT 公开推出以来，AI 生成内容的数量呈现出快速上升的趋势。根据报告的数据，AI 生成的文章比例从2022年底的约10% 迅速上升到2024年的40% 以上，之后的增长速度有所放缓。到2025年5月，AI 生成的文章所占比例达到52%，与人类写作的文章数量相当，双方呈现出五五开的局面。</p>
<p>更令人欣慰的是，AI 文章的比例似乎已达到一个平台期。在2024年11月达到高峰后，AI 和人类写作的文章比例一直在50% 左右徘徊。此外，研究者指出，实际上人类撰写的文章比例可能更高，因为许多付费网站开始阻止 Common Crawl（一个开源数据集）对其页面的索引。这意味着一些人类写作的内容可能被排除在分析之外。</p>
<p>需要注意的是，AI 检测工具的准确性也是值得怀疑的。在对 Surfer 进行测试时，Graphite 发现其将4.2% 的人工撰写文章误判为 AI 生成，而将0.6% 的 AI 生成文章误判为人类撰写。因此，尽管 AI 生成文章数量在上升，但在搜索引擎和聊天机器人响应中，人类写作的文章仍占据<span>绝对</span>优势。</p>
<p>关于 AI 文章数量停滞的原因，目前尚不明确。根据 Graphite 的第二份报告，AI 内容生成者可能意识到，劣质的 AI 生成内容在搜索引擎中的曝光率不高，因此越来越多的文章是由人类创作的，数据显示在 Google 搜索中，86% 的文章是人类撰写的，仅有14% 是 AI 生成的。</p>
<p>如今，越来越多的作家开始在创作过程中使用 AI 聊天机器人等工具，这种情况模糊了机器生成内容和人类创作内容之间的界限。正如加州大学洛杉矶分校计算机科学教授斯特凡诺・索阿托所说:“此时，机器与人类的关系更像是一种共生关系，而不是简单的对立关系。”</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>根据<span>最新</span>的研究报告，网络上约有一半的新文章是由人工智能生成的。这项研究由 SEO 公司 Graphite 发布，分析了2020年1月至2025年5月间发布的65000篇英文文章。为了评估这些文章是否由 AI 撰写，研究团队使用了名为 Surfer 的 AI 检测工具，任何被判定为50% 以上内容由大型语言模型生成的文章都被视为 AI 生成的。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6a425afd08.png"></p>
<p>自从2022年11月 ChatGPT 公开推出以来，AI 生成内容的数量呈现出快速上升的趋势。根据报告的数据，AI 生成的文章比例从2022年底的约10% 迅速上升到2024年的40% 以上，之后的增长速度有所放缓。到2025年5月，AI 生成的文章所占比例达到52%，与人类写作的文章数量相当，双方呈现出五五开的局面。</p>
<p>更令人欣慰的是，AI 文章的比例似乎已达到一个平台期。在2024年11月达到高峰后，AI 和人类写作的文章比例一直在50% 左右徘徊。此外，研究者指出，实际上人类撰写的文章比例可能更高，因为许多付费网站开始阻止 Common Crawl（一个开源数据集）对其页面的索引。这意味着一些人类写作的内容可能被排除在分析之外。</p>
<p>需要注意的是，AI 检测工具的准确性也是值得怀疑的。在对 Surfer 进行测试时，Graphite 发现其将4.2% 的人工撰写文章误判为 AI 生成，而将0.6% 的 AI 生成文章误判为人类撰写。因此，尽管 AI 生成文章数量在上升，但在搜索引擎和聊天机器人响应中，人类写作的文章仍占据<span>绝对</span>优势。</p>
<p>关于 AI 文章数量停滞的原因，目前尚不明确。根据 Graphite 的第二份报告，AI 内容生成者可能意识到，劣质的 AI 生成内容在搜索引擎中的曝光率不高，因此越来越多的文章是由人类创作的，数据显示在 Google 搜索中，86% 的文章是人类撰写的，仅有14% 是 AI 生成的。</p>
<p>如今，越来越多的作家开始在创作过程中使用 AI 聊天机器人等工具，这种情况模糊了机器生成内容和人类创作内容之间的界限。正如加州大学洛杉矶分校计算机科学教授斯特凡诺・索阿托所说:“此时，机器与人类的关系更像是一种共生关系，而不是简单的对立关系。”</p>]]>
    </description>
    <content:encoded><![CDATA[<p>根据<span>最新</span>的研究报告，网络上约有一半的新文章是由人工智能生成的。这项研究由 SEO 公司 Graphite 发布，分析了2020年1月至2025年5月间发布的65000篇英文文章。为了评估这些文章是否由 AI 撰写，研究团队使用了名为 Surfer 的 AI 检测工具，任何被判定为50% 以上内容由大型语言模型生成的文章都被视为 AI 生成的。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6a425afd08.png"></p>
<p>自从2022年11月 ChatGPT 公开推出以来，AI 生成内容的数量呈现出快速上升的趋势。根据报告的数据，AI 生成的文章比例从2022年底的约10% 迅速上升到2024年的40% 以上，之后的增长速度有所放缓。到2025年5月，AI 生成的文章所占比例达到52%，与人类写作的文章数量相当，双方呈现出五五开的局面。</p>
<p>更令人欣慰的是，AI 文章的比例似乎已达到一个平台期。在2024年11月达到高峰后，AI 和人类写作的文章比例一直在50% 左右徘徊。此外，研究者指出，实际上人类撰写的文章比例可能更高，因为许多付费网站开始阻止 Common Crawl（一个开源数据集）对其页面的索引。这意味着一些人类写作的内容可能被排除在分析之外。</p>
<p>需要注意的是，AI 检测工具的准确性也是值得怀疑的。在对 Surfer 进行测试时，Graphite 发现其将4.2% 的人工撰写文章误判为 AI 生成，而将0.6% 的 AI 生成文章误判为人类撰写。因此，尽管 AI 生成文章数量在上升，但在搜索引擎和聊天机器人响应中，人类写作的文章仍占据<span>绝对</span>优势。</p>
<p>关于 AI 文章数量停滞的原因，目前尚不明确。根据 Graphite 的第二份报告，AI 内容生成者可能意识到，劣质的 AI 生成内容在搜索引擎中的曝光率不高，因此越来越多的文章是由人类创作的，数据显示在 Google 搜索中，86% 的文章是人类撰写的，仅有14% 是 AI 生成的。</p>
<p>如今，越来越多的作家开始在创作过程中使用 AI 聊天机器人等工具，这种情况模糊了机器生成内容和人类创作内容之间的界限。正如加州大学洛杉矶分校计算机科学教授斯特凡诺・索阿托所说:“此时，机器与人类的关系更像是一种共生关系，而不是简单的对立关系。”</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6a425afd08.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6a425afd08.png" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 10:09:20 +0800</pubDate>
  </item><item>
    <title><![CDATA[GreatSQL 8.4.4-4 GA (2025-10-15)]]></title>
    <link>https://www.oschina.net/news/377461</link>
    <itunes:title><![CDATA[GreatSQL 8.4.4-4 GA (2025-10-15)]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<h1><strong>GreatSQL 8.4.4-4 GA (2025-10-15)</strong></h1>
<h2><strong>版本信息</strong></h2>
<ul>
<li> <p>发布时间：2025年10月15日</p> </li>
<li> <p>版本号：8.4.4-4, Revision d73de75905d</p> </li>
<li> <p>下载链接：https://gitee.com/GreatSQL/GreatSQL/releases/tag/GreatSQL-8.4.4-4</p> </li>
<li> <p>用户手册：https://greatsql.cn/docs/8.4.4-4/</p> </li>
</ul>
<h2><strong>特性增强</strong></h2>
<p>GreatSQL 8.4.4.-4版本在Percona Server for MySQL 8.4.4-4版本的基础上，主要在 <strong>高可用</strong>、<strong>高性能</strong>、<strong>高兼容</strong>、<strong>高安全</strong>四个方面进行了多项特性增强，使得 GreatSQL 可在普通硬件上满足金融级应用场景，可作为 MySQL 或 Percona Server for MySQL 的理想可选替换。</p>
<h3><strong>高可用</strong></h3>
<p>针对 MGR 及主从复制进行了大量改进和提升工作，支持 地理标签、仲裁节点、读写动态 VIP、快速单主模式、智能选主 等特性，并针对 流控算法、事务认证队列清理算法、节点加入&amp;退出机制、recovery机制、大事务传输压缩等多个 MGR 底层工作机制算法进行深度优化，进一步提升优化了 MGR 的高可用保障及性能稳定性。</p>
<ul>
<li>支持 地理标签 特性，提升多机房架构数据可靠性。</li>
<li>支持 仲裁节点 特性，用更低的服务器成本实现更高可用。</li>
<li>支持 读写动态 VIP 特性，高可用切换更便捷，更快实现读负载均衡。支持 当主节点切换时，主动关闭当前活跃连接，缩短应用端不可用时长。。</li>
<li>支持 快速单主模式，在单主模式下更快，性能更高。</li>
<li>支持 智能选主 特性，高可用切换选主机制更合理。</li>
<li>优化 流控算法，使得事务更平稳，避免剧烈抖动。</li>
<li>支持 记录 MGR 网络通信开销超过阈值的事件，用于进一步分析和优化。</li>
<li>支持自动选择从最新事务数据的成员节点复制数据，可有效提升 Clone 速度，提高 MGR 的服务可靠性。</li>
<li>在主从复制中，从节点向主节点发起 Binlog 读取请求时支持限速控制。</li>
<li>优化了 asynchronous connection failover 中的故障检测效率，降低主从复制链路断开的时间，提高整体可用性。
<ul>
<li>https://dev.mysql.com/doc/refman/8.0/en/replication-asynchronous-connection-failover.html</li>
</ul> </li>
<li>支持在跨机房容灾场景中的 主主双向复制防止回路 机制。</li>
<li>优化了 MGR 节点加入、退出时可能导致性能剧烈抖动的问题。</li>
<li>解决了个别节点上磁盘空间爆满时导致MGR集群整体被阻塞的问题。</li>
<li>优化了 MGR 事务认证队列清理算法，高负载下不复存在每 60 秒性能抖动问题。</li>
<li>解决了 MGR 中长事务造成无法选主的问题。</li>
<li>修复了 MGR recovery 过程中长时间等待的问题。</li>
<li>优化了MGR大事务传输时压缩超过限制的处理机制。</li>
</ul>
<p>更多信息详见文档：</p>
<ul>
<li>高可用：https://greatsql.cn/docs/8.4.4-4/5-enhance/5-2-ha.html</li>
</ul>
<h3><strong>高性能</strong></h3>
<p>相对 MySQL 及 Percona Server For MySQL 的性能表现更稳定优异，支持 Rapid 引擎、Turbo引擎、事务无锁化、并行 LOAD DATA、异步删除大表、线程池、非阻塞式 DDL、NUMA 亲和调度优化 等特性，在 TPC-C 测试中相对 MySQL 性能提升超过 30%</p>
<ul>
<li>https://greatsql.cn/docs/8.4.4-4/10-optimize/3-5-benchmark-greatsql-vs-mysql-tpcc-report.html</li>
</ul>
<p>在 TPC-H 测试中的性能表现是 MySQL 的十几倍甚至上百倍</p>
<ul>
<li> <p>https://greatsql.cn/docs/8.4.4-4/10-optimize/3-3-benchmark-greatsql-tpch-report.html</p> </li>
<li> <p>支持 大规模并行、基于内存查询、高压缩比的高性能 Rapid 引擎，可将数据分析性能提升几个数量级。</p> </li>
<li> <p>支持 高性能并行查询引擎Turbo，使GreatSQL具备多线程并发的向量化实时查询功能。</p> </li>
<li> <p>优化 InnoDB 事务系统，实现了大锁拆分及无锁化等多种优化方案，OLTP 场景整体性能提升约 20%。</p> </li>
<li> <p>支持 并行 LOAD DATA，适用于频繁导入大批量数据的应用场景，性能可提升约 20 多倍；对于无显式定义主键的场景亦有优化提升。</p> </li>
<li> <p>支持 异步删除大表，提高 InnoDB 引擎运行时性能的稳定性。</p> </li>
<li> <p>支持 线程池，降低了线程创建和销毁的代价，保证高并发下，性能稳定不会明显衰退。</p> </li>
<li> <p>支持 非阻塞式 DDL，可以避免数据库因为必须尽快完成 DDL 操作而导致业务请求大量被阻塞的问题。</p> </li>
<li> <p>支持 NUMA 亲和性优化，通过 NUMA 亲和性调度优化，将前端用户线程和后台线程绑定到固定 NUMA 节点上以提升线程处理性能。</p> </li>
</ul>
<p>更多信息详见文档：</p>
<ul>
<li>高性能：https://greatsql.cn/docs/8.4.4-4/5-enhance/5-1-highperf.html</li>
</ul>
<h3><strong>高兼容</strong></h3>
<p>GreatSQL 实现 100% 完全兼容 MySQL 及 Percona Server For MySQL 语法，支持大多数常见 Oracle 语法，包括<code>数据类型兼容</code>、<code>函数兼容</code>、<code>SQL 语法兼容</code>、<code>存储程序兼容</code>等众多兼容扩展用法。</p>
<p>更多信息详见文档：</p>
<ul>
<li>高兼容：https://greatsql.cn/docs/8.4.4-4/5-enhance/5-3-easyuse.html</li>
</ul>
<h3><strong>高安全</strong></h3>
<p>GreatSQL 支持逻辑备份加密、CLONE 备份加密、审计、表空间国密加密、敏感数据脱敏、存储登录历史等多个安全提升特性，进一步保障业务数据安全，更适用于金融级应用场景。</p>
<ul>
<li>支持 mysqldump 逻辑备份加密，提供了利用 mysqldump 逻辑备份的安全加密需求。</li>
<li>支持 Clone 备份加密，提供了利用 Clone 物理备份的安全加密需求。</li>
<li>支持 审计功能，及时记录和发现未授权或不安全行为。</li>
<li>支持 InnoDB 表空间国密加密算法，确保重要数据的加密安全。</li>
<li>支持 基于函数和策略的两种数据脱敏 工作方式，保障敏感用户数据查询结果保密性。</li>
</ul>
<p>通过上述多个安全提升特性，进一步保障业务数据安全。</p>
<p>更多信息详见文档：</p>
<ul>
<li>高安全：https://greatsql.cn/docs/8.4.4-4/5-enhance/5-4-security.html</li>
</ul>
<h3><strong>其他</strong></h3>
<ul>
<li>支持 Clone 在线全量热备、增备及恢复，结合 Binlog 可实现恢复到指定时间点。此外，Clone 备份还支持压缩功能。
<ul>
<li>https://greatsql.cn/docs/8.4.4-4/5-enhance/5-5-clone-compressed-and-incrment-backup.html</li>
</ul> </li>
<li>支持 InnoDB Page透明压缩采用Zstd算法，进一步提高数据压缩率，尤其是当有大量长文本重复数据时。
<ul>
<li>https://greatsql.cn/docs/8.4.4-4/5-enhance/5-5-innodb-page-compression.html</li>
</ul> </li>
</ul>
<h2><strong>注意事项</strong></h2>
<p>从8.0升级到8.4版本，对现有运维管控系统最大的影响是，原先包含 <code>MASTER/SLAVE</code> 关键字的指令不再可用，相应的主要改动详见下表</p>
<table>
<tbody>
<tr>
<th>旧指令</th>
<th>新指令</th>
</tr>
</tbody>
<tbody>
<tr>
<td>START SLAVE</td>
<td>START REPLICA</td>
</tr>
<tr>
<td>STOP SLAVE</td>
<td>STOP REPLICA</td>
</tr>
<tr>
<td>SHOW SLAVE STATUS</td>
<td>SHOW REPLICA STATUS</td>
</tr>
<tr>
<td>SHOW SLAVE HOSTS</td>
<td>SHOW REPLICAS</td>
</tr>
<tr>
<td>RESET SLAVE</td>
<td>RESET REPLICA</td>
</tr>
<tr>
<td>CHANGE MASTER TO</td>
<td>CHANGE REPLICATION SOURCE TO</td>
</tr>
<tr>
<td>RESET MASTER</td>
<td>RESET BINARY LOGS AND GTIDS</td>
</tr>
<tr>
<td>SHOW MASTER STATUS</td>
<td>SHOW BINARY LOG STATUS</td>
</tr>
<tr>
<td>PURGE MASTER LOGS</td>
<td>PURGE BINARY LOGS</td>
</tr>
<tr>
<td>SHOW MASTER LOGS</td>
<td>SHOW BINARY LOGS</td>
</tr>
</tbody>
</table>
<p>此外，原来在 <code>CHANGE MASTER</code>（新的指令 <code>CHANGE REPLICATION SOURCE TO</code>） 以及 <code>START SLAVE</code>（新的指令 <code>START REPLICA</code>） 中相关的参数变量也同样发生变化，详见下表</p>
<table>
<tbody>
<tr>
<th>旧参数名</th>
<th>新参数名</th>
</tr>
</tbody>
<tbody>
<tr>
<td>MASTER_AUTO_POSITION</td>
<td>SOURCE_AUTO_POSITION</td>
</tr>
<tr>
<td>MASTER_HOST</td>
<td>SOURCE_HOST</td>
</tr>
<tr>
<td>MASTER_BIND</td>
<td>SOURCE_BIND</td>
</tr>
<tr>
<td>MASTER_USER</td>
<td>SOURCE_USER</td>
</tr>
<tr>
<td>MASTER_PASSWORD</td>
<td>SOURCE_PASSWORD</td>
</tr>
<tr>
<td>MASTER_PORT</td>
<td>SOURCE_PORT</td>
</tr>
<tr>
<td>MASTER_CONNECT_RETRY</td>
<td>SOURCE_CONNECT_RETRY</td>
</tr>
<tr>
<td>MASTER_RETRY_COUNT</td>
<td>SOURCE_RETRY_COUNT</td>
</tr>
<tr>
<td>MASTER_DELAY</td>
<td>SOURCE_DELAY</td>
</tr>
<tr>
<td>MASTER_SSL</td>
<td>SOURCE_SSL</td>
</tr>
<tr>
<td>MASTER_SSL_CA</td>
<td>SOURCE_SSL_CA</td>
</tr>
<tr>
<td>MASTER_SSL_CAPATH</td>
<td>SOURCE_SSL_CAPATH</td>
</tr>
<tr>
<td>MASTER_SSL_CIPHER</td>
<td>SOURCE_SSL_CIPHER</td>
</tr>
<tr>
<td>MASTER_SSL_CRL</td>
<td>SOURCE_SSL_CRL</td>
</tr>
<tr>
<td>MASTER_SSL_CRLPATH</td>
<td>SOURCE_SSL_CRLPATH</td>
</tr>
<tr>
<td>MASTER_SSL_KEY</td>
<td>SOURCE_SSL_KEY</td>
</tr>
<tr>
<td>MASTER_SSL_VERIFY_SERVER_CERT</td>
<td>SOURCE_SSL_VERIFY_SERVER_CERT</td>
</tr>
<tr>
<td>MASTER_TLS_VERSION</td>
<td>SOURCE_TLS_VERSION</td>
</tr>
<tr>
<td>MASTER_TLS_CIPHERSUITES</td>
<td>SOURCE_TLS_CIPHERSUITES</td>
</tr>
<tr>
<td>MASTER_SSL_CERT</td>
<td>SOURCE_SSL_CERT</td>
</tr>
<tr>
<td>MASTER_PUBLIC_KEY_PATH</td>
<td>SOURCE_PUBLIC_KEY_PATH</td>
</tr>
<tr>
<td>GET_MASTER_PUBLIC_KEY</td>
<td>GET_SOURCE_PUBLIC_KEY</td>
</tr>
<tr>
<td>MASTER_HEARTBEAT_PERIOD</td>
<td>SOURCE_HEARTBEAT_PERIOD</td>
</tr>
<tr>
<td>MASTER_COMPRESSION_ALGORITHMS</td>
<td>SOURCE_COMPRESSION_ALGORITHMS</td>
</tr>
<tr>
<td>MASTER_ZSTD_COMPRESSION_LEVEL</td>
<td>SOURCE_ZSTD_COMPRESSION_LEVEL</td>
</tr>
<tr>
<td>MASTER_LOG_FILE</td>
<td>SOURCE_LOG_FILE</td>
</tr>
<tr>
<td>MASTER_LOG_POS</td>
<td>SOURCE_LOG_POS</td>
</tr>
</tbody>
</table>
<p>执行 SQL 命令 <code>SHOW [GLOBAL] STATUS</code> 的结果中，也有部分状态变量发生变化，详见下表</p>
<table>
<tbody>
<tr>
<th>旧状态变量名</th>
<th>新状态变量名</th>
</tr>
</tbody>
<tbody>
<tr>
<td>Com_slave_start</td>
<td>Com_replica_start</td>
</tr>
<tr>
<td>Com_slave_stop</td>
<td>Com_replica_stop</td>
</tr>
<tr>
<td>Com_show_slave_status</td>
<td>Com_show_replica_status</td>
</tr>
<tr>
<td>Com_show_slave_hosts</td>
<td>Com_show_replicas</td>
</tr>
<tr>
<td>Com_show_master_status</td>
<td>Com_show_binary_log_status</td>
</tr>
<tr>
<td>Com_change_master</td>
<td>Com_change_replication_source</td>
</tr>
</tbody>
</table>
<h2><strong>升级/降级到 GreatSQL 8.4.4-4</strong></h2>
<h3><strong>升级到 GreatSQL 8.4.4-4</strong></h3>
<ul>
<li> <p>如果是 GreatSQL 5.7 等系列版本，可以直接在原来的 <code>datadir</code> 基础上，修改 <code>basedir</code> 后，原地（in-place）启动 GreatSQL 8.0.32-27 版本后，先原地升级到 GreatSQL 8.0.32-27 版本。再继续在该 <code>datadir</code> 基础上升级，即修改 <code>basedir</code> 指向 GreatSQL 8.4.4-4 新版本，再次进行原地升级。需要注意的是，从 5.7 版本升级到 8.0 版本，再升级到 8.4 版本后，数据库中的账号仍采用 <code>mysql_native_password</code> 密码验证插件。当最终升级到 8.4 版本后，需要修改 <em>my.cnf</em> 配置文件，加上 <code>mysql_native_password=1</code>，以保证原有的账号能正常登录。</p> </li>
<li> <p>如果是 GreatSQL 8.0 等系列版本，并且没有使用 <strong>Rapid</strong> 引擎，则可以直接在原来的 <code>datadir</code> 基础上，修改 <code>basedir</code> 后，原地（in-place）启动 GreatSQL 8.4.4-4 后会完成自动升级。</p> </li>
<li> <p>如果旧版本是 GreatSQL 8.0.32-27 且已启用 <strong>Rapid</strong> 引擎，可以直接在原来的 <code>datadir</code> 基础上，修改 <code>basedir</code> 后，原地（in-place）启动 GreatSQL 8.4.4-4 后会完成自动升级。</p> </li>
<li> <p>如果旧版本是 GreatSQL 8.0.32-25 或 8.0.32-26 且已启用 <strong>Rapid</strong> 引擎，<strong>这种情况下无法原地升级</strong>，需要卸载所有 <strong>Rapid</strong> 引擎表，删除 <strong>Rapid</strong> 数据文件，才可以在原来的 <code>datadir</code> 基础上，修改 <code>basedir</code> 后，原地（in-place）启动 GreatSQL 8.4.4-4 后进行自动升级。新版本实例启动后，对所有 <strong>Rapid</strong> 引擎表执行 <code>ALTER TABLE SECONDARY_LOAD</code> 完成全量数据导入，再执行 <code>SELECT START_SECONDARY_ENGINE_INCREMENT_LOAD_TASK()</code> 启动增量导入任务，完成 <strong>Rapid</strong> 引擎表升级工作。下面是一个升级参考过程：</p> <pre><code>&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong style="color:#000000"&gt;1. 查询并记录所有Rapid引擎表&lt;/strong&gt;
&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;可以执行下面的SQL，查询当前有哪些表使用了Rapid引擎：
&lt;pre style="margin-left:5px; margin-right:5px; text-align:left"&gt;
</code></pre> <p><code>greatsql&gt; <span>SELECT</span> TABLE_SCHEMA, TABLE_NAME, TABLE_ROWS <span>FROM</span> information_schema.TABLES <span>WHERE</span> CREATE_OPTIONS <span>LIKE</span> <span>'%Rapid%'</span>; +<em>--------------+----------------+------------+</em> | TABLE_SCHEMA | TABLE_NAME | TABLE_ROWS | +<em>--------------+----------------+------------+</em> | tpch100g | customer | 14854987 | | tpch100g | lineitem | 582868392 | | tpch100g | nation | 25 | | tpch100g | orders | 148492582 | | tpch100g | part | 19943155 | | tpch100g | partsupp | 79832625 | | tpch100g | region | 5 | | tpch100g | supplier | 989416 | +<em>--------------+----------------+------------+</em> </code></p> <pre><code>&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong style="color:#000000"&gt;2. 正常停止GreatSQL实例进程&lt;/strong&gt;
&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;在停止GreatSQL实例进程前，先修改&lt;code&gt;innodb_fast_shutdown=0&lt;/code&gt;后再执行&lt;code&gt;SHUTDOWN&lt;/code&gt;停止实例
&lt;pre style="margin-left:5px; margin-right:5px; text-align:left"&gt;
</code></pre> <p><code>greatsql&gt; <span>SET</span> <span>GLOBAL</span> innodb_fast_shutdown=<span>0</span>; greatsql&gt; SHUTDOWN; </code></p> <pre><code>&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong style="color:#000000"&gt;3. 删除旧的Rapid引擎数据文件&lt;/strong&gt;
&lt;pre style="margin-left:5px; margin-right:5px; text-align:left"&gt;
</code></pre> <p><code><span>cd</span> /data/GreatSQL &amp;&amp; rm -f duckdb* </code></p> <pre><code>&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong style="color:#000000"&gt;4. 修改&lt;code&gt;my.cnf&lt;/code&gt;配置文件中的&lt;code&gt;basedir&lt;/code&gt;参数，指向GreatSQL 8.4.4-4新版本&lt;/strong&gt;
&lt;pre style="margin-left:5px; margin-right:5px; text-align:left"&gt;
</code></pre> <p><code>#my.cnf [mysqld] basedir=/usr/local/GreatSQL-8.4.4-4-Linux-glibc2.28-x86_64 </code></p> <pre><code>&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;并确保参数&lt;code&gt;upgrade&lt;/code&gt;不是设置为&lt;em&gt;NONE&lt;/em&gt;。
&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong style="color:#000000"&gt;5. 启动GreatSQL 8.4.4-4新版本实例&lt;/strong&gt;
&lt;pre style="margin-left:5px; margin-right:5px; text-align:left"&gt;
</code></pre> <p><code>systemctl start greatsql </code></p> <pre><code>&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong style="color:#000000"&gt;6. 重新安装Rapid引擎&lt;/strong&gt;
&lt;pre style="margin-left:5px; margin-right:5px; text-align:left"&gt;
</code></pre> <p><code>greatsql&gt; <span>INSTALL</span> <span>PLUGIN</span> rapid <span>SONAME</span> <span>'ha_rapid.so'</span>; </code></p> <pre><code>&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong style="color:#000000"&gt;7. 对Rapid引擎表做一次全量数据导入&lt;/strong&gt;
&lt;pre style="margin-left:5px; margin-right:5px; text-align:left"&gt;
</code></pre> <p><code>greatsql&gt; <span>ALTER</span> <span>TABLE</span> test.t1 SECONDARY_LOAD; </code></p> </li>
</ul>
<blockquote>
<p>tip 小贴士：由于在升级前没有去掉该表的<code>SECONDARY_ENGINE=rapid</code>属性，所以无需重新设置。如果在升级前卸载所有Rapid引擎表，则需要重新设置。</p>
</blockquote>
<p><strong>8. 再次启动增量导入任务</strong></p>
<pre><code>greatsql&gt; <span>SELECT</span> START_SECONDARY_ENGINE_INCREMENT_LOAD_TASK(<span>'test'</span>, <span>'t1'</span>);
</code></pre>
<p>这就完成Rapid引擎表的升级操作了。</p>
<ul>
<li> <p>如果是 MySQL 5.7 或 Percona Server 5.7 等系列版本，可以直接在原来的 <code>datadir</code> 基础上，修改 <code>basedir</code> 后，原地（in-place）启动 GreatSQL 8.0.32-27 版本后，确认升级成功后，再次在原来 <code>datadir</code> 基础上继续升级，即修改 <code>basedir</code> 指向 GreatSQL 8.4.4-4 新版本，之后就能完成自动升级。需要注意的是，从 5.7 版本升级到 8.0 版本，再升级到 8.4 版本后，数据库中的账号仍采用 <code>mysql_native_password</code> 密码验证插件。当最终升级到 8.4 版本后，需要修改 <em>my.cnf</em> 配置文件，加上 <code>mysql_native_password=1</code>，以保证原有的账号能正常登录。</p> </li>
<li> <p>如果是 MySQL 8.0 或 Percona Server 8.0 等系列版本，则可以直接在原来的 <code>datadir</code> 基础上，修改 <code>basedir</code> 后，原地（in-place）启动 GreatSQL 8.4.4-4 后会完成自动升级。</p> </li>
<li> <p>其他情况下，最好采用导入逻辑备份文件方式升级到 GreatSQL 8.4.4-4 版本。</p> </li>
</ul>
<p>在以上几个原地升级场景中，务必保证<code>my.cnf</code>中参数<code>upgrade</code>不能设置为<em>NONE</em>，可以设置为默认的<em>AUTO</em>或<em>FORCE</em>。例如：</p>
<pre><code>#my.cnf
[mysqld]
upgrade = AUTO
</code></pre>
<p>更多迁移升级方案请参考：</p>
<ul>
<li>迁移升级：https://greatsql.cn/docs/8.4.4-4/7-migrate-and-upgrade/0-migrate-and-upgrade.html</li>
</ul>
<h3><strong>降级到 GreatSQL 8.4.4-4</strong></h3>
<p>如果是要从 MySQL/Percona 8.4 系列较高的小版本降级到 GreatSQL 8.4.4-4 版本，可以采用原地降级方式快速完成版本降级操作。即可以直接在原来的 <code>datadir</code> 基础上，修改 <code>basedir</code> 后，并增加设置参数<code>upgrade=FORCE</code>，原地（in-place）启动 GreatSQL 8.4.4-4 后会完成自动降级。</p>
<p>如果是要从 MySQL/Percona 9.0 及之后的版本降级到 GreatSQL 8.4.4-4 版本，则需要采取逻辑备份 + 逻辑导入方式完成降级操作，并且在逻辑备份导入完成后的首次重启时，务必设置 <code>upgrade=FORCE</code> 强制升级所有数据表，包括系统表。</p>
<p>降级过程操作大致如下所示：</p>
<p><strong>1. 在高版本中逻辑备份全量数据</strong></p>
<pre><code>mysqldump -S/data/MySQL/mysql.sock -A --triggers --routines --events --single-transaction &gt; /data/backup/fulldump.sql
</code></pre>
<p><strong>2. 在GreatSQL 8.4.4-4版本环境中导入逻辑备份文件，完成逻辑恢复</strong></p>
<pre><code>mysql -S/data/GreatSQL/mysql.sock -f &lt; /data/backup/fulldump.sql
</code></pre>
<p><strong>3. 修改<code>my.cnf</code>，确保设置<code>upgrade=FORCE</code></strong></p>
<pre><code>#my.cnf
[mysqld]
upgrade = FORCE
</code></pre>
<p><strong>4. 重启GreatSQL，降级完成</strong></p>
<pre><code>systemctl restart greatsql
</code></pre>
<p>重启过程中，可以看到日志有类似下面的强制降级过程</p>
<pre><code>[Note] [MY-013387] [Server] Upgrading system table data.
[Note] [MY-013385] [Server] Upgrading the sys schema.
[Note] [MY-013400] [Server] Upgrade of help tables started.
[Note] [MY-013400] [Server] Upgrade of help tables completed.
[Note] [MY-013394] [Server] Checking 'mysql' schema.
[Note] [MY-013394] [Server] Checking 'sys' schema.
[System] [MY-014064] [Server] Server downgrade from '80406' to '80404' started.
[System] [MY-014064] [Server] Server downgrade from '80406' to '80404' completed.
</code></pre>
<p>如果不设置 <code>upgrade = FORCE</code> 强制升级所有表，有可能发生系统表 <code>mysql.procs_priv</code> 损坏错误，在创建用户时可能会报告类似下面的错误：</p>
<pre><code>greatsql&gt; <span>CREATE</span> <span>USER</span> tpch <span>IDENTIFIED</span> <span>BY</span> <span>'tpch'</span>;
ERROR 1728 (HY000): Cannot <span>load</span> <span>from</span> mysql.procs_priv. The <span>table</span> <span>is</span> probably corrupted
</code></pre>
<h2><strong>GreatSQL vs MySQL</strong></h2>
<table>
<tbody>
<tr>
<th><strong>1.主要特性</strong></th>
<th>GreatSQL 8.4.4-4</th>
<th>MySQL 8.4.4</th>
</tr>
</tbody>
<tbody>
<tr>
<td>开源</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>ACID 完整性</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>MVCC 特性</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>支持行锁</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>Crash 自动修复</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>表分区（Partitioning）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>视图（Views）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>子查询（Subqueries）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>触发器（Triggers）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>存储程序（Stored Programs）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>外键（Foreign Keys）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>窗口函数（Window Functions）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>通用表表达式 CTE</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>地理信息（GIS）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>基于 GTID 的复制</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>组复制（MGR）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>MyRocks 引擎</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>支持龙芯架构</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td><strong>2. 性能提升扩展</strong></td>
<td>GreatSQL 8.4.4-4</td>
<td>MySQL 8.4.4</td>
</tr>
<tr>
<td>Rapid 引擎</td>
<td>✔️</td>
<td>仅云上HeatWave</td>
</tr>
<tr>
<td>Turbo 引擎</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>NUMA 亲和性优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>非阻塞式 DDL</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>无主键表导入优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>并行 LOAD DATA</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>InnoDB 事务 ReadView 无锁优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>InnoDB 事务大锁拆分优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>InnoDB Page压缩支持Zstd</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>InnoDB 资源组</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>自定义 InnoDB 页大小</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>Contention-Aware Transaction Scheduling</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>InnoDB Mutexes 拆分优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MEMORY 引擎优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>InnoDB Flushing 优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>并行 Doublewrite Buffer</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>InnoDB 快速索引创建优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>VARCHAR/BLOB/JSON 类型存储单列压缩</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>数据字典中存储单列压缩信息</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td><strong>3. 面向开发者提升改进</strong></td>
<td>GreatSQL 8.4.4-4</td>
<td>MySQL 8.4.4</td>
</tr>
<tr>
<td>X API</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>JSON</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>NoSQL Socket-Level接口</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>InnoDB 全文搜索改进</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>更多 Hash/Digest 函数</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Oracle 兼容-数据类型</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Oracle 兼容-函数</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Oracle 兼容-SQL语法</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Oracle 兼容-存储程序</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td><strong>4. 基础特性提升改进</strong></td>
<td>GreatSQL 8.4.4-4</td>
<td>MySQL 8.4.4</td>
</tr>
<tr>
<td>MGR 提升-地理标签</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-仲裁节点</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-读写节点绑定VIP</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-快速单主模式</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-智能选主机制</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-全新流控算法</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-网络分区异常处理</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-节点异常退出处理</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-节点磁盘满处理</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-自动选择 donor 节点</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-大事务压缩优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Clone 增量备份</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Clone 备份压缩</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Binlog 读取限速</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>information_schema 表数量</td>
<td>95</td>
<td>65</td>
</tr>
<tr>
<td>全局性能和状态指标</td>
<td>853</td>
<td>434</td>
</tr>
<tr>
<td>优化器直方图（Histograms）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>Per-Table 性能指标</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Per-Index 性能指标</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Per-User 性能指标</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Per-Client 性能指标</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Per-Thread 性能指标</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>全局查询相应耗时统计</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>SHOW ENGINE INNODB STATUS 增强</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>回滚段信息增强</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>临时表信息增强</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>用户统计信息增强</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Slow log 信息增强</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td><strong>5.安全性提升</strong></td>
<td>GreatSQL 8.4.4-4</td>
<td>MySQL 8.4.4</td>
</tr>
<tr>
<td>国密支持</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>备份加密</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>审计</td>
<td>✔️</td>
<td>仅企业版</td>
</tr>
<tr>
<td>数据脱敏</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>SQL Roles</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>SHA-2 密码Hashing</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>密码轮换策略</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>PAM 认证插件</td>
<td>✔️</td>
<td>仅企业版</td>
</tr>
<tr>
<td>Keyring 存储在文件中</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>Keyring 存储在Hashicorp Vault中</td>
<td>✔️</td>
<td>仅企业版</td>
</tr>
<tr>
<td>InnoDB 数据加密</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>InnoDB 日志加密</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>InnoDB 各种表空间文件加密</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>二进制日志加密</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>临时文件加密</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>强制加密</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td><strong>6. 运维便利性提升</strong></td>
<td>GreatSQL 8.4.4-4</td>
<td>MySQL 8.4.4</td>
</tr>
<tr>
<td>DDL 原子性</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>数据字典存储 InnoDB 表</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>快速 DDL</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>SET PERSIST</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>不可见索引</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>线程池（Threadpool）</td>
<td>✔️</td>
<td>仅企业版</td>
</tr>
<tr>
<td>备份锁</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>SHOW GRANTS 扩展</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>表损坏动作扩展</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>杀掉不活跃事务</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>START TRANSACTION WITH CONSISTENT SNAPSHOT 扩展</td>
<td>✔️</td>
<td>❌</td>
</tr>
</tbody>
</table>
<p>GreatSQL 8.4.4-4 基于 Percona Server for MySQL 8.4.4-4 版本，它在 MySQL 8.4.4 基础上做了大量的改进和提升以及众多新特性，详情请见：</p>
<ul>
<li>Percona Server for MySQL feature comparison: https://docs.percona.com/percona-server/8.4/feature-comparison.html</li>
</ul>
<p>这其中包括线程池、审计、数据脱敏等 MySQL 企业版才有的特性，以及 performance_schema 提升、information_schema 提升、性能和可扩展性提升、用户统计增强、PROCESSLIST 增强、Slow Log 增强等大量改进和提升，这里不一一重复列出。</p>
<h2><strong>GreatSQL Release Notes</strong></h2>
<h3><strong>GreatSQL 8.4</strong></h3>
<ul>
<li>Changes in GreatSQL 8.4.4-4 (2025-10-15) https://greatsql.cn/docs/8.4.4-4/1-docs-intro/relnotes/changes-greatsql-8444.html</li>
</ul>
<h3><strong>GreatSQL 8.0</strong></h3>
<ul>
<li>Changes in GreatSQL 8.0.32-27 (2025-3-10)</li>
<li>Changes in GreatSQL 8.0.32-26 (2024-8-5)</li>
<li>Changes in GreatSQL 8.0.32-25 (2023-12-28)</li>
<li>Changes in GreatSQL 8.0.32-24 (2023-6-5)</li>
<li>Changes in GreatSQL 8.0.25-17 (2023-3-13)</li>
<li>Changes in GreatSQL 8.0.25-16 (2022-5-16)</li>
<li>Changes in GreatSQL 8.0.25-15 (2021-8-26)</li>
</ul>
<h3><strong>GreatSQL 5.7</strong></h3>
<ul>
<li>Changes in GreatSQL 5.7.36-39 (2022-4-7)</li>
</ul>]]>
    </itunes:summary>
    <description>
      <![CDATA[<h1><strong>GreatSQL 8.4.4-4 GA (2025-10-15)</strong></h1>
<h2><strong>版本信息</strong></h2>
<ul>
<li> <p>发布时间：2025年10月15日</p> </li>
<li> <p>版本号：8.4.4-4, Revision d73de75905d</p> </li>
<li> <p>下载链接：https://gitee.com/GreatSQL/GreatSQL/releases/tag/GreatSQL-8.4.4-4</p> </li>
<li> <p>用户手册：https://greatsql.cn/docs/8.4.4-4/</p> </li>
</ul>
<h2><strong>特性增强</strong></h2>
<p>GreatSQL 8.4.4.-4版本在Percona Server for MySQL 8.4.4-4版本的基础上，主要在 <strong>高可用</strong>、<strong>高性能</strong>、<strong>高兼容</strong>、<strong>高安全</strong>四个方面进行了多项特性增强，使得 GreatSQL 可在普通硬件上满足金融级应用场景，可作为 MySQL 或 Percona Server for MySQL 的理想可选替换。</p>
<h3><strong>高可用</strong></h3>
<p>针对 MGR 及主从复制进行了大量改进和提升工作，支持 地理标签、仲裁节点、读写动态 VIP、快速单主模式、智能选主 等特性，并针对 流控算法、事务认证队列清理算法、节点加入&amp;退出机制、recovery机制、大事务传输压缩等多个 MGR 底层工作机制算法进行深度优化，进一步提升优化了 MGR 的高可用保障及性能稳定性。</p>
<ul>
<li>支持 地理标签 特性，提升多机房架构数据可靠性。</li>
<li>支持 仲裁节点 特性，用更低的服务器成本实现更高可用。</li>
<li>支持 读写动态 VIP 特性，高可用切换更便捷，更快实现读负载均衡。支持 当主节点切换时，主动关闭当前活跃连接，缩短应用端不可用时长。。</li>
<li>支持 快速单主模式，在单主模式下更快，性能更高。</li>
<li>支持 智能选主 特性，高可用切换选主机制更合理。</li>
<li>优化 流控算法，使得事务更平稳，避免剧烈抖动。</li>
<li>支持 记录 MGR 网络通信开销超过阈值的事件，用于进一步分析和优化。</li>
<li>支持自动选择从最新事务数据的成员节点复制数据，可有效提升 Clone 速度，提高 MGR 的服务可靠性。</li>
<li>在主从复制中，从节点向主节点发起 Binlog 读取请求时支持限速控制。</li>
<li>优化了 asynchronous connection failover 中的故障检测效率，降低主从复制链路断开的时间，提高整体可用性。
<ul>
<li>https://dev.mysql.com/doc/refman/8.0/en/replication-asynchronous-connection-failover.html</li>
</ul> </li>
<li>支持在跨机房容灾场景中的 主主双向复制防止回路 机制。</li>
<li>优化了 MGR 节点加入、退出时可能导致性能剧烈抖动的问题。</li>
<li>解决了个别节点上磁盘空间爆满时导致MGR集群整体被阻塞的问题。</li>
<li>优化了 MGR 事务认证队列清理算法，高负载下不复存在每 60 秒性能抖动问题。</li>
<li>解决了 MGR 中长事务造成无法选主的问题。</li>
<li>修复了 MGR recovery 过程中长时间等待的问题。</li>
<li>优化了MGR大事务传输时压缩超过限制的处理机制。</li>
</ul>
<p>更多信息详见文档：</p>
<ul>
<li>高可用：https://greatsql.cn/docs/8.4.4-4/5-enhance/5-2-ha.html</li>
</ul>
<h3><strong>高性能</strong></h3>
<p>相对 MySQL 及 Percona Server For MySQL 的性能表现更稳定优异，支持 Rapid 引擎、Turbo引擎、事务无锁化、并行 LOAD DATA、异步删除大表、线程池、非阻塞式 DDL、NUMA 亲和调度优化 等特性，在 TPC-C 测试中相对 MySQL 性能提升超过 30%</p>
<ul>
<li>https://greatsql.cn/docs/8.4.4-4/10-optimize/3-5-benchmark-greatsql-vs-mysql-tpcc-report.html</li>
</ul>
<p>在 TPC-H 测试中的性能表现是 MySQL 的十几倍甚至上百倍</p>
<ul>
<li> <p>https://greatsql.cn/docs/8.4.4-4/10-optimize/3-3-benchmark-greatsql-tpch-report.html</p> </li>
<li> <p>支持 大规模并行、基于内存查询、高压缩比的高性能 Rapid 引擎，可将数据分析性能提升几个数量级。</p> </li>
<li> <p>支持 高性能并行查询引擎Turbo，使GreatSQL具备多线程并发的向量化实时查询功能。</p> </li>
<li> <p>优化 InnoDB 事务系统，实现了大锁拆分及无锁化等多种优化方案，OLTP 场景整体性能提升约 20%。</p> </li>
<li> <p>支持 并行 LOAD DATA，适用于频繁导入大批量数据的应用场景，性能可提升约 20 多倍；对于无显式定义主键的场景亦有优化提升。</p> </li>
<li> <p>支持 异步删除大表，提高 InnoDB 引擎运行时性能的稳定性。</p> </li>
<li> <p>支持 线程池，降低了线程创建和销毁的代价，保证高并发下，性能稳定不会明显衰退。</p> </li>
<li> <p>支持 非阻塞式 DDL，可以避免数据库因为必须尽快完成 DDL 操作而导致业务请求大量被阻塞的问题。</p> </li>
<li> <p>支持 NUMA 亲和性优化，通过 NUMA 亲和性调度优化，将前端用户线程和后台线程绑定到固定 NUMA 节点上以提升线程处理性能。</p> </li>
</ul>
<p>更多信息详见文档：</p>
<ul>
<li>高性能：https://greatsql.cn/docs/8.4.4-4/5-enhance/5-1-highperf.html</li>
</ul>
<h3><strong>高兼容</strong></h3>
<p>GreatSQL 实现 100% 完全兼容 MySQL 及 Percona Server For MySQL 语法，支持大多数常见 Oracle 语法，包括<code>数据类型兼容</code>、<code>函数兼容</code>、<code>SQL 语法兼容</code>、<code>存储程序兼容</code>等众多兼容扩展用法。</p>
<p>更多信息详见文档：</p>
<ul>
<li>高兼容：https://greatsql.cn/docs/8.4.4-4/5-enhance/5-3-easyuse.html</li>
</ul>
<h3><strong>高安全</strong></h3>
<p>GreatSQL 支持逻辑备份加密、CLONE 备份加密、审计、表空间国密加密、敏感数据脱敏、存储登录历史等多个安全提升特性，进一步保障业务数据安全，更适用于金融级应用场景。</p>
<ul>
<li>支持 mysqldump 逻辑备份加密，提供了利用 mysqldump 逻辑备份的安全加密需求。</li>
<li>支持 Clone 备份加密，提供了利用 Clone 物理备份的安全加密需求。</li>
<li>支持 审计功能，及时记录和发现未授权或不安全行为。</li>
<li>支持 InnoDB 表空间国密加密算法，确保重要数据的加密安全。</li>
<li>支持 基于函数和策略的两种数据脱敏 工作方式，保障敏感用户数据查询结果保密性。</li>
</ul>
<p>通过上述多个安全提升特性，进一步保障业务数据安全。</p>
<p>更多信息详见文档：</p>
<ul>
<li>高安全：https://greatsql.cn/docs/8.4.4-4/5-enhance/5-4-security.html</li>
</ul>
<h3><strong>其他</strong></h3>
<ul>
<li>支持 Clone 在线全量热备、增备及恢复，结合 Binlog 可实现恢复到指定时间点。此外，Clone 备份还支持压缩功能。
<ul>
<li>https://greatsql.cn/docs/8.4.4-4/5-enhance/5-5-clone-compressed-and-incrment-backup.html</li>
</ul> </li>
<li>支持 InnoDB Page透明压缩采用Zstd算法，进一步提高数据压缩率，尤其是当有大量长文本重复数据时。
<ul>
<li>https://greatsql.cn/docs/8.4.4-4/5-enhance/5-5-innodb-page-compression.html</li>
</ul> </li>
</ul>
<h2><strong>注意事项</strong></h2>
<p>从8.0升级到8.4版本，对现有运维管控系统最大的影响是，原先包含 <code>MASTER/SLAVE</code> 关键字的指令不再可用，相应的主要改动详见下表</p>
<table>
<tbody>
<tr>
<th>旧指令</th>
<th>新指令</th>
</tr>
</tbody>
<tbody>
<tr>
<td>START SLAVE</td>
<td>START REPLICA</td>
</tr>
<tr>
<td>STOP SLAVE</td>
<td>STOP REPLICA</td>
</tr>
<tr>
<td>SHOW SLAVE STATUS</td>
<td>SHOW REPLICA STATUS</td>
</tr>
<tr>
<td>SHOW SLAVE HOSTS</td>
<td>SHOW REPLICAS</td>
</tr>
<tr>
<td>RESET SLAVE</td>
<td>RESET REPLICA</td>
</tr>
<tr>
<td>CHANGE MASTER TO</td>
<td>CHANGE REPLICATION SOURCE TO</td>
</tr>
<tr>
<td>RESET MASTER</td>
<td>RESET BINARY LOGS AND GTIDS</td>
</tr>
<tr>
<td>SHOW MASTER STATUS</td>
<td>SHOW BINARY LOG STATUS</td>
</tr>
<tr>
<td>PURGE MASTER LOGS</td>
<td>PURGE BINARY LOGS</td>
</tr>
<tr>
<td>SHOW MASTER LOGS</td>
<td>SHOW BINARY LOGS</td>
</tr>
</tbody>
</table>
<p>此外，原来在 <code>CHANGE MASTER</code>（新的指令 <code>CHANGE REPLICATION SOURCE TO</code>） 以及 <code>START SLAVE</code>（新的指令 <code>START REPLICA</code>） 中相关的参数变量也同样发生变化，详见下表</p>
<table>
<tbody>
<tr>
<th>旧参数名</th>
<th>新参数名</th>
</tr>
</tbody>
<tbody>
<tr>
<td>MASTER_AUTO_POSITION</td>
<td>SOURCE_AUTO_POSITION</td>
</tr>
<tr>
<td>MASTER_HOST</td>
<td>SOURCE_HOST</td>
</tr>
<tr>
<td>MASTER_BIND</td>
<td>SOURCE_BIND</td>
</tr>
<tr>
<td>MASTER_USER</td>
<td>SOURCE_USER</td>
</tr>
<tr>
<td>MASTER_PASSWORD</td>
<td>SOURCE_PASSWORD</td>
</tr>
<tr>
<td>MASTER_PORT</td>
<td>SOURCE_PORT</td>
</tr>
<tr>
<td>MASTER_CONNECT_RETRY</td>
<td>SOURCE_CONNECT_RETRY</td>
</tr>
<tr>
<td>MASTER_RETRY_COUNT</td>
<td>SOURCE_RETRY_COUNT</td>
</tr>
<tr>
<td>MASTER_DELAY</td>
<td>SOURCE_DELAY</td>
</tr>
<tr>
<td>MASTER_SSL</td>
<td>SOURCE_SSL</td>
</tr>
<tr>
<td>MASTER_SSL_CA</td>
<td>SOURCE_SSL_CA</td>
</tr>
<tr>
<td>MASTER_SSL_CAPATH</td>
<td>SOURCE_SSL_CAPATH</td>
</tr>
<tr>
<td>MASTER_SSL_CIPHER</td>
<td>SOURCE_SSL_CIPHER</td>
</tr>
<tr>
<td>MASTER_SSL_CRL</td>
<td>SOURCE_SSL_CRL</td>
</tr>
<tr>
<td>MASTER_SSL_CRLPATH</td>
<td>SOURCE_SSL_CRLPATH</td>
</tr>
<tr>
<td>MASTER_SSL_KEY</td>
<td>SOURCE_SSL_KEY</td>
</tr>
<tr>
<td>MASTER_SSL_VERIFY_SERVER_CERT</td>
<td>SOURCE_SSL_VERIFY_SERVER_CERT</td>
</tr>
<tr>
<td>MASTER_TLS_VERSION</td>
<td>SOURCE_TLS_VERSION</td>
</tr>
<tr>
<td>MASTER_TLS_CIPHERSUITES</td>
<td>SOURCE_TLS_CIPHERSUITES</td>
</tr>
<tr>
<td>MASTER_SSL_CERT</td>
<td>SOURCE_SSL_CERT</td>
</tr>
<tr>
<td>MASTER_PUBLIC_KEY_PATH</td>
<td>SOURCE_PUBLIC_KEY_PATH</td>
</tr>
<tr>
<td>GET_MASTER_PUBLIC_KEY</td>
<td>GET_SOURCE_PUBLIC_KEY</td>
</tr>
<tr>
<td>MASTER_HEARTBEAT_PERIOD</td>
<td>SOURCE_HEARTBEAT_PERIOD</td>
</tr>
<tr>
<td>MASTER_COMPRESSION_ALGORITHMS</td>
<td>SOURCE_COMPRESSION_ALGORITHMS</td>
</tr>
<tr>
<td>MASTER_ZSTD_COMPRESSION_LEVEL</td>
<td>SOURCE_ZSTD_COMPRESSION_LEVEL</td>
</tr>
<tr>
<td>MASTER_LOG_FILE</td>
<td>SOURCE_LOG_FILE</td>
</tr>
<tr>
<td>MASTER_LOG_POS</td>
<td>SOURCE_LOG_POS</td>
</tr>
</tbody>
</table>
<p>执行 SQL 命令 <code>SHOW [GLOBAL] STATUS</code> 的结果中，也有部分状态变量发生变化，详见下表</p>
<table>
<tbody>
<tr>
<th>旧状态变量名</th>
<th>新状态变量名</th>
</tr>
</tbody>
<tbody>
<tr>
<td>Com_slave_start</td>
<td>Com_replica_start</td>
</tr>
<tr>
<td>Com_slave_stop</td>
<td>Com_replica_stop</td>
</tr>
<tr>
<td>Com_show_slave_status</td>
<td>Com_show_replica_status</td>
</tr>
<tr>
<td>Com_show_slave_hosts</td>
<td>Com_show_replicas</td>
</tr>
<tr>
<td>Com_show_master_status</td>
<td>Com_show_binary_log_status</td>
</tr>
<tr>
<td>Com_change_master</td>
<td>Com_change_replication_source</td>
</tr>
</tbody>
</table>
<h2><strong>升级/降级到 GreatSQL 8.4.4-4</strong></h2>
<h3><strong>升级到 GreatSQL 8.4.4-4</strong></h3>
<ul>
<li> <p>如果是 GreatSQL 5.7 等系列版本，可以直接在原来的 <code>datadir</code> 基础上，修改 <code>basedir</code> 后，原地（in-place）启动 GreatSQL 8.0.32-27 版本后，先原地升级到 GreatSQL 8.0.32-27 版本。再继续在该 <code>datadir</code> 基础上升级，即修改 <code>basedir</code> 指向 GreatSQL 8.4.4-4 新版本，再次进行原地升级。需要注意的是，从 5.7 版本升级到 8.0 版本，再升级到 8.4 版本后，数据库中的账号仍采用 <code>mysql_native_password</code> 密码验证插件。当最终升级到 8.4 版本后，需要修改 <em>my.cnf</em> 配置文件，加上 <code>mysql_native_password=1</code>，以保证原有的账号能正常登录。</p> </li>
<li> <p>如果是 GreatSQL 8.0 等系列版本，并且没有使用 <strong>Rapid</strong> 引擎，则可以直接在原来的 <code>datadir</code> 基础上，修改 <code>basedir</code> 后，原地（in-place）启动 GreatSQL 8.4.4-4 后会完成自动升级。</p> </li>
<li> <p>如果旧版本是 GreatSQL 8.0.32-27 且已启用 <strong>Rapid</strong> 引擎，可以直接在原来的 <code>datadir</code> 基础上，修改 <code>basedir</code> 后，原地（in-place）启动 GreatSQL 8.4.4-4 后会完成自动升级。</p> </li>
<li> <p>如果旧版本是 GreatSQL 8.0.32-25 或 8.0.32-26 且已启用 <strong>Rapid</strong> 引擎，<strong>这种情况下无法原地升级</strong>，需要卸载所有 <strong>Rapid</strong> 引擎表，删除 <strong>Rapid</strong> 数据文件，才可以在原来的 <code>datadir</code> 基础上，修改 <code>basedir</code> 后，原地（in-place）启动 GreatSQL 8.4.4-4 后进行自动升级。新版本实例启动后，对所有 <strong>Rapid</strong> 引擎表执行 <code>ALTER TABLE SECONDARY_LOAD</code> 完成全量数据导入，再执行 <code>SELECT START_SECONDARY_ENGINE_INCREMENT_LOAD_TASK()</code> 启动增量导入任务，完成 <strong>Rapid</strong> 引擎表升级工作。下面是一个升级参考过程：</p> <pre><code>&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong style="color:#000000"&gt;1. 查询并记录所有Rapid引擎表&lt;/strong&gt;
&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;可以执行下面的SQL，查询当前有哪些表使用了Rapid引擎：
&lt;pre style="margin-left:5px; margin-right:5px; text-align:left"&gt;
</code></pre> <p><code>greatsql&gt; <span>SELECT</span> TABLE_SCHEMA, TABLE_NAME, TABLE_ROWS <span>FROM</span> information_schema.TABLES <span>WHERE</span> CREATE_OPTIONS <span>LIKE</span> <span>'%Rapid%'</span>; +<em>--------------+----------------+------------+</em> | TABLE_SCHEMA | TABLE_NAME | TABLE_ROWS | +<em>--------------+----------------+------------+</em> | tpch100g | customer | 14854987 | | tpch100g | lineitem | 582868392 | | tpch100g | nation | 25 | | tpch100g | orders | 148492582 | | tpch100g | part | 19943155 | | tpch100g | partsupp | 79832625 | | tpch100g | region | 5 | | tpch100g | supplier | 989416 | +<em>--------------+----------------+------------+</em> </code></p> <pre><code>&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong style="color:#000000"&gt;2. 正常停止GreatSQL实例进程&lt;/strong&gt;
&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;在停止GreatSQL实例进程前，先修改&lt;code&gt;innodb_fast_shutdown=0&lt;/code&gt;后再执行&lt;code&gt;SHUTDOWN&lt;/code&gt;停止实例
&lt;pre style="margin-left:5px; margin-right:5px; text-align:left"&gt;
</code></pre> <p><code>greatsql&gt; <span>SET</span> <span>GLOBAL</span> innodb_fast_shutdown=<span>0</span>; greatsql&gt; SHUTDOWN; </code></p> <pre><code>&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong style="color:#000000"&gt;3. 删除旧的Rapid引擎数据文件&lt;/strong&gt;
&lt;pre style="margin-left:5px; margin-right:5px; text-align:left"&gt;
</code></pre> <p><code><span>cd</span> /data/GreatSQL &amp;&amp; rm -f duckdb* </code></p> <pre><code>&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong style="color:#000000"&gt;4. 修改&lt;code&gt;my.cnf&lt;/code&gt;配置文件中的&lt;code&gt;basedir&lt;/code&gt;参数，指向GreatSQL 8.4.4-4新版本&lt;/strong&gt;
&lt;pre style="margin-left:5px; margin-right:5px; text-align:left"&gt;
</code></pre> <p><code>#my.cnf [mysqld] basedir=/usr/local/GreatSQL-8.4.4-4-Linux-glibc2.28-x86_64 </code></p> <pre><code>&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;并确保参数&lt;code&gt;upgrade&lt;/code&gt;不是设置为&lt;em&gt;NONE&lt;/em&gt;。
&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong style="color:#000000"&gt;5. 启动GreatSQL 8.4.4-4新版本实例&lt;/strong&gt;
&lt;pre style="margin-left:5px; margin-right:5px; text-align:left"&gt;
</code></pre> <p><code>systemctl start greatsql </code></p> <pre><code>&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong style="color:#000000"&gt;6. 重新安装Rapid引擎&lt;/strong&gt;
&lt;pre style="margin-left:5px; margin-right:5px; text-align:left"&gt;
</code></pre> <p><code>greatsql&gt; <span>INSTALL</span> <span>PLUGIN</span> rapid <span>SONAME</span> <span>'ha_rapid.so'</span>; </code></p> <pre><code>&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong style="color:#000000"&gt;7. 对Rapid引擎表做一次全量数据导入&lt;/strong&gt;
&lt;pre style="margin-left:5px; margin-right:5px; text-align:left"&gt;
</code></pre> <p><code>greatsql&gt; <span>ALTER</span> <span>TABLE</span> test.t1 SECONDARY_LOAD; </code></p> </li>
</ul>
<blockquote>
<p>tip 小贴士：由于在升级前没有去掉该表的<code>SECONDARY_ENGINE=rapid</code>属性，所以无需重新设置。如果在升级前卸载所有Rapid引擎表，则需要重新设置。</p>
</blockquote>
<p><strong>8. 再次启动增量导入任务</strong></p>
<pre><code>greatsql&gt; <span>SELECT</span> START_SECONDARY_ENGINE_INCREMENT_LOAD_TASK(<span>'test'</span>, <span>'t1'</span>);
</code></pre>
<p>这就完成Rapid引擎表的升级操作了。</p>
<ul>
<li> <p>如果是 MySQL 5.7 或 Percona Server 5.7 等系列版本，可以直接在原来的 <code>datadir</code> 基础上，修改 <code>basedir</code> 后，原地（in-place）启动 GreatSQL 8.0.32-27 版本后，确认升级成功后，再次在原来 <code>datadir</code> 基础上继续升级，即修改 <code>basedir</code> 指向 GreatSQL 8.4.4-4 新版本，之后就能完成自动升级。需要注意的是，从 5.7 版本升级到 8.0 版本，再升级到 8.4 版本后，数据库中的账号仍采用 <code>mysql_native_password</code> 密码验证插件。当最终升级到 8.4 版本后，需要修改 <em>my.cnf</em> 配置文件，加上 <code>mysql_native_password=1</code>，以保证原有的账号能正常登录。</p> </li>
<li> <p>如果是 MySQL 8.0 或 Percona Server 8.0 等系列版本，则可以直接在原来的 <code>datadir</code> 基础上，修改 <code>basedir</code> 后，原地（in-place）启动 GreatSQL 8.4.4-4 后会完成自动升级。</p> </li>
<li> <p>其他情况下，最好采用导入逻辑备份文件方式升级到 GreatSQL 8.4.4-4 版本。</p> </li>
</ul>
<p>在以上几个原地升级场景中，务必保证<code>my.cnf</code>中参数<code>upgrade</code>不能设置为<em>NONE</em>，可以设置为默认的<em>AUTO</em>或<em>FORCE</em>。例如：</p>
<pre><code>#my.cnf
[mysqld]
upgrade = AUTO
</code></pre>
<p>更多迁移升级方案请参考：</p>
<ul>
<li>迁移升级：https://greatsql.cn/docs/8.4.4-4/7-migrate-and-upgrade/0-migrate-and-upgrade.html</li>
</ul>
<h3><strong>降级到 GreatSQL 8.4.4-4</strong></h3>
<p>如果是要从 MySQL/Percona 8.4 系列较高的小版本降级到 GreatSQL 8.4.4-4 版本，可以采用原地降级方式快速完成版本降级操作。即可以直接在原来的 <code>datadir</code> 基础上，修改 <code>basedir</code> 后，并增加设置参数<code>upgrade=FORCE</code>，原地（in-place）启动 GreatSQL 8.4.4-4 后会完成自动降级。</p>
<p>如果是要从 MySQL/Percona 9.0 及之后的版本降级到 GreatSQL 8.4.4-4 版本，则需要采取逻辑备份 + 逻辑导入方式完成降级操作，并且在逻辑备份导入完成后的首次重启时，务必设置 <code>upgrade=FORCE</code> 强制升级所有数据表，包括系统表。</p>
<p>降级过程操作大致如下所示：</p>
<p><strong>1. 在高版本中逻辑备份全量数据</strong></p>
<pre><code>mysqldump -S/data/MySQL/mysql.sock -A --triggers --routines --events --single-transaction &gt; /data/backup/fulldump.sql
</code></pre>
<p><strong>2. 在GreatSQL 8.4.4-4版本环境中导入逻辑备份文件，完成逻辑恢复</strong></p>
<pre><code>mysql -S/data/GreatSQL/mysql.sock -f &lt; /data/backup/fulldump.sql
</code></pre>
<p><strong>3. 修改<code>my.cnf</code>，确保设置<code>upgrade=FORCE</code></strong></p>
<pre><code>#my.cnf
[mysqld]
upgrade = FORCE
</code></pre>
<p><strong>4. 重启GreatSQL，降级完成</strong></p>
<pre><code>systemctl restart greatsql
</code></pre>
<p>重启过程中，可以看到日志有类似下面的强制降级过程</p>
<pre><code>[Note] [MY-013387] [Server] Upgrading system table data.
[Note] [MY-013385] [Server] Upgrading the sys schema.
[Note] [MY-013400] [Server] Upgrade of help tables started.
[Note] [MY-013400] [Server] Upgrade of help tables completed.
[Note] [MY-013394] [Server] Checking 'mysql' schema.
[Note] [MY-013394] [Server] Checking 'sys' schema.
[System] [MY-014064] [Server] Server downgrade from '80406' to '80404' started.
[System] [MY-014064] [Server] Server downgrade from '80406' to '80404' completed.
</code></pre>
<p>如果不设置 <code>upgrade = FORCE</code> 强制升级所有表，有可能发生系统表 <code>mysql.procs_priv</code> 损坏错误，在创建用户时可能会报告类似下面的错误：</p>
<pre><code>greatsql&gt; <span>CREATE</span> <span>USER</span> tpch <span>IDENTIFIED</span> <span>BY</span> <span>'tpch'</span>;
ERROR 1728 (HY000): Cannot <span>load</span> <span>from</span> mysql.procs_priv. The <span>table</span> <span>is</span> probably corrupted
</code></pre>
<h2><strong>GreatSQL vs MySQL</strong></h2>
<table>
<tbody>
<tr>
<th><strong>1.主要特性</strong></th>
<th>GreatSQL 8.4.4-4</th>
<th>MySQL 8.4.4</th>
</tr>
</tbody>
<tbody>
<tr>
<td>开源</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>ACID 完整性</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>MVCC 特性</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>支持行锁</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>Crash 自动修复</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>表分区（Partitioning）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>视图（Views）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>子查询（Subqueries）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>触发器（Triggers）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>存储程序（Stored Programs）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>外键（Foreign Keys）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>窗口函数（Window Functions）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>通用表表达式 CTE</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>地理信息（GIS）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>基于 GTID 的复制</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>组复制（MGR）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>MyRocks 引擎</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>支持龙芯架构</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td><strong>2. 性能提升扩展</strong></td>
<td>GreatSQL 8.4.4-4</td>
<td>MySQL 8.4.4</td>
</tr>
<tr>
<td>Rapid 引擎</td>
<td>✔️</td>
<td>仅云上HeatWave</td>
</tr>
<tr>
<td>Turbo 引擎</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>NUMA 亲和性优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>非阻塞式 DDL</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>无主键表导入优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>并行 LOAD DATA</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>InnoDB 事务 ReadView 无锁优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>InnoDB 事务大锁拆分优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>InnoDB Page压缩支持Zstd</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>InnoDB 资源组</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>自定义 InnoDB 页大小</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>Contention-Aware Transaction Scheduling</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>InnoDB Mutexes 拆分优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MEMORY 引擎优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>InnoDB Flushing 优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>并行 Doublewrite Buffer</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>InnoDB 快速索引创建优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>VARCHAR/BLOB/JSON 类型存储单列压缩</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>数据字典中存储单列压缩信息</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td><strong>3. 面向开发者提升改进</strong></td>
<td>GreatSQL 8.4.4-4</td>
<td>MySQL 8.4.4</td>
</tr>
<tr>
<td>X API</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>JSON</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>NoSQL Socket-Level接口</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>InnoDB 全文搜索改进</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>更多 Hash/Digest 函数</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Oracle 兼容-数据类型</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Oracle 兼容-函数</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Oracle 兼容-SQL语法</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Oracle 兼容-存储程序</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td><strong>4. 基础特性提升改进</strong></td>
<td>GreatSQL 8.4.4-4</td>
<td>MySQL 8.4.4</td>
</tr>
<tr>
<td>MGR 提升-地理标签</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-仲裁节点</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-读写节点绑定VIP</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-快速单主模式</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-智能选主机制</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-全新流控算法</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-网络分区异常处理</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-节点异常退出处理</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-节点磁盘满处理</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-自动选择 donor 节点</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-大事务压缩优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Clone 增量备份</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Clone 备份压缩</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Binlog 读取限速</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>information_schema 表数量</td>
<td>95</td>
<td>65</td>
</tr>
<tr>
<td>全局性能和状态指标</td>
<td>853</td>
<td>434</td>
</tr>
<tr>
<td>优化器直方图（Histograms）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>Per-Table 性能指标</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Per-Index 性能指标</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Per-User 性能指标</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Per-Client 性能指标</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Per-Thread 性能指标</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>全局查询相应耗时统计</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>SHOW ENGINE INNODB STATUS 增强</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>回滚段信息增强</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>临时表信息增强</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>用户统计信息增强</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Slow log 信息增强</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td><strong>5.安全性提升</strong></td>
<td>GreatSQL 8.4.4-4</td>
<td>MySQL 8.4.4</td>
</tr>
<tr>
<td>国密支持</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>备份加密</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>审计</td>
<td>✔️</td>
<td>仅企业版</td>
</tr>
<tr>
<td>数据脱敏</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>SQL Roles</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>SHA-2 密码Hashing</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>密码轮换策略</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>PAM 认证插件</td>
<td>✔️</td>
<td>仅企业版</td>
</tr>
<tr>
<td>Keyring 存储在文件中</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>Keyring 存储在Hashicorp Vault中</td>
<td>✔️</td>
<td>仅企业版</td>
</tr>
<tr>
<td>InnoDB 数据加密</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>InnoDB 日志加密</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>InnoDB 各种表空间文件加密</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>二进制日志加密</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>临时文件加密</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>强制加密</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td><strong>6. 运维便利性提升</strong></td>
<td>GreatSQL 8.4.4-4</td>
<td>MySQL 8.4.4</td>
</tr>
<tr>
<td>DDL 原子性</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>数据字典存储 InnoDB 表</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>快速 DDL</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>SET PERSIST</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>不可见索引</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>线程池（Threadpool）</td>
<td>✔️</td>
<td>仅企业版</td>
</tr>
<tr>
<td>备份锁</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>SHOW GRANTS 扩展</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>表损坏动作扩展</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>杀掉不活跃事务</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>START TRANSACTION WITH CONSISTENT SNAPSHOT 扩展</td>
<td>✔️</td>
<td>❌</td>
</tr>
</tbody>
</table>
<p>GreatSQL 8.4.4-4 基于 Percona Server for MySQL 8.4.4-4 版本，它在 MySQL 8.4.4 基础上做了大量的改进和提升以及众多新特性，详情请见：</p>
<ul>
<li>Percona Server for MySQL feature comparison: https://docs.percona.com/percona-server/8.4/feature-comparison.html</li>
</ul>
<p>这其中包括线程池、审计、数据脱敏等 MySQL 企业版才有的特性，以及 performance_schema 提升、information_schema 提升、性能和可扩展性提升、用户统计增强、PROCESSLIST 增强、Slow Log 增强等大量改进和提升，这里不一一重复列出。</p>
<h2><strong>GreatSQL Release Notes</strong></h2>
<h3><strong>GreatSQL 8.4</strong></h3>
<ul>
<li>Changes in GreatSQL 8.4.4-4 (2025-10-15) https://greatsql.cn/docs/8.4.4-4/1-docs-intro/relnotes/changes-greatsql-8444.html</li>
</ul>
<h3><strong>GreatSQL 8.0</strong></h3>
<ul>
<li>Changes in GreatSQL 8.0.32-27 (2025-3-10)</li>
<li>Changes in GreatSQL 8.0.32-26 (2024-8-5)</li>
<li>Changes in GreatSQL 8.0.32-25 (2023-12-28)</li>
<li>Changes in GreatSQL 8.0.32-24 (2023-6-5)</li>
<li>Changes in GreatSQL 8.0.25-17 (2023-3-13)</li>
<li>Changes in GreatSQL 8.0.25-16 (2022-5-16)</li>
<li>Changes in GreatSQL 8.0.25-15 (2021-8-26)</li>
</ul>
<h3><strong>GreatSQL 5.7</strong></h3>
<ul>
<li>Changes in GreatSQL 5.7.36-39 (2022-4-7)</li>
</ul>]]>
    </description>
    <content:encoded><![CDATA[<h1><strong>GreatSQL 8.4.4-4 GA (2025-10-15)</strong></h1>
<h2><strong>版本信息</strong></h2>
<ul>
<li> <p>发布时间：2025年10月15日</p> </li>
<li> <p>版本号：8.4.4-4, Revision d73de75905d</p> </li>
<li> <p>下载链接：https://gitee.com/GreatSQL/GreatSQL/releases/tag/GreatSQL-8.4.4-4</p> </li>
<li> <p>用户手册：https://greatsql.cn/docs/8.4.4-4/</p> </li>
</ul>
<h2><strong>特性增强</strong></h2>
<p>GreatSQL 8.4.4.-4版本在Percona Server for MySQL 8.4.4-4版本的基础上，主要在 <strong>高可用</strong>、<strong>高性能</strong>、<strong>高兼容</strong>、<strong>高安全</strong>四个方面进行了多项特性增强，使得 GreatSQL 可在普通硬件上满足金融级应用场景，可作为 MySQL 或 Percona Server for MySQL 的理想可选替换。</p>
<h3><strong>高可用</strong></h3>
<p>针对 MGR 及主从复制进行了大量改进和提升工作，支持 地理标签、仲裁节点、读写动态 VIP、快速单主模式、智能选主 等特性，并针对 流控算法、事务认证队列清理算法、节点加入&amp;退出机制、recovery机制、大事务传输压缩等多个 MGR 底层工作机制算法进行深度优化，进一步提升优化了 MGR 的高可用保障及性能稳定性。</p>
<ul>
<li>支持 地理标签 特性，提升多机房架构数据可靠性。</li>
<li>支持 仲裁节点 特性，用更低的服务器成本实现更高可用。</li>
<li>支持 读写动态 VIP 特性，高可用切换更便捷，更快实现读负载均衡。支持 当主节点切换时，主动关闭当前活跃连接，缩短应用端不可用时长。。</li>
<li>支持 快速单主模式，在单主模式下更快，性能更高。</li>
<li>支持 智能选主 特性，高可用切换选主机制更合理。</li>
<li>优化 流控算法，使得事务更平稳，避免剧烈抖动。</li>
<li>支持 记录 MGR 网络通信开销超过阈值的事件，用于进一步分析和优化。</li>
<li>支持自动选择从最新事务数据的成员节点复制数据，可有效提升 Clone 速度，提高 MGR 的服务可靠性。</li>
<li>在主从复制中，从节点向主节点发起 Binlog 读取请求时支持限速控制。</li>
<li>优化了 asynchronous connection failover 中的故障检测效率，降低主从复制链路断开的时间，提高整体可用性。
<ul>
<li>https://dev.mysql.com/doc/refman/8.0/en/replication-asynchronous-connection-failover.html</li>
</ul> </li>
<li>支持在跨机房容灾场景中的 主主双向复制防止回路 机制。</li>
<li>优化了 MGR 节点加入、退出时可能导致性能剧烈抖动的问题。</li>
<li>解决了个别节点上磁盘空间爆满时导致MGR集群整体被阻塞的问题。</li>
<li>优化了 MGR 事务认证队列清理算法，高负载下不复存在每 60 秒性能抖动问题。</li>
<li>解决了 MGR 中长事务造成无法选主的问题。</li>
<li>修复了 MGR recovery 过程中长时间等待的问题。</li>
<li>优化了MGR大事务传输时压缩超过限制的处理机制。</li>
</ul>
<p>更多信息详见文档：</p>
<ul>
<li>高可用：https://greatsql.cn/docs/8.4.4-4/5-enhance/5-2-ha.html</li>
</ul>
<h3><strong>高性能</strong></h3>
<p>相对 MySQL 及 Percona Server For MySQL 的性能表现更稳定优异，支持 Rapid 引擎、Turbo引擎、事务无锁化、并行 LOAD DATA、异步删除大表、线程池、非阻塞式 DDL、NUMA 亲和调度优化 等特性，在 TPC-C 测试中相对 MySQL 性能提升超过 30%</p>
<ul>
<li>https://greatsql.cn/docs/8.4.4-4/10-optimize/3-5-benchmark-greatsql-vs-mysql-tpcc-report.html</li>
</ul>
<p>在 TPC-H 测试中的性能表现是 MySQL 的十几倍甚至上百倍</p>
<ul>
<li> <p>https://greatsql.cn/docs/8.4.4-4/10-optimize/3-3-benchmark-greatsql-tpch-report.html</p> </li>
<li> <p>支持 大规模并行、基于内存查询、高压缩比的高性能 Rapid 引擎，可将数据分析性能提升几个数量级。</p> </li>
<li> <p>支持 高性能并行查询引擎Turbo，使GreatSQL具备多线程并发的向量化实时查询功能。</p> </li>
<li> <p>优化 InnoDB 事务系统，实现了大锁拆分及无锁化等多种优化方案，OLTP 场景整体性能提升约 20%。</p> </li>
<li> <p>支持 并行 LOAD DATA，适用于频繁导入大批量数据的应用场景，性能可提升约 20 多倍；对于无显式定义主键的场景亦有优化提升。</p> </li>
<li> <p>支持 异步删除大表，提高 InnoDB 引擎运行时性能的稳定性。</p> </li>
<li> <p>支持 线程池，降低了线程创建和销毁的代价，保证高并发下，性能稳定不会明显衰退。</p> </li>
<li> <p>支持 非阻塞式 DDL，可以避免数据库因为必须尽快完成 DDL 操作而导致业务请求大量被阻塞的问题。</p> </li>
<li> <p>支持 NUMA 亲和性优化，通过 NUMA 亲和性调度优化，将前端用户线程和后台线程绑定到固定 NUMA 节点上以提升线程处理性能。</p> </li>
</ul>
<p>更多信息详见文档：</p>
<ul>
<li>高性能：https://greatsql.cn/docs/8.4.4-4/5-enhance/5-1-highperf.html</li>
</ul>
<h3><strong>高兼容</strong></h3>
<p>GreatSQL 实现 100% 完全兼容 MySQL 及 Percona Server For MySQL 语法，支持大多数常见 Oracle 语法，包括<code>数据类型兼容</code>、<code>函数兼容</code>、<code>SQL 语法兼容</code>、<code>存储程序兼容</code>等众多兼容扩展用法。</p>
<p>更多信息详见文档：</p>
<ul>
<li>高兼容：https://greatsql.cn/docs/8.4.4-4/5-enhance/5-3-easyuse.html</li>
</ul>
<h3><strong>高安全</strong></h3>
<p>GreatSQL 支持逻辑备份加密、CLONE 备份加密、审计、表空间国密加密、敏感数据脱敏、存储登录历史等多个安全提升特性，进一步保障业务数据安全，更适用于金融级应用场景。</p>
<ul>
<li>支持 mysqldump 逻辑备份加密，提供了利用 mysqldump 逻辑备份的安全加密需求。</li>
<li>支持 Clone 备份加密，提供了利用 Clone 物理备份的安全加密需求。</li>
<li>支持 审计功能，及时记录和发现未授权或不安全行为。</li>
<li>支持 InnoDB 表空间国密加密算法，确保重要数据的加密安全。</li>
<li>支持 基于函数和策略的两种数据脱敏 工作方式，保障敏感用户数据查询结果保密性。</li>
</ul>
<p>通过上述多个安全提升特性，进一步保障业务数据安全。</p>
<p>更多信息详见文档：</p>
<ul>
<li>高安全：https://greatsql.cn/docs/8.4.4-4/5-enhance/5-4-security.html</li>
</ul>
<h3><strong>其他</strong></h3>
<ul>
<li>支持 Clone 在线全量热备、增备及恢复，结合 Binlog 可实现恢复到指定时间点。此外，Clone 备份还支持压缩功能。
<ul>
<li>https://greatsql.cn/docs/8.4.4-4/5-enhance/5-5-clone-compressed-and-incrment-backup.html</li>
</ul> </li>
<li>支持 InnoDB Page透明压缩采用Zstd算法，进一步提高数据压缩率，尤其是当有大量长文本重复数据时。
<ul>
<li>https://greatsql.cn/docs/8.4.4-4/5-enhance/5-5-innodb-page-compression.html</li>
</ul> </li>
</ul>
<h2><strong>注意事项</strong></h2>
<p>从8.0升级到8.4版本，对现有运维管控系统最大的影响是，原先包含 <code>MASTER/SLAVE</code> 关键字的指令不再可用，相应的主要改动详见下表</p>
<table>
<tbody>
<tr>
<th>旧指令</th>
<th>新指令</th>
</tr>
</tbody>
<tbody>
<tr>
<td>START SLAVE</td>
<td>START REPLICA</td>
</tr>
<tr>
<td>STOP SLAVE</td>
<td>STOP REPLICA</td>
</tr>
<tr>
<td>SHOW SLAVE STATUS</td>
<td>SHOW REPLICA STATUS</td>
</tr>
<tr>
<td>SHOW SLAVE HOSTS</td>
<td>SHOW REPLICAS</td>
</tr>
<tr>
<td>RESET SLAVE</td>
<td>RESET REPLICA</td>
</tr>
<tr>
<td>CHANGE MASTER TO</td>
<td>CHANGE REPLICATION SOURCE TO</td>
</tr>
<tr>
<td>RESET MASTER</td>
<td>RESET BINARY LOGS AND GTIDS</td>
</tr>
<tr>
<td>SHOW MASTER STATUS</td>
<td>SHOW BINARY LOG STATUS</td>
</tr>
<tr>
<td>PURGE MASTER LOGS</td>
<td>PURGE BINARY LOGS</td>
</tr>
<tr>
<td>SHOW MASTER LOGS</td>
<td>SHOW BINARY LOGS</td>
</tr>
</tbody>
</table>
<p>此外，原来在 <code>CHANGE MASTER</code>（新的指令 <code>CHANGE REPLICATION SOURCE TO</code>） 以及 <code>START SLAVE</code>（新的指令 <code>START REPLICA</code>） 中相关的参数变量也同样发生变化，详见下表</p>
<table>
<tbody>
<tr>
<th>旧参数名</th>
<th>新参数名</th>
</tr>
</tbody>
<tbody>
<tr>
<td>MASTER_AUTO_POSITION</td>
<td>SOURCE_AUTO_POSITION</td>
</tr>
<tr>
<td>MASTER_HOST</td>
<td>SOURCE_HOST</td>
</tr>
<tr>
<td>MASTER_BIND</td>
<td>SOURCE_BIND</td>
</tr>
<tr>
<td>MASTER_USER</td>
<td>SOURCE_USER</td>
</tr>
<tr>
<td>MASTER_PASSWORD</td>
<td>SOURCE_PASSWORD</td>
</tr>
<tr>
<td>MASTER_PORT</td>
<td>SOURCE_PORT</td>
</tr>
<tr>
<td>MASTER_CONNECT_RETRY</td>
<td>SOURCE_CONNECT_RETRY</td>
</tr>
<tr>
<td>MASTER_RETRY_COUNT</td>
<td>SOURCE_RETRY_COUNT</td>
</tr>
<tr>
<td>MASTER_DELAY</td>
<td>SOURCE_DELAY</td>
</tr>
<tr>
<td>MASTER_SSL</td>
<td>SOURCE_SSL</td>
</tr>
<tr>
<td>MASTER_SSL_CA</td>
<td>SOURCE_SSL_CA</td>
</tr>
<tr>
<td>MASTER_SSL_CAPATH</td>
<td>SOURCE_SSL_CAPATH</td>
</tr>
<tr>
<td>MASTER_SSL_CIPHER</td>
<td>SOURCE_SSL_CIPHER</td>
</tr>
<tr>
<td>MASTER_SSL_CRL</td>
<td>SOURCE_SSL_CRL</td>
</tr>
<tr>
<td>MASTER_SSL_CRLPATH</td>
<td>SOURCE_SSL_CRLPATH</td>
</tr>
<tr>
<td>MASTER_SSL_KEY</td>
<td>SOURCE_SSL_KEY</td>
</tr>
<tr>
<td>MASTER_SSL_VERIFY_SERVER_CERT</td>
<td>SOURCE_SSL_VERIFY_SERVER_CERT</td>
</tr>
<tr>
<td>MASTER_TLS_VERSION</td>
<td>SOURCE_TLS_VERSION</td>
</tr>
<tr>
<td>MASTER_TLS_CIPHERSUITES</td>
<td>SOURCE_TLS_CIPHERSUITES</td>
</tr>
<tr>
<td>MASTER_SSL_CERT</td>
<td>SOURCE_SSL_CERT</td>
</tr>
<tr>
<td>MASTER_PUBLIC_KEY_PATH</td>
<td>SOURCE_PUBLIC_KEY_PATH</td>
</tr>
<tr>
<td>GET_MASTER_PUBLIC_KEY</td>
<td>GET_SOURCE_PUBLIC_KEY</td>
</tr>
<tr>
<td>MASTER_HEARTBEAT_PERIOD</td>
<td>SOURCE_HEARTBEAT_PERIOD</td>
</tr>
<tr>
<td>MASTER_COMPRESSION_ALGORITHMS</td>
<td>SOURCE_COMPRESSION_ALGORITHMS</td>
</tr>
<tr>
<td>MASTER_ZSTD_COMPRESSION_LEVEL</td>
<td>SOURCE_ZSTD_COMPRESSION_LEVEL</td>
</tr>
<tr>
<td>MASTER_LOG_FILE</td>
<td>SOURCE_LOG_FILE</td>
</tr>
<tr>
<td>MASTER_LOG_POS</td>
<td>SOURCE_LOG_POS</td>
</tr>
</tbody>
</table>
<p>执行 SQL 命令 <code>SHOW [GLOBAL] STATUS</code> 的结果中，也有部分状态变量发生变化，详见下表</p>
<table>
<tbody>
<tr>
<th>旧状态变量名</th>
<th>新状态变量名</th>
</tr>
</tbody>
<tbody>
<tr>
<td>Com_slave_start</td>
<td>Com_replica_start</td>
</tr>
<tr>
<td>Com_slave_stop</td>
<td>Com_replica_stop</td>
</tr>
<tr>
<td>Com_show_slave_status</td>
<td>Com_show_replica_status</td>
</tr>
<tr>
<td>Com_show_slave_hosts</td>
<td>Com_show_replicas</td>
</tr>
<tr>
<td>Com_show_master_status</td>
<td>Com_show_binary_log_status</td>
</tr>
<tr>
<td>Com_change_master</td>
<td>Com_change_replication_source</td>
</tr>
</tbody>
</table>
<h2><strong>升级/降级到 GreatSQL 8.4.4-4</strong></h2>
<h3><strong>升级到 GreatSQL 8.4.4-4</strong></h3>
<ul>
<li> <p>如果是 GreatSQL 5.7 等系列版本，可以直接在原来的 <code>datadir</code> 基础上，修改 <code>basedir</code> 后，原地（in-place）启动 GreatSQL 8.0.32-27 版本后，先原地升级到 GreatSQL 8.0.32-27 版本。再继续在该 <code>datadir</code> 基础上升级，即修改 <code>basedir</code> 指向 GreatSQL 8.4.4-4 新版本，再次进行原地升级。需要注意的是，从 5.7 版本升级到 8.0 版本，再升级到 8.4 版本后，数据库中的账号仍采用 <code>mysql_native_password</code> 密码验证插件。当最终升级到 8.4 版本后，需要修改 <em>my.cnf</em> 配置文件，加上 <code>mysql_native_password=1</code>，以保证原有的账号能正常登录。</p> </li>
<li> <p>如果是 GreatSQL 8.0 等系列版本，并且没有使用 <strong>Rapid</strong> 引擎，则可以直接在原来的 <code>datadir</code> 基础上，修改 <code>basedir</code> 后，原地（in-place）启动 GreatSQL 8.4.4-4 后会完成自动升级。</p> </li>
<li> <p>如果旧版本是 GreatSQL 8.0.32-27 且已启用 <strong>Rapid</strong> 引擎，可以直接在原来的 <code>datadir</code> 基础上，修改 <code>basedir</code> 后，原地（in-place）启动 GreatSQL 8.4.4-4 后会完成自动升级。</p> </li>
<li> <p>如果旧版本是 GreatSQL 8.0.32-25 或 8.0.32-26 且已启用 <strong>Rapid</strong> 引擎，<strong>这种情况下无法原地升级</strong>，需要卸载所有 <strong>Rapid</strong> 引擎表，删除 <strong>Rapid</strong> 数据文件，才可以在原来的 <code>datadir</code> 基础上，修改 <code>basedir</code> 后，原地（in-place）启动 GreatSQL 8.4.4-4 后进行自动升级。新版本实例启动后，对所有 <strong>Rapid</strong> 引擎表执行 <code>ALTER TABLE SECONDARY_LOAD</code> 完成全量数据导入，再执行 <code>SELECT START_SECONDARY_ENGINE_INCREMENT_LOAD_TASK()</code> 启动增量导入任务，完成 <strong>Rapid</strong> 引擎表升级工作。下面是一个升级参考过程：</p> <pre><code>&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong style="color:#000000"&gt;1. 查询并记录所有Rapid引擎表&lt;/strong&gt;
&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;可以执行下面的SQL，查询当前有哪些表使用了Rapid引擎：
&lt;pre style="margin-left:5px; margin-right:5px; text-align:left"&gt;
</code></pre> <p><code>greatsql&gt; <span>SELECT</span> TABLE_SCHEMA, TABLE_NAME, TABLE_ROWS <span>FROM</span> information_schema.TABLES <span>WHERE</span> CREATE_OPTIONS <span>LIKE</span> <span>'%Rapid%'</span>; +<em>--------------+----------------+------------+</em> | TABLE_SCHEMA | TABLE_NAME | TABLE_ROWS | +<em>--------------+----------------+------------+</em> | tpch100g | customer | 14854987 | | tpch100g | lineitem | 582868392 | | tpch100g | nation | 25 | | tpch100g | orders | 148492582 | | tpch100g | part | 19943155 | | tpch100g | partsupp | 79832625 | | tpch100g | region | 5 | | tpch100g | supplier | 989416 | +<em>--------------+----------------+------------+</em> </code></p> <pre><code>&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong style="color:#000000"&gt;2. 正常停止GreatSQL实例进程&lt;/strong&gt;
&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;在停止GreatSQL实例进程前，先修改&lt;code&gt;innodb_fast_shutdown=0&lt;/code&gt;后再执行&lt;code&gt;SHUTDOWN&lt;/code&gt;停止实例
&lt;pre style="margin-left:5px; margin-right:5px; text-align:left"&gt;
</code></pre> <p><code>greatsql&gt; <span>SET</span> <span>GLOBAL</span> innodb_fast_shutdown=<span>0</span>; greatsql&gt; SHUTDOWN; </code></p> <pre><code>&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong style="color:#000000"&gt;3. 删除旧的Rapid引擎数据文件&lt;/strong&gt;
&lt;pre style="margin-left:5px; margin-right:5px; text-align:left"&gt;
</code></pre> <p><code><span>cd</span> /data/GreatSQL &amp;&amp; rm -f duckdb* </code></p> <pre><code>&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong style="color:#000000"&gt;4. 修改&lt;code&gt;my.cnf&lt;/code&gt;配置文件中的&lt;code&gt;basedir&lt;/code&gt;参数，指向GreatSQL 8.4.4-4新版本&lt;/strong&gt;
&lt;pre style="margin-left:5px; margin-right:5px; text-align:left"&gt;
</code></pre> <p><code>#my.cnf [mysqld] basedir=/usr/local/GreatSQL-8.4.4-4-Linux-glibc2.28-x86_64 </code></p> <pre><code>&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;并确保参数&lt;code&gt;upgrade&lt;/code&gt;不是设置为&lt;em&gt;NONE&lt;/em&gt;。
&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong style="color:#000000"&gt;5. 启动GreatSQL 8.4.4-4新版本实例&lt;/strong&gt;
&lt;pre style="margin-left:5px; margin-right:5px; text-align:left"&gt;
</code></pre> <p><code>systemctl start greatsql </code></p> <pre><code>&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong style="color:#000000"&gt;6. 重新安装Rapid引擎&lt;/strong&gt;
&lt;pre style="margin-left:5px; margin-right:5px; text-align:left"&gt;
</code></pre> <p><code>greatsql&gt; <span>INSTALL</span> <span>PLUGIN</span> rapid <span>SONAME</span> <span>'ha_rapid.so'</span>; </code></p> <pre><code>&lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong style="color:#000000"&gt;7. 对Rapid引擎表做一次全量数据导入&lt;/strong&gt;
&lt;pre style="margin-left:5px; margin-right:5px; text-align:left"&gt;
</code></pre> <p><code>greatsql&gt; <span>ALTER</span> <span>TABLE</span> test.t1 SECONDARY_LOAD; </code></p> </li>
</ul>
<blockquote>
<p>tip 小贴士：由于在升级前没有去掉该表的<code>SECONDARY_ENGINE=rapid</code>属性，所以无需重新设置。如果在升级前卸载所有Rapid引擎表，则需要重新设置。</p>
</blockquote>
<p><strong>8. 再次启动增量导入任务</strong></p>
<pre><code>greatsql&gt; <span>SELECT</span> START_SECONDARY_ENGINE_INCREMENT_LOAD_TASK(<span>'test'</span>, <span>'t1'</span>);
</code></pre>
<p>这就完成Rapid引擎表的升级操作了。</p>
<ul>
<li> <p>如果是 MySQL 5.7 或 Percona Server 5.7 等系列版本，可以直接在原来的 <code>datadir</code> 基础上，修改 <code>basedir</code> 后，原地（in-place）启动 GreatSQL 8.0.32-27 版本后，确认升级成功后，再次在原来 <code>datadir</code> 基础上继续升级，即修改 <code>basedir</code> 指向 GreatSQL 8.4.4-4 新版本，之后就能完成自动升级。需要注意的是，从 5.7 版本升级到 8.0 版本，再升级到 8.4 版本后，数据库中的账号仍采用 <code>mysql_native_password</code> 密码验证插件。当最终升级到 8.4 版本后，需要修改 <em>my.cnf</em> 配置文件，加上 <code>mysql_native_password=1</code>，以保证原有的账号能正常登录。</p> </li>
<li> <p>如果是 MySQL 8.0 或 Percona Server 8.0 等系列版本，则可以直接在原来的 <code>datadir</code> 基础上，修改 <code>basedir</code> 后，原地（in-place）启动 GreatSQL 8.4.4-4 后会完成自动升级。</p> </li>
<li> <p>其他情况下，最好采用导入逻辑备份文件方式升级到 GreatSQL 8.4.4-4 版本。</p> </li>
</ul>
<p>在以上几个原地升级场景中，务必保证<code>my.cnf</code>中参数<code>upgrade</code>不能设置为<em>NONE</em>，可以设置为默认的<em>AUTO</em>或<em>FORCE</em>。例如：</p>
<pre><code>#my.cnf
[mysqld]
upgrade = AUTO
</code></pre>
<p>更多迁移升级方案请参考：</p>
<ul>
<li>迁移升级：https://greatsql.cn/docs/8.4.4-4/7-migrate-and-upgrade/0-migrate-and-upgrade.html</li>
</ul>
<h3><strong>降级到 GreatSQL 8.4.4-4</strong></h3>
<p>如果是要从 MySQL/Percona 8.4 系列较高的小版本降级到 GreatSQL 8.4.4-4 版本，可以采用原地降级方式快速完成版本降级操作。即可以直接在原来的 <code>datadir</code> 基础上，修改 <code>basedir</code> 后，并增加设置参数<code>upgrade=FORCE</code>，原地（in-place）启动 GreatSQL 8.4.4-4 后会完成自动降级。</p>
<p>如果是要从 MySQL/Percona 9.0 及之后的版本降级到 GreatSQL 8.4.4-4 版本，则需要采取逻辑备份 + 逻辑导入方式完成降级操作，并且在逻辑备份导入完成后的首次重启时，务必设置 <code>upgrade=FORCE</code> 强制升级所有数据表，包括系统表。</p>
<p>降级过程操作大致如下所示：</p>
<p><strong>1. 在高版本中逻辑备份全量数据</strong></p>
<pre><code>mysqldump -S/data/MySQL/mysql.sock -A --triggers --routines --events --single-transaction &gt; /data/backup/fulldump.sql
</code></pre>
<p><strong>2. 在GreatSQL 8.4.4-4版本环境中导入逻辑备份文件，完成逻辑恢复</strong></p>
<pre><code>mysql -S/data/GreatSQL/mysql.sock -f &lt; /data/backup/fulldump.sql
</code></pre>
<p><strong>3. 修改<code>my.cnf</code>，确保设置<code>upgrade=FORCE</code></strong></p>
<pre><code>#my.cnf
[mysqld]
upgrade = FORCE
</code></pre>
<p><strong>4. 重启GreatSQL，降级完成</strong></p>
<pre><code>systemctl restart greatsql
</code></pre>
<p>重启过程中，可以看到日志有类似下面的强制降级过程</p>
<pre><code>[Note] [MY-013387] [Server] Upgrading system table data.
[Note] [MY-013385] [Server] Upgrading the sys schema.
[Note] [MY-013400] [Server] Upgrade of help tables started.
[Note] [MY-013400] [Server] Upgrade of help tables completed.
[Note] [MY-013394] [Server] Checking 'mysql' schema.
[Note] [MY-013394] [Server] Checking 'sys' schema.
[System] [MY-014064] [Server] Server downgrade from '80406' to '80404' started.
[System] [MY-014064] [Server] Server downgrade from '80406' to '80404' completed.
</code></pre>
<p>如果不设置 <code>upgrade = FORCE</code> 强制升级所有表，有可能发生系统表 <code>mysql.procs_priv</code> 损坏错误，在创建用户时可能会报告类似下面的错误：</p>
<pre><code>greatsql&gt; <span>CREATE</span> <span>USER</span> tpch <span>IDENTIFIED</span> <span>BY</span> <span>'tpch'</span>;
ERROR 1728 (HY000): Cannot <span>load</span> <span>from</span> mysql.procs_priv. The <span>table</span> <span>is</span> probably corrupted
</code></pre>
<h2><strong>GreatSQL vs MySQL</strong></h2>
<table>
<tbody>
<tr>
<th><strong>1.主要特性</strong></th>
<th>GreatSQL 8.4.4-4</th>
<th>MySQL 8.4.4</th>
</tr>
</tbody>
<tbody>
<tr>
<td>开源</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>ACID 完整性</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>MVCC 特性</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>支持行锁</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>Crash 自动修复</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>表分区（Partitioning）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>视图（Views）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>子查询（Subqueries）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>触发器（Triggers）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>存储程序（Stored Programs）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>外键（Foreign Keys）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>窗口函数（Window Functions）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>通用表表达式 CTE</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>地理信息（GIS）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>基于 GTID 的复制</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>组复制（MGR）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>MyRocks 引擎</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>支持龙芯架构</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td><strong>2. 性能提升扩展</strong></td>
<td>GreatSQL 8.4.4-4</td>
<td>MySQL 8.4.4</td>
</tr>
<tr>
<td>Rapid 引擎</td>
<td>✔️</td>
<td>仅云上HeatWave</td>
</tr>
<tr>
<td>Turbo 引擎</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>NUMA 亲和性优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>非阻塞式 DDL</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>无主键表导入优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>并行 LOAD DATA</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>InnoDB 事务 ReadView 无锁优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>InnoDB 事务大锁拆分优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>InnoDB Page压缩支持Zstd</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>InnoDB 资源组</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>自定义 InnoDB 页大小</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>Contention-Aware Transaction Scheduling</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>InnoDB Mutexes 拆分优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MEMORY 引擎优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>InnoDB Flushing 优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>并行 Doublewrite Buffer</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>InnoDB 快速索引创建优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>VARCHAR/BLOB/JSON 类型存储单列压缩</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>数据字典中存储单列压缩信息</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td><strong>3. 面向开发者提升改进</strong></td>
<td>GreatSQL 8.4.4-4</td>
<td>MySQL 8.4.4</td>
</tr>
<tr>
<td>X API</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>JSON</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>NoSQL Socket-Level接口</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>InnoDB 全文搜索改进</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>更多 Hash/Digest 函数</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Oracle 兼容-数据类型</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Oracle 兼容-函数</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Oracle 兼容-SQL语法</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Oracle 兼容-存储程序</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td><strong>4. 基础特性提升改进</strong></td>
<td>GreatSQL 8.4.4-4</td>
<td>MySQL 8.4.4</td>
</tr>
<tr>
<td>MGR 提升-地理标签</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-仲裁节点</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-读写节点绑定VIP</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-快速单主模式</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-智能选主机制</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-全新流控算法</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-网络分区异常处理</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-节点异常退出处理</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-节点磁盘满处理</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-自动选择 donor 节点</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>MGR 提升-大事务压缩优化</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Clone 增量备份</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Clone 备份压缩</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Binlog 读取限速</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>information_schema 表数量</td>
<td>95</td>
<td>65</td>
</tr>
<tr>
<td>全局性能和状态指标</td>
<td>853</td>
<td>434</td>
</tr>
<tr>
<td>优化器直方图（Histograms）</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>Per-Table 性能指标</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Per-Index 性能指标</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Per-User 性能指标</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Per-Client 性能指标</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Per-Thread 性能指标</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>全局查询相应耗时统计</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>SHOW ENGINE INNODB STATUS 增强</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>回滚段信息增强</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>临时表信息增强</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>用户统计信息增强</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>Slow log 信息增强</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td><strong>5.安全性提升</strong></td>
<td>GreatSQL 8.4.4-4</td>
<td>MySQL 8.4.4</td>
</tr>
<tr>
<td>国密支持</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>备份加密</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>审计</td>
<td>✔️</td>
<td>仅企业版</td>
</tr>
<tr>
<td>数据脱敏</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>SQL Roles</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>SHA-2 密码Hashing</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>密码轮换策略</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>PAM 认证插件</td>
<td>✔️</td>
<td>仅企业版</td>
</tr>
<tr>
<td>Keyring 存储在文件中</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>Keyring 存储在Hashicorp Vault中</td>
<td>✔️</td>
<td>仅企业版</td>
</tr>
<tr>
<td>InnoDB 数据加密</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>InnoDB 日志加密</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>InnoDB 各种表空间文件加密</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>二进制日志加密</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>临时文件加密</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>强制加密</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td><strong>6. 运维便利性提升</strong></td>
<td>GreatSQL 8.4.4-4</td>
<td>MySQL 8.4.4</td>
</tr>
<tr>
<td>DDL 原子性</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>数据字典存储 InnoDB 表</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>快速 DDL</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>SET PERSIST</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>不可见索引</td>
<td>✔️</td>
<td>✔️</td>
</tr>
<tr>
<td>线程池（Threadpool）</td>
<td>✔️</td>
<td>仅企业版</td>
</tr>
<tr>
<td>备份锁</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>SHOW GRANTS 扩展</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>表损坏动作扩展</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>杀掉不活跃事务</td>
<td>✔️</td>
<td>❌</td>
</tr>
<tr>
<td>START TRANSACTION WITH CONSISTENT SNAPSHOT 扩展</td>
<td>✔️</td>
<td>❌</td>
</tr>
</tbody>
</table>
<p>GreatSQL 8.4.4-4 基于 Percona Server for MySQL 8.4.4-4 版本，它在 MySQL 8.4.4 基础上做了大量的改进和提升以及众多新特性，详情请见：</p>
<ul>
<li>Percona Server for MySQL feature comparison: https://docs.percona.com/percona-server/8.4/feature-comparison.html</li>
</ul>
<p>这其中包括线程池、审计、数据脱敏等 MySQL 企业版才有的特性，以及 performance_schema 提升、information_schema 提升、性能和可扩展性提升、用户统计增强、PROCESSLIST 增强、Slow Log 增强等大量改进和提升，这里不一一重复列出。</p>
<h2><strong>GreatSQL Release Notes</strong></h2>
<h3><strong>GreatSQL 8.4</strong></h3>
<ul>
<li>Changes in GreatSQL 8.4.4-4 (2025-10-15) https://greatsql.cn/docs/8.4.4-4/1-docs-intro/relnotes/changes-greatsql-8444.html</li>
</ul>
<h3><strong>GreatSQL 8.0</strong></h3>
<ul>
<li>Changes in GreatSQL 8.0.32-27 (2025-3-10)</li>
<li>Changes in GreatSQL 8.0.32-26 (2024-8-5)</li>
<li>Changes in GreatSQL 8.0.32-25 (2023-12-28)</li>
<li>Changes in GreatSQL 8.0.32-24 (2023-6-5)</li>
<li>Changes in GreatSQL 8.0.25-17 (2023-3-13)</li>
<li>Changes in GreatSQL 8.0.25-16 (2022-5-16)</li>
<li>Changes in GreatSQL 8.0.25-15 (2021-8-26)</li>
</ul>
<h3><strong>GreatSQL 5.7</strong></h3>
<ul>
<li>Changes in GreatSQL 5.7.36-39 (2022-4-7)</li>
</ul>]]></content:encoded>
    
    <pubDate>Wed, 15 Oct 2025 09:26:31 +0800</pubDate>
  </item><item>
    <title><![CDATA[高性能跨平台网络通信框架 HP-Socket v6.0.7 发布]]></title>
    <link>https://www.oschina.net/news/377453</link>
    <itunes:title><![CDATA[高性能跨平台网络通信框架 HP-Socket v6.0.7 发布]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fldcsaa%2FHP-Socket" target="_blank"><img alt="HP-Socket" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-68508a98b0.png"></a></p>
<ul>
<li>项目主页&nbsp;:&nbsp;<a href="http://www.oschina.net/p/hp-socket" target="_blank">http://www.oschina.net/p/hp-socket</a></li>
<li>开发文档&nbsp;: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.docin.com%2Fp-4592706661.html" target="_blank">https://www.docin.com/p-4592706661.html</a></li>
<li>下载地址&nbsp;: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fldcsaa%2FHP-Socket" target="_blank">https://github.com/ldcsaa/HP-Socket</a></li>
<li>QQ Group: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjq.qq.com%2F%3F_wv%3D1027%26k%3D3UAbrhTG" target="_blank">44636872</a>, <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjq.qq.com%2F%3F_wv%3D1027%26k%3DuYBpc6bG" target="_blank">663903943</a></li>
</ul>
<hr>
<h2><span><strong>v6.0.7 更新</strong></span></h2>
<p><strong>一、主要更新</strong></p>
<ol>
<li>优化Linux通信组件多路复用处理架构，避免“惊群”问题，提升性能。</li>
<li>自动为 HP-Socket 工作线程设置唯一线程名称，方便跟踪调试。</li>
<li>TCP Client/Agent 以同步方式连接服务端时，支持通过 <em>SetSyncConnectTimeout()</em> 设置连接超时时间。</li>
<li>TcpServer/UdpServer/UdpNode 支持通过 SetDualStack() 方法设置是否支持 IPv4/IPv6 双协议栈。</li>
<li>客户端组件（Client/Agent）手工绑定本地地址的情况下，会根据连接的远程地址自动绑定本地的IPv4或IPv6地址。</li>
<li>支持定时回收垃圾内存和被动回收垃圾内存（默认使用定时回收，回收间隔 15 秒）。</li>
<li>Windows版本支持在没有安装 MFC 的环境下编译。</li>
</ol>
<p><strong>二、第三方库更新</strong></p>
<ol>
<li>openssl 升级到 3.0.18 版本</li>
<li>mimalloc 升级到 2.2.4 版本</li>
</ol>
<hr>
<h2><span><strong>HP-Socket 组件列表</strong></span></h2>
<ol>
<li><span><strong>基础组件<br> <img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-1a71c07c2e.png"></strong></span></li>
<li><span><strong>SSL 组件<br> <img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-fa2fd83cad.png"></strong></span></li>
<li><span><strong>HTTP 组件<br> <img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-979c3f87aa.png"></strong></span></li>
</ol>
<hr>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fldcsaa%2FHP-Socket" target="_blank"><img alt="HP-Socket" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-68508a98b0.png"></a></p>
<ul>
<li>项目主页&nbsp;:&nbsp;<a href="http://www.oschina.net/p/hp-socket" target="_blank">http://www.oschina.net/p/hp-socket</a></li>
<li>开发文档&nbsp;: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.docin.com%2Fp-4592706661.html" target="_blank">https://www.docin.com/p-4592706661.html</a></li>
<li>下载地址&nbsp;: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fldcsaa%2FHP-Socket" target="_blank">https://github.com/ldcsaa/HP-Socket</a></li>
<li>QQ Group: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjq.qq.com%2F%3F_wv%3D1027%26k%3D3UAbrhTG" target="_blank">44636872</a>, <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjq.qq.com%2F%3F_wv%3D1027%26k%3DuYBpc6bG" target="_blank">663903943</a></li>
</ul>
<hr>
<h2><span><strong>v6.0.7 更新</strong></span></h2>
<p><strong>一、主要更新</strong></p>
<ol>
<li>优化Linux通信组件多路复用处理架构，避免“惊群”问题，提升性能。</li>
<li>自动为 HP-Socket 工作线程设置唯一线程名称，方便跟踪调试。</li>
<li>TCP Client/Agent 以同步方式连接服务端时，支持通过 <em>SetSyncConnectTimeout()</em> 设置连接超时时间。</li>
<li>TcpServer/UdpServer/UdpNode 支持通过 SetDualStack() 方法设置是否支持 IPv4/IPv6 双协议栈。</li>
<li>客户端组件（Client/Agent）手工绑定本地地址的情况下，会根据连接的远程地址自动绑定本地的IPv4或IPv6地址。</li>
<li>支持定时回收垃圾内存和被动回收垃圾内存（默认使用定时回收，回收间隔 15 秒）。</li>
<li>Windows版本支持在没有安装 MFC 的环境下编译。</li>
</ol>
<p><strong>二、第三方库更新</strong></p>
<ol>
<li>openssl 升级到 3.0.18 版本</li>
<li>mimalloc 升级到 2.2.4 版本</li>
</ol>
<hr>
<h2><span><strong>HP-Socket 组件列表</strong></span></h2>
<ol>
<li><span><strong>基础组件<br> <img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-1a71c07c2e.png"></strong></span></li>
<li><span><strong>SSL 组件<br> <img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-fa2fd83cad.png"></strong></span></li>
<li><span><strong>HTTP 组件<br> <img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-979c3f87aa.png"></strong></span></li>
</ol>
<hr>]]>
    </description>
    <content:encoded><![CDATA[<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fldcsaa%2FHP-Socket" target="_blank"><img alt="HP-Socket" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-68508a98b0.png"></a></p>
<ul>
<li>项目主页&nbsp;:&nbsp;<a href="http://www.oschina.net/p/hp-socket" target="_blank">http://www.oschina.net/p/hp-socket</a></li>
<li>开发文档&nbsp;: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.docin.com%2Fp-4592706661.html" target="_blank">https://www.docin.com/p-4592706661.html</a></li>
<li>下载地址&nbsp;: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fldcsaa%2FHP-Socket" target="_blank">https://github.com/ldcsaa/HP-Socket</a></li>
<li>QQ Group: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjq.qq.com%2F%3F_wv%3D1027%26k%3D3UAbrhTG" target="_blank">44636872</a>, <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjq.qq.com%2F%3F_wv%3D1027%26k%3DuYBpc6bG" target="_blank">663903943</a></li>
</ul>
<hr>
<h2><span><strong>v6.0.7 更新</strong></span></h2>
<p><strong>一、主要更新</strong></p>
<ol>
<li>优化Linux通信组件多路复用处理架构，避免“惊群”问题，提升性能。</li>
<li>自动为 HP-Socket 工作线程设置唯一线程名称，方便跟踪调试。</li>
<li>TCP Client/Agent 以同步方式连接服务端时，支持通过 <em>SetSyncConnectTimeout()</em> 设置连接超时时间。</li>
<li>TcpServer/UdpServer/UdpNode 支持通过 SetDualStack() 方法设置是否支持 IPv4/IPv6 双协议栈。</li>
<li>客户端组件（Client/Agent）手工绑定本地地址的情况下，会根据连接的远程地址自动绑定本地的IPv4或IPv6地址。</li>
<li>支持定时回收垃圾内存和被动回收垃圾内存（默认使用定时回收，回收间隔 15 秒）。</li>
<li>Windows版本支持在没有安装 MFC 的环境下编译。</li>
</ol>
<p><strong>二、第三方库更新</strong></p>
<ol>
<li>openssl 升级到 3.0.18 版本</li>
<li>mimalloc 升级到 2.2.4 版本</li>
</ol>
<hr>
<h2><span><strong>HP-Socket 组件列表</strong></span></h2>
<ol>
<li><span><strong>基础组件<br> <img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-1a71c07c2e.png"></strong></span></li>
<li><span><strong>SSL 组件<br> <img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-fa2fd83cad.png"></strong></span></li>
<li><span><strong>HTTP 组件<br> <img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-979c3f87aa.png"></strong></span></li>
</ol>
<hr>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-68508a98b0.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-68508a98b0.png" medium="image"/>
    <pubDate>Wed, 15 Oct 2025 03:28:54 +0800</pubDate>
  </item><item>
    <title><![CDATA[GNOME Flatpak 运行时不再兼容 32 位扩展]]></title>
    <link>https://www.oschina.net/news/377416</link>
    <itunes:title><![CDATA[GNOME Flatpak 运行时不再兼容 32 位扩展]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>GNOME 团队近日<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblogs.gnome.org%2Falatiera%2F2025%2F10%2F13%2Fflatpak-32bit%2F" target="_blank">宣布</a>，在最新的 <strong>GNOME 49</strong> 中，Flatpak 运行时正式移除用于 32 位环境的兼容扩展（<code>org.gnome.Platform.i386.Compat</code>），意味着 GNOME 平台今后将仅支持 <strong>x86_64</strong> 和 <strong>AArch64</strong> 架构。</p>
<p>更早之前，GNOME 已经移除了对 <strong>ARMv7（32 位 ARM）</strong> 的支持，以及对 i386（传统的 32 位 x86） 构建的支持。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-deeab67562.png"></p>
<p>这一扩展最初用于支持如 Wine 等依赖 32 位库的应用，但由于维护资源有限，GNOME 开发者决定放弃该功能。据称，这一调整部分原因是<span><strong>项目失去了持续集成环境中的捐赠硬件</strong></span>，32 位兼容模块因此成为首个被精简的目标。</p>
<p>在官方公告中（由 Jordan Petridis 发布）提到，如果有发行版或用户还依赖于 32 位 GNOME 构建，那么他们将需要自行维护、调试这些版本，或直接参与上游（GNOME 社区）的工作，以避免 32 位版本逐渐“腐蚀”（bit rot）。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>GNOME 团队近日<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblogs.gnome.org%2Falatiera%2F2025%2F10%2F13%2Fflatpak-32bit%2F" target="_blank">宣布</a>，在最新的 <strong>GNOME 49</strong> 中，Flatpak 运行时正式移除用于 32 位环境的兼容扩展（<code>org.gnome.Platform.i386.Compat</code>），意味着 GNOME 平台今后将仅支持 <strong>x86_64</strong> 和 <strong>AArch64</strong> 架构。</p>
<p>更早之前，GNOME 已经移除了对 <strong>ARMv7（32 位 ARM）</strong> 的支持，以及对 i386（传统的 32 位 x86） 构建的支持。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-deeab67562.png"></p>
<p>这一扩展最初用于支持如 Wine 等依赖 32 位库的应用，但由于维护资源有限，GNOME 开发者决定放弃该功能。据称，这一调整部分原因是<span><strong>项目失去了持续集成环境中的捐赠硬件</strong></span>，32 位兼容模块因此成为首个被精简的目标。</p>
<p>在官方公告中（由 Jordan Petridis 发布）提到，如果有发行版或用户还依赖于 32 位 GNOME 构建，那么他们将需要自行维护、调试这些版本，或直接参与上游（GNOME 社区）的工作，以避免 32 位版本逐渐“腐蚀”（bit rot）。</p>]]>
    </description>
    <content:encoded><![CDATA[<p>GNOME 团队近日<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblogs.gnome.org%2Falatiera%2F2025%2F10%2F13%2Fflatpak-32bit%2F" target="_blank">宣布</a>，在最新的 <strong>GNOME 49</strong> 中，Flatpak 运行时正式移除用于 32 位环境的兼容扩展（<code>org.gnome.Platform.i386.Compat</code>），意味着 GNOME 平台今后将仅支持 <strong>x86_64</strong> 和 <strong>AArch64</strong> 架构。</p>
<p>更早之前，GNOME 已经移除了对 <strong>ARMv7（32 位 ARM）</strong> 的支持，以及对 i386（传统的 32 位 x86） 构建的支持。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-deeab67562.png"></p>
<p>这一扩展最初用于支持如 Wine 等依赖 32 位库的应用，但由于维护资源有限，GNOME 开发者决定放弃该功能。据称，这一调整部分原因是<span><strong>项目失去了持续集成环境中的捐赠硬件</strong></span>，32 位兼容模块因此成为首个被精简的目标。</p>
<p>在官方公告中（由 Jordan Petridis 发布）提到，如果有发行版或用户还依赖于 32 位 GNOME 构建，那么他们将需要自行维护、调试这些版本，或直接参与上游（GNOME 社区）的工作，以避免 32 位版本逐渐“腐蚀”（bit rot）。</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-deeab67562.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-deeab67562.png" medium="image"/>
    <pubDate>Tue, 14 Oct 2025 19:26:44 +0800</pubDate>
  </item><item>
    <title><![CDATA[WinBoat - 在 Linux 上运行 Windows 应用]]></title>
    <link>https://www.oschina.net/p/winboat</link>
    <itunes:title><![CDATA[WinBoat - 在 Linux 上运行 Windows 应用]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>WinBoat 是一款 Electron 应用，它允许你使用容器化方法在 Linux 上运行 Windows 应用。Windows 以虚拟机的形式在 Docker 容器内运行，使用&nbsp;<span><span>&nbsp;</span></span><a href="https://github.com/TibixDev/winboat/tree/main/guest_server">WinBoat Guest Server</a><span><span>&nbsp;</span></span>与其通信，从 Windows 中检索所需的数据。为了将应用程序合成为原生操作系统级窗口，将 FreeRDP 与 Windows 的 RemoteApp 协议结合使用。</p>
<p><span>WinBoat 目前处于测试阶段。</span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-17332fb737.png"></p>
<p><strong>特性：</strong></p>
<ul>
<li><strong>优雅的界面</strong>：时尚直观的界面，将 Windows 无缝集成到你的 Linux 桌面环境中，让你感觉像原生体验</li>
<li><strong>自动安装</strong>：通过界面进行简单的安装过程 - 选择你的偏好和规格，然后自动处理其余部分</li>
<li><strong>运行任何应用程序</strong>：只要能在 Windows 上运行，就能在 WinBoat 上运行。在 Linux 环境中，像原生操作系统级窗口一样畅享各种 Windows 应用程序。</li>
<li><strong>完整的 Windows 桌面</strong>：在需要时访问完整的 Windows 桌面体验，或运行无缝集成到 Linux 工作流程中的单个应用程序</li>
<li><strong>文件系统集成</strong>：主目录安装在 Windows 中，允许在两个系统之间轻松共享文件，没有任何麻烦</li>
<li><strong>还有更多</strong>：智能卡直通、资源监控以及定期添加的更多功能</li>
</ul>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>WinBoat 是一款 Electron 应用，它允许你使用容器化方法在 Linux 上运行 Windows 应用。Windows 以虚拟机的形式在 Docker 容器内运行，使用&nbsp;<span><span>&nbsp;</span></span><a href="https://github.com/TibixDev/winboat/tree/main/guest_server">WinBoat Guest Server</a><span><span>&nbsp;</span></span>与其通信，从 Windows 中检索所需的数据。为了将应用程序合成为原生操作系统级窗口，将 FreeRDP 与 Windows 的 RemoteApp 协议结合使用。</p>
<p><span>WinBoat 目前处于测试阶段。</span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-17332fb737.png"></p>
<p><strong>特性：</strong></p>
<ul>
<li><strong>优雅的界面</strong>：时尚直观的界面，将 Windows 无缝集成到你的 Linux 桌面环境中，让你感觉像原生体验</li>
<li><strong>自动安装</strong>：通过界面进行简单的安装过程 - 选择你的偏好和规格，然后自动处理其余部分</li>
<li><strong>运行任何应用程序</strong>：只要能在 Windows 上运行，就能在 WinBoat 上运行。在 Linux 环境中，像原生操作系统级窗口一样畅享各种 Windows 应用程序。</li>
<li><strong>完整的 Windows 桌面</strong>：在需要时访问完整的 Windows 桌面体验，或运行无缝集成到 Linux 工作流程中的单个应用程序</li>
<li><strong>文件系统集成</strong>：主目录安装在 Windows 中，允许在两个系统之间轻松共享文件，没有任何麻烦</li>
<li><strong>还有更多</strong>：智能卡直通、资源监控以及定期添加的更多功能</li>
</ul>]]>
    </description>
    <content:encoded><![CDATA[<p>WinBoat 是一款 Electron 应用，它允许你使用容器化方法在 Linux 上运行 Windows 应用。Windows 以虚拟机的形式在 Docker 容器内运行，使用&nbsp;<span><span>&nbsp;</span></span><a href="https://github.com/TibixDev/winboat/tree/main/guest_server">WinBoat Guest Server</a><span><span>&nbsp;</span></span>与其通信，从 Windows 中检索所需的数据。为了将应用程序合成为原生操作系统级窗口，将 FreeRDP 与 Windows 的 RemoteApp 协议结合使用。</p>
<p><span>WinBoat 目前处于测试阶段。</span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-17332fb737.png"></p>
<p><strong>特性：</strong></p>
<ul>
<li><strong>优雅的界面</strong>：时尚直观的界面，将 Windows 无缝集成到你的 Linux 桌面环境中，让你感觉像原生体验</li>
<li><strong>自动安装</strong>：通过界面进行简单的安装过程 - 选择你的偏好和规格，然后自动处理其余部分</li>
<li><strong>运行任何应用程序</strong>：只要能在 Windows 上运行，就能在 WinBoat 上运行。在 Linux 环境中，像原生操作系统级窗口一样畅享各种 Windows 应用程序。</li>
<li><strong>完整的 Windows 桌面</strong>：在需要时访问完整的 Windows 桌面体验，或运行无缝集成到 Linux 工作流程中的单个应用程序</li>
<li><strong>文件系统集成</strong>：主目录安装在 Windows 中，允许在两个系统之间轻松共享文件，没有任何麻烦</li>
<li><strong>还有更多</strong>：智能卡直通、资源监控以及定期添加的更多功能</li>
</ul>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-17332fb737.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-17332fb737.png" medium="image"/>
    <pubDate>Tue, 14 Oct 2025 18:37:46 +0800</pubDate>
  </item><item>
    <title><![CDATA[抖音与 LV-NUS 联合推出 SAIL-VL2 模型]]></title>
    <link>https://www.oschina.net/news/377404</link>
    <itunes:title><![CDATA[抖音与 LV-NUS 联合推出 SAIL-VL2 模型]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>抖音 SAIL 团队与 LV-NUS Lab 联手推出了一款名为 SAIL-VL2 的多模态大模型，并已开源。这个新模型在保持较小参数规模的同时，还在复杂推理任务中超过了许多同类模型，甚至能与更大型的闭源模型相抗衡。</p>
<p>SAIL-VL2的参数设置分为2B 和8B，在106个数据集上实现了性能的突破，尤其在 MMMU、MathVista 等复杂推理基准测试中表现优异。SAIL-VL2在数据、训练及架构设计上进行了三大方面的创新。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-3cfa38b868.png"></p>
<p>在架构设计上，SAIL-VL2引入了稀疏混合专家（MoE），以优化性能和计算效率。其视觉编码器 SAIL-ViT 采用渐进式优化，逐步提升视觉 - 语言的对齐能力。这种创新设计使得 SAIL-VL2在推理时仅需激活部分参数，大幅度提升了模型的计算效率。</p>
<p>数据层面上，SAIL-VL2构建了高质量的多模态语料库，通过评分过滤和合成增强手段，确保数据的准确性和多样性。同时，团队还设计了一套渐进式的训练框架，从基础感知逐步过渡到复杂推理，使得模型在不同任务中的表现更加出色。</p>
<p>通过全链路优化，SAIL-VL2在基础模型的性能上取得了显著进展。数据显示，该模型在多项基准测试中脱颖而出，其8B 规模的模型在推理能力上，已然与<span>最新</span>的 GPT-4o 不相上下。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>抖音 SAIL 团队与 LV-NUS Lab 联手推出了一款名为 SAIL-VL2 的多模态大模型，并已开源。这个新模型在保持较小参数规模的同时，还在复杂推理任务中超过了许多同类模型，甚至能与更大型的闭源模型相抗衡。</p>
<p>SAIL-VL2的参数设置分为2B 和8B，在106个数据集上实现了性能的突破，尤其在 MMMU、MathVista 等复杂推理基准测试中表现优异。SAIL-VL2在数据、训练及架构设计上进行了三大方面的创新。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-3cfa38b868.png"></p>
<p>在架构设计上，SAIL-VL2引入了稀疏混合专家（MoE），以优化性能和计算效率。其视觉编码器 SAIL-ViT 采用渐进式优化，逐步提升视觉 - 语言的对齐能力。这种创新设计使得 SAIL-VL2在推理时仅需激活部分参数，大幅度提升了模型的计算效率。</p>
<p>数据层面上，SAIL-VL2构建了高质量的多模态语料库，通过评分过滤和合成增强手段，确保数据的准确性和多样性。同时，团队还设计了一套渐进式的训练框架，从基础感知逐步过渡到复杂推理，使得模型在不同任务中的表现更加出色。</p>
<p>通过全链路优化，SAIL-VL2在基础模型的性能上取得了显著进展。数据显示，该模型在多项基准测试中脱颖而出，其8B 规模的模型在推理能力上，已然与<span>最新</span>的 GPT-4o 不相上下。</p>]]>
    </description>
    <content:encoded><![CDATA[<p>抖音 SAIL 团队与 LV-NUS Lab 联手推出了一款名为 SAIL-VL2 的多模态大模型，并已开源。这个新模型在保持较小参数规模的同时，还在复杂推理任务中超过了许多同类模型，甚至能与更大型的闭源模型相抗衡。</p>
<p>SAIL-VL2的参数设置分为2B 和8B，在106个数据集上实现了性能的突破，尤其在 MMMU、MathVista 等复杂推理基准测试中表现优异。SAIL-VL2在数据、训练及架构设计上进行了三大方面的创新。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-3cfa38b868.png"></p>
<p>在架构设计上，SAIL-VL2引入了稀疏混合专家（MoE），以优化性能和计算效率。其视觉编码器 SAIL-ViT 采用渐进式优化，逐步提升视觉 - 语言的对齐能力。这种创新设计使得 SAIL-VL2在推理时仅需激活部分参数，大幅度提升了模型的计算效率。</p>
<p>数据层面上，SAIL-VL2构建了高质量的多模态语料库，通过评分过滤和合成增强手段，确保数据的准确性和多样性。同时，团队还设计了一套渐进式的训练框架，从基础感知逐步过渡到复杂推理，使得模型在不同任务中的表现更加出色。</p>
<p>通过全链路优化，SAIL-VL2在基础模型的性能上取得了显著进展。数据显示，该模型在多项基准测试中脱颖而出，其8B 规模的模型在推理能力上，已然与<span>最新</span>的 GPT-4o 不相上下。</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-3cfa38b868.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-3cfa38b868.png" medium="image"/>
    <pubDate>Tue, 14 Oct 2025 18:13:21 +0800</pubDate>
  </item><item>
    <title><![CDATA[苹果发布全新 FS-DFM 模型，提升长文本生成效率]]></title>
    <link>https://www.oschina.net/news/377398</link>
    <itunes:title><![CDATA[苹果发布全新 FS-DFM 模型，提升长文本生成效率]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>苹果公司与俄亥俄州立大学研究团队联合发布了名为FS-DFM（Few-Step Discrete Flow-Matching）的全新语言模型。该模型在长文本生成方面实现了重大突破，通过三步法优化了迭代机制，使其在文本生成的困惑度和熵等关键指标上优于其他大型模型。</p>
<p><strong>生成速度大幅提升</strong></p>
<p>FS-DFM模型仅需<strong>8轮快速迭代</strong>即可生成高质量长文本，速度较传统扩散模型提升<strong>128倍</strong>，显著缩短了长文本生成的等待时间。</p>
<p><strong>文本质量保持领先</strong></p>
<p>在困惑度（衡量文本准确性和流畅性）和熵（衡量选词置信度）等关键指标上，FS-DFM的表现优于拥有数十亿参数的主流模型（如Dream-7B、LLaDA-8B），且参数量仅为1.7亿至17亿，实现了“小模型大效果”。</p>
<p><strong>技术创新与优化</strong></p>
<ul>
<li><strong>动态迭代预算</strong>：模型可根据任务需求自动调整迭代深度，避免冗余计算。</li>
<li><strong>教师指导机制</strong>：引入高精度“教师模型”引导迭代，确保更新精准且稳定。</li>
<li><strong>稳态收敛策略</strong>：优化迭代步长，加速模型收敛，减少步骤的同时保证质量。</li>
</ul>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-65d4f10f40.png"></p>
<p>详情：<em>https://machinelearning.apple.com/research/fs-dfm</em></p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>苹果公司与俄亥俄州立大学研究团队联合发布了名为FS-DFM（Few-Step Discrete Flow-Matching）的全新语言模型。该模型在长文本生成方面实现了重大突破，通过三步法优化了迭代机制，使其在文本生成的困惑度和熵等关键指标上优于其他大型模型。</p>
<p><strong>生成速度大幅提升</strong></p>
<p>FS-DFM模型仅需<strong>8轮快速迭代</strong>即可生成高质量长文本，速度较传统扩散模型提升<strong>128倍</strong>，显著缩短了长文本生成的等待时间。</p>
<p><strong>文本质量保持领先</strong></p>
<p>在困惑度（衡量文本准确性和流畅性）和熵（衡量选词置信度）等关键指标上，FS-DFM的表现优于拥有数十亿参数的主流模型（如Dream-7B、LLaDA-8B），且参数量仅为1.7亿至17亿，实现了“小模型大效果”。</p>
<p><strong>技术创新与优化</strong></p>
<ul>
<li><strong>动态迭代预算</strong>：模型可根据任务需求自动调整迭代深度，避免冗余计算。</li>
<li><strong>教师指导机制</strong>：引入高精度“教师模型”引导迭代，确保更新精准且稳定。</li>
<li><strong>稳态收敛策略</strong>：优化迭代步长，加速模型收敛，减少步骤的同时保证质量。</li>
</ul>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-65d4f10f40.png"></p>
<p>详情：<em>https://machinelearning.apple.com/research/fs-dfm</em></p>]]>
    </description>
    <content:encoded><![CDATA[<p>苹果公司与俄亥俄州立大学研究团队联合发布了名为FS-DFM（Few-Step Discrete Flow-Matching）的全新语言模型。该模型在长文本生成方面实现了重大突破，通过三步法优化了迭代机制，使其在文本生成的困惑度和熵等关键指标上优于其他大型模型。</p>
<p><strong>生成速度大幅提升</strong></p>
<p>FS-DFM模型仅需<strong>8轮快速迭代</strong>即可生成高质量长文本，速度较传统扩散模型提升<strong>128倍</strong>，显著缩短了长文本生成的等待时间。</p>
<p><strong>文本质量保持领先</strong></p>
<p>在困惑度（衡量文本准确性和流畅性）和熵（衡量选词置信度）等关键指标上，FS-DFM的表现优于拥有数十亿参数的主流模型（如Dream-7B、LLaDA-8B），且参数量仅为1.7亿至17亿，实现了“小模型大效果”。</p>
<p><strong>技术创新与优化</strong></p>
<ul>
<li><strong>动态迭代预算</strong>：模型可根据任务需求自动调整迭代深度，避免冗余计算。</li>
<li><strong>教师指导机制</strong>：引入高精度“教师模型”引导迭代，确保更新精准且稳定。</li>
<li><strong>稳态收敛策略</strong>：优化迭代步长，加速模型收敛，减少步骤的同时保证质量。</li>
</ul>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-65d4f10f40.png"></p>
<p>详情：<em>https://machinelearning.apple.com/research/fs-dfm</em></p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-65d4f10f40.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-65d4f10f40.png" medium="image"/>
    <pubDate>Tue, 14 Oct 2025 17:55:17 +0800</pubDate>
  </item><item>
    <title><![CDATA[马斯克收到黄仁勋亲手交付的 AI 超算 DGX Spark]]></title>
    <link>https://www.oschina.net/news/377397</link>
    <itunes:title><![CDATA[马斯克收到黄仁勋亲手交付的 AI 超算 DGX Spark]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>英伟达官方账号在X上发帖称：“为了庆祝DGX Spark从周三开始全球发货，我们的CEO黄仁勋今天在德克萨斯州的星舰基地将首批产品亲手交付给了SpaceX首席工程师埃隆·马斯克。</p>
<p>这次交流与这款新的桌面AI超算的起源——NVIDIA DGX-1超级计算机——有关，因为马斯克是2016年从黄仁勋那里收到的第一批DGX-1的用户之一。”</p>
<p>马斯克回应称：“这是DGX Spark，每瓦特计算能力比DGX-1多100倍。DGX-1是第一个专用的AI计算机，詹森2016年在OpenAI 交付给了我！”</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-d8c442baba.png"></p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>英伟达官方账号在X上发帖称：“为了庆祝DGX Spark从周三开始全球发货，我们的CEO黄仁勋今天在德克萨斯州的星舰基地将首批产品亲手交付给了SpaceX首席工程师埃隆·马斯克。</p>
<p>这次交流与这款新的桌面AI超算的起源——NVIDIA DGX-1超级计算机——有关，因为马斯克是2016年从黄仁勋那里收到的第一批DGX-1的用户之一。”</p>
<p>马斯克回应称：“这是DGX Spark，每瓦特计算能力比DGX-1多100倍。DGX-1是第一个专用的AI计算机，詹森2016年在OpenAI 交付给了我！”</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-d8c442baba.png"></p>]]>
    </description>
    <content:encoded><![CDATA[<p>英伟达官方账号在X上发帖称：“为了庆祝DGX Spark从周三开始全球发货，我们的CEO黄仁勋今天在德克萨斯州的星舰基地将首批产品亲手交付给了SpaceX首席工程师埃隆·马斯克。</p>
<p>这次交流与这款新的桌面AI超算的起源——NVIDIA DGX-1超级计算机——有关，因为马斯克是2016年从黄仁勋那里收到的第一批DGX-1的用户之一。”</p>
<p>马斯克回应称：“这是DGX Spark，每瓦特计算能力比DGX-1多100倍。DGX-1是第一个专用的AI计算机，詹森2016年在OpenAI 交付给了我！”</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-d8c442baba.png"></p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-d8c442baba.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-d8c442baba.png" medium="image"/>
    <pubDate>Tue, 14 Oct 2025 17:51:54 +0800</pubDate>
  </item><item>
    <title><![CDATA[半年估值翻 3 倍，Cursor 冲刺 270 亿美元]]></title>
    <link>https://www.oschina.net/news/377377</link>
    <itunes:title><![CDATA[半年估值翻 3 倍，Cursor 冲刺 270 亿美元]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>据 The Information 报道，Coatue 和 Accel 正在与知名 AI 编码助手 Cursor 的母公司 Anysphere 商谈一笔至少10亿美元的融资，融资前估值高达270亿美元。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-b405eeb0bc.png"></p>
<p>今年6月，Accel 以99亿美元估值参与了上一轮融资，短短几个月后估值几乎翻了三倍。过去两年，Accel 在 Scale AI、Cyera 等项目上都采取了类似的持续加仓策略，精准卡位 AI 基础设施赛道。</p>
<p>尽管 Anysphere 账面上仍有约8亿美元现金储备，但随着其自研大型语言模型驱动 Cursor 核心功能，训练与推理的成本持续攀升，这笔融资几乎是必然选择。</p>
<p>Anysphere 的崛起堪称"教科书式"。公司完成40万美元种子轮后，于2022年4月启动 Cursor 开发。2023年3月，Cursor 上线公测——一款基于 VS Code 打造、支持自然语言编程的新型 IDE。到2023年底，四人团队创造的 ARR 已突破100万美元，日活用户超3万。2024年11月收购代码补全工具 Supermaven 后，模型能力进一步增强。</p>
<p>Cursor 的增长速度堪称离谱。自2023年3月推出以来，仅20个月 ARR 就突破1亿美元，几乎零营销投入。2025年初势能彻底引爆:2月有4000至5000家公司请求接入，3月 ARR 达3亿美元、付费用户超36万，4月日活突破100万、企业客户达1.4万。截至6月，ARR 已超5亿美元。据彭博社报道，预计年底将达10亿美元。Cursor 已成为史上增长最快的 AI SaaS 产品之一，并登上《Fast Company》"全球最具创新力公司"榜单第26位。</p>
<p>Cursor 不只是"自动补全神器"，而是正在变成工程团队的"主力开发环境"。与 GitHub Copilot 等竞品相比，它在上下文理解、可解释性与隐私部署上优势明显。开发者可依赖它完成从代码编写、调试到架构设计的全流程——一句"帮我重构这段逻辑"，就能自动完成优化到文档生成。</p>
<p>Cursor CEO Michael Truell 称："编程将会消失，未来的 IDE 不再是工具，而是一个会写、会跑、会自我优化的智能体。"</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>据 The Information 报道，Coatue 和 Accel 正在与知名 AI 编码助手 Cursor 的母公司 Anysphere 商谈一笔至少10亿美元的融资，融资前估值高达270亿美元。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-b405eeb0bc.png"></p>
<p>今年6月，Accel 以99亿美元估值参与了上一轮融资，短短几个月后估值几乎翻了三倍。过去两年，Accel 在 Scale AI、Cyera 等项目上都采取了类似的持续加仓策略，精准卡位 AI 基础设施赛道。</p>
<p>尽管 Anysphere 账面上仍有约8亿美元现金储备，但随着其自研大型语言模型驱动 Cursor 核心功能，训练与推理的成本持续攀升，这笔融资几乎是必然选择。</p>
<p>Anysphere 的崛起堪称"教科书式"。公司完成40万美元种子轮后，于2022年4月启动 Cursor 开发。2023年3月，Cursor 上线公测——一款基于 VS Code 打造、支持自然语言编程的新型 IDE。到2023年底，四人团队创造的 ARR 已突破100万美元，日活用户超3万。2024年11月收购代码补全工具 Supermaven 后，模型能力进一步增强。</p>
<p>Cursor 的增长速度堪称离谱。自2023年3月推出以来，仅20个月 ARR 就突破1亿美元，几乎零营销投入。2025年初势能彻底引爆:2月有4000至5000家公司请求接入，3月 ARR 达3亿美元、付费用户超36万，4月日活突破100万、企业客户达1.4万。截至6月，ARR 已超5亿美元。据彭博社报道，预计年底将达10亿美元。Cursor 已成为史上增长最快的 AI SaaS 产品之一，并登上《Fast Company》"全球最具创新力公司"榜单第26位。</p>
<p>Cursor 不只是"自动补全神器"，而是正在变成工程团队的"主力开发环境"。与 GitHub Copilot 等竞品相比，它在上下文理解、可解释性与隐私部署上优势明显。开发者可依赖它完成从代码编写、调试到架构设计的全流程——一句"帮我重构这段逻辑"，就能自动完成优化到文档生成。</p>
<p>Cursor CEO Michael Truell 称："编程将会消失，未来的 IDE 不再是工具，而是一个会写、会跑、会自我优化的智能体。"</p>]]>
    </description>
    <content:encoded><![CDATA[<p>据 The Information 报道，Coatue 和 Accel 正在与知名 AI 编码助手 Cursor 的母公司 Anysphere 商谈一笔至少10亿美元的融资，融资前估值高达270亿美元。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-b405eeb0bc.png"></p>
<p>今年6月，Accel 以99亿美元估值参与了上一轮融资，短短几个月后估值几乎翻了三倍。过去两年，Accel 在 Scale AI、Cyera 等项目上都采取了类似的持续加仓策略，精准卡位 AI 基础设施赛道。</p>
<p>尽管 Anysphere 账面上仍有约8亿美元现金储备，但随着其自研大型语言模型驱动 Cursor 核心功能，训练与推理的成本持续攀升，这笔融资几乎是必然选择。</p>
<p>Anysphere 的崛起堪称"教科书式"。公司完成40万美元种子轮后，于2022年4月启动 Cursor 开发。2023年3月，Cursor 上线公测——一款基于 VS Code 打造、支持自然语言编程的新型 IDE。到2023年底，四人团队创造的 ARR 已突破100万美元，日活用户超3万。2024年11月收购代码补全工具 Supermaven 后，模型能力进一步增强。</p>
<p>Cursor 的增长速度堪称离谱。自2023年3月推出以来，仅20个月 ARR 就突破1亿美元，几乎零营销投入。2025年初势能彻底引爆:2月有4000至5000家公司请求接入，3月 ARR 达3亿美元、付费用户超36万，4月日活突破100万、企业客户达1.4万。截至6月，ARR 已超5亿美元。据彭博社报道，预计年底将达10亿美元。Cursor 已成为史上增长最快的 AI SaaS 产品之一，并登上《Fast Company》"全球最具创新力公司"榜单第26位。</p>
<p>Cursor 不只是"自动补全神器"，而是正在变成工程团队的"主力开发环境"。与 GitHub Copilot 等竞品相比，它在上下文理解、可解释性与隐私部署上优势明显。开发者可依赖它完成从代码编写、调试到架构设计的全流程——一句"帮我重构这段逻辑"，就能自动完成优化到文档生成。</p>
<p>Cursor CEO Michael Truell 称："编程将会消失，未来的 IDE 不再是工具，而是一个会写、会跑、会自我优化的智能体。"</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-b405eeb0bc.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-b405eeb0bc.png" medium="image"/>
    <pubDate>Tue, 14 Oct 2025 16:28:29 +0800</pubDate>
  </item><item>
    <title><![CDATA[全球 AI 投资形成“史上最大科技泡沫”：规模是互联网泡沫的 17 倍]]></title>
    <link>https://www.oschina.net/news/377369</link>
    <itunes:title><![CDATA[全球 AI 投资形成“史上最大科技泡沫”：规模是互联网泡沫的 17 倍]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.marketwatch.com%2Fstory%2Fthe-ai-bubble-is-17-times-the-size-of-the-dot-com-frenzy-this-analyst-argues-046e7c5c" target="_blank">据 MarketWatch 报道</a>，独立研究机构 MacroStrategy Partnership 在最新报告中警告，当前全球人工智能投资热潮已形成“史上最大科技泡沫”——其规模被估算为<strong>上世纪互联网泡沫的 17 倍，也是 2008 年次贷危机的 4 倍</strong>。</p>
<p><span>他们使用古典／威克塞尔 (Wicksellian) 资本理论来支撑评估：</span></p>
<ul>
<li> <p>在理想状态下，资本应在借贷成本比名义 GDP 高 2 个百分点时才能视为“均衡配置”。</p> </li>
<li> <p>但是由于极度宽松的利率环境导致资金误配，资本被投入到高风险、边际效益递减的 AI 领域。</p> </li>
</ul>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-7e26977d36.png"></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-e8903ede47.png"></p>
<p>分析师 Julien Garran 指出，宽松的利率环境使资本大量涌入 AI 领域，资金被误配到成本高、回报不确定的项目中。他认为 AI 模型正遭遇“边际收益递减”：训练成本快速上升，但性能提升有限；同时模型间差异化不强，缺乏可持续的商业护城河。</p>
<p>报告称，新一代语言模型（LLM）训练成本增大、性能提升幅度收窄，比如 GPT-3 相比 GPT-4 的训练费用增长很大，但性能改善并不成比例。AI 公司的模型并不容易形成差异化壁垒（其他竞争者可能复制或赶超），难以对客户收取高额溢价。</p>
<p>报告还指出，AI 公司普遍面临盈利模式不清、成本过高的问题，许多项目尚未形成稳定营收。虽然 AI 应用与模型研发备受追捧，但很多公司还未建立稳定、可扩展的营收体系，支出很重、回报尚未显现。</p>
<p>MacroStrategy 预测，随着 AI 投资与数据中心支出见顶，全球经济可能面临通缩性调整。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.marketwatch.com%2Fstory%2Fthe-ai-bubble-is-17-times-the-size-of-the-dot-com-frenzy-this-analyst-argues-046e7c5c" target="_blank">据 MarketWatch 报道</a>，独立研究机构 MacroStrategy Partnership 在最新报告中警告，当前全球人工智能投资热潮已形成“史上最大科技泡沫”——其规模被估算为<strong>上世纪互联网泡沫的 17 倍，也是 2008 年次贷危机的 4 倍</strong>。</p>
<p><span>他们使用古典／威克塞尔 (Wicksellian) 资本理论来支撑评估：</span></p>
<ul>
<li> <p>在理想状态下，资本应在借贷成本比名义 GDP 高 2 个百分点时才能视为“均衡配置”。</p> </li>
<li> <p>但是由于极度宽松的利率环境导致资金误配，资本被投入到高风险、边际效益递减的 AI 领域。</p> </li>
</ul>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-7e26977d36.png"></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-e8903ede47.png"></p>
<p>分析师 Julien Garran 指出，宽松的利率环境使资本大量涌入 AI 领域，资金被误配到成本高、回报不确定的项目中。他认为 AI 模型正遭遇“边际收益递减”：训练成本快速上升，但性能提升有限；同时模型间差异化不强，缺乏可持续的商业护城河。</p>
<p>报告称，新一代语言模型（LLM）训练成本增大、性能提升幅度收窄，比如 GPT-3 相比 GPT-4 的训练费用增长很大，但性能改善并不成比例。AI 公司的模型并不容易形成差异化壁垒（其他竞争者可能复制或赶超），难以对客户收取高额溢价。</p>
<p>报告还指出，AI 公司普遍面临盈利模式不清、成本过高的问题，许多项目尚未形成稳定营收。虽然 AI 应用与模型研发备受追捧，但很多公司还未建立稳定、可扩展的营收体系，支出很重、回报尚未显现。</p>
<p>MacroStrategy 预测，随着 AI 投资与数据中心支出见顶，全球经济可能面临通缩性调整。</p>]]>
    </description>
    <content:encoded><![CDATA[<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.marketwatch.com%2Fstory%2Fthe-ai-bubble-is-17-times-the-size-of-the-dot-com-frenzy-this-analyst-argues-046e7c5c" target="_blank">据 MarketWatch 报道</a>，独立研究机构 MacroStrategy Partnership 在最新报告中警告，当前全球人工智能投资热潮已形成“史上最大科技泡沫”——其规模被估算为<strong>上世纪互联网泡沫的 17 倍，也是 2008 年次贷危机的 4 倍</strong>。</p>
<p><span>他们使用古典／威克塞尔 (Wicksellian) 资本理论来支撑评估：</span></p>
<ul>
<li> <p>在理想状态下，资本应在借贷成本比名义 GDP 高 2 个百分点时才能视为“均衡配置”。</p> </li>
<li> <p>但是由于极度宽松的利率环境导致资金误配，资本被投入到高风险、边际效益递减的 AI 领域。</p> </li>
</ul>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-7e26977d36.png"></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-e8903ede47.png"></p>
<p>分析师 Julien Garran 指出，宽松的利率环境使资本大量涌入 AI 领域，资金被误配到成本高、回报不确定的项目中。他认为 AI 模型正遭遇“边际收益递减”：训练成本快速上升，但性能提升有限；同时模型间差异化不强，缺乏可持续的商业护城河。</p>
<p>报告称，新一代语言模型（LLM）训练成本增大、性能提升幅度收窄，比如 GPT-3 相比 GPT-4 的训练费用增长很大，但性能改善并不成比例。AI 公司的模型并不容易形成差异化壁垒（其他竞争者可能复制或赶超），难以对客户收取高额溢价。</p>
<p>报告还指出，AI 公司普遍面临盈利模式不清、成本过高的问题，许多项目尚未形成稳定营收。虽然 AI 应用与模型研发备受追捧，但很多公司还未建立稳定、可扩展的营收体系，支出很重、回报尚未显现。</p>
<p>MacroStrategy 预测，随着 AI 投资与数据中心支出见顶，全球经济可能面临通缩性调整。</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-7e26977d36.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-7e26977d36.png" medium="image"/>
    <pubDate>Tue, 14 Oct 2025 15:46:45 +0800</pubDate>
  </item><item>
    <title><![CDATA[腾讯启动青云奖学金，面向 AI 领域硕博生提供价值 50 万元支持]]></title>
    <link>https://www.oschina.net/news/377363</link>
    <itunes:title><![CDATA[腾讯启动青云奖学金，面向 AI 领域硕博生提供价值 50 万元支持]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p><span>腾讯<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FCTMCNkk9OwBsPSpkNht37A" target="_blank">宣布</a>全面启动青云奖学金。该项目重点关注人工智能领域的基础研究与应用创新，针对中国大陆及港澳台地区院校就读、具有中国国籍的硕士或博士生，希望申请者来自计算机科学、人工智能及其交叉领域，并拥有前瞻性科研视野。项目首期预计评选出15位获奖者，每位获奖者将获得总价值50万元人民币的现金及算力资源支持。</span></p>
<p><span>具体包括：20万元现金奖励，用于支持获奖者的科研活动和个人发展；价值30万元的云异构算力资源。腾讯方面表示，30万元大约可以支持3个月前沿GPU实例24小时不间断使用。除这些奖励外，15名获奖者还将有机会进入腾讯实习或就业。</span></p>
<p><span><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-58731a2eb0.png"></span></p>
<p><span>腾讯招聘全球负责人罗海波表示，腾讯青云奖学金不仅是一份经济上的支持，也是一个连接学术界与产业界的平台。腾讯希望通过这个计划，为青年学者提供更多资源和机会。</span></p>
<p><span>2024年，腾讯研发投入达707亿元，自2018年至今研发投入超过3795亿元。目前，腾讯科技类人才占比已达73%。</span></p>
<p><span>该公司此前曾推出面向全球顶尖技术学子的人才专项“青云计划”。该专项通过提供定制化培养方案、开放核心业务工作机会、解锁前瞻性技术课题和极具竞争力的薪酬，培养未来的科技人才。其招募对象是2024年1月-2026年12月毕业的博士生，2025年1月-2026年12月毕业的本硕生，以及2025年9月以后毕业的本硕和博士生。</span></p>
<p><span>“青云计划”提供双导师制，有专属岗位导师、发展导师和项目顾问提供日常实时业务辅导、定期成长辅导和跨界科研项目交流。还包括线下集中学习、定制化精品内容授课、顶尖实验室参访等定制化培养方案。工作地点包括深圳、北京、上海和西雅图等全球20多个城市。</span></p>
<p><span>在对顶尖人才的招揽过程中，大厂对AI相关人才的争抢颇为激烈。今年6月，腾讯也曾举办算法大赛，提供百万现金奖池，其中冠军团可获得200万奖金；闯入十强，即可获得腾讯核心业务的直通offer。</span></p>
<p><span>5月，京东推出“顶尖青年技术天才计划”，面向全球高校本硕博毕业生及毕业两年内的技术人才开放招募，薪酬不设上限，研究方向涵盖多模态大模型与应用、AI Infra等方向。</span></p>
<p><span>阿里在3到4月也曾开启大规模AI人才校园招聘，主要面向清华、北大、浙大、麻省理工、斯坦福等全球顶尖高校，招募大语言模型等领域技术人才。其头部AI科技人才培养计划——“Bravo 102”，打破了传统的校招体系，面试通过后可反选项目和团队。</span></p>
<p><span>脉脉发布的《2025年AI人才流动报告》显示，今年1-7月，AI新发岗位量同比增长超10倍，简历投递量也暴涨了11倍。但技术人才整体供不应求，平均每5个AI岗位只有2个人才竞争，尤其是搜索算法人才，供需比仅为0.39。</span></p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p><span>腾讯<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FCTMCNkk9OwBsPSpkNht37A" target="_blank">宣布</a>全面启动青云奖学金。该项目重点关注人工智能领域的基础研究与应用创新，针对中国大陆及港澳台地区院校就读、具有中国国籍的硕士或博士生，希望申请者来自计算机科学、人工智能及其交叉领域，并拥有前瞻性科研视野。项目首期预计评选出15位获奖者，每位获奖者将获得总价值50万元人民币的现金及算力资源支持。</span></p>
<p><span>具体包括：20万元现金奖励，用于支持获奖者的科研活动和个人发展；价值30万元的云异构算力资源。腾讯方面表示，30万元大约可以支持3个月前沿GPU实例24小时不间断使用。除这些奖励外，15名获奖者还将有机会进入腾讯实习或就业。</span></p>
<p><span><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-58731a2eb0.png"></span></p>
<p><span>腾讯招聘全球负责人罗海波表示，腾讯青云奖学金不仅是一份经济上的支持，也是一个连接学术界与产业界的平台。腾讯希望通过这个计划，为青年学者提供更多资源和机会。</span></p>
<p><span>2024年，腾讯研发投入达707亿元，自2018年至今研发投入超过3795亿元。目前，腾讯科技类人才占比已达73%。</span></p>
<p><span>该公司此前曾推出面向全球顶尖技术学子的人才专项“青云计划”。该专项通过提供定制化培养方案、开放核心业务工作机会、解锁前瞻性技术课题和极具竞争力的薪酬，培养未来的科技人才。其招募对象是2024年1月-2026年12月毕业的博士生，2025年1月-2026年12月毕业的本硕生，以及2025年9月以后毕业的本硕和博士生。</span></p>
<p><span>“青云计划”提供双导师制，有专属岗位导师、发展导师和项目顾问提供日常实时业务辅导、定期成长辅导和跨界科研项目交流。还包括线下集中学习、定制化精品内容授课、顶尖实验室参访等定制化培养方案。工作地点包括深圳、北京、上海和西雅图等全球20多个城市。</span></p>
<p><span>在对顶尖人才的招揽过程中，大厂对AI相关人才的争抢颇为激烈。今年6月，腾讯也曾举办算法大赛，提供百万现金奖池，其中冠军团可获得200万奖金；闯入十强，即可获得腾讯核心业务的直通offer。</span></p>
<p><span>5月，京东推出“顶尖青年技术天才计划”，面向全球高校本硕博毕业生及毕业两年内的技术人才开放招募，薪酬不设上限，研究方向涵盖多模态大模型与应用、AI Infra等方向。</span></p>
<p><span>阿里在3到4月也曾开启大规模AI人才校园招聘，主要面向清华、北大、浙大、麻省理工、斯坦福等全球顶尖高校，招募大语言模型等领域技术人才。其头部AI科技人才培养计划——“Bravo 102”，打破了传统的校招体系，面试通过后可反选项目和团队。</span></p>
<p><span>脉脉发布的《2025年AI人才流动报告》显示，今年1-7月，AI新发岗位量同比增长超10倍，简历投递量也暴涨了11倍。但技术人才整体供不应求，平均每5个AI岗位只有2个人才竞争，尤其是搜索算法人才，供需比仅为0.39。</span></p>]]>
    </description>
    <content:encoded><![CDATA[<p><span>腾讯<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FCTMCNkk9OwBsPSpkNht37A" target="_blank">宣布</a>全面启动青云奖学金。该项目重点关注人工智能领域的基础研究与应用创新，针对中国大陆及港澳台地区院校就读、具有中国国籍的硕士或博士生，希望申请者来自计算机科学、人工智能及其交叉领域，并拥有前瞻性科研视野。项目首期预计评选出15位获奖者，每位获奖者将获得总价值50万元人民币的现金及算力资源支持。</span></p>
<p><span>具体包括：20万元现金奖励，用于支持获奖者的科研活动和个人发展；价值30万元的云异构算力资源。腾讯方面表示，30万元大约可以支持3个月前沿GPU实例24小时不间断使用。除这些奖励外，15名获奖者还将有机会进入腾讯实习或就业。</span></p>
<p><span><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-58731a2eb0.png"></span></p>
<p><span>腾讯招聘全球负责人罗海波表示，腾讯青云奖学金不仅是一份经济上的支持，也是一个连接学术界与产业界的平台。腾讯希望通过这个计划，为青年学者提供更多资源和机会。</span></p>
<p><span>2024年，腾讯研发投入达707亿元，自2018年至今研发投入超过3795亿元。目前，腾讯科技类人才占比已达73%。</span></p>
<p><span>该公司此前曾推出面向全球顶尖技术学子的人才专项“青云计划”。该专项通过提供定制化培养方案、开放核心业务工作机会、解锁前瞻性技术课题和极具竞争力的薪酬，培养未来的科技人才。其招募对象是2024年1月-2026年12月毕业的博士生，2025年1月-2026年12月毕业的本硕生，以及2025年9月以后毕业的本硕和博士生。</span></p>
<p><span>“青云计划”提供双导师制，有专属岗位导师、发展导师和项目顾问提供日常实时业务辅导、定期成长辅导和跨界科研项目交流。还包括线下集中学习、定制化精品内容授课、顶尖实验室参访等定制化培养方案。工作地点包括深圳、北京、上海和西雅图等全球20多个城市。</span></p>
<p><span>在对顶尖人才的招揽过程中，大厂对AI相关人才的争抢颇为激烈。今年6月，腾讯也曾举办算法大赛，提供百万现金奖池，其中冠军团可获得200万奖金；闯入十强，即可获得腾讯核心业务的直通offer。</span></p>
<p><span>5月，京东推出“顶尖青年技术天才计划”，面向全球高校本硕博毕业生及毕业两年内的技术人才开放招募，薪酬不设上限，研究方向涵盖多模态大模型与应用、AI Infra等方向。</span></p>
<p><span>阿里在3到4月也曾开启大规模AI人才校园招聘，主要面向清华、北大、浙大、麻省理工、斯坦福等全球顶尖高校，招募大语言模型等领域技术人才。其头部AI科技人才培养计划——“Bravo 102”，打破了传统的校招体系，面试通过后可反选项目和团队。</span></p>
<p><span>脉脉发布的《2025年AI人才流动报告》显示，今年1-7月，AI新发岗位量同比增长超10倍，简历投递量也暴涨了11倍。但技术人才整体供不应求，平均每5个AI岗位只有2个人才竞争，尤其是搜索算法人才，供需比仅为0.39。</span></p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-58731a2eb0.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-58731a2eb0.png" medium="image"/>
    <pubDate>Tue, 14 Oct 2025 15:31:33 +0800</pubDate>
  </item><item>
    <title><![CDATA[腾讯优图实验室开源 Youtu-Embedding]]></title>
    <link>https://www.oschina.net/news/377360</link>
    <itunes:title><![CDATA[腾讯优图实验室开源 Youtu-Embedding]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p><span>腾讯优图实验室正式<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F5iZEv9TewfQrkEyebbhq-g" target="_blank">开源</a>&nbsp;Youtu-Embedding，这是一款面向企业级应用打造的通用文本表示模型，可同时胜任文本检索、意图理解、相似度判断、分类聚类等六大主流任务。在信息检索（IR）、语义相似度（STS）、聚类、重排序和分类等一系列广泛的自然语言处理任务上，均展现出卓越的性能。</span></p>
<p><span>模型权重、推理代码及完整的训练框架现已开源，首个模型版本已在HuggingFace上发布，这是一个拥有20亿（2B）参数的通用语义表示模型。</span></p>
<p><span><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-8e5cba0cfc.png"></span></p>
<p><span>根据介绍，Youtu-Embedding的核心优势包括：</span></p>
<ul>
<li><span>在中文文本嵌入评测基准 CMTEB 上，Youtu-Embedding&nbsp;以 77.46 的高分荣登榜首（截至2025年09月）</span></li>
</ul>
<p><span><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-a7284db496.png"></span></p>
<ul>
<li><span>精密的三阶段训练：通过“LLM基础预训练 → 弱监督对齐 → 协同-判别式微调”的训练流程，系统性地将大模型的广博知识转化为专用于嵌入任务的判别能力。</span></li>
<li><span>创新的微调框架：设计了统一数据格式、任务差异化损失函数和动态单任务采样机制，解决了多任务学习中的“负迁移”难题，实现了多任务的稳定协同训练。（该框架在多种基础编码器上进行了验证，保障其通用性和有效性）</span></li>
<li><span>精细化的数据工程：结合了基于LLM的高质量数据合成技术与高效的难负例挖掘策略，为模型训练提供了最坚实的数据基础。</span></li>
</ul>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p><span>腾讯优图实验室正式<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F5iZEv9TewfQrkEyebbhq-g" target="_blank">开源</a>&nbsp;Youtu-Embedding，这是一款面向企业级应用打造的通用文本表示模型，可同时胜任文本检索、意图理解、相似度判断、分类聚类等六大主流任务。在信息检索（IR）、语义相似度（STS）、聚类、重排序和分类等一系列广泛的自然语言处理任务上，均展现出卓越的性能。</span></p>
<p><span>模型权重、推理代码及完整的训练框架现已开源，首个模型版本已在HuggingFace上发布，这是一个拥有20亿（2B）参数的通用语义表示模型。</span></p>
<p><span><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-8e5cba0cfc.png"></span></p>
<p><span>根据介绍，Youtu-Embedding的核心优势包括：</span></p>
<ul>
<li><span>在中文文本嵌入评测基准 CMTEB 上，Youtu-Embedding&nbsp;以 77.46 的高分荣登榜首（截至2025年09月）</span></li>
</ul>
<p><span><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-a7284db496.png"></span></p>
<ul>
<li><span>精密的三阶段训练：通过“LLM基础预训练 → 弱监督对齐 → 协同-判别式微调”的训练流程，系统性地将大模型的广博知识转化为专用于嵌入任务的判别能力。</span></li>
<li><span>创新的微调框架：设计了统一数据格式、任务差异化损失函数和动态单任务采样机制，解决了多任务学习中的“负迁移”难题，实现了多任务的稳定协同训练。（该框架在多种基础编码器上进行了验证，保障其通用性和有效性）</span></li>
<li><span>精细化的数据工程：结合了基于LLM的高质量数据合成技术与高效的难负例挖掘策略，为模型训练提供了最坚实的数据基础。</span></li>
</ul>]]>
    </description>
    <content:encoded><![CDATA[<p><span>腾讯优图实验室正式<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F5iZEv9TewfQrkEyebbhq-g" target="_blank">开源</a>&nbsp;Youtu-Embedding，这是一款面向企业级应用打造的通用文本表示模型，可同时胜任文本检索、意图理解、相似度判断、分类聚类等六大主流任务。在信息检索（IR）、语义相似度（STS）、聚类、重排序和分类等一系列广泛的自然语言处理任务上，均展现出卓越的性能。</span></p>
<p><span>模型权重、推理代码及完整的训练框架现已开源，首个模型版本已在HuggingFace上发布，这是一个拥有20亿（2B）参数的通用语义表示模型。</span></p>
<p><span><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-8e5cba0cfc.png"></span></p>
<p><span>根据介绍，Youtu-Embedding的核心优势包括：</span></p>
<ul>
<li><span>在中文文本嵌入评测基准 CMTEB 上，Youtu-Embedding&nbsp;以 77.46 的高分荣登榜首（截至2025年09月）</span></li>
</ul>
<p><span><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-a7284db496.png"></span></p>
<ul>
<li><span>精密的三阶段训练：通过“LLM基础预训练 → 弱监督对齐 → 协同-判别式微调”的训练流程，系统性地将大模型的广博知识转化为专用于嵌入任务的判别能力。</span></li>
<li><span>创新的微调框架：设计了统一数据格式、任务差异化损失函数和动态单任务采样机制，解决了多任务学习中的“负迁移”难题，实现了多任务的稳定协同训练。（该框架在多种基础编码器上进行了验证，保障其通用性和有效性）</span></li>
<li><span>精细化的数据工程：结合了基于LLM的高质量数据合成技术与高效的难负例挖掘策略，为模型训练提供了最坚实的数据基础。</span></li>
</ul>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-8e5cba0cfc.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-8e5cba0cfc.png" medium="image"/>
    <pubDate>Tue, 14 Oct 2025 15:12:22 +0800</pubDate>
  </item><item>
    <title><![CDATA[线程池 ThreadPoolExecutor 源码深度解析]]></title>
    <link>https://my.oschina.net/u/5783135/blog/18695444</link>
    <itunes:title><![CDATA[线程池 ThreadPoolExecutor 源码深度解析]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<h1>一、引 言</h1>
<p><strong>为什么进行源码角度的深度解析？</strong></p>
<p>大家在项目中到处都在使用线程池做一些性能接口层次的优化，原先串行的多个远程调用，因为rt过高，通过线程池批量异步优化，从而降低rt。还有像RocketMQ中broker启动时，同时通过ScheduledThreadPoolExecutor线程池执行其他组件的定时任务，每隔一段时间处理相关的任务。线程池广泛的应用在外面各种实际开发场景中，我们很多同学可能在项目里只是简单的copy了一些前人的代码参数并不知道其中的含义，从而导致生产级别的bug。所以本篇文章，旨在帮助还不熟悉或者想要熟悉线程池的同学，分享我自己在学习线程池源码上的一些内容来更简单、快速的掌握线程池。</p>
<h1>二、为什么使用线程池？</h1>
<p>并发编程中，对于常见的操作系统，线程都是执行任务的基本单元，如果每次执行任务时都创建新的线程，任务执行完毕又进行销毁，会出现以下的问题：</p>
<ul>
<li><strong>资源开销</strong>：比如在Linux系统中，频繁的创建和销毁线程，一个是频繁的进行一个系统调用，另外是一些内存和CPU资源调度的占用。虽然有一些写时复制的策略防止lwp的创建时的内存占用，但是实际写入还是会申请系统内存的，何况一些页表等本身就有内存占用。</li>
<li><strong>性能瓶颈</strong>：线程的创建需要系统调用，如果只是简单的计算任务，可能耗时还没创建的rt高，这里反而降低了系统的吞吐量。</li>
<li><strong>缺乏资源管理</strong>：无限制的创建线程会导致内存溢出，java.lang.OutOfMemoryError: unable to create native thread，这里主要因为Java的线程其实Linux中是lwp线程，需要通过JNI进行系统调用创建，每个线程默认需要1MB的栈空间，很容易导致无休止的创建线程导致内存溢出，另外就是频繁的系统调用，导致的上下文切换，占用了过多的CPU，反而起到了相反的作用。</li>
<li><strong>功能受限</strong>：手动管理线程难以实现更高级的功能，如定时任务、周期任务、任务管理、并发任务数的控制等。</li>
</ul>
<p>通过上面的问题，我们其实可以清晰的感知到这些问题都是归拢到资源没有得到合理的分配和控制导致的，线程池出现的核心宗旨其实就是对资源的合理分配和控制。除了线程池，其实更多的也接触过数据库连接池、netty的对象池等池化技术，这些池化思想其实都是为了更好的降低资源的消耗以及更好的进行资源管理。</p>
<h1>三、JDK线程池的架构设计</h1>
<h1>3.1 JUC并发包下的Executor框架的uml类图</h1>
<div>
<img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-10e0261f0e.jpg">
</div>
<ul>
<li><strong>Executor</strong>：任务执行的顶层接口，主要是分离任务提交与执行逻辑，支持同步/异步执行，遵循Java内存模型的&nbsp;happen-before规则。</li>
<li><strong>ExecutorService</strong>：继承Executor接口，提供了更完善的生命周期管理能力，通过Future对象提供任务取消、状态查询、结果获取能力实现了任务监控。</li>
<li><strong>AbstractExecutorService</strong>：常见的设计模式为了简化线程池的开发，通常通过父类进行一些基础的默认实现让子类继承。</li>
<li><strong>ScheduledExecutorService</strong>：ExecutorService的扩展接口，支持延迟执行和周期性任务调度。</li>
<li><strong>ThreadPoolExecutor</strong>：是ExecutorService接口最核心和最常用的实现类，它提供了高度可配置的线程池，允许我们精细控制线程池的各种行为。</li>
<li><strong>ScheduledThreadPoolExecutor</strong>：是ScheduledExecutorService接口的实现类，它继承自ThreadPoolExecutor，专门用于处理定时和周期任务。</li>
<li><strong>Executors</strong>：一个静态工厂模式的工具类，提供了一系列静态方法来创建各种常见配置的线程池，newFixedThreadPool(), newCachedThreadPool(),等，简化了创建线程池的使用但是会带来一些问题，很多开发规范里都不建议大家直接使用。JDK内置的线程池如果我们不熟悉里面的参数很有可能导致出乎自己意料的结果，池大小设置、阻塞队列选择等等都是有考究的，这一点后续会进行一些详细说明。生产环境中建议谨慎使用或直接使用ThreadPoolExecutor构造函数自定义。</li>
</ul>
<h1>3.2 ThreadPoolExecutor的参数解析</h1>
<div>
<img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-2b578a85a8.jpg">
</div>
<ul>
<li><strong>corePoolSize&nbsp;</strong>核心线程数：
<ul>
<li>线程池中还未退出的alive的核心线程数量。</li>
<li>虽然线程处于空闲状态（其实是阻塞在阻塞队列中），除非显示设置了allowCoreThreadTimeOut=true，否则这些线程不会从自己的run方法中退出被回收。</li>
<li>添加新任务时，如果当前工作线程小于coreSize，此时即使存在空闲的core线程，线程池也会通过addWorker方法创建一个新的线程。</li>
<li>&nbsp;</li>
</ul> </li>
<li><strong>maximumPoolSize&nbsp;</strong>最大线程数：
<ul>
<li>线程池可以创建的最大线程数。</li>
<li>如果是有界队列，当队列满时，仍然有任务进来，此时线程池会创建小于最大线程数的线程来完成任务，空闲。</li>
<li>如果是无界队列，那么永远不会出现第二点的情况，除了内存异常，否则会一直保持核心线程数，多余的任务会一直往队列中加入。</li>
</ul> </li>
</ul>
<ul>
<li><strong>keepAliveTime</strong>&nbsp;线程空闲存活时间
<ul>
<li>线程数超过corePoolSize后创建的线程我们理解为非核心线程，对于这类线程，他的回收机制在于我们设置的keepAliveTime,线程会限期阻塞在队列中获取任务，如果超时未获取就会进行清理并退出。</li>
<li>另外如果设置allowCoreThreadTimeOut=true，所谓的核心线程在空闲时间达到keepAliveTime时也会被回收。</li>
</ul> </li>
</ul>
<ul>
<li><strong>unit&nbsp;</strong>时间单位
<ul>
<li>keepAliveTime参数的时间单位，TimeUnit中时分秒等。</li>
<li>&nbsp;</li>
</ul> </li>
<li><strong>workQueue&nbsp;</strong>任务队列
<ul>
<li>阻塞队列，核心线程数满时，新加入的任务，会先添加到阻塞队列中等待线程获取任务并执行。</li>
<li>常用的BlockingQueue实现有：
<ul>
<li>ArrayBlockingQueue：数组实现的先进先出原则的有界阻塞队列，构造方法必须指定容量。</li>
<li>LinkedBlockingQueue：链表实现的阻塞队列，构造传入容量则有界，未传则是无界队列，此时设置的最大线程数其实就不会有作用了。</li>
<li>SynchronousQueue：一个不存储元素的阻塞队列。每个put操作必须等待一个take操作，反之亦然。它相当于一个传递通道，非常适合传递性需求，吞吐量高，但要求maximumPoolSize足够大。</li>
<li>PriorityBlockingQueue：二叉堆实现的优先级阻塞队列，构造时可自行调整排序行为（小顶堆或大顶堆）。</li>
<li>DelayQueue：支持延时的无界阻塞队列，主要用于周期性的任务，我们可以直接通过它来实现一些简单的延迟任务需求，复杂的周期性任务建议使用ScheduledThreadPoolExecutor。</li>
</ul> </li>
</ul> </li>
</ul>
<ul>
<li><strong>threadFactory&nbsp;</strong>线程工厂
<ul>
<li>用于创建新线程的工厂。通过自定义ThreadFactory，我们可以为线程池中的线程设置更有意义的名称、设置守护线程状态、设置线程优先级、指定UncaughtExceptionHandler等。</li>
<li>Executors.defaultThreadFactory()是默认实现。</li>
</ul> </li>
</ul>
<ul>
<li><strong>handler&nbsp;</strong>拒绝策略
<ul>
<li>ThreadPoolExecutor.AbortPolicy：默认的拒绝策略，简单粗暴，当execute中添加woker失败时，直接在当前线程抛出异常。</li>
<li>JDK内置了四种拒绝策略：
<ul>
<li>ThreadPoolExecutor.AbortPolicy：默认的拒绝策略，简单粗暴，当execute中添加woker失败时，直接在当前线程抛出异常。</li>
<li>ThreadPoolExecutor.CallerRunsPolicy：提交任务的线程，直接执行任务。变相的背压机制，可以降低任务往线程中加入。</li>
<li>ThreadPoolExecutor.DiscardPolicy：直接丢弃被拒绝的任务，不做任何通知，需容忍数据丢失。</li>
<li>ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列中最旧的任务，然后重试提交当前任务，需容忍数据丢失。</li>
<li>实现RejectedExecutionHandler接口自定义拒绝策略，在实际生产应用中推荐使用，可以做一些打印观察日志的操作，告警、兜底的相关处理等。</li>
</ul> </li>
</ul> </li>
</ul>
<h1>3.3 运行机制详解</h1>
<p>新任务通过execute()方法提交给ThreadPoolExecutor时，其处理流程如下：</p>
<p><strong>判断核心线程数</strong>：如果当前运行的线程数小于corePoolSize，则创建新线程（即使有空闲的核心线程）来执行任务。</p>
<p><strong>尝试入队</strong>：如果当前运行的线程数大于或等于corePoolSize，则尝试将任务添加到workQueue中。</p>
<ul>
<li>如果workQueue.offer()成功（队列未满），任务入队等待执行。</li>
</ul>
<p><strong>尝试创建非核心线程</strong>：如果workQueue.offer()失败（队列已满）：</p>
<ul>
<li>判断当前运行的线程数是否小于maximumPoolSize；</li>
<li>如果是，则创建新的非核心线程来执行任务。</li>
</ul>
<p><strong>执行拒绝策略：</strong></p>
<p>如果当前运行的线程数也达到了maximumPoolSize（即核心线程和非核心线程都已用尽，且队列也满了），则执行RejectedExecutionHandler所定义的拒绝策略。</p>
<p>参考网络中的经典执行图：</p>
<div>
<img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-88df05dbfd.jpg">
</div>
<p>这个图能很好的表明运行原理，但是忽略了很多细节，比如所谓的缓冲执行是在什么条件下去走的呢？直接执行又是什么逻辑下执行呢？最后的任务拒绝又是怎么回事？带着这些疑问点，我们直接来进行一个源码级别的分析：</p>
<h1>execute核心流程的源码分析</h1>
<pre><code>public&nbsp;void&nbsp;execute(Runnable command)&nbsp;{
&nbsp; &nbsp;&nbsp;if&nbsp;(command ==&nbsp;null)
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;throw&nbsp;new&nbsp;NullPointerException();
&nbsp; &nbsp;&nbsp;//线程池状态 高3位表示线程状态 低29位代表线程数量
&nbsp; &nbsp;&nbsp;int&nbsp;c = ctl.get();
&nbsp; &nbsp;&nbsp;//判断当前线程池线程数量是否小于核心线程数
&nbsp; &nbsp;&nbsp;if&nbsp;(workerCountOf(c) &lt; corePoolSize) {
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//作为核心线程数进行线程的创建，并且创建成功线程会将command的任务执行--》对应图上的直接执行
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(addWorker(command,&nbsp;true))
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;return;
&nbsp; &nbsp; &nbsp; &nbsp; c = ctl.get();
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;//创建核心线程失败或者当前线程数量超过核心线程数
&nbsp; &nbsp;&nbsp;//当前线程池是否还在运行状态，尝试将任务添加到阻塞队列 --》对应图上的缓冲执行
&nbsp; &nbsp;&nbsp;//BlockingQueue队列的顶级抽象定义了offer不是进行阻塞添加而是立即返回，添加失败直接返回false，区别于put
&nbsp; &nbsp;&nbsp;if&nbsp;(isRunning(c) &amp;&amp; workQueue.offer(command)) {
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//重新获取线程池标志位
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;int&nbsp;recheck = ctl.get();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//如果线程此时不在运行状态中，那么将任务删除
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(! isRunning(recheck) &amp;&amp;&nbsp;remove(command))
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//删除任务成功，走拒绝策略拒绝掉当前任务
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; reject(command);
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;else&nbsp;if&nbsp;(workerCountOf(recheck) ==&nbsp;0)
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//如果线程池中的工作线程都没有的时候，这里需要创建一个线程去执行添加到队列中的任务
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//防止因为并发的原因工作线程都被终止掉了，此时任务在阻塞队列里等着，缺没有工作线程
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; addWorker(null,&nbsp;false);
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;//到这里那就是添加队列失败，或者线程池状态异常，但是这里仍然尝试进行创建一个worker
&nbsp; &nbsp;&nbsp;//如果创建失败，也是走拒绝策略拒绝当前任务
&nbsp; &nbsp;&nbsp;else&nbsp;if&nbsp;(!addWorker(command,&nbsp;false))
&nbsp; &nbsp; &nbsp; &nbsp; reject(command);
}</code></pre>
<p>接下来我们仔细看看addWorker这个方法具体是在做什么：</p>
<pre><code>//核心逻辑其实就是在无限循环创建一个worker，创建失败直接返回，创建成功，则将worker执行
// 因为worker有thread的成员变量，最终添加worker成功，会启动线程的start方法
//start方法最终会回调到外层的runWorker方法，改方法会不停的从阻塞队列里以阻塞的take方式
//获取任务，除非达到能被终止的条件，此时当前线程会终止
private&nbsp;boolean&nbsp;addWorker(Runnable firstTask,&nbsp;boolean&nbsp;core)&nbsp;{
&nbsp; &nbsp; retry:
&nbsp; &nbsp;&nbsp;for&nbsp;(;;) {
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;int&nbsp;c&nbsp;=&nbsp;ctl.get();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;int&nbsp;rs&nbsp;=&nbsp;runStateOf(c);
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// Check if queue empty only if necessary.
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(rs &gt;= SHUTDOWN &amp;&amp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ! (rs == SHUTDOWN &amp;&amp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;firstTask ==&nbsp;null&nbsp;&amp;&amp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;! workQueue.isEmpty()))
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;return&nbsp;false;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;for&nbsp;(;;) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;int&nbsp;wc&nbsp;=&nbsp;workerCountOf(c);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(wc &gt;= CAPACITY ||
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; wc &gt;= (core ? corePoolSize : maximumPoolSize))
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;return&nbsp;false;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//不停的重试添加worker的计数，只有添加成功的才会进行后续的worker启动
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(compareAndIncrementWorkerCount(c))
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;break&nbsp;retry;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; c = ctl.get(); &nbsp;// Re-read ctl
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//重试期间，如果其他线程导致线程池状态不一致了。重新回到第一个循环进行check判断
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(runStateOf(c) != rs)
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;continue&nbsp;retry;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// else CAS failed due to workerCount change; retry inner loop
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;boolean&nbsp;workerStarted&nbsp;=&nbsp;false;
&nbsp; &nbsp;&nbsp;boolean&nbsp;workerAdded&nbsp;=&nbsp;false;
&nbsp; &nbsp;&nbsp;Worker&nbsp;w&nbsp;=&nbsp;null;
&nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; w =&nbsp;new&nbsp;Worker(firstTask);
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;final&nbsp;Thread&nbsp;t&nbsp;=&nbsp;w.thread;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(t !=&nbsp;null) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//这里加锁一个是workers.add时需要加锁，另外是防止其他线程已经在尝试修改线程池状态了
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;final&nbsp;ReentrantLock&nbsp;mainLock&nbsp;=&nbsp;this.mainLock;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; mainLock.lock();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// Recheck while holding lock.
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// Back out on ThreadFactory failure or if
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// shut down before lock acquired.
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;int&nbsp;rs&nbsp;=&nbsp;runStateOf(ctl.get());
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(rs &lt; SHUTDOWN ||
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (rs == SHUTDOWN &amp;&amp; firstTask ==&nbsp;null)) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(t.isAlive())&nbsp;// precheck that t is startable
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;throw&nbsp;new&nbsp;IllegalThreadStateException();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//将worker的引用添加到workers的hashSet中
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; workers.add(w);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;int&nbsp;s&nbsp;=&nbsp;workers.size();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//更新线程池此时最大的线程数
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(s &gt; largestPoolSize)
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; largestPoolSize = s;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; workerAdded =&nbsp;true;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;finally&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; mainLock.unlock();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//如果添加成功，就启动worker中的线程
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(workerAdded) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; t.start();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; workerStarted =&nbsp;true;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; }&nbsp;finally&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//这里添加失败的话，需要把线程池的count数进行--，并且要把worker引用从hashSer中移除
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(! workerStarted)
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; addWorkerFailed(w);
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;return&nbsp;workerStarted;
}</code></pre>
<h1>3.4 线程池的生命周期</h1>
<p>在介绍运行机制原理的源码分析时，其实是有提到线程池状态这个概念的。介绍这个状态其实也是让大家更方便的去管理线程池，比如我们关闭线程池时，怎么去优雅的关闭，使用不同的方法可能会有不同的效果，我们需要根据自己的业务场景去酌情分析、权衡使用。</p>
<pre><code>//线程池的状态和计数采用一个Integer变量设置的
//这里之所以用一个变量来储存状态和数量，其实很有讲究的，因为我们在上面的运行原理上可以看到
//源码中有大量的进行状态以及数量的判断，如果分开采用变量的记录的话，在维护二者一致性方面
//可能就需要加锁的维护成本了，而且计算中都是位移运算也是非常高效的
private&nbsp;final&nbsp;AtomicInteger&nbsp;ctl&nbsp;=&nbsp;new&nbsp;AtomicInteger(ctlOf(RUNNING,&nbsp;0));
//线程池的大小由ctl低29位表示，现成状态由ctl高3位表示
private&nbsp;static&nbsp;final&nbsp;int&nbsp;COUNT_BITS&nbsp;=&nbsp;Integer.SIZE -&nbsp;3;
private&nbsp;static&nbsp;final&nbsp;int&nbsp;CAPACITY&nbsp; &nbsp;=&nbsp;(1&nbsp;&lt;&lt; COUNT_BITS) -&nbsp;1;
// 线程池的状态通过简单的位移就能计算出来，状态只能从低到高流转，不能逆向
private&nbsp;static&nbsp;final&nbsp;int&nbsp;RUNNING&nbsp; &nbsp;&nbsp;=&nbsp;-1&nbsp;&lt;&lt; COUNT_BITS;
private&nbsp;static&nbsp;final&nbsp;int&nbsp;SHUTDOWN&nbsp; &nbsp;=&nbsp;&nbsp;0&nbsp;&lt;&lt; COUNT_BITS;
private&nbsp;static&nbsp;final&nbsp;int&nbsp;STOP&nbsp; &nbsp; &nbsp; &nbsp;=&nbsp;&nbsp;1&nbsp;&lt;&lt; COUNT_BITS;
private&nbsp;static&nbsp;final&nbsp;int&nbsp;TIDYING&nbsp; &nbsp;&nbsp;=&nbsp;&nbsp;2&nbsp;&lt;&lt; COUNT_BITS;
private&nbsp;static&nbsp;final&nbsp;int&nbsp;TERMINATED&nbsp;=&nbsp;&nbsp;3&nbsp;&lt;&lt; COUNT_BITS;
// 这里是获取线程状态以及获取线程数量的简单高效的位移方法
private&nbsp;static&nbsp;int&nbsp;runStateOf(int&nbsp;c)&nbsp; &nbsp; &nbsp;{&nbsp;return&nbsp;c &amp; ~CAPACITY; }
private&nbsp;static&nbsp;int&nbsp;workerCountOf(int&nbsp;c)&nbsp; {&nbsp;return&nbsp;c &amp; CAPACITY; }
private&nbsp;static&nbsp;int&nbsp;ctlOf(int&nbsp;rs,&nbsp;int&nbsp;wc)&nbsp;{&nbsp;return&nbsp;rs | wc; }</code></pre>
<p>接下来结合源码详细介绍下线程池的5种状态以及分别有什么不同的表现行为？</p>
<pre><code>先说下结论：
RUNNING&nbsp; &nbsp; &nbsp;这个就是线程池运行中状态，我们可以添加任务也可以处理阻塞队列任务
SHUTDOWN &nbsp; 不能添加新的任务，但是会将阻塞队列中任务执行完毕
STOP &nbsp; &nbsp; &nbsp; 不能添加新的任务，执行中的线程也会被打断，也不会处理阻塞队列的任务
TIDYING &nbsp; &nbsp;所有线程都被终止，并且workCount=0时会被置为的状态
TERMINATED &nbsp; 调用完钩子方法terminated()被置为的状态&nbsp;</code></pre>
<h1>shutdown状态源码分析：</h1>
<pre><code>&nbsp;
&nbsp;//线程池关闭
&nbsp;public&nbsp;void&nbsp;shutdown()&nbsp;{
&nbsp; &nbsp;&nbsp;final&nbsp;ReentrantLock&nbsp;mainLock&nbsp;=&nbsp;this.mainLock;
&nbsp; &nbsp; mainLock.lock();
&nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; checkShutdownAccess();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//循环cas设置线程池状态，直到成功或状态已经state&gt;=SHUTDOWN
&nbsp; &nbsp; &nbsp; &nbsp; advanceRunState(SHUTDOWN);
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//这个是真正得出结论的地方
&nbsp; &nbsp; &nbsp; &nbsp; interruptIdleWorkers();
&nbsp; &nbsp; &nbsp; &nbsp; onShutdown();&nbsp;// hook for ScheduledThreadPoolExecutor
&nbsp; &nbsp; }&nbsp;finally&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; mainLock.unlock();
&nbsp; &nbsp; }
&nbsp; &nbsp; tryTerminate();
}
private&nbsp;void&nbsp;interruptIdleWorkers()&nbsp;{
&nbsp; &nbsp; interruptIdleWorkers(false);
}
//打断空闲的线程，如何判断线程是否空闲还是运行？
private&nbsp;void&nbsp;interruptIdleWorkers(boolean&nbsp;onlyOne)&nbsp;{
&nbsp; &nbsp;&nbsp;final&nbsp;ReentrantLock&nbsp;mainLock&nbsp;=&nbsp;this.mainLock;
&nbsp; &nbsp; mainLock.lock();
&nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;for&nbsp;(Worker w : workers) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;Thread&nbsp;t&nbsp;=&nbsp;w.thread;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//worker的线程没有被打断过，并且能获取到worker的aqs独占锁
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(!t.isInterrupted() &amp;&amp; w.tryLock()) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//打断当前线程，如果线程在阻塞队列中阻塞，此时会被中断
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; t.interrupt();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;catch&nbsp;(SecurityException ignore) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;finally&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; w.unlock();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(onlyOne)
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;break;
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; }&nbsp;finally&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; mainLock.unlock();
&nbsp; &nbsp; }
}
</code></pre>
<h1>STOP状态分析</h1>
<pre><code>//循环cas修改线程池状态为stop。打断所有线程，取出阻塞队列的所有任务
public&nbsp;List&lt;Runnable&gt;&nbsp;shutdownNow()&nbsp;{
&nbsp; &nbsp; List&lt;Runnable&gt; tasks;
&nbsp; &nbsp; final ReentrantLock mainLock =&nbsp;this.mainLock;
&nbsp; &nbsp; mainLock.lock();
&nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//检查线程的权限
&nbsp; &nbsp; &nbsp; &nbsp; checkShutdownAccess();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//将状态case为stop
&nbsp; &nbsp; &nbsp; &nbsp; advanceRunState(STOP);
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//打断所有worker不管是不是正在执行任务
&nbsp; &nbsp; &nbsp; &nbsp; interruptWorkers();
&nbsp; &nbsp; &nbsp; &nbsp; tasks = drainQueue();
&nbsp; &nbsp; }&nbsp;finally&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; mainLock.unlock();
&nbsp; &nbsp; }
&nbsp; &nbsp; tryTerminate();
&nbsp; &nbsp;&nbsp;return&nbsp;tasks;
}
//这里获取锁之后。打断了所有的线程
private&nbsp;void&nbsp;interruptWorkers()&nbsp;{
&nbsp; &nbsp; final ReentrantLock mainLock =&nbsp;this.mainLock;
&nbsp; &nbsp; mainLock.lock();
&nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;for&nbsp;(Worker w : workers)
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; w.interruptIfStarted();
&nbsp; &nbsp; }&nbsp;finally&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; mainLock.unlock();
&nbsp; &nbsp; }
}</code></pre>
<h1>TIDYING、TERMINATED&nbsp;状态分析</h1>
<pre><code>//这个方法在每个线程退出时都会进行调用，如果是运行中、或者状态大于等于TIDYING或者shutdown但是队列不为空都
//直接返回，如果不满足以上条件，并且线程数不为0的话，打断一个空闲线程
final&nbsp;void tryTerminate() {
&nbsp; &nbsp;&nbsp;for&nbsp;(;;) {
&nbsp; &nbsp; &nbsp; &nbsp; int c = ctl.get();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(isRunning(c) ||
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; runStateAtLeast(c, TIDYING) ||
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (runStateOf(c) == SHUTDOWN &amp;&amp; ! workQueue.isEmpty()))
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;return;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(workerCountOf(c) !=&nbsp;0) {&nbsp;// Eligible to terminate
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; interruptIdleWorkers(ONLY_ONE);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;return;
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//此时到这里，状态要么为STOP。要么是shutdown并且队列为空了
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 获取一个锁，尝试cas修改状态为TIDYING
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//调用terminated()的钩子方法，
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//修改线程池为终态TERMINATED，并且唤醒阻塞在termination队列上的线程
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;final&nbsp;ReentrantLock mainLock =&nbsp;this.mainLock;
&nbsp; &nbsp; &nbsp; &nbsp; mainLock.lock();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(ctl.compareAndSet(c, ctlOf(TIDYING,&nbsp;0))) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; terminated();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;finally&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ctl.set(ctlOf(TERMINATED,&nbsp;0));
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; termination.signalAll();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;return;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;finally&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; mainLock.unlock();
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// else retry on failed CAS
&nbsp; &nbsp; }
}</code></pre>
<h1>四、JDK内置线程池的问题</h1>
<p>java.util.concurrent.Executors工厂类提供了一些静态方法，方便我们快速创建几种预设配置的线程池：</p>
<ul>
<li>Executors.newFixedThreadPool(int nThreads)：
<ul>
<li>创建一个固定大小的线程池。corePoolSize和maximumPoolSize都等于nThreads。</li>
<li>keepAliveTime为0L（因为线程数不会超过corePoolSize，所以此参数无效，除非allowCoreThreadTimeOut为true）。</li>
<li>使用无界的LinkedBlockingQueue作为工作队列。</li>
<li><strong>问题</strong>：由于使用无界队列，当任务提交速度远大于处理速度时，队列会持续增长，可能导致内存溢出（OOM）。此时maximumPoolSize参数实际上是无效的，线程数永远不会超过nThreads。</li>
</ul> </li>
</ul>
<ul>
<li>Executors.newSingleThreadExecutor()：
<ul>
<li>创建一个只有一个工作线程的线程池。corePoolSize和maximumPoolSize都为1。</li>
<li>同样使用<strong>无界</strong>的LinkedBlockingQueue。</li>
<li>保证所有任务按照提交顺序（FIFO）执行。</li>
<li><strong>问题</strong>：与newFixedThreadPool类似，无界队列可能导致OOM。</li>
</ul> </li>
</ul>
<ul>
<li>Executors.newCachedThreadPool()：
<ul>
<li>创建一个可缓存的线程池。</li>
<li>corePoolSize为0。</li>
<li>maximumPoolSize为Integer.MAX_VALUE (几乎是无界的)。</li>
<li>keepAliveTime为60秒。</li>
<li>使用SynchronousQueue作为工作队列。这种队列不存储元素，任务提交后必须有空闲线程立即接收，否则会创建新线程（如果未达到maximumPoolSize）。</li>
<li><strong>问题</strong>：如果任务提交速度过快，会创建大量线程（理论上可达Integer.MAX_VALUE个），可能耗尽系统资源，导致OOM以及频繁的上下文切换。</li>
</ul> </li>
</ul>
<ul>
<li>Executors.newSingleThreadScheduledExecutor()、Executors.newScheduledThreadPool(int corePoolSize):
<ul>
<li>创建用于调度任务的线程池。</li>
<li>内部使用ScheduledThreadPoolExecutor实现，其任务队列是DelayedWorkQueue (一种特殊的PriorityQueue)。</li>
<li>newSingleThreadScheduledExecutor的corePoolSize为1，maximumPoolSize为Integer.MAX_VALUE（但由于队列是DelayedWorkQueue，通常不会无限增长线程，除非有大量同时到期的任务且处理不过来）。</li>
<li>newScheduledThreadPool可以指定corePoolSize。</li>
<li><strong>问题</strong>：虽然DelayedWorkQueue本身是无界的，但ScheduledThreadPoolExecutor在任务执行逻辑上与普通ThreadPoolExecutor有所不同。主要风险仍然是如果corePoolSize设置不当，且大量任务同时到期并执行缓慢，可能导致任务积压。</li>
</ul> </li>
</ul>
<div>
<img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-a0860059e7.jpg">
</div>
<p>某一线互联网Java开发手册</p>
<h1>五、线程池中的问题与最佳实践</h1>
<h1>5.1 invokeAll 超时机制无效？</h1>
<p>ExecutorService.invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit)方法会提交一组Callable任务，并等待所有任务完成，或者直到超时。如果超时发生，它会尝试取消（中断）所有尚未完成的任务，然后返回一个List&lt;Future&gt;。</p>
<p><strong>失效场景分析：</strong></p>
<ul>
<li>任务不响应中断（最常见）：任务内部捕获&nbsp;InterruptedException&nbsp;后静默处理，或执行不检查中断状态的阻塞操作（如循环计算）：</li>
</ul>
<pre><code>Callable&lt;String&gt; task = () -&gt; {
&nbsp; &nbsp;&nbsp;while&nbsp;(true) {
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//缺少此检查将导致超时失效
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(Thread.interrupted())&nbsp;break;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 耗时计算...
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;return&nbsp;"done";
};</code></pre>
<ul>
<li><strong>使用非响应中断的API</strong>：任务调用了不响应&nbsp;interrupt()&nbsp;的第三方库或JNI代码（如某些IO操作）</li>
</ul>
<pre><code>Callable&lt;Integer&gt; task&nbsp;=&nbsp;() -&gt; {
&nbsp; &nbsp;&nbsp;Files.copy(in, path);&nbsp;// 某些NIO操作不响应中断
&nbsp; &nbsp;&nbsp;return&nbsp;1;
};</code></pre>
<ul>
<li><strong>任务依赖外部资源阻塞</strong>：任务因外部资源（如数据库连接、网络请求）阻塞且未设置超时。</li>
</ul>
<pre><code>Callable&lt;Result&gt; task&nbsp;=&nbsp;() -&gt; {
&nbsp; &nbsp;&nbsp;//未设查询超时时间
&nbsp; &nbsp;&nbsp;return&nbsp;jdbcTemplate.query("SELECT * FROM large_table");&nbsp;
};</code></pre>
<ul>
<li><strong>线程池配置缺陷</strong>：核心线程数过大或队列无界，导致&nbsp;invokeAll&nbsp;超时前任务无法全部启动，任务堆积在队列，invokeAll&nbsp;超时后仍有大量任务未执行。</li>
</ul>
<pre><code>new&nbsp;ThreadPoolExecutor(
&nbsp; &nbsp;&nbsp;100,&nbsp;100,&nbsp;// 核心线程数过大
&nbsp; &nbsp; 0L,&nbsp;TimeUnit.MILLISECONDS,
&nbsp; &nbsp;&nbsp;new&nbsp;LinkedBlockingQueue&lt;&gt;()&nbsp;// 无界队列
);</code></pre>
<p><strong>invokeAll超时失效demo:</strong></p>
<pre><code>import&nbsp;java.util.*;
import&nbsp;java.util.concurrent.*;
public&nbsp;class&nbsp;InvokeAllTimeoutDemo&nbsp;{
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;// 模拟耗时任务（可配置是否响应中断）
&nbsp; &nbsp;&nbsp;static&nbsp;class&nbsp;Task&nbsp;implements&nbsp;Callable&lt;String&gt; {
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;private&nbsp;final&nbsp;int&nbsp;id;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;private&nbsp;final&nbsp;long&nbsp;durationMs;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;private&nbsp;final&nbsp;boolean&nbsp;respectInterrupt;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; Task(int&nbsp;id,&nbsp;long&nbsp;durationMs,&nbsp;boolean&nbsp;respectInterrupt) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;this.id = id;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;this.durationMs = durationMs;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;this.respectInterrupt = respectInterrupt;
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;@Override
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;public&nbsp;String&nbsp;call()&nbsp;throws&nbsp;Exception {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.out.printf("Task %d started%n", id);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;long&nbsp;start&nbsp;=&nbsp;System.currentTimeMillis();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 模拟工作（检查中断状态）
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;while&nbsp;(System.currentTimeMillis() - start &lt; durationMs) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(respectInterrupt &amp;&amp; Thread.interrupted()) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;throw&nbsp;new&nbsp;InterruptedException("Task "&nbsp;+ id +&nbsp;" interrupted");
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 不响应中断的任务会继续执行
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.out.printf("Task %d completed%n", id);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;return&nbsp;"Result-"&nbsp;+ id;
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;public&nbsp;static&nbsp;void&nbsp;main(String[] args)&nbsp;throws&nbsp;InterruptedException {
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;ExecutorService&nbsp;executor&nbsp;=&nbsp;Executors.newFixedThreadPool(2);
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; List&lt;Callable&lt;String&gt;&gt; tasks = Arrays.asList(
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;new&nbsp;Task(1,&nbsp;2000,&nbsp;true), &nbsp;&nbsp;// 2秒，响应中断
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;new&nbsp;Task(2,&nbsp;10000,&nbsp;false) &nbsp;// 10秒，不响应中断
&nbsp; &nbsp; &nbsp; &nbsp; );
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; System.out.println("Invoking with 3s timeout...");
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//设置3秒超时
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; List&lt;Future&lt;String&gt;&gt; futures = executor.invokeAll(tasks,&nbsp;3, TimeUnit.SECONDS);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;for&nbsp;(Future&lt;String&gt; f : futures) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 明确处理取消状态
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(f.isCancelled()) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.out.println("Task was cancelled"); &nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;else&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.out.println("Result: "&nbsp;+ f.get(100, TimeUnit.MILLISECONDS));
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;catch&nbsp;(TimeoutException | ExecutionException e) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.out.println("Task failed: "&nbsp;+ e.getCause());
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;finally&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; executor.shutdownNow();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.out.println("Executor shutdown");
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; }
}</code></pre>
<p>当我们使用invokeAll(tasks, timeout)&nbsp;提交多个任务时，如果出现某个任务对中断不响应或者响应不及时，那我们即使设置了超时时间，不响应中断的任务2仍在后台运行（即使调用了&nbsp;shutdownNow()）</p>
<h1>5.2 submit()的异常消失了？</h1>
<p>使用ExecutorService.submit()提交任务时，任务执行过程中如果抛出未捕获的异常（无论是受检异常还是运行时异常），这个异常会被Future的包装类如FutureTask重写的run()方法捕获并封装在返回的Future包装对象的成员变量中。</p>
<ul>
<li><strong>不显示调用</strong>Future.get()，该异常我们就无法感知，好像没有发生过一样。线程池的工作线程本身通常会有一个默认的未捕获异常处理器，可能会打印堆栈到控制台，但你的主业务逻辑不会知道。</li>
<li><strong>显示调用</strong>Future.get()，抛出声明式的ExecutionException，其cause属性才是原始的任务异常。</li>
<li>如果调用Future.get(long timeout, TimeUnit unit)超时，向外抛出声明式的TimeoutException。此时任务可能仍在后台执行，可能错过了内部的异常。</li>
</ul>
<p><strong>submit()异常消失demo:</strong></p>
<pre><code>public&nbsp;class&nbsp;ThreadPoolExceptionDemo&nbsp;{
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;public&nbsp;static&nbsp;void&nbsp;main(String[] args)&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 创建单线程线程池（便于观察异常）
&nbsp; &nbsp; &nbsp; &nbsp; ExecutorService executor = Executors.newSingleThreadExecutor();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 场景1：Callable抛出异常（通过Future.get()捕获）
&nbsp; &nbsp; &nbsp; &nbsp; Future&lt;String&gt; future1 = executor.submit(() -&gt; {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.out.println("[Callable] 开始执行");
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Thread.sleep(100);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;throw&nbsp;new&nbsp;RuntimeException("Callable故意抛出的异常");
&nbsp; &nbsp; &nbsp; &nbsp; });
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.out.println("Callable结果: "&nbsp;+ future1.get());
&nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;catch&nbsp;(ExecutionException e) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.err.println("捕获到Callable异常: "&nbsp;+ e.getCause().getMessage());
&nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;catch&nbsp;(InterruptedException e) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Thread.currentThread().interrupt();
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 场景2：Runnable抛出异常（同样通过Future.get()捕获）
&nbsp; &nbsp; &nbsp; &nbsp; Future&lt;?&gt; future2 = executor.submit(() -&gt; {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.out.println("[Runnable] 开始执行");
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;throw&nbsp;new&nbsp;IllegalArgumentException("Runnable故意抛出的异常");
&nbsp; &nbsp; &nbsp; &nbsp; });
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; future2.get();&nbsp;// Runnable成功时返回null
&nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;catch&nbsp;(ExecutionException e) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.err.println("捕获到Runnable异常: "&nbsp;+ e.getCause().getMessage());
&nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;catch&nbsp;(InterruptedException e) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Thread.currentThread().interrupt();
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 场景3：未处理的任务异常（需设置异常处理器）
&nbsp; &nbsp; &nbsp; &nbsp; executor.submit(() -&gt; {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.out.println("[未捕获的任务] 开始执行");
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;throw&nbsp;new&nbsp;IllegalStateException("这个异常会被默认处理器处理");
&nbsp; &nbsp; &nbsp; &nbsp; });
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; executor.shutdown();
&nbsp; &nbsp; }
}</code></pre>
<h1>5.3 异常处理实践</h1>
<div>
<img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-851f74dab6.jpg">
</div>
<ul>
<li><strong>Callable/Runnable catch处理异常：</strong>
<ul>
<li><strong>不要捕获Throwable或Exception然后静默处理（只打日志）</strong>。如果确实需要捕获，请考虑是否应该重新抛出（包装成业务允许的受检异常或运行时异常）。</li>
<li><strong>禁止静默处理&nbsp;</strong>InterruptedException：</li>
<li>在JDK的JUC底层源码中，我们可以看到很多声明了InterruptedException的方法，基本上都是对这类方法catch异常，要么继续往外抛出，或者处理完相关资源后，重置中断状态，<strong>绝对不要静默处理。</strong></li>
<li>如果方法没有声明InterruptedException如Runnable.run()，在catch&nbsp;InterruptedException后最好调用Thread.currentThread().interrupt()来恢复中断标记。</li>
<li><strong>正确处理中断</strong>：callable在耗时的loop任务处理中，如果出现了中断异常，因为Java代码中中断只是一种协作方式，其并没真的终止线程，所以一般都是需要我们进行一个中断标志的传递，如线程池中的shutdownNow()就依赖次机制处理。</li>
</ul> </li>
</ul>
<ul>
<li><strong>submit()执行的任务，谨慎处理Future：</strong>
<ul>
<li>使用带过期时间的future.get(long timeOut)获取结果，并要对该方法进行try cache防止其他异常抛出。</li>
<li>多个任务并行处理时，如果有下个请求依赖上个请求，务必使用get()让主线程等待这一结果执行完成后，流转到下一个异步任务。</li>
</ul> </li>
</ul>
<ul>
<li><strong>实现线程Thread的UncaughtExceptionHandler属性</strong>，在自定义的TheadFactory中通过set方法赋值：execute()方法执行时，对于没有捕获的异常使用线程组的兜底统一处理机制。</li>
</ul>
<pre><code>//自定义当前线程组创建线程的统一异常处理，类似于controller的统一异常处理机制
ThreadFactory&nbsp;myThreadFactory&nbsp;=&nbsp;new&nbsp;ThreadFactory() {
&nbsp; &nbsp;&nbsp;private&nbsp;final&nbsp;AtomicInteger&nbsp;atomicInteger&nbsp;=&nbsp;new&nbsp;AtomicInteger(0);
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;private&nbsp;final&nbsp;String&nbsp;threadNamePrefix&nbsp;=&nbsp;"myThreadFactory-";
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;@Override
&nbsp; &nbsp;&nbsp;public&nbsp;Thread&nbsp;newThread(Runnable r)&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;Thread&nbsp;t&nbsp;=&nbsp;&nbsp;new&nbsp;Thread(r,threadNamePrefix + atomicInteger.getAndIncrement());
&nbsp; &nbsp; &nbsp; &nbsp; t.setUncaughtExceptionHandler((thread, throwable) -&gt; {
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//异常的统一处理，日志打印、兜底处理、监控、资源释放等
&nbsp; &nbsp; &nbsp; &nbsp; System.err.println("线程["&nbsp;+ thread.getName() +&nbsp;"]异常: "&nbsp;+ throwable);});
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;return&nbsp;t;
&nbsp; &nbsp; }
};
//构造方法时使用自定义的线程工厂
ExecutorService&nbsp;executor&nbsp;=&nbsp;new&nbsp;ThreadPoolExecutor(
&nbsp; &nbsp; corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,
&nbsp; &nbsp; threadFactory,
&nbsp; &nbsp; handler
);</code></pre>
<ul>
<li><strong>使用自定义线程池时建议重写钩子方法afterExecute(Runnable r, Throwable t)</strong>：这个hook方法是用来解决当前任务线程发生的异常，默认是空实现，我们可以重写他，比如进行兜底的线程继续执行，打印日志记录，以及同步失败使用兜底异步处理等等方式。还要注意释放应用中的资源，比如文件锁的占用等，最好手动释放掉，避免底层操作系统线程对这类资源释放失败导致长期占用，最后只能重启Java进程的尴尬地步。</li>
</ul>
<pre><code>public&nbsp;class&nbsp;MyThreadPoolExecutor&nbsp;extends&nbsp;ThreadPoolExecutor&nbsp;{
&nbsp; &nbsp;&nbsp;public&nbsp;MyThreadPoolExecutor(int&nbsp;corePoolSize,&nbsp;int&nbsp;maximumPoolSize,&nbsp;long&nbsp;keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue)&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue);
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;@Override
&nbsp; &nbsp;&nbsp;protected&nbsp;void&nbsp;afterExecute(Runnable r, Throwable t)&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;//需要特别注意任务是否为submit提交，如果是execute提交的任务，那这里很直接的知道任务是否发生异常以及后续去怎么处理
&nbsp; &nbsp; &nbsp; &nbsp;if(r&nbsp;instanceof&nbsp;Future){
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;if(((Future&lt;?&gt;) r).isDone() || ((Future&lt;?&gt;) r).isCancelled()){
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;//继续使用主线程完成任务,一般不建议，最好使用兜底方式：例如异步发消息，由后续的消费组统一处理异常的任务
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;}
&nbsp; &nbsp; &nbsp; &nbsp;}else&nbsp;if( t !=&nbsp;null){
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//execute异常处理
&nbsp; &nbsp; &nbsp; &nbsp;}
&nbsp; &nbsp; }
}
//FutureTask 把run方法进行了重写，并且catch住了异常，所以说afterExecute的t 如果是submit提交的方式
//那么t基本上就是null
public&nbsp;void&nbsp;run()&nbsp;{
&nbsp; &nbsp;&nbsp;//....
&nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; Callable&lt;V&gt; c = callable;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(c !=&nbsp;null&nbsp;&amp;&amp; state == NEW) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; V result;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;boolean&nbsp;ran;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; result = c.call();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ran =&nbsp;true;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;catch&nbsp;(Throwable ex) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; result =&nbsp;null;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ran =&nbsp;false;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; setException(ex);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(ran)
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; set(result);
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; }&nbsp;finally&nbsp;{
&nbsp; &nbsp; &nbsp;//...
}</code></pre>
<p><strong>afterExecute可以借鉴的示例：</strong></p>
<pre><code>import&nbsp;java.util.concurrent.*;
import&nbsp;java.util.concurrent.atomic.*;
import&nbsp;org.slf4j.*;
public&nbsp;class&nbsp;RobustThreadPool&nbsp;extends&nbsp;ThreadPoolExecutor&nbsp;{
&nbsp; &nbsp;&nbsp;private&nbsp;static&nbsp;final&nbsp;Logger&nbsp;logger&nbsp;=&nbsp;LoggerFactory.getLogger(RobustThreadPool.class);
&nbsp; &nbsp;&nbsp;private&nbsp;final&nbsp;AtomicLong&nbsp;failureCounter&nbsp;=&nbsp;new&nbsp;AtomicLong();
&nbsp; &nbsp;&nbsp;private&nbsp;final&nbsp;RetryPolicy retryPolicy;&nbsp;// 重试策略
&nbsp; &nbsp;&nbsp;private&nbsp;final&nbsp;ThreadLocal&lt;Long&gt; startTime =&nbsp;new&nbsp;ThreadLocal&lt;&gt;();
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;public&nbsp;RobustThreadPool(int&nbsp;corePoolSize,&nbsp;int&nbsp;maxPoolSize,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; BlockingQueue&lt;Runnable&gt; workQueue,
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; RetryPolicy retryPolicy) {
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;super(corePoolSize, maxPoolSize,&nbsp;60L, TimeUnit.SECONDS, workQueue);
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;this.retryPolicy = retryPolicy;
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;@Override
&nbsp; &nbsp;&nbsp;protected&nbsp;void&nbsp;beforeExecute(Thread t, Runnable r)&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; logger.debug("开始执行任务: {}", r);
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;@Override
&nbsp; &nbsp;&nbsp;protected&nbsp;void&nbsp;afterExecute(Runnable r, Throwable t)&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 1. 异常分类处理
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;if(r&nbsp;instanceof&nbsp;Future){
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;if(((Future&lt;?&gt;) r).isDone()){
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;//错误记录以及异常处理
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; failureCounter.incrementAndGet();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; handleFailure(r, t, costTime);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;}
&nbsp; &nbsp; &nbsp; &nbsp;}else&nbsp;if( t !=&nbsp;null){
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//execute异常处理
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; failureCounter.incrementAndGet();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; handleFailure(r, t, costTime);
&nbsp; &nbsp; &nbsp; &nbsp;}
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 2. 资源清理
&nbsp; &nbsp; &nbsp; &nbsp; cleanThreadLocals();
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;private&nbsp;void&nbsp;handleFailure(Runnable r, Throwable t)&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 1. 异常类型识别
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(t&nbsp;instanceof&nbsp;OutOfMemoryError) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; logger.error("JVM内存不足，终止任务: {}", t.getMessage());
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.exit(1);&nbsp;// 严重错误直接终止
&nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 2. 可重试异常处理
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;else&nbsp;if&nbsp;(isRetryable(t)) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;int&nbsp;retryCount&nbsp;=&nbsp;retryPolicy.getCurrentRetryCount(r);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(retryCount &lt; retryPolicy.getMaxRetries()) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; logger.warn("任务第{}次失败，准备重试...",&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; retryCount +&nbsp;1, t);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; retryPolicy.retry(r,&nbsp;this);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;else&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; logger.error("任务超过最大重试次数({})，转入死信队列",&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; retryPolicy.getMaxRetries(), t);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; DeadLetterQueue.add(r, t);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 3. 不可重试异常
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;else&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; logger.error("不可恢复任务失败", t);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Metrics.recordFailure(t.getClass());&nbsp;// 上报监控
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;private&nbsp;boolean&nbsp;isRetryable(Throwable t)&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;return&nbsp;t&nbsp;instanceof&nbsp;IOException ||&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;t&nbsp;instanceof&nbsp;TimeoutException ||
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;(t.getCause() !=&nbsp;null&nbsp;&amp;&amp; isRetryable(t.getCause()));
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;private&nbsp;void&nbsp;cleanThreadLocals()&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 清理可能的内存泄漏
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ThreadLocal&lt;?&gt;[] holders = {&nbsp;/* 其他ThreadLocal */};
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;for&nbsp;(ThreadLocal&lt;?&gt; holder : holders) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; holder.remove();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;catch&nbsp;(Exception e) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; logger.warn("清理ThreadLocal失败", e);
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;// 重试策略嵌套类
&nbsp; &nbsp;&nbsp;public&nbsp;static&nbsp;class&nbsp;RetryPolicy&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;private&nbsp;final&nbsp;int&nbsp;maxRetries;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;private&nbsp;final&nbsp;long&nbsp;retryDelayMs;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;private&nbsp;final&nbsp;Map&lt;Runnable, AtomicInteger&gt; retryMap =&nbsp;new&nbsp;ConcurrentHashMap&lt;&gt;();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;public&nbsp;RetryPolicy(int&nbsp;maxRetries,&nbsp;long&nbsp;retryDelayMs)&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;this.maxRetries = maxRetries;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;this.retryDelayMs = retryDelayMs;
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;public&nbsp;void&nbsp;retry(Runnable task, Executor executor)&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; retryMap.computeIfAbsent(task, k -&gt;&nbsp;new&nbsp;AtomicInteger()).incrementAndGet();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(retryDelayMs &gt;&nbsp;0) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; executor.execute(() -&gt; {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Thread.sleep(retryDelayMs);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;catch&nbsp;(InterruptedException ignored) {}
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; executor.execute(task);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; });
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;else&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; executor.execute(task);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;public&nbsp;int&nbsp;getCurrentRetryCount(Runnable task)&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;return&nbsp;retryMap.getOrDefault(task,&nbsp;new&nbsp;AtomicInteger()).get();
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;public&nbsp;int&nbsp;getMaxRetries()&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;return&nbsp;maxRetries;
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; }
}</code></pre>
<p><strong>异常处理小结</strong>：要特别注意使用future.get()方法时，我们一定要注意设置超时时间，防止主线程无限期的阻塞避免边缘的业务查询影响了主业务造成得不偿失的效果，另外我们需要注意一个点就是submit()方法的提交任务时，afterExecute(Runnable r, Throwable t)中的t恒为null，如果是execute方法提交的任务，那么就是直接获取的任务执行的异常，对于submit提交的任务异常其被封装到了Futrure&nbsp;包装对象中，一般需要我们再次判断任务时执行完毕还是异常或被取消了，如果发生了异常，Future.get()会抛出封装的ExecutionException异常，当然还可能是取消异常以及中断异常。invokeAll和invokeAny我们需要对返回的Future结果检查可能抛出的异常，对于callable&nbsp;前面一再强调了要对InterruptedException不要静默处理，因为线程的中断标记只是一个协作方式，他并没有停止当前线程的运行，我们需要根据自身的场景对发生的中断进行快速响应以及传递中断标志。</p>
<h1>5.4 拒绝策略实践</h1>
<p>先带大家回顾一下策略是如何触发执行的流程：</p>
<pre><code>//添加任务，当不满足条件时会执行拒绝方法reject
public&nbsp;void&nbsp;execute(Runnable command)&nbsp;{
&nbsp; &nbsp;//...
&nbsp; &nbsp;&nbsp;if&nbsp;(isRunning(c) &amp;&amp; workQueue.offer(command)) {
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;int&nbsp;recheck = ctl.get();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(! isRunning(recheck) &amp;&amp;&nbsp;remove(command))
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; reject(command);
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;else&nbsp;if&nbsp;(workerCountOf(recheck) ==&nbsp;0)
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; addWorker(null,&nbsp;false);
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;else&nbsp;if&nbsp;(!addWorker(command,&nbsp;false))
&nbsp; &nbsp; &nbsp; &nbsp; reject(command);
}
//这里就是拒绝的入口。handler是有构造方法传入
final&nbsp;void&nbsp;reject(Runnable command)&nbsp;{
&nbsp; &nbsp; handler.rejectedExecution(command,&nbsp;this);
}
public&nbsp;ThreadPoolExecutor(int&nbsp;corePoolSize,
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;int&nbsp;maximumPoolSize,
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;long&nbsp;keepAliveTime,
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; TimeUnit unit,
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; BlockingQueue&lt;Runnable&gt; workQueue,
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ThreadFactory threadFactory,
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; RejectedExecutionHandler handler) {
&nbsp; &nbsp;&nbsp;//....
&nbsp; &nbsp;&nbsp;//指定拒绝策略
&nbsp; &nbsp;&nbsp;this.handler = handler;
}</code></pre>
<p><strong>AbortPolicy</strong>：默认的拒绝策略，简单粗暴，当execute中添加woker失败时，直接在当前线程抛出异常。</p>
<pre><code>public&nbsp;static&nbsp;class&nbsp;AbortPolicy&nbsp;implements&nbsp;RejectedExecutionHandler&nbsp;{
&nbsp; &nbsp; &nbsp;//直接抛出RejectedExecutionException
&nbsp; &nbsp;&nbsp;public&nbsp;void&nbsp;rejectedExecution(Runnable r, ThreadPoolExecutor e) {
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;throw&nbsp;new&nbsp;RejectedExecutionException("Task "&nbsp;+ r.toString() +
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;" rejected from "&nbsp;+
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;e.toString());
&nbsp; &nbsp; }
}</code></pre>
<p><strong>优点</strong>：快速失败，立即暴露系统过载问题、避免任务静默丢失，便于监控系统捕获</p>
<p><strong>缺点</strong>：需要调用方显式处理异常，增加代码复杂度，可能中断主业务流程</p>
<p><strong>适用场景</strong>：适用于那些对任务丢失非常敏感，配合熔断机制使用的快速失败场景</p>
<p><strong>CallerRunsPolicy</strong>：提交任务的线程，直接执行任务</p>
<pre><code>public&nbsp;static&nbsp;class&nbsp;CallerRunsPolicy&nbsp;implements&nbsp;RejectedExecutionHandler&nbsp;{
&nbsp; &nbsp;&nbsp;//直接在提交任务的线程中执行任务
&nbsp; &nbsp;&nbsp;public&nbsp;void&nbsp;rejectedExecution(Runnable r, ThreadPoolExecutor e) {
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(!e.isShutdown()) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; r.run();
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; }
}</code></pre>
<p><strong>优点</strong>：任务都会被执行，不会丢任务，并且由于主线程执行任务，天然的流量控制，避免了大量的任务进入线程池。</p>
<p><strong>缺点</strong>：调用线程可能被阻塞，导致上游服务雪崩。不适合高并发场景（可能拖垮整个调用链）。</p>
<p><strong>适用场景</strong>：适用于处理能力不高，并且资源过载能够平滑过渡，同时不丢失任务的场景。如：低并发、高可靠性的后台任务（如日志归档）、允许同步执行的批处理系统。</p>
<p><strong>DiscardPolicy</strong>：直接丢弃被拒绝的任务，不做任何通知。</p>
<pre><code>public&nbsp;static&nbsp;class&nbsp;DiscardPolicy&nbsp;implements&nbsp;RejectedExecutionHandler&nbsp;{
&nbsp; &nbsp;//空实现
&nbsp; &nbsp;&nbsp;public&nbsp;void&nbsp;rejectedExecution(Runnable r, ThreadPoolExecutor e) {
&nbsp; &nbsp; }
}</code></pre>
<p><strong>优点</strong>：实现简单，无额外性能开销。避免异常传播影响主流程</p>
<p><strong>缺点</strong>：数据静默丢失，可能会掩盖系统容量问题</p>
<p><strong>适用场景</strong>：边缘业务的监控上报数据，统计类的uv、pv统计任务</p>
<p>DiscardOldestPolicy：丢弃队列中最旧的任务，然后重试提交当前任务。</p>
<pre><code>public&nbsp;static&nbsp;class&nbsp;DiscardOldestPolicy&nbsp;implements&nbsp;RejectedExecutionHandler&nbsp;{
&nbsp; &nbsp;&nbsp;//丢弃队列中最旧的任务，重试当前任务
&nbsp; &nbsp;&nbsp;public&nbsp;void&nbsp;rejectedExecution(Runnable r, ThreadPoolExecutor e) {
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(!e.isShutdown()) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; e.getQueue().poll();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; e.execute(r);
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; }
}</code></pre>
<p><strong>优点</strong>：优先保证新任务执行，避免队列堆积导致内存溢出。</p>
<p><strong>缺点</strong>：可能丢失关键旧任务、任务执行顺序无法保证。</p>
<p><strong>适用场景</strong>：适用于可容忍部分数据丢失，并且实时性要求高于历史数据的场景，比如：行情推送。</p>
<p>通过上线的介绍，我们可以看到JDK内置策略基本上只使用于简单处理的场景，在生产实践中一般推荐我们自定义拒绝策略，进行相关的业务处理。</p>
<p><strong>1. 自定义RejectedExecutionHandler</strong>：</p>
<pre><code>/**
&nbsp;* 带监控统计的拒绝策略处理器
&nbsp;*/
public&nbsp;class&nbsp;MetricsRejectedExecutionHandler&nbsp;implements&nbsp;RejectedExecutionHandler&nbsp;{
&nbsp; &nbsp;&nbsp;private&nbsp;static&nbsp;final&nbsp;org.slf4j.Logger&nbsp;logger&nbsp;=&nbsp;org.slf4j.LoggerFactory.getLogger(MetricsRejectedExecutionHandler.class);
&nbsp; &nbsp;&nbsp;// 统计被拒绝的任务数量
&nbsp; &nbsp;&nbsp;private&nbsp;final&nbsp;AtomicLong&nbsp;rejectedCount&nbsp;=&nbsp;new&nbsp;AtomicLong(0);
&nbsp; &nbsp;&nbsp;@Override
&nbsp; &nbsp;&nbsp;public&nbsp;void&nbsp;rejectedExecution(Runnable r, ThreadPoolExecutor executor)&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 1. 采集线程池关键指标
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;int&nbsp;poolSize&nbsp;=&nbsp;executor.getPoolSize();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;int&nbsp;activeThreads&nbsp;=&nbsp;executor.getActiveCount();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;int&nbsp;corePoolSize&nbsp;=&nbsp;executor.getCorePoolSize();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;int&nbsp;maxPoolSize&nbsp;=&nbsp;executor.getMaximumPoolSize();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;int&nbsp;queueSize&nbsp;=&nbsp;executor.getQueue().size();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;long&nbsp;completedTasks&nbsp;=&nbsp;executor.getCompletedTaskCount();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 2. 递增拒绝计数器
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;long&nbsp;totalRejected&nbsp;=&nbsp;rejectedCount.incrementAndGet();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 3. 输出警告日志（包含完整指标）
&nbsp; &nbsp; &nbsp; &nbsp; logger.warn("""
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;任务被拒绝执行！线程池状态:
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; |- 活跃线程数/当前线程数: {}/{}
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; |- 核心/最大线程数: {}/{}
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; |- 队列大小: {}
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; |- 已完成任务数: {}
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; |- 历史拒绝总数: {}
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; |- 被拒绝任务: {}
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; """,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; activeThreads, poolSize,
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; corePoolSize, maxPoolSize,
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; queueSize,
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; completedTasks,
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; totalRejected,
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; r.getClass().getName());
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 4. 可选：降级处理（如存入数据库等待重试）
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// fallbackToDatabase(r);
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 5. 抛出RejectedExecutionException（保持默认行为）
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;throw&nbsp;new&nbsp;RejectedExecutionException("Task "&nbsp;+ r.toString() +&nbsp;" rejected");
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;// 获取累计拒绝次数（用于监控）
&nbsp; &nbsp;&nbsp;public&nbsp;long&nbsp;getRejectedCount()&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;return&nbsp;rejectedCount.get();
&nbsp; &nbsp; }
}</code></pre>
<ul>
<li><strong>记录日志并告警</strong>：所有的异常处理中，最常见简单的方式无外乎，先记录个日志，然后有告警系统的进行相关的某书、某信以及短信等的告警信息推送，方便开发人员以及运维人员的及时发现问题并介入处理。</li>
<li><strong>兜底处理机制</strong>：一般常见的就是通过异步的方式提交到MQ，然后统一进行兜底处理。</li>
<li><strong>带超时和重试的拒绝</strong>：可以尝试等待一小段时间，或者重试几次提交，如果仍然失败，再执行最终的拒绝逻辑（如告警、持久化或抛异常）。</li>
<li><strong>动态调整策略</strong>：根据系统的负载或任务类型，动态的执行兜底策略机制，就如前面写的源码示例方式。</li>
</ul>
<p><strong>2. 根据自身业务场景选择合适的拒绝策略：</strong></p>
<ul>
<li><strong>核心业务，不容丢失</strong>：如果任务非常重要，不能丢失，可以考虑：
<ul>
<li>CallerRunsPolicy：调用线程承担任务执行压力，是否可支撑；</li>
<li>自定义策略：尝试持久化到MQ或DB，然后由专门的消费组补偿任务处理；</li>
<li>AbortPolicy：如果希望系统快速失败并由上层进行重试或熔断。</li>
<li>&nbsp;</li>
</ul> </li>
<li><strong>非核心业务，可容忍部分丢失</strong>：
<ul>
<li>DiscardOldestPolicy：新任务更重要时，如行情推送；</li>
<li>DiscardPolicy：边缘业务场景，比如一些pv统计等，丢失了无所谓；</li>
<li>及时的进行监控查看，了解任务的丢失情况。</li>
</ul> </li>
</ul>
<p><strong>3. 结合线程池参数综合考虑：</strong></p>
<ul>
<li>拒绝策略的选择也与线程池的队列类型（有界/无界）、队列容量、maximumPoolSize等参数密切相关。</li>
<li>如果使用无界队列LinkedBlockingQueue的无参构造，只有机器内存不够时才会进行拒绝策略，不过这种极端场景已经不是影响线程池本身，内存不够可能导致Java进程被操作系统直接kill可能。</li>
<li>如果使用有界队列，需要权衡队列的大小，核心场景甚至可以动态追踪阻塞队列大小，以及动态调整队列大小来保证核心业务的正常流转。</li>
</ul>
<ol>
<li><strong>充分测试和监控</strong>：无论选择哪种策略，都必须在压测环境中充分测试其行为，并在线上环境建立完善的监控体系，监控线程池的各项指标（活跃线程数、队列长度、任务完成数、任务拒绝数等）。当拒绝发生时，应有相应的告警通知。</li>
</ol>
<p><strong>拒绝策略小结</strong>：</p>
<p>策略的选择跟我们大多数的系统设计哲学是保持一致的，都是在应对不同的场景中，做出一定的trade off。最好的策略需要根据业务场景、系统容忍度、资源等方面的综合考量，<strong>一个黄金的实践原则</strong>：拒绝事件做好监控告警、根据业务SLA定义策略，是否可丢失，快速失败等，定期的进行压力测试，验证策略的有效性。</p>
<h1>5.5 池隔离实践</h1>
<p><strong>核心思想</strong>：根据任务的资源类型 、优先级和业务特性 ，划分多个独立的线程池，避免不同性质的任务相互干扰。</p>
<p><strong>1. 隔离维度</strong>：</p>
<ul>
<li><strong>资源类型</strong>：CPU密集型 vs &nbsp;I/O密集型任务</li>
<li><strong>执行时长</strong>：短时任务（毫秒级） vs 长时任务（分钟级）</li>
<li><strong>实时性要求</strong>：高实时性 vs 可延迟（最终一致即可）</li>
<li><strong>业务重要性</strong>：支付交易（高优先级） vs 日志清理（低优先级）</li>
<li><strong>是否依赖外部资源</strong>：例如，访问特定数据库、调用特定第三方API的任务可以归为一类。</li>
</ul>
<p><strong>2. 不同业务场景线程池独立使用</strong>：在不同的业务场景下，为自己的特定业务，创建独立的线程池。</p>
<ul>
<li><strong>线程命名</strong>：通过ThreadFactory为每个线程池及其线程设置有意义的名称，例如netty-io-compress-pool-%d，excel-export-pool-%d, 主要方便区别不同的业务场景以及问题排查。</li>
<li><strong>参数调优</strong>：不同的业务场景设置不同的参数。
<ul>
<li>corePoolSize, maximumPoolSize：CPU密集型的计算任务可以设置小点减少上下文的切换，I/O密集型可以较大，在io阻塞等待期间，多去处理其他任务。</li>
<li>阻塞队列blockQueue：选择合适的队列类型，以及设置合理的队列大小。</li>
<li>RejectedExecutionHandler：有内置的四种的策略以及自定义策略选择，一般建议做好日志、监控以及兜底的处理。</li>
<li>&nbsp;</li>
</ul> </li>
</ul>
<p><strong>3. 自定义Executor避免线程池共用</strong></p>
<pre><code>// 创建CPU密集型任务线程池（线程数=CPU核心数）
ExecutorService cpuIntensiveExecutor =&nbsp;new&nbsp;ThreadPoolExecutor(
&nbsp; &nbsp; Runtime.getRuntime().availableProcessors(),&nbsp;// 核心线程数=CPU核心数
&nbsp; &nbsp; Runtime.getRuntime().availableProcessors(),&nbsp;// 最大线程数=CPU核心数
&nbsp; &nbsp;&nbsp;30L, TimeUnit.SECONDS,
&nbsp; &nbsp;&nbsp;new&nbsp;LinkedBlockingQueue&lt;&gt;(500),
&nbsp; &nbsp;&nbsp;new&nbsp;ThreadFactoryBuilder()
&nbsp; &nbsp; &nbsp; &nbsp; .setNameFormat("cpu-pool-%d")
&nbsp; &nbsp; &nbsp; &nbsp; .setPriority(Thread.MAX_PRIORITY)&nbsp;// 提高优先级
&nbsp; &nbsp; &nbsp; &nbsp; .build(),
&nbsp; &nbsp;&nbsp;new&nbsp;ThreadPoolExecutor.AbortPolicy()&nbsp;// 直接拒绝
);
// 使用示例
CompletableFuture.supplyAsync(() -&gt; {
&nbsp; &nbsp;&nbsp;// 矩阵计算等CPU密集型任务
&nbsp; &nbsp;&nbsp;double[][] result = matrixMultiply(largeMatrixA, largeMatrixB);
&nbsp; &nbsp;&nbsp;return&nbsp;result;
}, cpuIntensiveExecutor)
.thenAccept(result -&gt; {
&nbsp; &nbsp; System.out.println("计算结果维度: "&nbsp;+ result.length +&nbsp;"x"&nbsp;+ result[0].length);
});</code></pre>
<p><strong>线程池隔离小结</strong>：</p>
<p>专池专用的本质是通过物理隔离实现：</p>
<ul>
<li>资源保障 ：关键业务独占线程资源</li>
<li>故障隔离 ：避免级联雪崩</li>
<li>性能优化 ：针对任务类型最大化吞吐量</li>
</ul>
<p>最终呈现的效果是像专业厨房的分区（切配区/炒菜区/面点区）一样，让每个线程池专注处理同类任务，提升整体效率和可靠性。</p>
<h1>六、总结</h1>
<p>线程池是Java并发编程的核心组件，通过复用线程减少资源开销，提升系统吞吐量。其核心设计包括线程复用机制 、任务队列和拒绝策略 ，通过ThreadPoolExecutor的参数（核心线程数、最大线程数、队列容量等）实现灵活的资源控制。线程池的生命周期由RUNNING、SHUTDOWN等状态管理，确保任务有序执行或终止。</p>
<p>内置线程池（如Executors.newCachedThreadPool）虽便捷，但存在内存溢出或无界队列堆积的风险，需谨慎选择。invokeAll的超时失效和submit提交任务的异常消失是常见陷阱需通过正确处理中断和检查Future.get()规避。</p>
<p>最佳实践包括：</p>
<ul>
<li>异常处理：通过afterExecute来对发生的异常进行兜底处理，任务细粒度的try catch或UncaughtExceptionH捕获异常处理防止线程崩溃退出；</li>
<li>拒绝策略：根据业务选择拒绝策略或自定义降级逻辑，生产级应用建议尽量自定义处理；</li>
<li>线程隔离 ：按任务类型（CPU/I/O）或优先级划分线程池，避免资源竞争。</li>
</ul>
<p>合理使用线程池能显著提升性能，但需结合业务场景精细调参，确保稳定性和可维护性，希望这篇文章能给大家带来一些生产实践上的指导，减少一些因为不熟悉线程池相关原理生产误用导致的一些问题。</p>
<h4>往期回顾</h4>
<p>1.&nbsp;基于浏览器扩展 API Mock 工具开发探索｜得物技术</p>
<p>2.&nbsp;破解gh-ost变更导致MySQL表膨胀之谜｜得物技术</p>
<p>3.&nbsp;MySQL单表为何别超2000万行？揭秘B+树与16KB页的生死博弈｜得物技术</p>
<p>4.&nbsp;0基础带你精通Java对象序列化--以Hessian为例｜得物技术</p>
<p>5.&nbsp;前端日志回捞系统的性能优化实践｜得物技术</p>
<h4>文 /舍得</h4>
<p>关注得物技术，每周更新技术干货</p>
<p>要是觉得文章对你有帮助的话，欢迎评论转发点赞～</p>
<p>未经得物技术许可严禁转载，否则依法追究法律责任。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<h1>一、引 言</h1>
<p><strong>为什么进行源码角度的深度解析？</strong></p>
<p>大家在项目中到处都在使用线程池做一些性能接口层次的优化，原先串行的多个远程调用，因为rt过高，通过线程池批量异步优化，从而降低rt。还有像RocketMQ中broker启动时，同时通过ScheduledThreadPoolExecutor线程池执行其他组件的定时任务，每隔一段时间处理相关的任务。线程池广泛的应用在外面各种实际开发场景中，我们很多同学可能在项目里只是简单的copy了一些前人的代码参数并不知道其中的含义，从而导致生产级别的bug。所以本篇文章，旨在帮助还不熟悉或者想要熟悉线程池的同学，分享我自己在学习线程池源码上的一些内容来更简单、快速的掌握线程池。</p>
<h1>二、为什么使用线程池？</h1>
<p>并发编程中，对于常见的操作系统，线程都是执行任务的基本单元，如果每次执行任务时都创建新的线程，任务执行完毕又进行销毁，会出现以下的问题：</p>
<ul>
<li><strong>资源开销</strong>：比如在Linux系统中，频繁的创建和销毁线程，一个是频繁的进行一个系统调用，另外是一些内存和CPU资源调度的占用。虽然有一些写时复制的策略防止lwp的创建时的内存占用，但是实际写入还是会申请系统内存的，何况一些页表等本身就有内存占用。</li>
<li><strong>性能瓶颈</strong>：线程的创建需要系统调用，如果只是简单的计算任务，可能耗时还没创建的rt高，这里反而降低了系统的吞吐量。</li>
<li><strong>缺乏资源管理</strong>：无限制的创建线程会导致内存溢出，java.lang.OutOfMemoryError: unable to create native thread，这里主要因为Java的线程其实Linux中是lwp线程，需要通过JNI进行系统调用创建，每个线程默认需要1MB的栈空间，很容易导致无休止的创建线程导致内存溢出，另外就是频繁的系统调用，导致的上下文切换，占用了过多的CPU，反而起到了相反的作用。</li>
<li><strong>功能受限</strong>：手动管理线程难以实现更高级的功能，如定时任务、周期任务、任务管理、并发任务数的控制等。</li>
</ul>
<p>通过上面的问题，我们其实可以清晰的感知到这些问题都是归拢到资源没有得到合理的分配和控制导致的，线程池出现的核心宗旨其实就是对资源的合理分配和控制。除了线程池，其实更多的也接触过数据库连接池、netty的对象池等池化技术，这些池化思想其实都是为了更好的降低资源的消耗以及更好的进行资源管理。</p>
<h1>三、JDK线程池的架构设计</h1>
<h1>3.1 JUC并发包下的Executor框架的uml类图</h1>
<div>
<img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-10e0261f0e.jpg">
</div>
<ul>
<li><strong>Executor</strong>：任务执行的顶层接口，主要是分离任务提交与执行逻辑，支持同步/异步执行，遵循Java内存模型的&nbsp;happen-before规则。</li>
<li><strong>ExecutorService</strong>：继承Executor接口，提供了更完善的生命周期管理能力，通过Future对象提供任务取消、状态查询、结果获取能力实现了任务监控。</li>
<li><strong>AbstractExecutorService</strong>：常见的设计模式为了简化线程池的开发，通常通过父类进行一些基础的默认实现让子类继承。</li>
<li><strong>ScheduledExecutorService</strong>：ExecutorService的扩展接口，支持延迟执行和周期性任务调度。</li>
<li><strong>ThreadPoolExecutor</strong>：是ExecutorService接口最核心和最常用的实现类，它提供了高度可配置的线程池，允许我们精细控制线程池的各种行为。</li>
<li><strong>ScheduledThreadPoolExecutor</strong>：是ScheduledExecutorService接口的实现类，它继承自ThreadPoolExecutor，专门用于处理定时和周期任务。</li>
<li><strong>Executors</strong>：一个静态工厂模式的工具类，提供了一系列静态方法来创建各种常见配置的线程池，newFixedThreadPool(), newCachedThreadPool(),等，简化了创建线程池的使用但是会带来一些问题，很多开发规范里都不建议大家直接使用。JDK内置的线程池如果我们不熟悉里面的参数很有可能导致出乎自己意料的结果，池大小设置、阻塞队列选择等等都是有考究的，这一点后续会进行一些详细说明。生产环境中建议谨慎使用或直接使用ThreadPoolExecutor构造函数自定义。</li>
</ul>
<h1>3.2 ThreadPoolExecutor的参数解析</h1>
<div>
<img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-2b578a85a8.jpg">
</div>
<ul>
<li><strong>corePoolSize&nbsp;</strong>核心线程数：
<ul>
<li>线程池中还未退出的alive的核心线程数量。</li>
<li>虽然线程处于空闲状态（其实是阻塞在阻塞队列中），除非显示设置了allowCoreThreadTimeOut=true，否则这些线程不会从自己的run方法中退出被回收。</li>
<li>添加新任务时，如果当前工作线程小于coreSize，此时即使存在空闲的core线程，线程池也会通过addWorker方法创建一个新的线程。</li>
<li>&nbsp;</li>
</ul> </li>
<li><strong>maximumPoolSize&nbsp;</strong>最大线程数：
<ul>
<li>线程池可以创建的最大线程数。</li>
<li>如果是有界队列，当队列满时，仍然有任务进来，此时线程池会创建小于最大线程数的线程来完成任务，空闲。</li>
<li>如果是无界队列，那么永远不会出现第二点的情况，除了内存异常，否则会一直保持核心线程数，多余的任务会一直往队列中加入。</li>
</ul> </li>
</ul>
<ul>
<li><strong>keepAliveTime</strong>&nbsp;线程空闲存活时间
<ul>
<li>线程数超过corePoolSize后创建的线程我们理解为非核心线程，对于这类线程，他的回收机制在于我们设置的keepAliveTime,线程会限期阻塞在队列中获取任务，如果超时未获取就会进行清理并退出。</li>
<li>另外如果设置allowCoreThreadTimeOut=true，所谓的核心线程在空闲时间达到keepAliveTime时也会被回收。</li>
</ul> </li>
</ul>
<ul>
<li><strong>unit&nbsp;</strong>时间单位
<ul>
<li>keepAliveTime参数的时间单位，TimeUnit中时分秒等。</li>
<li>&nbsp;</li>
</ul> </li>
<li><strong>workQueue&nbsp;</strong>任务队列
<ul>
<li>阻塞队列，核心线程数满时，新加入的任务，会先添加到阻塞队列中等待线程获取任务并执行。</li>
<li>常用的BlockingQueue实现有：
<ul>
<li>ArrayBlockingQueue：数组实现的先进先出原则的有界阻塞队列，构造方法必须指定容量。</li>
<li>LinkedBlockingQueue：链表实现的阻塞队列，构造传入容量则有界，未传则是无界队列，此时设置的最大线程数其实就不会有作用了。</li>
<li>SynchronousQueue：一个不存储元素的阻塞队列。每个put操作必须等待一个take操作，反之亦然。它相当于一个传递通道，非常适合传递性需求，吞吐量高，但要求maximumPoolSize足够大。</li>
<li>PriorityBlockingQueue：二叉堆实现的优先级阻塞队列，构造时可自行调整排序行为（小顶堆或大顶堆）。</li>
<li>DelayQueue：支持延时的无界阻塞队列，主要用于周期性的任务，我们可以直接通过它来实现一些简单的延迟任务需求，复杂的周期性任务建议使用ScheduledThreadPoolExecutor。</li>
</ul> </li>
</ul> </li>
</ul>
<ul>
<li><strong>threadFactory&nbsp;</strong>线程工厂
<ul>
<li>用于创建新线程的工厂。通过自定义ThreadFactory，我们可以为线程池中的线程设置更有意义的名称、设置守护线程状态、设置线程优先级、指定UncaughtExceptionHandler等。</li>
<li>Executors.defaultThreadFactory()是默认实现。</li>
</ul> </li>
</ul>
<ul>
<li><strong>handler&nbsp;</strong>拒绝策略
<ul>
<li>ThreadPoolExecutor.AbortPolicy：默认的拒绝策略，简单粗暴，当execute中添加woker失败时，直接在当前线程抛出异常。</li>
<li>JDK内置了四种拒绝策略：
<ul>
<li>ThreadPoolExecutor.AbortPolicy：默认的拒绝策略，简单粗暴，当execute中添加woker失败时，直接在当前线程抛出异常。</li>
<li>ThreadPoolExecutor.CallerRunsPolicy：提交任务的线程，直接执行任务。变相的背压机制，可以降低任务往线程中加入。</li>
<li>ThreadPoolExecutor.DiscardPolicy：直接丢弃被拒绝的任务，不做任何通知，需容忍数据丢失。</li>
<li>ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列中最旧的任务，然后重试提交当前任务，需容忍数据丢失。</li>
<li>实现RejectedExecutionHandler接口自定义拒绝策略，在实际生产应用中推荐使用，可以做一些打印观察日志的操作，告警、兜底的相关处理等。</li>
</ul> </li>
</ul> </li>
</ul>
<h1>3.3 运行机制详解</h1>
<p>新任务通过execute()方法提交给ThreadPoolExecutor时，其处理流程如下：</p>
<p><strong>判断核心线程数</strong>：如果当前运行的线程数小于corePoolSize，则创建新线程（即使有空闲的核心线程）来执行任务。</p>
<p><strong>尝试入队</strong>：如果当前运行的线程数大于或等于corePoolSize，则尝试将任务添加到workQueue中。</p>
<ul>
<li>如果workQueue.offer()成功（队列未满），任务入队等待执行。</li>
</ul>
<p><strong>尝试创建非核心线程</strong>：如果workQueue.offer()失败（队列已满）：</p>
<ul>
<li>判断当前运行的线程数是否小于maximumPoolSize；</li>
<li>如果是，则创建新的非核心线程来执行任务。</li>
</ul>
<p><strong>执行拒绝策略：</strong></p>
<p>如果当前运行的线程数也达到了maximumPoolSize（即核心线程和非核心线程都已用尽，且队列也满了），则执行RejectedExecutionHandler所定义的拒绝策略。</p>
<p>参考网络中的经典执行图：</p>
<div>
<img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-88df05dbfd.jpg">
</div>
<p>这个图能很好的表明运行原理，但是忽略了很多细节，比如所谓的缓冲执行是在什么条件下去走的呢？直接执行又是什么逻辑下执行呢？最后的任务拒绝又是怎么回事？带着这些疑问点，我们直接来进行一个源码级别的分析：</p>
<h1>execute核心流程的源码分析</h1>
<pre><code>public&nbsp;void&nbsp;execute(Runnable command)&nbsp;{
&nbsp; &nbsp;&nbsp;if&nbsp;(command ==&nbsp;null)
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;throw&nbsp;new&nbsp;NullPointerException();
&nbsp; &nbsp;&nbsp;//线程池状态 高3位表示线程状态 低29位代表线程数量
&nbsp; &nbsp;&nbsp;int&nbsp;c = ctl.get();
&nbsp; &nbsp;&nbsp;//判断当前线程池线程数量是否小于核心线程数
&nbsp; &nbsp;&nbsp;if&nbsp;(workerCountOf(c) &lt; corePoolSize) {
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//作为核心线程数进行线程的创建，并且创建成功线程会将command的任务执行--》对应图上的直接执行
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(addWorker(command,&nbsp;true))
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;return;
&nbsp; &nbsp; &nbsp; &nbsp; c = ctl.get();
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;//创建核心线程失败或者当前线程数量超过核心线程数
&nbsp; &nbsp;&nbsp;//当前线程池是否还在运行状态，尝试将任务添加到阻塞队列 --》对应图上的缓冲执行
&nbsp; &nbsp;&nbsp;//BlockingQueue队列的顶级抽象定义了offer不是进行阻塞添加而是立即返回，添加失败直接返回false，区别于put
&nbsp; &nbsp;&nbsp;if&nbsp;(isRunning(c) &amp;&amp; workQueue.offer(command)) {
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//重新获取线程池标志位
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;int&nbsp;recheck = ctl.get();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//如果线程此时不在运行状态中，那么将任务删除
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(! isRunning(recheck) &amp;&amp;&nbsp;remove(command))
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//删除任务成功，走拒绝策略拒绝掉当前任务
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; reject(command);
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;else&nbsp;if&nbsp;(workerCountOf(recheck) ==&nbsp;0)
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//如果线程池中的工作线程都没有的时候，这里需要创建一个线程去执行添加到队列中的任务
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//防止因为并发的原因工作线程都被终止掉了，此时任务在阻塞队列里等着，缺没有工作线程
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; addWorker(null,&nbsp;false);
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;//到这里那就是添加队列失败，或者线程池状态异常，但是这里仍然尝试进行创建一个worker
&nbsp; &nbsp;&nbsp;//如果创建失败，也是走拒绝策略拒绝当前任务
&nbsp; &nbsp;&nbsp;else&nbsp;if&nbsp;(!addWorker(command,&nbsp;false))
&nbsp; &nbsp; &nbsp; &nbsp; reject(command);
}</code></pre>
<p>接下来我们仔细看看addWorker这个方法具体是在做什么：</p>
<pre><code>//核心逻辑其实就是在无限循环创建一个worker，创建失败直接返回，创建成功，则将worker执行
// 因为worker有thread的成员变量，最终添加worker成功，会启动线程的start方法
//start方法最终会回调到外层的runWorker方法，改方法会不停的从阻塞队列里以阻塞的take方式
//获取任务，除非达到能被终止的条件，此时当前线程会终止
private&nbsp;boolean&nbsp;addWorker(Runnable firstTask,&nbsp;boolean&nbsp;core)&nbsp;{
&nbsp; &nbsp; retry:
&nbsp; &nbsp;&nbsp;for&nbsp;(;;) {
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;int&nbsp;c&nbsp;=&nbsp;ctl.get();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;int&nbsp;rs&nbsp;=&nbsp;runStateOf(c);
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// Check if queue empty only if necessary.
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(rs &gt;= SHUTDOWN &amp;&amp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ! (rs == SHUTDOWN &amp;&amp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;firstTask ==&nbsp;null&nbsp;&amp;&amp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;! workQueue.isEmpty()))
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;return&nbsp;false;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;for&nbsp;(;;) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;int&nbsp;wc&nbsp;=&nbsp;workerCountOf(c);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(wc &gt;= CAPACITY ||
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; wc &gt;= (core ? corePoolSize : maximumPoolSize))
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;return&nbsp;false;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//不停的重试添加worker的计数，只有添加成功的才会进行后续的worker启动
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(compareAndIncrementWorkerCount(c))
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;break&nbsp;retry;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; c = ctl.get(); &nbsp;// Re-read ctl
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//重试期间，如果其他线程导致线程池状态不一致了。重新回到第一个循环进行check判断
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(runStateOf(c) != rs)
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;continue&nbsp;retry;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// else CAS failed due to workerCount change; retry inner loop
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;boolean&nbsp;workerStarted&nbsp;=&nbsp;false;
&nbsp; &nbsp;&nbsp;boolean&nbsp;workerAdded&nbsp;=&nbsp;false;
&nbsp; &nbsp;&nbsp;Worker&nbsp;w&nbsp;=&nbsp;null;
&nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; w =&nbsp;new&nbsp;Worker(firstTask);
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;final&nbsp;Thread&nbsp;t&nbsp;=&nbsp;w.thread;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(t !=&nbsp;null) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//这里加锁一个是workers.add时需要加锁，另外是防止其他线程已经在尝试修改线程池状态了
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;final&nbsp;ReentrantLock&nbsp;mainLock&nbsp;=&nbsp;this.mainLock;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; mainLock.lock();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// Recheck while holding lock.
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// Back out on ThreadFactory failure or if
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// shut down before lock acquired.
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;int&nbsp;rs&nbsp;=&nbsp;runStateOf(ctl.get());
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(rs &lt; SHUTDOWN ||
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (rs == SHUTDOWN &amp;&amp; firstTask ==&nbsp;null)) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(t.isAlive())&nbsp;// precheck that t is startable
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;throw&nbsp;new&nbsp;IllegalThreadStateException();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//将worker的引用添加到workers的hashSet中
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; workers.add(w);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;int&nbsp;s&nbsp;=&nbsp;workers.size();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//更新线程池此时最大的线程数
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(s &gt; largestPoolSize)
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; largestPoolSize = s;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; workerAdded =&nbsp;true;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;finally&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; mainLock.unlock();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//如果添加成功，就启动worker中的线程
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(workerAdded) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; t.start();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; workerStarted =&nbsp;true;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; }&nbsp;finally&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//这里添加失败的话，需要把线程池的count数进行--，并且要把worker引用从hashSer中移除
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(! workerStarted)
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; addWorkerFailed(w);
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;return&nbsp;workerStarted;
}</code></pre>
<h1>3.4 线程池的生命周期</h1>
<p>在介绍运行机制原理的源码分析时，其实是有提到线程池状态这个概念的。介绍这个状态其实也是让大家更方便的去管理线程池，比如我们关闭线程池时，怎么去优雅的关闭，使用不同的方法可能会有不同的效果，我们需要根据自己的业务场景去酌情分析、权衡使用。</p>
<pre><code>//线程池的状态和计数采用一个Integer变量设置的
//这里之所以用一个变量来储存状态和数量，其实很有讲究的，因为我们在上面的运行原理上可以看到
//源码中有大量的进行状态以及数量的判断，如果分开采用变量的记录的话，在维护二者一致性方面
//可能就需要加锁的维护成本了，而且计算中都是位移运算也是非常高效的
private&nbsp;final&nbsp;AtomicInteger&nbsp;ctl&nbsp;=&nbsp;new&nbsp;AtomicInteger(ctlOf(RUNNING,&nbsp;0));
//线程池的大小由ctl低29位表示，现成状态由ctl高3位表示
private&nbsp;static&nbsp;final&nbsp;int&nbsp;COUNT_BITS&nbsp;=&nbsp;Integer.SIZE -&nbsp;3;
private&nbsp;static&nbsp;final&nbsp;int&nbsp;CAPACITY&nbsp; &nbsp;=&nbsp;(1&nbsp;&lt;&lt; COUNT_BITS) -&nbsp;1;
// 线程池的状态通过简单的位移就能计算出来，状态只能从低到高流转，不能逆向
private&nbsp;static&nbsp;final&nbsp;int&nbsp;RUNNING&nbsp; &nbsp;&nbsp;=&nbsp;-1&nbsp;&lt;&lt; COUNT_BITS;
private&nbsp;static&nbsp;final&nbsp;int&nbsp;SHUTDOWN&nbsp; &nbsp;=&nbsp;&nbsp;0&nbsp;&lt;&lt; COUNT_BITS;
private&nbsp;static&nbsp;final&nbsp;int&nbsp;STOP&nbsp; &nbsp; &nbsp; &nbsp;=&nbsp;&nbsp;1&nbsp;&lt;&lt; COUNT_BITS;
private&nbsp;static&nbsp;final&nbsp;int&nbsp;TIDYING&nbsp; &nbsp;&nbsp;=&nbsp;&nbsp;2&nbsp;&lt;&lt; COUNT_BITS;
private&nbsp;static&nbsp;final&nbsp;int&nbsp;TERMINATED&nbsp;=&nbsp;&nbsp;3&nbsp;&lt;&lt; COUNT_BITS;
// 这里是获取线程状态以及获取线程数量的简单高效的位移方法
private&nbsp;static&nbsp;int&nbsp;runStateOf(int&nbsp;c)&nbsp; &nbsp; &nbsp;{&nbsp;return&nbsp;c &amp; ~CAPACITY; }
private&nbsp;static&nbsp;int&nbsp;workerCountOf(int&nbsp;c)&nbsp; {&nbsp;return&nbsp;c &amp; CAPACITY; }
private&nbsp;static&nbsp;int&nbsp;ctlOf(int&nbsp;rs,&nbsp;int&nbsp;wc)&nbsp;{&nbsp;return&nbsp;rs | wc; }</code></pre>
<p>接下来结合源码详细介绍下线程池的5种状态以及分别有什么不同的表现行为？</p>
<pre><code>先说下结论：
RUNNING&nbsp; &nbsp; &nbsp;这个就是线程池运行中状态，我们可以添加任务也可以处理阻塞队列任务
SHUTDOWN &nbsp; 不能添加新的任务，但是会将阻塞队列中任务执行完毕
STOP &nbsp; &nbsp; &nbsp; 不能添加新的任务，执行中的线程也会被打断，也不会处理阻塞队列的任务
TIDYING &nbsp; &nbsp;所有线程都被终止，并且workCount=0时会被置为的状态
TERMINATED &nbsp; 调用完钩子方法terminated()被置为的状态&nbsp;</code></pre>
<h1>shutdown状态源码分析：</h1>
<pre><code>&nbsp;
&nbsp;//线程池关闭
&nbsp;public&nbsp;void&nbsp;shutdown()&nbsp;{
&nbsp; &nbsp;&nbsp;final&nbsp;ReentrantLock&nbsp;mainLock&nbsp;=&nbsp;this.mainLock;
&nbsp; &nbsp; mainLock.lock();
&nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; checkShutdownAccess();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//循环cas设置线程池状态，直到成功或状态已经state&gt;=SHUTDOWN
&nbsp; &nbsp; &nbsp; &nbsp; advanceRunState(SHUTDOWN);
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//这个是真正得出结论的地方
&nbsp; &nbsp; &nbsp; &nbsp; interruptIdleWorkers();
&nbsp; &nbsp; &nbsp; &nbsp; onShutdown();&nbsp;// hook for ScheduledThreadPoolExecutor
&nbsp; &nbsp; }&nbsp;finally&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; mainLock.unlock();
&nbsp; &nbsp; }
&nbsp; &nbsp; tryTerminate();
}
private&nbsp;void&nbsp;interruptIdleWorkers()&nbsp;{
&nbsp; &nbsp; interruptIdleWorkers(false);
}
//打断空闲的线程，如何判断线程是否空闲还是运行？
private&nbsp;void&nbsp;interruptIdleWorkers(boolean&nbsp;onlyOne)&nbsp;{
&nbsp; &nbsp;&nbsp;final&nbsp;ReentrantLock&nbsp;mainLock&nbsp;=&nbsp;this.mainLock;
&nbsp; &nbsp; mainLock.lock();
&nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;for&nbsp;(Worker w : workers) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;Thread&nbsp;t&nbsp;=&nbsp;w.thread;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//worker的线程没有被打断过，并且能获取到worker的aqs独占锁
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(!t.isInterrupted() &amp;&amp; w.tryLock()) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//打断当前线程，如果线程在阻塞队列中阻塞，此时会被中断
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; t.interrupt();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;catch&nbsp;(SecurityException ignore) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;finally&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; w.unlock();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(onlyOne)
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;break;
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; }&nbsp;finally&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; mainLock.unlock();
&nbsp; &nbsp; }
}
</code></pre>
<h1>STOP状态分析</h1>
<pre><code>//循环cas修改线程池状态为stop。打断所有线程，取出阻塞队列的所有任务
public&nbsp;List&lt;Runnable&gt;&nbsp;shutdownNow()&nbsp;{
&nbsp; &nbsp; List&lt;Runnable&gt; tasks;
&nbsp; &nbsp; final ReentrantLock mainLock =&nbsp;this.mainLock;
&nbsp; &nbsp; mainLock.lock();
&nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//检查线程的权限
&nbsp; &nbsp; &nbsp; &nbsp; checkShutdownAccess();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//将状态case为stop
&nbsp; &nbsp; &nbsp; &nbsp; advanceRunState(STOP);
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//打断所有worker不管是不是正在执行任务
&nbsp; &nbsp; &nbsp; &nbsp; interruptWorkers();
&nbsp; &nbsp; &nbsp; &nbsp; tasks = drainQueue();
&nbsp; &nbsp; }&nbsp;finally&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; mainLock.unlock();
&nbsp; &nbsp; }
&nbsp; &nbsp; tryTerminate();
&nbsp; &nbsp;&nbsp;return&nbsp;tasks;
}
//这里获取锁之后。打断了所有的线程
private&nbsp;void&nbsp;interruptWorkers()&nbsp;{
&nbsp; &nbsp; final ReentrantLock mainLock =&nbsp;this.mainLock;
&nbsp; &nbsp; mainLock.lock();
&nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;for&nbsp;(Worker w : workers)
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; w.interruptIfStarted();
&nbsp; &nbsp; }&nbsp;finally&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; mainLock.unlock();
&nbsp; &nbsp; }
}</code></pre>
<h1>TIDYING、TERMINATED&nbsp;状态分析</h1>
<pre><code>//这个方法在每个线程退出时都会进行调用，如果是运行中、或者状态大于等于TIDYING或者shutdown但是队列不为空都
//直接返回，如果不满足以上条件，并且线程数不为0的话，打断一个空闲线程
final&nbsp;void tryTerminate() {
&nbsp; &nbsp;&nbsp;for&nbsp;(;;) {
&nbsp; &nbsp; &nbsp; &nbsp; int c = ctl.get();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(isRunning(c) ||
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; runStateAtLeast(c, TIDYING) ||
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (runStateOf(c) == SHUTDOWN &amp;&amp; ! workQueue.isEmpty()))
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;return;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(workerCountOf(c) !=&nbsp;0) {&nbsp;// Eligible to terminate
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; interruptIdleWorkers(ONLY_ONE);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;return;
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//此时到这里，状态要么为STOP。要么是shutdown并且队列为空了
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 获取一个锁，尝试cas修改状态为TIDYING
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//调用terminated()的钩子方法，
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//修改线程池为终态TERMINATED，并且唤醒阻塞在termination队列上的线程
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;final&nbsp;ReentrantLock mainLock =&nbsp;this.mainLock;
&nbsp; &nbsp; &nbsp; &nbsp; mainLock.lock();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(ctl.compareAndSet(c, ctlOf(TIDYING,&nbsp;0))) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; terminated();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;finally&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ctl.set(ctlOf(TERMINATED,&nbsp;0));
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; termination.signalAll();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;return;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;finally&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; mainLock.unlock();
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// else retry on failed CAS
&nbsp; &nbsp; }
}</code></pre>
<h1>四、JDK内置线程池的问题</h1>
<p>java.util.concurrent.Executors工厂类提供了一些静态方法，方便我们快速创建几种预设配置的线程池：</p>
<ul>
<li>Executors.newFixedThreadPool(int nThreads)：
<ul>
<li>创建一个固定大小的线程池。corePoolSize和maximumPoolSize都等于nThreads。</li>
<li>keepAliveTime为0L（因为线程数不会超过corePoolSize，所以此参数无效，除非allowCoreThreadTimeOut为true）。</li>
<li>使用无界的LinkedBlockingQueue作为工作队列。</li>
<li><strong>问题</strong>：由于使用无界队列，当任务提交速度远大于处理速度时，队列会持续增长，可能导致内存溢出（OOM）。此时maximumPoolSize参数实际上是无效的，线程数永远不会超过nThreads。</li>
</ul> </li>
</ul>
<ul>
<li>Executors.newSingleThreadExecutor()：
<ul>
<li>创建一个只有一个工作线程的线程池。corePoolSize和maximumPoolSize都为1。</li>
<li>同样使用<strong>无界</strong>的LinkedBlockingQueue。</li>
<li>保证所有任务按照提交顺序（FIFO）执行。</li>
<li><strong>问题</strong>：与newFixedThreadPool类似，无界队列可能导致OOM。</li>
</ul> </li>
</ul>
<ul>
<li>Executors.newCachedThreadPool()：
<ul>
<li>创建一个可缓存的线程池。</li>
<li>corePoolSize为0。</li>
<li>maximumPoolSize为Integer.MAX_VALUE (几乎是无界的)。</li>
<li>keepAliveTime为60秒。</li>
<li>使用SynchronousQueue作为工作队列。这种队列不存储元素，任务提交后必须有空闲线程立即接收，否则会创建新线程（如果未达到maximumPoolSize）。</li>
<li><strong>问题</strong>：如果任务提交速度过快，会创建大量线程（理论上可达Integer.MAX_VALUE个），可能耗尽系统资源，导致OOM以及频繁的上下文切换。</li>
</ul> </li>
</ul>
<ul>
<li>Executors.newSingleThreadScheduledExecutor()、Executors.newScheduledThreadPool(int corePoolSize):
<ul>
<li>创建用于调度任务的线程池。</li>
<li>内部使用ScheduledThreadPoolExecutor实现，其任务队列是DelayedWorkQueue (一种特殊的PriorityQueue)。</li>
<li>newSingleThreadScheduledExecutor的corePoolSize为1，maximumPoolSize为Integer.MAX_VALUE（但由于队列是DelayedWorkQueue，通常不会无限增长线程，除非有大量同时到期的任务且处理不过来）。</li>
<li>newScheduledThreadPool可以指定corePoolSize。</li>
<li><strong>问题</strong>：虽然DelayedWorkQueue本身是无界的，但ScheduledThreadPoolExecutor在任务执行逻辑上与普通ThreadPoolExecutor有所不同。主要风险仍然是如果corePoolSize设置不当，且大量任务同时到期并执行缓慢，可能导致任务积压。</li>
</ul> </li>
</ul>
<div>
<img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-a0860059e7.jpg">
</div>
<p>某一线互联网Java开发手册</p>
<h1>五、线程池中的问题与最佳实践</h1>
<h1>5.1 invokeAll 超时机制无效？</h1>
<p>ExecutorService.invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit)方法会提交一组Callable任务，并等待所有任务完成，或者直到超时。如果超时发生，它会尝试取消（中断）所有尚未完成的任务，然后返回一个List&lt;Future&gt;。</p>
<p><strong>失效场景分析：</strong></p>
<ul>
<li>任务不响应中断（最常见）：任务内部捕获&nbsp;InterruptedException&nbsp;后静默处理，或执行不检查中断状态的阻塞操作（如循环计算）：</li>
</ul>
<pre><code>Callable&lt;String&gt; task = () -&gt; {
&nbsp; &nbsp;&nbsp;while&nbsp;(true) {
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//缺少此检查将导致超时失效
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(Thread.interrupted())&nbsp;break;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 耗时计算...
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;return&nbsp;"done";
};</code></pre>
<ul>
<li><strong>使用非响应中断的API</strong>：任务调用了不响应&nbsp;interrupt()&nbsp;的第三方库或JNI代码（如某些IO操作）</li>
</ul>
<pre><code>Callable&lt;Integer&gt; task&nbsp;=&nbsp;() -&gt; {
&nbsp; &nbsp;&nbsp;Files.copy(in, path);&nbsp;// 某些NIO操作不响应中断
&nbsp; &nbsp;&nbsp;return&nbsp;1;
};</code></pre>
<ul>
<li><strong>任务依赖外部资源阻塞</strong>：任务因外部资源（如数据库连接、网络请求）阻塞且未设置超时。</li>
</ul>
<pre><code>Callable&lt;Result&gt; task&nbsp;=&nbsp;() -&gt; {
&nbsp; &nbsp;&nbsp;//未设查询超时时间
&nbsp; &nbsp;&nbsp;return&nbsp;jdbcTemplate.query("SELECT * FROM large_table");&nbsp;
};</code></pre>
<ul>
<li><strong>线程池配置缺陷</strong>：核心线程数过大或队列无界，导致&nbsp;invokeAll&nbsp;超时前任务无法全部启动，任务堆积在队列，invokeAll&nbsp;超时后仍有大量任务未执行。</li>
</ul>
<pre><code>new&nbsp;ThreadPoolExecutor(
&nbsp; &nbsp;&nbsp;100,&nbsp;100,&nbsp;// 核心线程数过大
&nbsp; &nbsp; 0L,&nbsp;TimeUnit.MILLISECONDS,
&nbsp; &nbsp;&nbsp;new&nbsp;LinkedBlockingQueue&lt;&gt;()&nbsp;// 无界队列
);</code></pre>
<p><strong>invokeAll超时失效demo:</strong></p>
<pre><code>import&nbsp;java.util.*;
import&nbsp;java.util.concurrent.*;
public&nbsp;class&nbsp;InvokeAllTimeoutDemo&nbsp;{
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;// 模拟耗时任务（可配置是否响应中断）
&nbsp; &nbsp;&nbsp;static&nbsp;class&nbsp;Task&nbsp;implements&nbsp;Callable&lt;String&gt; {
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;private&nbsp;final&nbsp;int&nbsp;id;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;private&nbsp;final&nbsp;long&nbsp;durationMs;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;private&nbsp;final&nbsp;boolean&nbsp;respectInterrupt;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; Task(int&nbsp;id,&nbsp;long&nbsp;durationMs,&nbsp;boolean&nbsp;respectInterrupt) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;this.id = id;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;this.durationMs = durationMs;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;this.respectInterrupt = respectInterrupt;
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;@Override
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;public&nbsp;String&nbsp;call()&nbsp;throws&nbsp;Exception {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.out.printf("Task %d started%n", id);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;long&nbsp;start&nbsp;=&nbsp;System.currentTimeMillis();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 模拟工作（检查中断状态）
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;while&nbsp;(System.currentTimeMillis() - start &lt; durationMs) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(respectInterrupt &amp;&amp; Thread.interrupted()) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;throw&nbsp;new&nbsp;InterruptedException("Task "&nbsp;+ id +&nbsp;" interrupted");
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 不响应中断的任务会继续执行
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.out.printf("Task %d completed%n", id);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;return&nbsp;"Result-"&nbsp;+ id;
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;public&nbsp;static&nbsp;void&nbsp;main(String[] args)&nbsp;throws&nbsp;InterruptedException {
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;ExecutorService&nbsp;executor&nbsp;=&nbsp;Executors.newFixedThreadPool(2);
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; List&lt;Callable&lt;String&gt;&gt; tasks = Arrays.asList(
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;new&nbsp;Task(1,&nbsp;2000,&nbsp;true), &nbsp;&nbsp;// 2秒，响应中断
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;new&nbsp;Task(2,&nbsp;10000,&nbsp;false) &nbsp;// 10秒，不响应中断
&nbsp; &nbsp; &nbsp; &nbsp; );
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; System.out.println("Invoking with 3s timeout...");
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//设置3秒超时
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; List&lt;Future&lt;String&gt;&gt; futures = executor.invokeAll(tasks,&nbsp;3, TimeUnit.SECONDS);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;for&nbsp;(Future&lt;String&gt; f : futures) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 明确处理取消状态
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(f.isCancelled()) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.out.println("Task was cancelled"); &nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;else&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.out.println("Result: "&nbsp;+ f.get(100, TimeUnit.MILLISECONDS));
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;catch&nbsp;(TimeoutException | ExecutionException e) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.out.println("Task failed: "&nbsp;+ e.getCause());
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;finally&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; executor.shutdownNow();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.out.println("Executor shutdown");
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; }
}</code></pre>
<p>当我们使用invokeAll(tasks, timeout)&nbsp;提交多个任务时，如果出现某个任务对中断不响应或者响应不及时，那我们即使设置了超时时间，不响应中断的任务2仍在后台运行（即使调用了&nbsp;shutdownNow()）</p>
<h1>5.2 submit()的异常消失了？</h1>
<p>使用ExecutorService.submit()提交任务时，任务执行过程中如果抛出未捕获的异常（无论是受检异常还是运行时异常），这个异常会被Future的包装类如FutureTask重写的run()方法捕获并封装在返回的Future包装对象的成员变量中。</p>
<ul>
<li><strong>不显示调用</strong>Future.get()，该异常我们就无法感知，好像没有发生过一样。线程池的工作线程本身通常会有一个默认的未捕获异常处理器，可能会打印堆栈到控制台，但你的主业务逻辑不会知道。</li>
<li><strong>显示调用</strong>Future.get()，抛出声明式的ExecutionException，其cause属性才是原始的任务异常。</li>
<li>如果调用Future.get(long timeout, TimeUnit unit)超时，向外抛出声明式的TimeoutException。此时任务可能仍在后台执行，可能错过了内部的异常。</li>
</ul>
<p><strong>submit()异常消失demo:</strong></p>
<pre><code>public&nbsp;class&nbsp;ThreadPoolExceptionDemo&nbsp;{
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;public&nbsp;static&nbsp;void&nbsp;main(String[] args)&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 创建单线程线程池（便于观察异常）
&nbsp; &nbsp; &nbsp; &nbsp; ExecutorService executor = Executors.newSingleThreadExecutor();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 场景1：Callable抛出异常（通过Future.get()捕获）
&nbsp; &nbsp; &nbsp; &nbsp; Future&lt;String&gt; future1 = executor.submit(() -&gt; {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.out.println("[Callable] 开始执行");
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Thread.sleep(100);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;throw&nbsp;new&nbsp;RuntimeException("Callable故意抛出的异常");
&nbsp; &nbsp; &nbsp; &nbsp; });
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.out.println("Callable结果: "&nbsp;+ future1.get());
&nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;catch&nbsp;(ExecutionException e) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.err.println("捕获到Callable异常: "&nbsp;+ e.getCause().getMessage());
&nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;catch&nbsp;(InterruptedException e) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Thread.currentThread().interrupt();
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 场景2：Runnable抛出异常（同样通过Future.get()捕获）
&nbsp; &nbsp; &nbsp; &nbsp; Future&lt;?&gt; future2 = executor.submit(() -&gt; {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.out.println("[Runnable] 开始执行");
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;throw&nbsp;new&nbsp;IllegalArgumentException("Runnable故意抛出的异常");
&nbsp; &nbsp; &nbsp; &nbsp; });
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; future2.get();&nbsp;// Runnable成功时返回null
&nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;catch&nbsp;(ExecutionException e) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.err.println("捕获到Runnable异常: "&nbsp;+ e.getCause().getMessage());
&nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;catch&nbsp;(InterruptedException e) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Thread.currentThread().interrupt();
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 场景3：未处理的任务异常（需设置异常处理器）
&nbsp; &nbsp; &nbsp; &nbsp; executor.submit(() -&gt; {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.out.println("[未捕获的任务] 开始执行");
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;throw&nbsp;new&nbsp;IllegalStateException("这个异常会被默认处理器处理");
&nbsp; &nbsp; &nbsp; &nbsp; });
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; executor.shutdown();
&nbsp; &nbsp; }
}</code></pre>
<h1>5.3 异常处理实践</h1>
<div>
<img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-851f74dab6.jpg">
</div>
<ul>
<li><strong>Callable/Runnable catch处理异常：</strong>
<ul>
<li><strong>不要捕获Throwable或Exception然后静默处理（只打日志）</strong>。如果确实需要捕获，请考虑是否应该重新抛出（包装成业务允许的受检异常或运行时异常）。</li>
<li><strong>禁止静默处理&nbsp;</strong>InterruptedException：</li>
<li>在JDK的JUC底层源码中，我们可以看到很多声明了InterruptedException的方法，基本上都是对这类方法catch异常，要么继续往外抛出，或者处理完相关资源后，重置中断状态，<strong>绝对不要静默处理。</strong></li>
<li>如果方法没有声明InterruptedException如Runnable.run()，在catch&nbsp;InterruptedException后最好调用Thread.currentThread().interrupt()来恢复中断标记。</li>
<li><strong>正确处理中断</strong>：callable在耗时的loop任务处理中，如果出现了中断异常，因为Java代码中中断只是一种协作方式，其并没真的终止线程，所以一般都是需要我们进行一个中断标志的传递，如线程池中的shutdownNow()就依赖次机制处理。</li>
</ul> </li>
</ul>
<ul>
<li><strong>submit()执行的任务，谨慎处理Future：</strong>
<ul>
<li>使用带过期时间的future.get(long timeOut)获取结果，并要对该方法进行try cache防止其他异常抛出。</li>
<li>多个任务并行处理时，如果有下个请求依赖上个请求，务必使用get()让主线程等待这一结果执行完成后，流转到下一个异步任务。</li>
</ul> </li>
</ul>
<ul>
<li><strong>实现线程Thread的UncaughtExceptionHandler属性</strong>，在自定义的TheadFactory中通过set方法赋值：execute()方法执行时，对于没有捕获的异常使用线程组的兜底统一处理机制。</li>
</ul>
<pre><code>//自定义当前线程组创建线程的统一异常处理，类似于controller的统一异常处理机制
ThreadFactory&nbsp;myThreadFactory&nbsp;=&nbsp;new&nbsp;ThreadFactory() {
&nbsp; &nbsp;&nbsp;private&nbsp;final&nbsp;AtomicInteger&nbsp;atomicInteger&nbsp;=&nbsp;new&nbsp;AtomicInteger(0);
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;private&nbsp;final&nbsp;String&nbsp;threadNamePrefix&nbsp;=&nbsp;"myThreadFactory-";
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;@Override
&nbsp; &nbsp;&nbsp;public&nbsp;Thread&nbsp;newThread(Runnable r)&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;Thread&nbsp;t&nbsp;=&nbsp;&nbsp;new&nbsp;Thread(r,threadNamePrefix + atomicInteger.getAndIncrement());
&nbsp; &nbsp; &nbsp; &nbsp; t.setUncaughtExceptionHandler((thread, throwable) -&gt; {
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//异常的统一处理，日志打印、兜底处理、监控、资源释放等
&nbsp; &nbsp; &nbsp; &nbsp; System.err.println("线程["&nbsp;+ thread.getName() +&nbsp;"]异常: "&nbsp;+ throwable);});
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;return&nbsp;t;
&nbsp; &nbsp; }
};
//构造方法时使用自定义的线程工厂
ExecutorService&nbsp;executor&nbsp;=&nbsp;new&nbsp;ThreadPoolExecutor(
&nbsp; &nbsp; corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,
&nbsp; &nbsp; threadFactory,
&nbsp; &nbsp; handler
);</code></pre>
<ul>
<li><strong>使用自定义线程池时建议重写钩子方法afterExecute(Runnable r, Throwable t)</strong>：这个hook方法是用来解决当前任务线程发生的异常，默认是空实现，我们可以重写他，比如进行兜底的线程继续执行，打印日志记录，以及同步失败使用兜底异步处理等等方式。还要注意释放应用中的资源，比如文件锁的占用等，最好手动释放掉，避免底层操作系统线程对这类资源释放失败导致长期占用，最后只能重启Java进程的尴尬地步。</li>
</ul>
<pre><code>public&nbsp;class&nbsp;MyThreadPoolExecutor&nbsp;extends&nbsp;ThreadPoolExecutor&nbsp;{
&nbsp; &nbsp;&nbsp;public&nbsp;MyThreadPoolExecutor(int&nbsp;corePoolSize,&nbsp;int&nbsp;maximumPoolSize,&nbsp;long&nbsp;keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue)&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue);
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;@Override
&nbsp; &nbsp;&nbsp;protected&nbsp;void&nbsp;afterExecute(Runnable r, Throwable t)&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;//需要特别注意任务是否为submit提交，如果是execute提交的任务，那这里很直接的知道任务是否发生异常以及后续去怎么处理
&nbsp; &nbsp; &nbsp; &nbsp;if(r&nbsp;instanceof&nbsp;Future){
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;if(((Future&lt;?&gt;) r).isDone() || ((Future&lt;?&gt;) r).isCancelled()){
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;//继续使用主线程完成任务,一般不建议，最好使用兜底方式：例如异步发消息，由后续的消费组统一处理异常的任务
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;}
&nbsp; &nbsp; &nbsp; &nbsp;}else&nbsp;if( t !=&nbsp;null){
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//execute异常处理
&nbsp; &nbsp; &nbsp; &nbsp;}
&nbsp; &nbsp; }
}
//FutureTask 把run方法进行了重写，并且catch住了异常，所以说afterExecute的t 如果是submit提交的方式
//那么t基本上就是null
public&nbsp;void&nbsp;run()&nbsp;{
&nbsp; &nbsp;&nbsp;//....
&nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; Callable&lt;V&gt; c = callable;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(c !=&nbsp;null&nbsp;&amp;&amp; state == NEW) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; V result;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;boolean&nbsp;ran;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; result = c.call();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ran =&nbsp;true;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;catch&nbsp;(Throwable ex) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; result =&nbsp;null;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ran =&nbsp;false;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; setException(ex);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(ran)
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; set(result);
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; }&nbsp;finally&nbsp;{
&nbsp; &nbsp; &nbsp;//...
}</code></pre>
<p><strong>afterExecute可以借鉴的示例：</strong></p>
<pre><code>import&nbsp;java.util.concurrent.*;
import&nbsp;java.util.concurrent.atomic.*;
import&nbsp;org.slf4j.*;
public&nbsp;class&nbsp;RobustThreadPool&nbsp;extends&nbsp;ThreadPoolExecutor&nbsp;{
&nbsp; &nbsp;&nbsp;private&nbsp;static&nbsp;final&nbsp;Logger&nbsp;logger&nbsp;=&nbsp;LoggerFactory.getLogger(RobustThreadPool.class);
&nbsp; &nbsp;&nbsp;private&nbsp;final&nbsp;AtomicLong&nbsp;failureCounter&nbsp;=&nbsp;new&nbsp;AtomicLong();
&nbsp; &nbsp;&nbsp;private&nbsp;final&nbsp;RetryPolicy retryPolicy;&nbsp;// 重试策略
&nbsp; &nbsp;&nbsp;private&nbsp;final&nbsp;ThreadLocal&lt;Long&gt; startTime =&nbsp;new&nbsp;ThreadLocal&lt;&gt;();
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;public&nbsp;RobustThreadPool(int&nbsp;corePoolSize,&nbsp;int&nbsp;maxPoolSize,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; BlockingQueue&lt;Runnable&gt; workQueue,
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; RetryPolicy retryPolicy) {
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;super(corePoolSize, maxPoolSize,&nbsp;60L, TimeUnit.SECONDS, workQueue);
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;this.retryPolicy = retryPolicy;
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;@Override
&nbsp; &nbsp;&nbsp;protected&nbsp;void&nbsp;beforeExecute(Thread t, Runnable r)&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; logger.debug("开始执行任务: {}", r);
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;@Override
&nbsp; &nbsp;&nbsp;protected&nbsp;void&nbsp;afterExecute(Runnable r, Throwable t)&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 1. 异常分类处理
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;if(r&nbsp;instanceof&nbsp;Future){
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;if(((Future&lt;?&gt;) r).isDone()){
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;//错误记录以及异常处理
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; failureCounter.incrementAndGet();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; handleFailure(r, t, costTime);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;}
&nbsp; &nbsp; &nbsp; &nbsp;}else&nbsp;if( t !=&nbsp;null){
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//execute异常处理
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; failureCounter.incrementAndGet();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; handleFailure(r, t, costTime);
&nbsp; &nbsp; &nbsp; &nbsp;}
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 2. 资源清理
&nbsp; &nbsp; &nbsp; &nbsp; cleanThreadLocals();
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;private&nbsp;void&nbsp;handleFailure(Runnable r, Throwable t)&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 1. 异常类型识别
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(t&nbsp;instanceof&nbsp;OutOfMemoryError) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; logger.error("JVM内存不足，终止任务: {}", t.getMessage());
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.exit(1);&nbsp;// 严重错误直接终止
&nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 2. 可重试异常处理
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;else&nbsp;if&nbsp;(isRetryable(t)) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;int&nbsp;retryCount&nbsp;=&nbsp;retryPolicy.getCurrentRetryCount(r);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(retryCount &lt; retryPolicy.getMaxRetries()) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; logger.warn("任务第{}次失败，准备重试...",&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; retryCount +&nbsp;1, t);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; retryPolicy.retry(r,&nbsp;this);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;else&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; logger.error("任务超过最大重试次数({})，转入死信队列",&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; retryPolicy.getMaxRetries(), t);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; DeadLetterQueue.add(r, t);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 3. 不可重试异常
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;else&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; logger.error("不可恢复任务失败", t);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Metrics.recordFailure(t.getClass());&nbsp;// 上报监控
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;private&nbsp;boolean&nbsp;isRetryable(Throwable t)&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;return&nbsp;t&nbsp;instanceof&nbsp;IOException ||&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;t&nbsp;instanceof&nbsp;TimeoutException ||
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;(t.getCause() !=&nbsp;null&nbsp;&amp;&amp; isRetryable(t.getCause()));
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;private&nbsp;void&nbsp;cleanThreadLocals()&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 清理可能的内存泄漏
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ThreadLocal&lt;?&gt;[] holders = {&nbsp;/* 其他ThreadLocal */};
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;for&nbsp;(ThreadLocal&lt;?&gt; holder : holders) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; holder.remove();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;catch&nbsp;(Exception e) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; logger.warn("清理ThreadLocal失败", e);
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;// 重试策略嵌套类
&nbsp; &nbsp;&nbsp;public&nbsp;static&nbsp;class&nbsp;RetryPolicy&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;private&nbsp;final&nbsp;int&nbsp;maxRetries;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;private&nbsp;final&nbsp;long&nbsp;retryDelayMs;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;private&nbsp;final&nbsp;Map&lt;Runnable, AtomicInteger&gt; retryMap =&nbsp;new&nbsp;ConcurrentHashMap&lt;&gt;();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;public&nbsp;RetryPolicy(int&nbsp;maxRetries,&nbsp;long&nbsp;retryDelayMs)&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;this.maxRetries = maxRetries;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;this.retryDelayMs = retryDelayMs;
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;public&nbsp;void&nbsp;retry(Runnable task, Executor executor)&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; retryMap.computeIfAbsent(task, k -&gt;&nbsp;new&nbsp;AtomicInteger()).incrementAndGet();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(retryDelayMs &gt;&nbsp;0) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; executor.execute(() -&gt; {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Thread.sleep(retryDelayMs);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;catch&nbsp;(InterruptedException ignored) {}
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; executor.execute(task);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; });
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;else&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; executor.execute(task);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;public&nbsp;int&nbsp;getCurrentRetryCount(Runnable task)&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;return&nbsp;retryMap.getOrDefault(task,&nbsp;new&nbsp;AtomicInteger()).get();
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;public&nbsp;int&nbsp;getMaxRetries()&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;return&nbsp;maxRetries;
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; }
}</code></pre>
<p><strong>异常处理小结</strong>：要特别注意使用future.get()方法时，我们一定要注意设置超时时间，防止主线程无限期的阻塞避免边缘的业务查询影响了主业务造成得不偿失的效果，另外我们需要注意一个点就是submit()方法的提交任务时，afterExecute(Runnable r, Throwable t)中的t恒为null，如果是execute方法提交的任务，那么就是直接获取的任务执行的异常，对于submit提交的任务异常其被封装到了Futrure&nbsp;包装对象中，一般需要我们再次判断任务时执行完毕还是异常或被取消了，如果发生了异常，Future.get()会抛出封装的ExecutionException异常，当然还可能是取消异常以及中断异常。invokeAll和invokeAny我们需要对返回的Future结果检查可能抛出的异常，对于callable&nbsp;前面一再强调了要对InterruptedException不要静默处理，因为线程的中断标记只是一个协作方式，他并没有停止当前线程的运行，我们需要根据自身的场景对发生的中断进行快速响应以及传递中断标志。</p>
<h1>5.4 拒绝策略实践</h1>
<p>先带大家回顾一下策略是如何触发执行的流程：</p>
<pre><code>//添加任务，当不满足条件时会执行拒绝方法reject
public&nbsp;void&nbsp;execute(Runnable command)&nbsp;{
&nbsp; &nbsp;//...
&nbsp; &nbsp;&nbsp;if&nbsp;(isRunning(c) &amp;&amp; workQueue.offer(command)) {
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;int&nbsp;recheck = ctl.get();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(! isRunning(recheck) &amp;&amp;&nbsp;remove(command))
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; reject(command);
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;else&nbsp;if&nbsp;(workerCountOf(recheck) ==&nbsp;0)
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; addWorker(null,&nbsp;false);
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;else&nbsp;if&nbsp;(!addWorker(command,&nbsp;false))
&nbsp; &nbsp; &nbsp; &nbsp; reject(command);
}
//这里就是拒绝的入口。handler是有构造方法传入
final&nbsp;void&nbsp;reject(Runnable command)&nbsp;{
&nbsp; &nbsp; handler.rejectedExecution(command,&nbsp;this);
}
public&nbsp;ThreadPoolExecutor(int&nbsp;corePoolSize,
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;int&nbsp;maximumPoolSize,
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;long&nbsp;keepAliveTime,
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; TimeUnit unit,
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; BlockingQueue&lt;Runnable&gt; workQueue,
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ThreadFactory threadFactory,
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; RejectedExecutionHandler handler) {
&nbsp; &nbsp;&nbsp;//....
&nbsp; &nbsp;&nbsp;//指定拒绝策略
&nbsp; &nbsp;&nbsp;this.handler = handler;
}</code></pre>
<p><strong>AbortPolicy</strong>：默认的拒绝策略，简单粗暴，当execute中添加woker失败时，直接在当前线程抛出异常。</p>
<pre><code>public&nbsp;static&nbsp;class&nbsp;AbortPolicy&nbsp;implements&nbsp;RejectedExecutionHandler&nbsp;{
&nbsp; &nbsp; &nbsp;//直接抛出RejectedExecutionException
&nbsp; &nbsp;&nbsp;public&nbsp;void&nbsp;rejectedExecution(Runnable r, ThreadPoolExecutor e) {
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;throw&nbsp;new&nbsp;RejectedExecutionException("Task "&nbsp;+ r.toString() +
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;" rejected from "&nbsp;+
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;e.toString());
&nbsp; &nbsp; }
}</code></pre>
<p><strong>优点</strong>：快速失败，立即暴露系统过载问题、避免任务静默丢失，便于监控系统捕获</p>
<p><strong>缺点</strong>：需要调用方显式处理异常，增加代码复杂度，可能中断主业务流程</p>
<p><strong>适用场景</strong>：适用于那些对任务丢失非常敏感，配合熔断机制使用的快速失败场景</p>
<p><strong>CallerRunsPolicy</strong>：提交任务的线程，直接执行任务</p>
<pre><code>public&nbsp;static&nbsp;class&nbsp;CallerRunsPolicy&nbsp;implements&nbsp;RejectedExecutionHandler&nbsp;{
&nbsp; &nbsp;&nbsp;//直接在提交任务的线程中执行任务
&nbsp; &nbsp;&nbsp;public&nbsp;void&nbsp;rejectedExecution(Runnable r, ThreadPoolExecutor e) {
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(!e.isShutdown()) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; r.run();
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; }
}</code></pre>
<p><strong>优点</strong>：任务都会被执行，不会丢任务，并且由于主线程执行任务，天然的流量控制，避免了大量的任务进入线程池。</p>
<p><strong>缺点</strong>：调用线程可能被阻塞，导致上游服务雪崩。不适合高并发场景（可能拖垮整个调用链）。</p>
<p><strong>适用场景</strong>：适用于处理能力不高，并且资源过载能够平滑过渡，同时不丢失任务的场景。如：低并发、高可靠性的后台任务（如日志归档）、允许同步执行的批处理系统。</p>
<p><strong>DiscardPolicy</strong>：直接丢弃被拒绝的任务，不做任何通知。</p>
<pre><code>public&nbsp;static&nbsp;class&nbsp;DiscardPolicy&nbsp;implements&nbsp;RejectedExecutionHandler&nbsp;{
&nbsp; &nbsp;//空实现
&nbsp; &nbsp;&nbsp;public&nbsp;void&nbsp;rejectedExecution(Runnable r, ThreadPoolExecutor e) {
&nbsp; &nbsp; }
}</code></pre>
<p><strong>优点</strong>：实现简单，无额外性能开销。避免异常传播影响主流程</p>
<p><strong>缺点</strong>：数据静默丢失，可能会掩盖系统容量问题</p>
<p><strong>适用场景</strong>：边缘业务的监控上报数据，统计类的uv、pv统计任务</p>
<p>DiscardOldestPolicy：丢弃队列中最旧的任务，然后重试提交当前任务。</p>
<pre><code>public&nbsp;static&nbsp;class&nbsp;DiscardOldestPolicy&nbsp;implements&nbsp;RejectedExecutionHandler&nbsp;{
&nbsp; &nbsp;&nbsp;//丢弃队列中最旧的任务，重试当前任务
&nbsp; &nbsp;&nbsp;public&nbsp;void&nbsp;rejectedExecution(Runnable r, ThreadPoolExecutor e) {
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(!e.isShutdown()) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; e.getQueue().poll();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; e.execute(r);
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; }
}</code></pre>
<p><strong>优点</strong>：优先保证新任务执行，避免队列堆积导致内存溢出。</p>
<p><strong>缺点</strong>：可能丢失关键旧任务、任务执行顺序无法保证。</p>
<p><strong>适用场景</strong>：适用于可容忍部分数据丢失，并且实时性要求高于历史数据的场景，比如：行情推送。</p>
<p>通过上线的介绍，我们可以看到JDK内置策略基本上只使用于简单处理的场景，在生产实践中一般推荐我们自定义拒绝策略，进行相关的业务处理。</p>
<p><strong>1. 自定义RejectedExecutionHandler</strong>：</p>
<pre><code>/**
&nbsp;* 带监控统计的拒绝策略处理器
&nbsp;*/
public&nbsp;class&nbsp;MetricsRejectedExecutionHandler&nbsp;implements&nbsp;RejectedExecutionHandler&nbsp;{
&nbsp; &nbsp;&nbsp;private&nbsp;static&nbsp;final&nbsp;org.slf4j.Logger&nbsp;logger&nbsp;=&nbsp;org.slf4j.LoggerFactory.getLogger(MetricsRejectedExecutionHandler.class);
&nbsp; &nbsp;&nbsp;// 统计被拒绝的任务数量
&nbsp; &nbsp;&nbsp;private&nbsp;final&nbsp;AtomicLong&nbsp;rejectedCount&nbsp;=&nbsp;new&nbsp;AtomicLong(0);
&nbsp; &nbsp;&nbsp;@Override
&nbsp; &nbsp;&nbsp;public&nbsp;void&nbsp;rejectedExecution(Runnable r, ThreadPoolExecutor executor)&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 1. 采集线程池关键指标
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;int&nbsp;poolSize&nbsp;=&nbsp;executor.getPoolSize();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;int&nbsp;activeThreads&nbsp;=&nbsp;executor.getActiveCount();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;int&nbsp;corePoolSize&nbsp;=&nbsp;executor.getCorePoolSize();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;int&nbsp;maxPoolSize&nbsp;=&nbsp;executor.getMaximumPoolSize();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;int&nbsp;queueSize&nbsp;=&nbsp;executor.getQueue().size();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;long&nbsp;completedTasks&nbsp;=&nbsp;executor.getCompletedTaskCount();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 2. 递增拒绝计数器
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;long&nbsp;totalRejected&nbsp;=&nbsp;rejectedCount.incrementAndGet();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 3. 输出警告日志（包含完整指标）
&nbsp; &nbsp; &nbsp; &nbsp; logger.warn("""
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;任务被拒绝执行！线程池状态:
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; |- 活跃线程数/当前线程数: {}/{}
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; |- 核心/最大线程数: {}/{}
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; |- 队列大小: {}
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; |- 已完成任务数: {}
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; |- 历史拒绝总数: {}
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; |- 被拒绝任务: {}
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; """,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; activeThreads, poolSize,
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; corePoolSize, maxPoolSize,
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; queueSize,
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; completedTasks,
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; totalRejected,
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; r.getClass().getName());
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 4. 可选：降级处理（如存入数据库等待重试）
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// fallbackToDatabase(r);
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 5. 抛出RejectedExecutionException（保持默认行为）
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;throw&nbsp;new&nbsp;RejectedExecutionException("Task "&nbsp;+ r.toString() +&nbsp;" rejected");
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;// 获取累计拒绝次数（用于监控）
&nbsp; &nbsp;&nbsp;public&nbsp;long&nbsp;getRejectedCount()&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;return&nbsp;rejectedCount.get();
&nbsp; &nbsp; }
}</code></pre>
<ul>
<li><strong>记录日志并告警</strong>：所有的异常处理中，最常见简单的方式无外乎，先记录个日志，然后有告警系统的进行相关的某书、某信以及短信等的告警信息推送，方便开发人员以及运维人员的及时发现问题并介入处理。</li>
<li><strong>兜底处理机制</strong>：一般常见的就是通过异步的方式提交到MQ，然后统一进行兜底处理。</li>
<li><strong>带超时和重试的拒绝</strong>：可以尝试等待一小段时间，或者重试几次提交，如果仍然失败，再执行最终的拒绝逻辑（如告警、持久化或抛异常）。</li>
<li><strong>动态调整策略</strong>：根据系统的负载或任务类型，动态的执行兜底策略机制，就如前面写的源码示例方式。</li>
</ul>
<p><strong>2. 根据自身业务场景选择合适的拒绝策略：</strong></p>
<ul>
<li><strong>核心业务，不容丢失</strong>：如果任务非常重要，不能丢失，可以考虑：
<ul>
<li>CallerRunsPolicy：调用线程承担任务执行压力，是否可支撑；</li>
<li>自定义策略：尝试持久化到MQ或DB，然后由专门的消费组补偿任务处理；</li>
<li>AbortPolicy：如果希望系统快速失败并由上层进行重试或熔断。</li>
<li>&nbsp;</li>
</ul> </li>
<li><strong>非核心业务，可容忍部分丢失</strong>：
<ul>
<li>DiscardOldestPolicy：新任务更重要时，如行情推送；</li>
<li>DiscardPolicy：边缘业务场景，比如一些pv统计等，丢失了无所谓；</li>
<li>及时的进行监控查看，了解任务的丢失情况。</li>
</ul> </li>
</ul>
<p><strong>3. 结合线程池参数综合考虑：</strong></p>
<ul>
<li>拒绝策略的选择也与线程池的队列类型（有界/无界）、队列容量、maximumPoolSize等参数密切相关。</li>
<li>如果使用无界队列LinkedBlockingQueue的无参构造，只有机器内存不够时才会进行拒绝策略，不过这种极端场景已经不是影响线程池本身，内存不够可能导致Java进程被操作系统直接kill可能。</li>
<li>如果使用有界队列，需要权衡队列的大小，核心场景甚至可以动态追踪阻塞队列大小，以及动态调整队列大小来保证核心业务的正常流转。</li>
</ul>
<ol>
<li><strong>充分测试和监控</strong>：无论选择哪种策略，都必须在压测环境中充分测试其行为，并在线上环境建立完善的监控体系，监控线程池的各项指标（活跃线程数、队列长度、任务完成数、任务拒绝数等）。当拒绝发生时，应有相应的告警通知。</li>
</ol>
<p><strong>拒绝策略小结</strong>：</p>
<p>策略的选择跟我们大多数的系统设计哲学是保持一致的，都是在应对不同的场景中，做出一定的trade off。最好的策略需要根据业务场景、系统容忍度、资源等方面的综合考量，<strong>一个黄金的实践原则</strong>：拒绝事件做好监控告警、根据业务SLA定义策略，是否可丢失，快速失败等，定期的进行压力测试，验证策略的有效性。</p>
<h1>5.5 池隔离实践</h1>
<p><strong>核心思想</strong>：根据任务的资源类型 、优先级和业务特性 ，划分多个独立的线程池，避免不同性质的任务相互干扰。</p>
<p><strong>1. 隔离维度</strong>：</p>
<ul>
<li><strong>资源类型</strong>：CPU密集型 vs &nbsp;I/O密集型任务</li>
<li><strong>执行时长</strong>：短时任务（毫秒级） vs 长时任务（分钟级）</li>
<li><strong>实时性要求</strong>：高实时性 vs 可延迟（最终一致即可）</li>
<li><strong>业务重要性</strong>：支付交易（高优先级） vs 日志清理（低优先级）</li>
<li><strong>是否依赖外部资源</strong>：例如，访问特定数据库、调用特定第三方API的任务可以归为一类。</li>
</ul>
<p><strong>2. 不同业务场景线程池独立使用</strong>：在不同的业务场景下，为自己的特定业务，创建独立的线程池。</p>
<ul>
<li><strong>线程命名</strong>：通过ThreadFactory为每个线程池及其线程设置有意义的名称，例如netty-io-compress-pool-%d，excel-export-pool-%d, 主要方便区别不同的业务场景以及问题排查。</li>
<li><strong>参数调优</strong>：不同的业务场景设置不同的参数。
<ul>
<li>corePoolSize, maximumPoolSize：CPU密集型的计算任务可以设置小点减少上下文的切换，I/O密集型可以较大，在io阻塞等待期间，多去处理其他任务。</li>
<li>阻塞队列blockQueue：选择合适的队列类型，以及设置合理的队列大小。</li>
<li>RejectedExecutionHandler：有内置的四种的策略以及自定义策略选择，一般建议做好日志、监控以及兜底的处理。</li>
<li>&nbsp;</li>
</ul> </li>
</ul>
<p><strong>3. 自定义Executor避免线程池共用</strong></p>
<pre><code>// 创建CPU密集型任务线程池（线程数=CPU核心数）
ExecutorService cpuIntensiveExecutor =&nbsp;new&nbsp;ThreadPoolExecutor(
&nbsp; &nbsp; Runtime.getRuntime().availableProcessors(),&nbsp;// 核心线程数=CPU核心数
&nbsp; &nbsp; Runtime.getRuntime().availableProcessors(),&nbsp;// 最大线程数=CPU核心数
&nbsp; &nbsp;&nbsp;30L, TimeUnit.SECONDS,
&nbsp; &nbsp;&nbsp;new&nbsp;LinkedBlockingQueue&lt;&gt;(500),
&nbsp; &nbsp;&nbsp;new&nbsp;ThreadFactoryBuilder()
&nbsp; &nbsp; &nbsp; &nbsp; .setNameFormat("cpu-pool-%d")
&nbsp; &nbsp; &nbsp; &nbsp; .setPriority(Thread.MAX_PRIORITY)&nbsp;// 提高优先级
&nbsp; &nbsp; &nbsp; &nbsp; .build(),
&nbsp; &nbsp;&nbsp;new&nbsp;ThreadPoolExecutor.AbortPolicy()&nbsp;// 直接拒绝
);
// 使用示例
CompletableFuture.supplyAsync(() -&gt; {
&nbsp; &nbsp;&nbsp;// 矩阵计算等CPU密集型任务
&nbsp; &nbsp;&nbsp;double[][] result = matrixMultiply(largeMatrixA, largeMatrixB);
&nbsp; &nbsp;&nbsp;return&nbsp;result;
}, cpuIntensiveExecutor)
.thenAccept(result -&gt; {
&nbsp; &nbsp; System.out.println("计算结果维度: "&nbsp;+ result.length +&nbsp;"x"&nbsp;+ result[0].length);
});</code></pre>
<p><strong>线程池隔离小结</strong>：</p>
<p>专池专用的本质是通过物理隔离实现：</p>
<ul>
<li>资源保障 ：关键业务独占线程资源</li>
<li>故障隔离 ：避免级联雪崩</li>
<li>性能优化 ：针对任务类型最大化吞吐量</li>
</ul>
<p>最终呈现的效果是像专业厨房的分区（切配区/炒菜区/面点区）一样，让每个线程池专注处理同类任务，提升整体效率和可靠性。</p>
<h1>六、总结</h1>
<p>线程池是Java并发编程的核心组件，通过复用线程减少资源开销，提升系统吞吐量。其核心设计包括线程复用机制 、任务队列和拒绝策略 ，通过ThreadPoolExecutor的参数（核心线程数、最大线程数、队列容量等）实现灵活的资源控制。线程池的生命周期由RUNNING、SHUTDOWN等状态管理，确保任务有序执行或终止。</p>
<p>内置线程池（如Executors.newCachedThreadPool）虽便捷，但存在内存溢出或无界队列堆积的风险，需谨慎选择。invokeAll的超时失效和submit提交任务的异常消失是常见陷阱需通过正确处理中断和检查Future.get()规避。</p>
<p>最佳实践包括：</p>
<ul>
<li>异常处理：通过afterExecute来对发生的异常进行兜底处理，任务细粒度的try catch或UncaughtExceptionH捕获异常处理防止线程崩溃退出；</li>
<li>拒绝策略：根据业务选择拒绝策略或自定义降级逻辑，生产级应用建议尽量自定义处理；</li>
<li>线程隔离 ：按任务类型（CPU/I/O）或优先级划分线程池，避免资源竞争。</li>
</ul>
<p>合理使用线程池能显著提升性能，但需结合业务场景精细调参，确保稳定性和可维护性，希望这篇文章能给大家带来一些生产实践上的指导，减少一些因为不熟悉线程池相关原理生产误用导致的一些问题。</p>
<h4>往期回顾</h4>
<p>1.&nbsp;基于浏览器扩展 API Mock 工具开发探索｜得物技术</p>
<p>2.&nbsp;破解gh-ost变更导致MySQL表膨胀之谜｜得物技术</p>
<p>3.&nbsp;MySQL单表为何别超2000万行？揭秘B+树与16KB页的生死博弈｜得物技术</p>
<p>4.&nbsp;0基础带你精通Java对象序列化--以Hessian为例｜得物技术</p>
<p>5.&nbsp;前端日志回捞系统的性能优化实践｜得物技术</p>
<h4>文 /舍得</h4>
<p>关注得物技术，每周更新技术干货</p>
<p>要是觉得文章对你有帮助的话，欢迎评论转发点赞～</p>
<p>未经得物技术许可严禁转载，否则依法追究法律责任。</p>]]>
    </description>
    <content:encoded><![CDATA[<h1>一、引 言</h1>
<p><strong>为什么进行源码角度的深度解析？</strong></p>
<p>大家在项目中到处都在使用线程池做一些性能接口层次的优化，原先串行的多个远程调用，因为rt过高，通过线程池批量异步优化，从而降低rt。还有像RocketMQ中broker启动时，同时通过ScheduledThreadPoolExecutor线程池执行其他组件的定时任务，每隔一段时间处理相关的任务。线程池广泛的应用在外面各种实际开发场景中，我们很多同学可能在项目里只是简单的copy了一些前人的代码参数并不知道其中的含义，从而导致生产级别的bug。所以本篇文章，旨在帮助还不熟悉或者想要熟悉线程池的同学，分享我自己在学习线程池源码上的一些内容来更简单、快速的掌握线程池。</p>
<h1>二、为什么使用线程池？</h1>
<p>并发编程中，对于常见的操作系统，线程都是执行任务的基本单元，如果每次执行任务时都创建新的线程，任务执行完毕又进行销毁，会出现以下的问题：</p>
<ul>
<li><strong>资源开销</strong>：比如在Linux系统中，频繁的创建和销毁线程，一个是频繁的进行一个系统调用，另外是一些内存和CPU资源调度的占用。虽然有一些写时复制的策略防止lwp的创建时的内存占用，但是实际写入还是会申请系统内存的，何况一些页表等本身就有内存占用。</li>
<li><strong>性能瓶颈</strong>：线程的创建需要系统调用，如果只是简单的计算任务，可能耗时还没创建的rt高，这里反而降低了系统的吞吐量。</li>
<li><strong>缺乏资源管理</strong>：无限制的创建线程会导致内存溢出，java.lang.OutOfMemoryError: unable to create native thread，这里主要因为Java的线程其实Linux中是lwp线程，需要通过JNI进行系统调用创建，每个线程默认需要1MB的栈空间，很容易导致无休止的创建线程导致内存溢出，另外就是频繁的系统调用，导致的上下文切换，占用了过多的CPU，反而起到了相反的作用。</li>
<li><strong>功能受限</strong>：手动管理线程难以实现更高级的功能，如定时任务、周期任务、任务管理、并发任务数的控制等。</li>
</ul>
<p>通过上面的问题，我们其实可以清晰的感知到这些问题都是归拢到资源没有得到合理的分配和控制导致的，线程池出现的核心宗旨其实就是对资源的合理分配和控制。除了线程池，其实更多的也接触过数据库连接池、netty的对象池等池化技术，这些池化思想其实都是为了更好的降低资源的消耗以及更好的进行资源管理。</p>
<h1>三、JDK线程池的架构设计</h1>
<h1>3.1 JUC并发包下的Executor框架的uml类图</h1>
<div>
<img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-10e0261f0e.jpg">
</div>
<ul>
<li><strong>Executor</strong>：任务执行的顶层接口，主要是分离任务提交与执行逻辑，支持同步/异步执行，遵循Java内存模型的&nbsp;happen-before规则。</li>
<li><strong>ExecutorService</strong>：继承Executor接口，提供了更完善的生命周期管理能力，通过Future对象提供任务取消、状态查询、结果获取能力实现了任务监控。</li>
<li><strong>AbstractExecutorService</strong>：常见的设计模式为了简化线程池的开发，通常通过父类进行一些基础的默认实现让子类继承。</li>
<li><strong>ScheduledExecutorService</strong>：ExecutorService的扩展接口，支持延迟执行和周期性任务调度。</li>
<li><strong>ThreadPoolExecutor</strong>：是ExecutorService接口最核心和最常用的实现类，它提供了高度可配置的线程池，允许我们精细控制线程池的各种行为。</li>
<li><strong>ScheduledThreadPoolExecutor</strong>：是ScheduledExecutorService接口的实现类，它继承自ThreadPoolExecutor，专门用于处理定时和周期任务。</li>
<li><strong>Executors</strong>：一个静态工厂模式的工具类，提供了一系列静态方法来创建各种常见配置的线程池，newFixedThreadPool(), newCachedThreadPool(),等，简化了创建线程池的使用但是会带来一些问题，很多开发规范里都不建议大家直接使用。JDK内置的线程池如果我们不熟悉里面的参数很有可能导致出乎自己意料的结果，池大小设置、阻塞队列选择等等都是有考究的，这一点后续会进行一些详细说明。生产环境中建议谨慎使用或直接使用ThreadPoolExecutor构造函数自定义。</li>
</ul>
<h1>3.2 ThreadPoolExecutor的参数解析</h1>
<div>
<img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-2b578a85a8.jpg">
</div>
<ul>
<li><strong>corePoolSize&nbsp;</strong>核心线程数：
<ul>
<li>线程池中还未退出的alive的核心线程数量。</li>
<li>虽然线程处于空闲状态（其实是阻塞在阻塞队列中），除非显示设置了allowCoreThreadTimeOut=true，否则这些线程不会从自己的run方法中退出被回收。</li>
<li>添加新任务时，如果当前工作线程小于coreSize，此时即使存在空闲的core线程，线程池也会通过addWorker方法创建一个新的线程。</li>
<li>&nbsp;</li>
</ul> </li>
<li><strong>maximumPoolSize&nbsp;</strong>最大线程数：
<ul>
<li>线程池可以创建的最大线程数。</li>
<li>如果是有界队列，当队列满时，仍然有任务进来，此时线程池会创建小于最大线程数的线程来完成任务，空闲。</li>
<li>如果是无界队列，那么永远不会出现第二点的情况，除了内存异常，否则会一直保持核心线程数，多余的任务会一直往队列中加入。</li>
</ul> </li>
</ul>
<ul>
<li><strong>keepAliveTime</strong>&nbsp;线程空闲存活时间
<ul>
<li>线程数超过corePoolSize后创建的线程我们理解为非核心线程，对于这类线程，他的回收机制在于我们设置的keepAliveTime,线程会限期阻塞在队列中获取任务，如果超时未获取就会进行清理并退出。</li>
<li>另外如果设置allowCoreThreadTimeOut=true，所谓的核心线程在空闲时间达到keepAliveTime时也会被回收。</li>
</ul> </li>
</ul>
<ul>
<li><strong>unit&nbsp;</strong>时间单位
<ul>
<li>keepAliveTime参数的时间单位，TimeUnit中时分秒等。</li>
<li>&nbsp;</li>
</ul> </li>
<li><strong>workQueue&nbsp;</strong>任务队列
<ul>
<li>阻塞队列，核心线程数满时，新加入的任务，会先添加到阻塞队列中等待线程获取任务并执行。</li>
<li>常用的BlockingQueue实现有：
<ul>
<li>ArrayBlockingQueue：数组实现的先进先出原则的有界阻塞队列，构造方法必须指定容量。</li>
<li>LinkedBlockingQueue：链表实现的阻塞队列，构造传入容量则有界，未传则是无界队列，此时设置的最大线程数其实就不会有作用了。</li>
<li>SynchronousQueue：一个不存储元素的阻塞队列。每个put操作必须等待一个take操作，反之亦然。它相当于一个传递通道，非常适合传递性需求，吞吐量高，但要求maximumPoolSize足够大。</li>
<li>PriorityBlockingQueue：二叉堆实现的优先级阻塞队列，构造时可自行调整排序行为（小顶堆或大顶堆）。</li>
<li>DelayQueue：支持延时的无界阻塞队列，主要用于周期性的任务，我们可以直接通过它来实现一些简单的延迟任务需求，复杂的周期性任务建议使用ScheduledThreadPoolExecutor。</li>
</ul> </li>
</ul> </li>
</ul>
<ul>
<li><strong>threadFactory&nbsp;</strong>线程工厂
<ul>
<li>用于创建新线程的工厂。通过自定义ThreadFactory，我们可以为线程池中的线程设置更有意义的名称、设置守护线程状态、设置线程优先级、指定UncaughtExceptionHandler等。</li>
<li>Executors.defaultThreadFactory()是默认实现。</li>
</ul> </li>
</ul>
<ul>
<li><strong>handler&nbsp;</strong>拒绝策略
<ul>
<li>ThreadPoolExecutor.AbortPolicy：默认的拒绝策略，简单粗暴，当execute中添加woker失败时，直接在当前线程抛出异常。</li>
<li>JDK内置了四种拒绝策略：
<ul>
<li>ThreadPoolExecutor.AbortPolicy：默认的拒绝策略，简单粗暴，当execute中添加woker失败时，直接在当前线程抛出异常。</li>
<li>ThreadPoolExecutor.CallerRunsPolicy：提交任务的线程，直接执行任务。变相的背压机制，可以降低任务往线程中加入。</li>
<li>ThreadPoolExecutor.DiscardPolicy：直接丢弃被拒绝的任务，不做任何通知，需容忍数据丢失。</li>
<li>ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列中最旧的任务，然后重试提交当前任务，需容忍数据丢失。</li>
<li>实现RejectedExecutionHandler接口自定义拒绝策略，在实际生产应用中推荐使用，可以做一些打印观察日志的操作，告警、兜底的相关处理等。</li>
</ul> </li>
</ul> </li>
</ul>
<h1>3.3 运行机制详解</h1>
<p>新任务通过execute()方法提交给ThreadPoolExecutor时，其处理流程如下：</p>
<p><strong>判断核心线程数</strong>：如果当前运行的线程数小于corePoolSize，则创建新线程（即使有空闲的核心线程）来执行任务。</p>
<p><strong>尝试入队</strong>：如果当前运行的线程数大于或等于corePoolSize，则尝试将任务添加到workQueue中。</p>
<ul>
<li>如果workQueue.offer()成功（队列未满），任务入队等待执行。</li>
</ul>
<p><strong>尝试创建非核心线程</strong>：如果workQueue.offer()失败（队列已满）：</p>
<ul>
<li>判断当前运行的线程数是否小于maximumPoolSize；</li>
<li>如果是，则创建新的非核心线程来执行任务。</li>
</ul>
<p><strong>执行拒绝策略：</strong></p>
<p>如果当前运行的线程数也达到了maximumPoolSize（即核心线程和非核心线程都已用尽，且队列也满了），则执行RejectedExecutionHandler所定义的拒绝策略。</p>
<p>参考网络中的经典执行图：</p>
<div>
<img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-88df05dbfd.jpg">
</div>
<p>这个图能很好的表明运行原理，但是忽略了很多细节，比如所谓的缓冲执行是在什么条件下去走的呢？直接执行又是什么逻辑下执行呢？最后的任务拒绝又是怎么回事？带着这些疑问点，我们直接来进行一个源码级别的分析：</p>
<h1>execute核心流程的源码分析</h1>
<pre><code>public&nbsp;void&nbsp;execute(Runnable command)&nbsp;{
&nbsp; &nbsp;&nbsp;if&nbsp;(command ==&nbsp;null)
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;throw&nbsp;new&nbsp;NullPointerException();
&nbsp; &nbsp;&nbsp;//线程池状态 高3位表示线程状态 低29位代表线程数量
&nbsp; &nbsp;&nbsp;int&nbsp;c = ctl.get();
&nbsp; &nbsp;&nbsp;//判断当前线程池线程数量是否小于核心线程数
&nbsp; &nbsp;&nbsp;if&nbsp;(workerCountOf(c) &lt; corePoolSize) {
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//作为核心线程数进行线程的创建，并且创建成功线程会将command的任务执行--》对应图上的直接执行
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(addWorker(command,&nbsp;true))
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;return;
&nbsp; &nbsp; &nbsp; &nbsp; c = ctl.get();
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;//创建核心线程失败或者当前线程数量超过核心线程数
&nbsp; &nbsp;&nbsp;//当前线程池是否还在运行状态，尝试将任务添加到阻塞队列 --》对应图上的缓冲执行
&nbsp; &nbsp;&nbsp;//BlockingQueue队列的顶级抽象定义了offer不是进行阻塞添加而是立即返回，添加失败直接返回false，区别于put
&nbsp; &nbsp;&nbsp;if&nbsp;(isRunning(c) &amp;&amp; workQueue.offer(command)) {
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//重新获取线程池标志位
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;int&nbsp;recheck = ctl.get();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//如果线程此时不在运行状态中，那么将任务删除
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(! isRunning(recheck) &amp;&amp;&nbsp;remove(command))
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//删除任务成功，走拒绝策略拒绝掉当前任务
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; reject(command);
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;else&nbsp;if&nbsp;(workerCountOf(recheck) ==&nbsp;0)
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//如果线程池中的工作线程都没有的时候，这里需要创建一个线程去执行添加到队列中的任务
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//防止因为并发的原因工作线程都被终止掉了，此时任务在阻塞队列里等着，缺没有工作线程
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; addWorker(null,&nbsp;false);
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;//到这里那就是添加队列失败，或者线程池状态异常，但是这里仍然尝试进行创建一个worker
&nbsp; &nbsp;&nbsp;//如果创建失败，也是走拒绝策略拒绝当前任务
&nbsp; &nbsp;&nbsp;else&nbsp;if&nbsp;(!addWorker(command,&nbsp;false))
&nbsp; &nbsp; &nbsp; &nbsp; reject(command);
}</code></pre>
<p>接下来我们仔细看看addWorker这个方法具体是在做什么：</p>
<pre><code>//核心逻辑其实就是在无限循环创建一个worker，创建失败直接返回，创建成功，则将worker执行
// 因为worker有thread的成员变量，最终添加worker成功，会启动线程的start方法
//start方法最终会回调到外层的runWorker方法，改方法会不停的从阻塞队列里以阻塞的take方式
//获取任务，除非达到能被终止的条件，此时当前线程会终止
private&nbsp;boolean&nbsp;addWorker(Runnable firstTask,&nbsp;boolean&nbsp;core)&nbsp;{
&nbsp; &nbsp; retry:
&nbsp; &nbsp;&nbsp;for&nbsp;(;;) {
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;int&nbsp;c&nbsp;=&nbsp;ctl.get();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;int&nbsp;rs&nbsp;=&nbsp;runStateOf(c);
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// Check if queue empty only if necessary.
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(rs &gt;= SHUTDOWN &amp;&amp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ! (rs == SHUTDOWN &amp;&amp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;firstTask ==&nbsp;null&nbsp;&amp;&amp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;! workQueue.isEmpty()))
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;return&nbsp;false;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;for&nbsp;(;;) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;int&nbsp;wc&nbsp;=&nbsp;workerCountOf(c);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(wc &gt;= CAPACITY ||
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; wc &gt;= (core ? corePoolSize : maximumPoolSize))
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;return&nbsp;false;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//不停的重试添加worker的计数，只有添加成功的才会进行后续的worker启动
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(compareAndIncrementWorkerCount(c))
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;break&nbsp;retry;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; c = ctl.get(); &nbsp;// Re-read ctl
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//重试期间，如果其他线程导致线程池状态不一致了。重新回到第一个循环进行check判断
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(runStateOf(c) != rs)
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;continue&nbsp;retry;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// else CAS failed due to workerCount change; retry inner loop
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;boolean&nbsp;workerStarted&nbsp;=&nbsp;false;
&nbsp; &nbsp;&nbsp;boolean&nbsp;workerAdded&nbsp;=&nbsp;false;
&nbsp; &nbsp;&nbsp;Worker&nbsp;w&nbsp;=&nbsp;null;
&nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; w =&nbsp;new&nbsp;Worker(firstTask);
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;final&nbsp;Thread&nbsp;t&nbsp;=&nbsp;w.thread;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(t !=&nbsp;null) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//这里加锁一个是workers.add时需要加锁，另外是防止其他线程已经在尝试修改线程池状态了
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;final&nbsp;ReentrantLock&nbsp;mainLock&nbsp;=&nbsp;this.mainLock;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; mainLock.lock();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// Recheck while holding lock.
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// Back out on ThreadFactory failure or if
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// shut down before lock acquired.
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;int&nbsp;rs&nbsp;=&nbsp;runStateOf(ctl.get());
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(rs &lt; SHUTDOWN ||
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (rs == SHUTDOWN &amp;&amp; firstTask ==&nbsp;null)) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(t.isAlive())&nbsp;// precheck that t is startable
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;throw&nbsp;new&nbsp;IllegalThreadStateException();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//将worker的引用添加到workers的hashSet中
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; workers.add(w);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;int&nbsp;s&nbsp;=&nbsp;workers.size();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//更新线程池此时最大的线程数
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(s &gt; largestPoolSize)
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; largestPoolSize = s;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; workerAdded =&nbsp;true;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;finally&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; mainLock.unlock();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//如果添加成功，就启动worker中的线程
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(workerAdded) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; t.start();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; workerStarted =&nbsp;true;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; }&nbsp;finally&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//这里添加失败的话，需要把线程池的count数进行--，并且要把worker引用从hashSer中移除
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(! workerStarted)
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; addWorkerFailed(w);
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;return&nbsp;workerStarted;
}</code></pre>
<h1>3.4 线程池的生命周期</h1>
<p>在介绍运行机制原理的源码分析时，其实是有提到线程池状态这个概念的。介绍这个状态其实也是让大家更方便的去管理线程池，比如我们关闭线程池时，怎么去优雅的关闭，使用不同的方法可能会有不同的效果，我们需要根据自己的业务场景去酌情分析、权衡使用。</p>
<pre><code>//线程池的状态和计数采用一个Integer变量设置的
//这里之所以用一个变量来储存状态和数量，其实很有讲究的，因为我们在上面的运行原理上可以看到
//源码中有大量的进行状态以及数量的判断，如果分开采用变量的记录的话，在维护二者一致性方面
//可能就需要加锁的维护成本了，而且计算中都是位移运算也是非常高效的
private&nbsp;final&nbsp;AtomicInteger&nbsp;ctl&nbsp;=&nbsp;new&nbsp;AtomicInteger(ctlOf(RUNNING,&nbsp;0));
//线程池的大小由ctl低29位表示，现成状态由ctl高3位表示
private&nbsp;static&nbsp;final&nbsp;int&nbsp;COUNT_BITS&nbsp;=&nbsp;Integer.SIZE -&nbsp;3;
private&nbsp;static&nbsp;final&nbsp;int&nbsp;CAPACITY&nbsp; &nbsp;=&nbsp;(1&nbsp;&lt;&lt; COUNT_BITS) -&nbsp;1;
// 线程池的状态通过简单的位移就能计算出来，状态只能从低到高流转，不能逆向
private&nbsp;static&nbsp;final&nbsp;int&nbsp;RUNNING&nbsp; &nbsp;&nbsp;=&nbsp;-1&nbsp;&lt;&lt; COUNT_BITS;
private&nbsp;static&nbsp;final&nbsp;int&nbsp;SHUTDOWN&nbsp; &nbsp;=&nbsp;&nbsp;0&nbsp;&lt;&lt; COUNT_BITS;
private&nbsp;static&nbsp;final&nbsp;int&nbsp;STOP&nbsp; &nbsp; &nbsp; &nbsp;=&nbsp;&nbsp;1&nbsp;&lt;&lt; COUNT_BITS;
private&nbsp;static&nbsp;final&nbsp;int&nbsp;TIDYING&nbsp; &nbsp;&nbsp;=&nbsp;&nbsp;2&nbsp;&lt;&lt; COUNT_BITS;
private&nbsp;static&nbsp;final&nbsp;int&nbsp;TERMINATED&nbsp;=&nbsp;&nbsp;3&nbsp;&lt;&lt; COUNT_BITS;
// 这里是获取线程状态以及获取线程数量的简单高效的位移方法
private&nbsp;static&nbsp;int&nbsp;runStateOf(int&nbsp;c)&nbsp; &nbsp; &nbsp;{&nbsp;return&nbsp;c &amp; ~CAPACITY; }
private&nbsp;static&nbsp;int&nbsp;workerCountOf(int&nbsp;c)&nbsp; {&nbsp;return&nbsp;c &amp; CAPACITY; }
private&nbsp;static&nbsp;int&nbsp;ctlOf(int&nbsp;rs,&nbsp;int&nbsp;wc)&nbsp;{&nbsp;return&nbsp;rs | wc; }</code></pre>
<p>接下来结合源码详细介绍下线程池的5种状态以及分别有什么不同的表现行为？</p>
<pre><code>先说下结论：
RUNNING&nbsp; &nbsp; &nbsp;这个就是线程池运行中状态，我们可以添加任务也可以处理阻塞队列任务
SHUTDOWN &nbsp; 不能添加新的任务，但是会将阻塞队列中任务执行完毕
STOP &nbsp; &nbsp; &nbsp; 不能添加新的任务，执行中的线程也会被打断，也不会处理阻塞队列的任务
TIDYING &nbsp; &nbsp;所有线程都被终止，并且workCount=0时会被置为的状态
TERMINATED &nbsp; 调用完钩子方法terminated()被置为的状态&nbsp;</code></pre>
<h1>shutdown状态源码分析：</h1>
<pre><code>&nbsp;
&nbsp;//线程池关闭
&nbsp;public&nbsp;void&nbsp;shutdown()&nbsp;{
&nbsp; &nbsp;&nbsp;final&nbsp;ReentrantLock&nbsp;mainLock&nbsp;=&nbsp;this.mainLock;
&nbsp; &nbsp; mainLock.lock();
&nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; checkShutdownAccess();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//循环cas设置线程池状态，直到成功或状态已经state&gt;=SHUTDOWN
&nbsp; &nbsp; &nbsp; &nbsp; advanceRunState(SHUTDOWN);
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//这个是真正得出结论的地方
&nbsp; &nbsp; &nbsp; &nbsp; interruptIdleWorkers();
&nbsp; &nbsp; &nbsp; &nbsp; onShutdown();&nbsp;// hook for ScheduledThreadPoolExecutor
&nbsp; &nbsp; }&nbsp;finally&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; mainLock.unlock();
&nbsp; &nbsp; }
&nbsp; &nbsp; tryTerminate();
}
private&nbsp;void&nbsp;interruptIdleWorkers()&nbsp;{
&nbsp; &nbsp; interruptIdleWorkers(false);
}
//打断空闲的线程，如何判断线程是否空闲还是运行？
private&nbsp;void&nbsp;interruptIdleWorkers(boolean&nbsp;onlyOne)&nbsp;{
&nbsp; &nbsp;&nbsp;final&nbsp;ReentrantLock&nbsp;mainLock&nbsp;=&nbsp;this.mainLock;
&nbsp; &nbsp; mainLock.lock();
&nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;for&nbsp;(Worker w : workers) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;Thread&nbsp;t&nbsp;=&nbsp;w.thread;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//worker的线程没有被打断过，并且能获取到worker的aqs独占锁
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(!t.isInterrupted() &amp;&amp; w.tryLock()) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//打断当前线程，如果线程在阻塞队列中阻塞，此时会被中断
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; t.interrupt();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;catch&nbsp;(SecurityException ignore) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;finally&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; w.unlock();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(onlyOne)
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;break;
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; }&nbsp;finally&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; mainLock.unlock();
&nbsp; &nbsp; }
}
</code></pre>
<h1>STOP状态分析</h1>
<pre><code>//循环cas修改线程池状态为stop。打断所有线程，取出阻塞队列的所有任务
public&nbsp;List&lt;Runnable&gt;&nbsp;shutdownNow()&nbsp;{
&nbsp; &nbsp; List&lt;Runnable&gt; tasks;
&nbsp; &nbsp; final ReentrantLock mainLock =&nbsp;this.mainLock;
&nbsp; &nbsp; mainLock.lock();
&nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//检查线程的权限
&nbsp; &nbsp; &nbsp; &nbsp; checkShutdownAccess();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//将状态case为stop
&nbsp; &nbsp; &nbsp; &nbsp; advanceRunState(STOP);
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//打断所有worker不管是不是正在执行任务
&nbsp; &nbsp; &nbsp; &nbsp; interruptWorkers();
&nbsp; &nbsp; &nbsp; &nbsp; tasks = drainQueue();
&nbsp; &nbsp; }&nbsp;finally&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; mainLock.unlock();
&nbsp; &nbsp; }
&nbsp; &nbsp; tryTerminate();
&nbsp; &nbsp;&nbsp;return&nbsp;tasks;
}
//这里获取锁之后。打断了所有的线程
private&nbsp;void&nbsp;interruptWorkers()&nbsp;{
&nbsp; &nbsp; final ReentrantLock mainLock =&nbsp;this.mainLock;
&nbsp; &nbsp; mainLock.lock();
&nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;for&nbsp;(Worker w : workers)
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; w.interruptIfStarted();
&nbsp; &nbsp; }&nbsp;finally&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; mainLock.unlock();
&nbsp; &nbsp; }
}</code></pre>
<h1>TIDYING、TERMINATED&nbsp;状态分析</h1>
<pre><code>//这个方法在每个线程退出时都会进行调用，如果是运行中、或者状态大于等于TIDYING或者shutdown但是队列不为空都
//直接返回，如果不满足以上条件，并且线程数不为0的话，打断一个空闲线程
final&nbsp;void tryTerminate() {
&nbsp; &nbsp;&nbsp;for&nbsp;(;;) {
&nbsp; &nbsp; &nbsp; &nbsp; int c = ctl.get();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(isRunning(c) ||
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; runStateAtLeast(c, TIDYING) ||
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (runStateOf(c) == SHUTDOWN &amp;&amp; ! workQueue.isEmpty()))
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;return;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(workerCountOf(c) !=&nbsp;0) {&nbsp;// Eligible to terminate
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; interruptIdleWorkers(ONLY_ONE);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;return;
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//此时到这里，状态要么为STOP。要么是shutdown并且队列为空了
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 获取一个锁，尝试cas修改状态为TIDYING
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//调用terminated()的钩子方法，
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//修改线程池为终态TERMINATED，并且唤醒阻塞在termination队列上的线程
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;final&nbsp;ReentrantLock mainLock =&nbsp;this.mainLock;
&nbsp; &nbsp; &nbsp; &nbsp; mainLock.lock();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(ctl.compareAndSet(c, ctlOf(TIDYING,&nbsp;0))) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; terminated();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;finally&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ctl.set(ctlOf(TERMINATED,&nbsp;0));
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; termination.signalAll();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;return;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;finally&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; mainLock.unlock();
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// else retry on failed CAS
&nbsp; &nbsp; }
}</code></pre>
<h1>四、JDK内置线程池的问题</h1>
<p>java.util.concurrent.Executors工厂类提供了一些静态方法，方便我们快速创建几种预设配置的线程池：</p>
<ul>
<li>Executors.newFixedThreadPool(int nThreads)：
<ul>
<li>创建一个固定大小的线程池。corePoolSize和maximumPoolSize都等于nThreads。</li>
<li>keepAliveTime为0L（因为线程数不会超过corePoolSize，所以此参数无效，除非allowCoreThreadTimeOut为true）。</li>
<li>使用无界的LinkedBlockingQueue作为工作队列。</li>
<li><strong>问题</strong>：由于使用无界队列，当任务提交速度远大于处理速度时，队列会持续增长，可能导致内存溢出（OOM）。此时maximumPoolSize参数实际上是无效的，线程数永远不会超过nThreads。</li>
</ul> </li>
</ul>
<ul>
<li>Executors.newSingleThreadExecutor()：
<ul>
<li>创建一个只有一个工作线程的线程池。corePoolSize和maximumPoolSize都为1。</li>
<li>同样使用<strong>无界</strong>的LinkedBlockingQueue。</li>
<li>保证所有任务按照提交顺序（FIFO）执行。</li>
<li><strong>问题</strong>：与newFixedThreadPool类似，无界队列可能导致OOM。</li>
</ul> </li>
</ul>
<ul>
<li>Executors.newCachedThreadPool()：
<ul>
<li>创建一个可缓存的线程池。</li>
<li>corePoolSize为0。</li>
<li>maximumPoolSize为Integer.MAX_VALUE (几乎是无界的)。</li>
<li>keepAliveTime为60秒。</li>
<li>使用SynchronousQueue作为工作队列。这种队列不存储元素，任务提交后必须有空闲线程立即接收，否则会创建新线程（如果未达到maximumPoolSize）。</li>
<li><strong>问题</strong>：如果任务提交速度过快，会创建大量线程（理论上可达Integer.MAX_VALUE个），可能耗尽系统资源，导致OOM以及频繁的上下文切换。</li>
</ul> </li>
</ul>
<ul>
<li>Executors.newSingleThreadScheduledExecutor()、Executors.newScheduledThreadPool(int corePoolSize):
<ul>
<li>创建用于调度任务的线程池。</li>
<li>内部使用ScheduledThreadPoolExecutor实现，其任务队列是DelayedWorkQueue (一种特殊的PriorityQueue)。</li>
<li>newSingleThreadScheduledExecutor的corePoolSize为1，maximumPoolSize为Integer.MAX_VALUE（但由于队列是DelayedWorkQueue，通常不会无限增长线程，除非有大量同时到期的任务且处理不过来）。</li>
<li>newScheduledThreadPool可以指定corePoolSize。</li>
<li><strong>问题</strong>：虽然DelayedWorkQueue本身是无界的，但ScheduledThreadPoolExecutor在任务执行逻辑上与普通ThreadPoolExecutor有所不同。主要风险仍然是如果corePoolSize设置不当，且大量任务同时到期并执行缓慢，可能导致任务积压。</li>
</ul> </li>
</ul>
<div>
<img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-a0860059e7.jpg">
</div>
<p>某一线互联网Java开发手册</p>
<h1>五、线程池中的问题与最佳实践</h1>
<h1>5.1 invokeAll 超时机制无效？</h1>
<p>ExecutorService.invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit)方法会提交一组Callable任务，并等待所有任务完成，或者直到超时。如果超时发生，它会尝试取消（中断）所有尚未完成的任务，然后返回一个List&lt;Future&gt;。</p>
<p><strong>失效场景分析：</strong></p>
<ul>
<li>任务不响应中断（最常见）：任务内部捕获&nbsp;InterruptedException&nbsp;后静默处理，或执行不检查中断状态的阻塞操作（如循环计算）：</li>
</ul>
<pre><code>Callable&lt;String&gt; task = () -&gt; {
&nbsp; &nbsp;&nbsp;while&nbsp;(true) {
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//缺少此检查将导致超时失效
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(Thread.interrupted())&nbsp;break;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 耗时计算...
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;return&nbsp;"done";
};</code></pre>
<ul>
<li><strong>使用非响应中断的API</strong>：任务调用了不响应&nbsp;interrupt()&nbsp;的第三方库或JNI代码（如某些IO操作）</li>
</ul>
<pre><code>Callable&lt;Integer&gt; task&nbsp;=&nbsp;() -&gt; {
&nbsp; &nbsp;&nbsp;Files.copy(in, path);&nbsp;// 某些NIO操作不响应中断
&nbsp; &nbsp;&nbsp;return&nbsp;1;
};</code></pre>
<ul>
<li><strong>任务依赖外部资源阻塞</strong>：任务因外部资源（如数据库连接、网络请求）阻塞且未设置超时。</li>
</ul>
<pre><code>Callable&lt;Result&gt; task&nbsp;=&nbsp;() -&gt; {
&nbsp; &nbsp;&nbsp;//未设查询超时时间
&nbsp; &nbsp;&nbsp;return&nbsp;jdbcTemplate.query("SELECT * FROM large_table");&nbsp;
};</code></pre>
<ul>
<li><strong>线程池配置缺陷</strong>：核心线程数过大或队列无界，导致&nbsp;invokeAll&nbsp;超时前任务无法全部启动，任务堆积在队列，invokeAll&nbsp;超时后仍有大量任务未执行。</li>
</ul>
<pre><code>new&nbsp;ThreadPoolExecutor(
&nbsp; &nbsp;&nbsp;100,&nbsp;100,&nbsp;// 核心线程数过大
&nbsp; &nbsp; 0L,&nbsp;TimeUnit.MILLISECONDS,
&nbsp; &nbsp;&nbsp;new&nbsp;LinkedBlockingQueue&lt;&gt;()&nbsp;// 无界队列
);</code></pre>
<p><strong>invokeAll超时失效demo:</strong></p>
<pre><code>import&nbsp;java.util.*;
import&nbsp;java.util.concurrent.*;
public&nbsp;class&nbsp;InvokeAllTimeoutDemo&nbsp;{
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;// 模拟耗时任务（可配置是否响应中断）
&nbsp; &nbsp;&nbsp;static&nbsp;class&nbsp;Task&nbsp;implements&nbsp;Callable&lt;String&gt; {
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;private&nbsp;final&nbsp;int&nbsp;id;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;private&nbsp;final&nbsp;long&nbsp;durationMs;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;private&nbsp;final&nbsp;boolean&nbsp;respectInterrupt;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; Task(int&nbsp;id,&nbsp;long&nbsp;durationMs,&nbsp;boolean&nbsp;respectInterrupt) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;this.id = id;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;this.durationMs = durationMs;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;this.respectInterrupt = respectInterrupt;
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;@Override
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;public&nbsp;String&nbsp;call()&nbsp;throws&nbsp;Exception {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.out.printf("Task %d started%n", id);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;long&nbsp;start&nbsp;=&nbsp;System.currentTimeMillis();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 模拟工作（检查中断状态）
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;while&nbsp;(System.currentTimeMillis() - start &lt; durationMs) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(respectInterrupt &amp;&amp; Thread.interrupted()) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;throw&nbsp;new&nbsp;InterruptedException("Task "&nbsp;+ id +&nbsp;" interrupted");
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 不响应中断的任务会继续执行
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.out.printf("Task %d completed%n", id);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;return&nbsp;"Result-"&nbsp;+ id;
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;public&nbsp;static&nbsp;void&nbsp;main(String[] args)&nbsp;throws&nbsp;InterruptedException {
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;ExecutorService&nbsp;executor&nbsp;=&nbsp;Executors.newFixedThreadPool(2);
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; List&lt;Callable&lt;String&gt;&gt; tasks = Arrays.asList(
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;new&nbsp;Task(1,&nbsp;2000,&nbsp;true), &nbsp;&nbsp;// 2秒，响应中断
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;new&nbsp;Task(2,&nbsp;10000,&nbsp;false) &nbsp;// 10秒，不响应中断
&nbsp; &nbsp; &nbsp; &nbsp; );
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; System.out.println("Invoking with 3s timeout...");
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//设置3秒超时
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; List&lt;Future&lt;String&gt;&gt; futures = executor.invokeAll(tasks,&nbsp;3, TimeUnit.SECONDS);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;for&nbsp;(Future&lt;String&gt; f : futures) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 明确处理取消状态
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(f.isCancelled()) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.out.println("Task was cancelled"); &nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;else&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.out.println("Result: "&nbsp;+ f.get(100, TimeUnit.MILLISECONDS));
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;catch&nbsp;(TimeoutException | ExecutionException e) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.out.println("Task failed: "&nbsp;+ e.getCause());
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;finally&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; executor.shutdownNow();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.out.println("Executor shutdown");
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; }
}</code></pre>
<p>当我们使用invokeAll(tasks, timeout)&nbsp;提交多个任务时，如果出现某个任务对中断不响应或者响应不及时，那我们即使设置了超时时间，不响应中断的任务2仍在后台运行（即使调用了&nbsp;shutdownNow()）</p>
<h1>5.2 submit()的异常消失了？</h1>
<p>使用ExecutorService.submit()提交任务时，任务执行过程中如果抛出未捕获的异常（无论是受检异常还是运行时异常），这个异常会被Future的包装类如FutureTask重写的run()方法捕获并封装在返回的Future包装对象的成员变量中。</p>
<ul>
<li><strong>不显示调用</strong>Future.get()，该异常我们就无法感知，好像没有发生过一样。线程池的工作线程本身通常会有一个默认的未捕获异常处理器，可能会打印堆栈到控制台，但你的主业务逻辑不会知道。</li>
<li><strong>显示调用</strong>Future.get()，抛出声明式的ExecutionException，其cause属性才是原始的任务异常。</li>
<li>如果调用Future.get(long timeout, TimeUnit unit)超时，向外抛出声明式的TimeoutException。此时任务可能仍在后台执行，可能错过了内部的异常。</li>
</ul>
<p><strong>submit()异常消失demo:</strong></p>
<pre><code>public&nbsp;class&nbsp;ThreadPoolExceptionDemo&nbsp;{
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;public&nbsp;static&nbsp;void&nbsp;main(String[] args)&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 创建单线程线程池（便于观察异常）
&nbsp; &nbsp; &nbsp; &nbsp; ExecutorService executor = Executors.newSingleThreadExecutor();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 场景1：Callable抛出异常（通过Future.get()捕获）
&nbsp; &nbsp; &nbsp; &nbsp; Future&lt;String&gt; future1 = executor.submit(() -&gt; {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.out.println("[Callable] 开始执行");
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Thread.sleep(100);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;throw&nbsp;new&nbsp;RuntimeException("Callable故意抛出的异常");
&nbsp; &nbsp; &nbsp; &nbsp; });
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.out.println("Callable结果: "&nbsp;+ future1.get());
&nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;catch&nbsp;(ExecutionException e) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.err.println("捕获到Callable异常: "&nbsp;+ e.getCause().getMessage());
&nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;catch&nbsp;(InterruptedException e) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Thread.currentThread().interrupt();
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 场景2：Runnable抛出异常（同样通过Future.get()捕获）
&nbsp; &nbsp; &nbsp; &nbsp; Future&lt;?&gt; future2 = executor.submit(() -&gt; {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.out.println("[Runnable] 开始执行");
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;throw&nbsp;new&nbsp;IllegalArgumentException("Runnable故意抛出的异常");
&nbsp; &nbsp; &nbsp; &nbsp; });
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; future2.get();&nbsp;// Runnable成功时返回null
&nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;catch&nbsp;(ExecutionException e) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.err.println("捕获到Runnable异常: "&nbsp;+ e.getCause().getMessage());
&nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;catch&nbsp;(InterruptedException e) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Thread.currentThread().interrupt();
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 场景3：未处理的任务异常（需设置异常处理器）
&nbsp; &nbsp; &nbsp; &nbsp; executor.submit(() -&gt; {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.out.println("[未捕获的任务] 开始执行");
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;throw&nbsp;new&nbsp;IllegalStateException("这个异常会被默认处理器处理");
&nbsp; &nbsp; &nbsp; &nbsp; });
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; executor.shutdown();
&nbsp; &nbsp; }
}</code></pre>
<h1>5.3 异常处理实践</h1>
<div>
<img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-851f74dab6.jpg">
</div>
<ul>
<li><strong>Callable/Runnable catch处理异常：</strong>
<ul>
<li><strong>不要捕获Throwable或Exception然后静默处理（只打日志）</strong>。如果确实需要捕获，请考虑是否应该重新抛出（包装成业务允许的受检异常或运行时异常）。</li>
<li><strong>禁止静默处理&nbsp;</strong>InterruptedException：</li>
<li>在JDK的JUC底层源码中，我们可以看到很多声明了InterruptedException的方法，基本上都是对这类方法catch异常，要么继续往外抛出，或者处理完相关资源后，重置中断状态，<strong>绝对不要静默处理。</strong></li>
<li>如果方法没有声明InterruptedException如Runnable.run()，在catch&nbsp;InterruptedException后最好调用Thread.currentThread().interrupt()来恢复中断标记。</li>
<li><strong>正确处理中断</strong>：callable在耗时的loop任务处理中，如果出现了中断异常，因为Java代码中中断只是一种协作方式，其并没真的终止线程，所以一般都是需要我们进行一个中断标志的传递，如线程池中的shutdownNow()就依赖次机制处理。</li>
</ul> </li>
</ul>
<ul>
<li><strong>submit()执行的任务，谨慎处理Future：</strong>
<ul>
<li>使用带过期时间的future.get(long timeOut)获取结果，并要对该方法进行try cache防止其他异常抛出。</li>
<li>多个任务并行处理时，如果有下个请求依赖上个请求，务必使用get()让主线程等待这一结果执行完成后，流转到下一个异步任务。</li>
</ul> </li>
</ul>
<ul>
<li><strong>实现线程Thread的UncaughtExceptionHandler属性</strong>，在自定义的TheadFactory中通过set方法赋值：execute()方法执行时，对于没有捕获的异常使用线程组的兜底统一处理机制。</li>
</ul>
<pre><code>//自定义当前线程组创建线程的统一异常处理，类似于controller的统一异常处理机制
ThreadFactory&nbsp;myThreadFactory&nbsp;=&nbsp;new&nbsp;ThreadFactory() {
&nbsp; &nbsp;&nbsp;private&nbsp;final&nbsp;AtomicInteger&nbsp;atomicInteger&nbsp;=&nbsp;new&nbsp;AtomicInteger(0);
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;private&nbsp;final&nbsp;String&nbsp;threadNamePrefix&nbsp;=&nbsp;"myThreadFactory-";
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;@Override
&nbsp; &nbsp;&nbsp;public&nbsp;Thread&nbsp;newThread(Runnable r)&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;Thread&nbsp;t&nbsp;=&nbsp;&nbsp;new&nbsp;Thread(r,threadNamePrefix + atomicInteger.getAndIncrement());
&nbsp; &nbsp; &nbsp; &nbsp; t.setUncaughtExceptionHandler((thread, throwable) -&gt; {
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//异常的统一处理，日志打印、兜底处理、监控、资源释放等
&nbsp; &nbsp; &nbsp; &nbsp; System.err.println("线程["&nbsp;+ thread.getName() +&nbsp;"]异常: "&nbsp;+ throwable);});
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;return&nbsp;t;
&nbsp; &nbsp; }
};
//构造方法时使用自定义的线程工厂
ExecutorService&nbsp;executor&nbsp;=&nbsp;new&nbsp;ThreadPoolExecutor(
&nbsp; &nbsp; corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,
&nbsp; &nbsp; threadFactory,
&nbsp; &nbsp; handler
);</code></pre>
<ul>
<li><strong>使用自定义线程池时建议重写钩子方法afterExecute(Runnable r, Throwable t)</strong>：这个hook方法是用来解决当前任务线程发生的异常，默认是空实现，我们可以重写他，比如进行兜底的线程继续执行，打印日志记录，以及同步失败使用兜底异步处理等等方式。还要注意释放应用中的资源，比如文件锁的占用等，最好手动释放掉，避免底层操作系统线程对这类资源释放失败导致长期占用，最后只能重启Java进程的尴尬地步。</li>
</ul>
<pre><code>public&nbsp;class&nbsp;MyThreadPoolExecutor&nbsp;extends&nbsp;ThreadPoolExecutor&nbsp;{
&nbsp; &nbsp;&nbsp;public&nbsp;MyThreadPoolExecutor(int&nbsp;corePoolSize,&nbsp;int&nbsp;maximumPoolSize,&nbsp;long&nbsp;keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue)&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue);
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;@Override
&nbsp; &nbsp;&nbsp;protected&nbsp;void&nbsp;afterExecute(Runnable r, Throwable t)&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;//需要特别注意任务是否为submit提交，如果是execute提交的任务，那这里很直接的知道任务是否发生异常以及后续去怎么处理
&nbsp; &nbsp; &nbsp; &nbsp;if(r&nbsp;instanceof&nbsp;Future){
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;if(((Future&lt;?&gt;) r).isDone() || ((Future&lt;?&gt;) r).isCancelled()){
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;//继续使用主线程完成任务,一般不建议，最好使用兜底方式：例如异步发消息，由后续的消费组统一处理异常的任务
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;}
&nbsp; &nbsp; &nbsp; &nbsp;}else&nbsp;if( t !=&nbsp;null){
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//execute异常处理
&nbsp; &nbsp; &nbsp; &nbsp;}
&nbsp; &nbsp; }
}
//FutureTask 把run方法进行了重写，并且catch住了异常，所以说afterExecute的t 如果是submit提交的方式
//那么t基本上就是null
public&nbsp;void&nbsp;run()&nbsp;{
&nbsp; &nbsp;&nbsp;//....
&nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; Callable&lt;V&gt; c = callable;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(c !=&nbsp;null&nbsp;&amp;&amp; state == NEW) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; V result;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;boolean&nbsp;ran;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; result = c.call();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ran =&nbsp;true;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;catch&nbsp;(Throwable ex) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; result =&nbsp;null;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ran =&nbsp;false;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; setException(ex);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(ran)
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; set(result);
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; }&nbsp;finally&nbsp;{
&nbsp; &nbsp; &nbsp;//...
}</code></pre>
<p><strong>afterExecute可以借鉴的示例：</strong></p>
<pre><code>import&nbsp;java.util.concurrent.*;
import&nbsp;java.util.concurrent.atomic.*;
import&nbsp;org.slf4j.*;
public&nbsp;class&nbsp;RobustThreadPool&nbsp;extends&nbsp;ThreadPoolExecutor&nbsp;{
&nbsp; &nbsp;&nbsp;private&nbsp;static&nbsp;final&nbsp;Logger&nbsp;logger&nbsp;=&nbsp;LoggerFactory.getLogger(RobustThreadPool.class);
&nbsp; &nbsp;&nbsp;private&nbsp;final&nbsp;AtomicLong&nbsp;failureCounter&nbsp;=&nbsp;new&nbsp;AtomicLong();
&nbsp; &nbsp;&nbsp;private&nbsp;final&nbsp;RetryPolicy retryPolicy;&nbsp;// 重试策略
&nbsp; &nbsp;&nbsp;private&nbsp;final&nbsp;ThreadLocal&lt;Long&gt; startTime =&nbsp;new&nbsp;ThreadLocal&lt;&gt;();
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;public&nbsp;RobustThreadPool(int&nbsp;corePoolSize,&nbsp;int&nbsp;maxPoolSize,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; BlockingQueue&lt;Runnable&gt; workQueue,
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; RetryPolicy retryPolicy) {
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;super(corePoolSize, maxPoolSize,&nbsp;60L, TimeUnit.SECONDS, workQueue);
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;this.retryPolicy = retryPolicy;
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;@Override
&nbsp; &nbsp;&nbsp;protected&nbsp;void&nbsp;beforeExecute(Thread t, Runnable r)&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; logger.debug("开始执行任务: {}", r);
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;@Override
&nbsp; &nbsp;&nbsp;protected&nbsp;void&nbsp;afterExecute(Runnable r, Throwable t)&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 1. 异常分类处理
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;if(r&nbsp;instanceof&nbsp;Future){
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;if(((Future&lt;?&gt;) r).isDone()){
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;//错误记录以及异常处理
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; failureCounter.incrementAndGet();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; handleFailure(r, t, costTime);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;}
&nbsp; &nbsp; &nbsp; &nbsp;}else&nbsp;if( t !=&nbsp;null){
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;//execute异常处理
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; failureCounter.incrementAndGet();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; handleFailure(r, t, costTime);
&nbsp; &nbsp; &nbsp; &nbsp;}
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 2. 资源清理
&nbsp; &nbsp; &nbsp; &nbsp; cleanThreadLocals();
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;private&nbsp;void&nbsp;handleFailure(Runnable r, Throwable t)&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 1. 异常类型识别
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(t&nbsp;instanceof&nbsp;OutOfMemoryError) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; logger.error("JVM内存不足，终止任务: {}", t.getMessage());
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.exit(1);&nbsp;// 严重错误直接终止
&nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 2. 可重试异常处理
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;else&nbsp;if&nbsp;(isRetryable(t)) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;int&nbsp;retryCount&nbsp;=&nbsp;retryPolicy.getCurrentRetryCount(r);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(retryCount &lt; retryPolicy.getMaxRetries()) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; logger.warn("任务第{}次失败，准备重试...",&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; retryCount +&nbsp;1, t);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; retryPolicy.retry(r,&nbsp;this);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;else&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; logger.error("任务超过最大重试次数({})，转入死信队列",&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; retryPolicy.getMaxRetries(), t);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; DeadLetterQueue.add(r, t);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 3. 不可重试异常
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;else&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; logger.error("不可恢复任务失败", t);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Metrics.recordFailure(t.getClass());&nbsp;// 上报监控
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;private&nbsp;boolean&nbsp;isRetryable(Throwable t)&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;return&nbsp;t&nbsp;instanceof&nbsp;IOException ||&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;t&nbsp;instanceof&nbsp;TimeoutException ||
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;(t.getCause() !=&nbsp;null&nbsp;&amp;&amp; isRetryable(t.getCause()));
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;private&nbsp;void&nbsp;cleanThreadLocals()&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 清理可能的内存泄漏
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ThreadLocal&lt;?&gt;[] holders = {&nbsp;/* 其他ThreadLocal */};
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;for&nbsp;(ThreadLocal&lt;?&gt; holder : holders) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; holder.remove();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;catch&nbsp;(Exception e) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; logger.warn("清理ThreadLocal失败", e);
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;// 重试策略嵌套类
&nbsp; &nbsp;&nbsp;public&nbsp;static&nbsp;class&nbsp;RetryPolicy&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;private&nbsp;final&nbsp;int&nbsp;maxRetries;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;private&nbsp;final&nbsp;long&nbsp;retryDelayMs;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;private&nbsp;final&nbsp;Map&lt;Runnable, AtomicInteger&gt; retryMap =&nbsp;new&nbsp;ConcurrentHashMap&lt;&gt;();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;public&nbsp;RetryPolicy(int&nbsp;maxRetries,&nbsp;long&nbsp;retryDelayMs)&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;this.maxRetries = maxRetries;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;this.retryDelayMs = retryDelayMs;
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;public&nbsp;void&nbsp;retry(Runnable task, Executor executor)&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; retryMap.computeIfAbsent(task, k -&gt;&nbsp;new&nbsp;AtomicInteger()).incrementAndGet();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(retryDelayMs &gt;&nbsp;0) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; executor.execute(() -&gt; {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;try&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Thread.sleep(retryDelayMs);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;catch&nbsp;(InterruptedException ignored) {}
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; executor.execute(task);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; });
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }&nbsp;else&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; executor.execute(task);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;public&nbsp;int&nbsp;getCurrentRetryCount(Runnable task)&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;return&nbsp;retryMap.getOrDefault(task,&nbsp;new&nbsp;AtomicInteger()).get();
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;public&nbsp;int&nbsp;getMaxRetries()&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;return&nbsp;maxRetries;
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; }
}</code></pre>
<p><strong>异常处理小结</strong>：要特别注意使用future.get()方法时，我们一定要注意设置超时时间，防止主线程无限期的阻塞避免边缘的业务查询影响了主业务造成得不偿失的效果，另外我们需要注意一个点就是submit()方法的提交任务时，afterExecute(Runnable r, Throwable t)中的t恒为null，如果是execute方法提交的任务，那么就是直接获取的任务执行的异常，对于submit提交的任务异常其被封装到了Futrure&nbsp;包装对象中，一般需要我们再次判断任务时执行完毕还是异常或被取消了，如果发生了异常，Future.get()会抛出封装的ExecutionException异常，当然还可能是取消异常以及中断异常。invokeAll和invokeAny我们需要对返回的Future结果检查可能抛出的异常，对于callable&nbsp;前面一再强调了要对InterruptedException不要静默处理，因为线程的中断标记只是一个协作方式，他并没有停止当前线程的运行，我们需要根据自身的场景对发生的中断进行快速响应以及传递中断标志。</p>
<h1>5.4 拒绝策略实践</h1>
<p>先带大家回顾一下策略是如何触发执行的流程：</p>
<pre><code>//添加任务，当不满足条件时会执行拒绝方法reject
public&nbsp;void&nbsp;execute(Runnable command)&nbsp;{
&nbsp; &nbsp;//...
&nbsp; &nbsp;&nbsp;if&nbsp;(isRunning(c) &amp;&amp; workQueue.offer(command)) {
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;int&nbsp;recheck = ctl.get();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(! isRunning(recheck) &amp;&amp;&nbsp;remove(command))
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; reject(command);
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;else&nbsp;if&nbsp;(workerCountOf(recheck) ==&nbsp;0)
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; addWorker(null,&nbsp;false);
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;else&nbsp;if&nbsp;(!addWorker(command,&nbsp;false))
&nbsp; &nbsp; &nbsp; &nbsp; reject(command);
}
//这里就是拒绝的入口。handler是有构造方法传入
final&nbsp;void&nbsp;reject(Runnable command)&nbsp;{
&nbsp; &nbsp; handler.rejectedExecution(command,&nbsp;this);
}
public&nbsp;ThreadPoolExecutor(int&nbsp;corePoolSize,
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;int&nbsp;maximumPoolSize,
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;long&nbsp;keepAliveTime,
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; TimeUnit unit,
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; BlockingQueue&lt;Runnable&gt; workQueue,
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ThreadFactory threadFactory,
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; RejectedExecutionHandler handler) {
&nbsp; &nbsp;&nbsp;//....
&nbsp; &nbsp;&nbsp;//指定拒绝策略
&nbsp; &nbsp;&nbsp;this.handler = handler;
}</code></pre>
<p><strong>AbortPolicy</strong>：默认的拒绝策略，简单粗暴，当execute中添加woker失败时，直接在当前线程抛出异常。</p>
<pre><code>public&nbsp;static&nbsp;class&nbsp;AbortPolicy&nbsp;implements&nbsp;RejectedExecutionHandler&nbsp;{
&nbsp; &nbsp; &nbsp;//直接抛出RejectedExecutionException
&nbsp; &nbsp;&nbsp;public&nbsp;void&nbsp;rejectedExecution(Runnable r, ThreadPoolExecutor e) {
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;throw&nbsp;new&nbsp;RejectedExecutionException("Task "&nbsp;+ r.toString() +
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;" rejected from "&nbsp;+
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;e.toString());
&nbsp; &nbsp; }
}</code></pre>
<p><strong>优点</strong>：快速失败，立即暴露系统过载问题、避免任务静默丢失，便于监控系统捕获</p>
<p><strong>缺点</strong>：需要调用方显式处理异常，增加代码复杂度，可能中断主业务流程</p>
<p><strong>适用场景</strong>：适用于那些对任务丢失非常敏感，配合熔断机制使用的快速失败场景</p>
<p><strong>CallerRunsPolicy</strong>：提交任务的线程，直接执行任务</p>
<pre><code>public&nbsp;static&nbsp;class&nbsp;CallerRunsPolicy&nbsp;implements&nbsp;RejectedExecutionHandler&nbsp;{
&nbsp; &nbsp;&nbsp;//直接在提交任务的线程中执行任务
&nbsp; &nbsp;&nbsp;public&nbsp;void&nbsp;rejectedExecution(Runnable r, ThreadPoolExecutor e) {
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(!e.isShutdown()) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; r.run();
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; }
}</code></pre>
<p><strong>优点</strong>：任务都会被执行，不会丢任务，并且由于主线程执行任务，天然的流量控制，避免了大量的任务进入线程池。</p>
<p><strong>缺点</strong>：调用线程可能被阻塞，导致上游服务雪崩。不适合高并发场景（可能拖垮整个调用链）。</p>
<p><strong>适用场景</strong>：适用于处理能力不高，并且资源过载能够平滑过渡，同时不丢失任务的场景。如：低并发、高可靠性的后台任务（如日志归档）、允许同步执行的批处理系统。</p>
<p><strong>DiscardPolicy</strong>：直接丢弃被拒绝的任务，不做任何通知。</p>
<pre><code>public&nbsp;static&nbsp;class&nbsp;DiscardPolicy&nbsp;implements&nbsp;RejectedExecutionHandler&nbsp;{
&nbsp; &nbsp;//空实现
&nbsp; &nbsp;&nbsp;public&nbsp;void&nbsp;rejectedExecution(Runnable r, ThreadPoolExecutor e) {
&nbsp; &nbsp; }
}</code></pre>
<p><strong>优点</strong>：实现简单，无额外性能开销。避免异常传播影响主流程</p>
<p><strong>缺点</strong>：数据静默丢失，可能会掩盖系统容量问题</p>
<p><strong>适用场景</strong>：边缘业务的监控上报数据，统计类的uv、pv统计任务</p>
<p>DiscardOldestPolicy：丢弃队列中最旧的任务，然后重试提交当前任务。</p>
<pre><code>public&nbsp;static&nbsp;class&nbsp;DiscardOldestPolicy&nbsp;implements&nbsp;RejectedExecutionHandler&nbsp;{
&nbsp; &nbsp;&nbsp;//丢弃队列中最旧的任务，重试当前任务
&nbsp; &nbsp;&nbsp;public&nbsp;void&nbsp;rejectedExecution(Runnable r, ThreadPoolExecutor e) {
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if&nbsp;(!e.isShutdown()) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; e.getQueue().poll();
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; e.execute(r);
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; }
}</code></pre>
<p><strong>优点</strong>：优先保证新任务执行，避免队列堆积导致内存溢出。</p>
<p><strong>缺点</strong>：可能丢失关键旧任务、任务执行顺序无法保证。</p>
<p><strong>适用场景</strong>：适用于可容忍部分数据丢失，并且实时性要求高于历史数据的场景，比如：行情推送。</p>
<p>通过上线的介绍，我们可以看到JDK内置策略基本上只使用于简单处理的场景，在生产实践中一般推荐我们自定义拒绝策略，进行相关的业务处理。</p>
<p><strong>1. 自定义RejectedExecutionHandler</strong>：</p>
<pre><code>/**
&nbsp;* 带监控统计的拒绝策略处理器
&nbsp;*/
public&nbsp;class&nbsp;MetricsRejectedExecutionHandler&nbsp;implements&nbsp;RejectedExecutionHandler&nbsp;{
&nbsp; &nbsp;&nbsp;private&nbsp;static&nbsp;final&nbsp;org.slf4j.Logger&nbsp;logger&nbsp;=&nbsp;org.slf4j.LoggerFactory.getLogger(MetricsRejectedExecutionHandler.class);
&nbsp; &nbsp;&nbsp;// 统计被拒绝的任务数量
&nbsp; &nbsp;&nbsp;private&nbsp;final&nbsp;AtomicLong&nbsp;rejectedCount&nbsp;=&nbsp;new&nbsp;AtomicLong(0);
&nbsp; &nbsp;&nbsp;@Override
&nbsp; &nbsp;&nbsp;public&nbsp;void&nbsp;rejectedExecution(Runnable r, ThreadPoolExecutor executor)&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 1. 采集线程池关键指标
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;int&nbsp;poolSize&nbsp;=&nbsp;executor.getPoolSize();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;int&nbsp;activeThreads&nbsp;=&nbsp;executor.getActiveCount();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;int&nbsp;corePoolSize&nbsp;=&nbsp;executor.getCorePoolSize();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;int&nbsp;maxPoolSize&nbsp;=&nbsp;executor.getMaximumPoolSize();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;int&nbsp;queueSize&nbsp;=&nbsp;executor.getQueue().size();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;long&nbsp;completedTasks&nbsp;=&nbsp;executor.getCompletedTaskCount();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 2. 递增拒绝计数器
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;long&nbsp;totalRejected&nbsp;=&nbsp;rejectedCount.incrementAndGet();
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 3. 输出警告日志（包含完整指标）
&nbsp; &nbsp; &nbsp; &nbsp; logger.warn("""
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;任务被拒绝执行！线程池状态:
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; |- 活跃线程数/当前线程数: {}/{}
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; |- 核心/最大线程数: {}/{}
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; |- 队列大小: {}
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; |- 已完成任务数: {}
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; |- 历史拒绝总数: {}
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; |- 被拒绝任务: {}
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; """,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; activeThreads, poolSize,
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; corePoolSize, maxPoolSize,
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; queueSize,
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; completedTasks,
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; totalRejected,
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; r.getClass().getName());
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 4. 可选：降级处理（如存入数据库等待重试）
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// fallbackToDatabase(r);
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;// 5. 抛出RejectedExecutionException（保持默认行为）
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;throw&nbsp;new&nbsp;RejectedExecutionException("Task "&nbsp;+ r.toString() +&nbsp;" rejected");
&nbsp; &nbsp; }
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;// 获取累计拒绝次数（用于监控）
&nbsp; &nbsp;&nbsp;public&nbsp;long&nbsp;getRejectedCount()&nbsp;{
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;return&nbsp;rejectedCount.get();
&nbsp; &nbsp; }
}</code></pre>
<ul>
<li><strong>记录日志并告警</strong>：所有的异常处理中，最常见简单的方式无外乎，先记录个日志，然后有告警系统的进行相关的某书、某信以及短信等的告警信息推送，方便开发人员以及运维人员的及时发现问题并介入处理。</li>
<li><strong>兜底处理机制</strong>：一般常见的就是通过异步的方式提交到MQ，然后统一进行兜底处理。</li>
<li><strong>带超时和重试的拒绝</strong>：可以尝试等待一小段时间，或者重试几次提交，如果仍然失败，再执行最终的拒绝逻辑（如告警、持久化或抛异常）。</li>
<li><strong>动态调整策略</strong>：根据系统的负载或任务类型，动态的执行兜底策略机制，就如前面写的源码示例方式。</li>
</ul>
<p><strong>2. 根据自身业务场景选择合适的拒绝策略：</strong></p>
<ul>
<li><strong>核心业务，不容丢失</strong>：如果任务非常重要，不能丢失，可以考虑：
<ul>
<li>CallerRunsPolicy：调用线程承担任务执行压力，是否可支撑；</li>
<li>自定义策略：尝试持久化到MQ或DB，然后由专门的消费组补偿任务处理；</li>
<li>AbortPolicy：如果希望系统快速失败并由上层进行重试或熔断。</li>
<li>&nbsp;</li>
</ul> </li>
<li><strong>非核心业务，可容忍部分丢失</strong>：
<ul>
<li>DiscardOldestPolicy：新任务更重要时，如行情推送；</li>
<li>DiscardPolicy：边缘业务场景，比如一些pv统计等，丢失了无所谓；</li>
<li>及时的进行监控查看，了解任务的丢失情况。</li>
</ul> </li>
</ul>
<p><strong>3. 结合线程池参数综合考虑：</strong></p>
<ul>
<li>拒绝策略的选择也与线程池的队列类型（有界/无界）、队列容量、maximumPoolSize等参数密切相关。</li>
<li>如果使用无界队列LinkedBlockingQueue的无参构造，只有机器内存不够时才会进行拒绝策略，不过这种极端场景已经不是影响线程池本身，内存不够可能导致Java进程被操作系统直接kill可能。</li>
<li>如果使用有界队列，需要权衡队列的大小，核心场景甚至可以动态追踪阻塞队列大小，以及动态调整队列大小来保证核心业务的正常流转。</li>
</ul>
<ol>
<li><strong>充分测试和监控</strong>：无论选择哪种策略，都必须在压测环境中充分测试其行为，并在线上环境建立完善的监控体系，监控线程池的各项指标（活跃线程数、队列长度、任务完成数、任务拒绝数等）。当拒绝发生时，应有相应的告警通知。</li>
</ol>
<p><strong>拒绝策略小结</strong>：</p>
<p>策略的选择跟我们大多数的系统设计哲学是保持一致的，都是在应对不同的场景中，做出一定的trade off。最好的策略需要根据业务场景、系统容忍度、资源等方面的综合考量，<strong>一个黄金的实践原则</strong>：拒绝事件做好监控告警、根据业务SLA定义策略，是否可丢失，快速失败等，定期的进行压力测试，验证策略的有效性。</p>
<h1>5.5 池隔离实践</h1>
<p><strong>核心思想</strong>：根据任务的资源类型 、优先级和业务特性 ，划分多个独立的线程池，避免不同性质的任务相互干扰。</p>
<p><strong>1. 隔离维度</strong>：</p>
<ul>
<li><strong>资源类型</strong>：CPU密集型 vs &nbsp;I/O密集型任务</li>
<li><strong>执行时长</strong>：短时任务（毫秒级） vs 长时任务（分钟级）</li>
<li><strong>实时性要求</strong>：高实时性 vs 可延迟（最终一致即可）</li>
<li><strong>业务重要性</strong>：支付交易（高优先级） vs 日志清理（低优先级）</li>
<li><strong>是否依赖外部资源</strong>：例如，访问特定数据库、调用特定第三方API的任务可以归为一类。</li>
</ul>
<p><strong>2. 不同业务场景线程池独立使用</strong>：在不同的业务场景下，为自己的特定业务，创建独立的线程池。</p>
<ul>
<li><strong>线程命名</strong>：通过ThreadFactory为每个线程池及其线程设置有意义的名称，例如netty-io-compress-pool-%d，excel-export-pool-%d, 主要方便区别不同的业务场景以及问题排查。</li>
<li><strong>参数调优</strong>：不同的业务场景设置不同的参数。
<ul>
<li>corePoolSize, maximumPoolSize：CPU密集型的计算任务可以设置小点减少上下文的切换，I/O密集型可以较大，在io阻塞等待期间，多去处理其他任务。</li>
<li>阻塞队列blockQueue：选择合适的队列类型，以及设置合理的队列大小。</li>
<li>RejectedExecutionHandler：有内置的四种的策略以及自定义策略选择，一般建议做好日志、监控以及兜底的处理。</li>
<li>&nbsp;</li>
</ul> </li>
</ul>
<p><strong>3. 自定义Executor避免线程池共用</strong></p>
<pre><code>// 创建CPU密集型任务线程池（线程数=CPU核心数）
ExecutorService cpuIntensiveExecutor =&nbsp;new&nbsp;ThreadPoolExecutor(
&nbsp; &nbsp; Runtime.getRuntime().availableProcessors(),&nbsp;// 核心线程数=CPU核心数
&nbsp; &nbsp; Runtime.getRuntime().availableProcessors(),&nbsp;// 最大线程数=CPU核心数
&nbsp; &nbsp;&nbsp;30L, TimeUnit.SECONDS,
&nbsp; &nbsp;&nbsp;new&nbsp;LinkedBlockingQueue&lt;&gt;(500),
&nbsp; &nbsp;&nbsp;new&nbsp;ThreadFactoryBuilder()
&nbsp; &nbsp; &nbsp; &nbsp; .setNameFormat("cpu-pool-%d")
&nbsp; &nbsp; &nbsp; &nbsp; .setPriority(Thread.MAX_PRIORITY)&nbsp;// 提高优先级
&nbsp; &nbsp; &nbsp; &nbsp; .build(),
&nbsp; &nbsp;&nbsp;new&nbsp;ThreadPoolExecutor.AbortPolicy()&nbsp;// 直接拒绝
);
// 使用示例
CompletableFuture.supplyAsync(() -&gt; {
&nbsp; &nbsp;&nbsp;// 矩阵计算等CPU密集型任务
&nbsp; &nbsp;&nbsp;double[][] result = matrixMultiply(largeMatrixA, largeMatrixB);
&nbsp; &nbsp;&nbsp;return&nbsp;result;
}, cpuIntensiveExecutor)
.thenAccept(result -&gt; {
&nbsp; &nbsp; System.out.println("计算结果维度: "&nbsp;+ result.length +&nbsp;"x"&nbsp;+ result[0].length);
});</code></pre>
<p><strong>线程池隔离小结</strong>：</p>
<p>专池专用的本质是通过物理隔离实现：</p>
<ul>
<li>资源保障 ：关键业务独占线程资源</li>
<li>故障隔离 ：避免级联雪崩</li>
<li>性能优化 ：针对任务类型最大化吞吐量</li>
</ul>
<p>最终呈现的效果是像专业厨房的分区（切配区/炒菜区/面点区）一样，让每个线程池专注处理同类任务，提升整体效率和可靠性。</p>
<h1>六、总结</h1>
<p>线程池是Java并发编程的核心组件，通过复用线程减少资源开销，提升系统吞吐量。其核心设计包括线程复用机制 、任务队列和拒绝策略 ，通过ThreadPoolExecutor的参数（核心线程数、最大线程数、队列容量等）实现灵活的资源控制。线程池的生命周期由RUNNING、SHUTDOWN等状态管理，确保任务有序执行或终止。</p>
<p>内置线程池（如Executors.newCachedThreadPool）虽便捷，但存在内存溢出或无界队列堆积的风险，需谨慎选择。invokeAll的超时失效和submit提交任务的异常消失是常见陷阱需通过正确处理中断和检查Future.get()规避。</p>
<p>最佳实践包括：</p>
<ul>
<li>异常处理：通过afterExecute来对发生的异常进行兜底处理，任务细粒度的try catch或UncaughtExceptionH捕获异常处理防止线程崩溃退出；</li>
<li>拒绝策略：根据业务选择拒绝策略或自定义降级逻辑，生产级应用建议尽量自定义处理；</li>
<li>线程隔离 ：按任务类型（CPU/I/O）或优先级划分线程池，避免资源竞争。</li>
</ul>
<p>合理使用线程池能显著提升性能，但需结合业务场景精细调参，确保稳定性和可维护性，希望这篇文章能给大家带来一些生产实践上的指导，减少一些因为不熟悉线程池相关原理生产误用导致的一些问题。</p>
<h4>往期回顾</h4>
<p>1.&nbsp;基于浏览器扩展 API Mock 工具开发探索｜得物技术</p>
<p>2.&nbsp;破解gh-ost变更导致MySQL表膨胀之谜｜得物技术</p>
<p>3.&nbsp;MySQL单表为何别超2000万行？揭秘B+树与16KB页的生死博弈｜得物技术</p>
<p>4.&nbsp;0基础带你精通Java对象序列化--以Hessian为例｜得物技术</p>
<p>5.&nbsp;前端日志回捞系统的性能优化实践｜得物技术</p>
<h4>文 /舍得</h4>
<p>关注得物技术，每周更新技术干货</p>
<p>要是觉得文章对你有帮助的话，欢迎评论转发点赞～</p>
<p>未经得物技术许可严禁转载，否则依法追究法律责任。</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-10e0261f0e.jpg"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-10e0261f0e.jpg" medium="image"/>
    <pubDate>Tue, 14 Oct 2025 14:59:05 +0800</pubDate>
  </item><item>
    <title><![CDATA[苹果将在 ICCV 2025 展示多项前沿视觉研究成果]]></title>
    <link>https://www.oschina.net/news/377355/apple-at-iccv-2025</link>
    <itunes:title><![CDATA[苹果将在 ICCV 2025 展示多项前沿视觉研究成果]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>苹果<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmachinelearning.apple.com%2Fupdates%2Fapple-at-iccv-2025" target="_blank">宣布</a>将携多篇论文亮相<strong> 2025 年国际计算机视觉大会（ICCV 2025）</strong>，展现其在<strong>多模态 AI、图像生成与视频理解</strong>等领域的研究实力。大会将于 10 月 19 日至 23 日在夏威夷檀香山举行。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-a28fbc2140.png"></p>
<p>今年，苹果共有<strong>八篇论文</strong> 入选大会，涵盖从文本生成视频的评估方法、三维空间理解、多模态模型的扩展规律，到图像生成与编辑的统一扩散模型等前沿方向。其中包括：</p>
<ul>
<li> <p><strong>ETVA</strong>：一种评估文本与视频对齐度的新方法；</p> </li>
<li> <p><strong>MM-Spatial</strong>：探索多模态大模型的 3D 空间理解能力；</p> </li>
<li> <p><strong>Scaling Laws for Native Multimodal Models</strong>：研究多模态模型的扩展规律；</p> </li>
<li> <p><strong>Stable Diffusion Models are Secretly Good at Visual In-Context Learning</strong>：揭示稳定扩散模型在视觉上下文学习中的潜力；</p> </li>
<li> <p><strong>UniVG</strong>：面向统一图像生成与编辑的通用扩散模型；</p> </li>
<li> <p>以及面向交互式智能体评测的 <strong>UINavBench</strong> 等研究。</p> </li>
</ul>
<p>此外，苹果应用研究经理 <strong>Dr. C. Thomas</strong> 将在大会的工业视觉检测专题中发表主旨演讲。苹果研究团队成员 <strong>Patricia Vitoria Carrera</strong> 与 <strong>Tanya Glozman</strong> 也将参与 “女性在计算机视觉”<em>（<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsites.google.com%2Fview%2Fwicv-iccv-2025" target="_blank">Women in Computer Vision (WiCV) Workshop</a>）</em>工作坊担任导师，支持学术多元化。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>苹果<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmachinelearning.apple.com%2Fupdates%2Fapple-at-iccv-2025" target="_blank">宣布</a>将携多篇论文亮相<strong> 2025 年国际计算机视觉大会（ICCV 2025）</strong>，展现其在<strong>多模态 AI、图像生成与视频理解</strong>等领域的研究实力。大会将于 10 月 19 日至 23 日在夏威夷檀香山举行。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-a28fbc2140.png"></p>
<p>今年，苹果共有<strong>八篇论文</strong> 入选大会，涵盖从文本生成视频的评估方法、三维空间理解、多模态模型的扩展规律，到图像生成与编辑的统一扩散模型等前沿方向。其中包括：</p>
<ul>
<li> <p><strong>ETVA</strong>：一种评估文本与视频对齐度的新方法；</p> </li>
<li> <p><strong>MM-Spatial</strong>：探索多模态大模型的 3D 空间理解能力；</p> </li>
<li> <p><strong>Scaling Laws for Native Multimodal Models</strong>：研究多模态模型的扩展规律；</p> </li>
<li> <p><strong>Stable Diffusion Models are Secretly Good at Visual In-Context Learning</strong>：揭示稳定扩散模型在视觉上下文学习中的潜力；</p> </li>
<li> <p><strong>UniVG</strong>：面向统一图像生成与编辑的通用扩散模型；</p> </li>
<li> <p>以及面向交互式智能体评测的 <strong>UINavBench</strong> 等研究。</p> </li>
</ul>
<p>此外，苹果应用研究经理 <strong>Dr. C. Thomas</strong> 将在大会的工业视觉检测专题中发表主旨演讲。苹果研究团队成员 <strong>Patricia Vitoria Carrera</strong> 与 <strong>Tanya Glozman</strong> 也将参与 “女性在计算机视觉”<em>（<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsites.google.com%2Fview%2Fwicv-iccv-2025" target="_blank">Women in Computer Vision (WiCV) Workshop</a>）</em>工作坊担任导师，支持学术多元化。</p>]]>
    </description>
    <content:encoded><![CDATA[<p>苹果<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmachinelearning.apple.com%2Fupdates%2Fapple-at-iccv-2025" target="_blank">宣布</a>将携多篇论文亮相<strong> 2025 年国际计算机视觉大会（ICCV 2025）</strong>，展现其在<strong>多模态 AI、图像生成与视频理解</strong>等领域的研究实力。大会将于 10 月 19 日至 23 日在夏威夷檀香山举行。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-a28fbc2140.png"></p>
<p>今年，苹果共有<strong>八篇论文</strong> 入选大会，涵盖从文本生成视频的评估方法、三维空间理解、多模态模型的扩展规律，到图像生成与编辑的统一扩散模型等前沿方向。其中包括：</p>
<ul>
<li> <p><strong>ETVA</strong>：一种评估文本与视频对齐度的新方法；</p> </li>
<li> <p><strong>MM-Spatial</strong>：探索多模态大模型的 3D 空间理解能力；</p> </li>
<li> <p><strong>Scaling Laws for Native Multimodal Models</strong>：研究多模态模型的扩展规律；</p> </li>
<li> <p><strong>Stable Diffusion Models are Secretly Good at Visual In-Context Learning</strong>：揭示稳定扩散模型在视觉上下文学习中的潜力；</p> </li>
<li> <p><strong>UniVG</strong>：面向统一图像生成与编辑的通用扩散模型；</p> </li>
<li> <p>以及面向交互式智能体评测的 <strong>UINavBench</strong> 等研究。</p> </li>
</ul>
<p>此外，苹果应用研究经理 <strong>Dr. C. Thomas</strong> 将在大会的工业视觉检测专题中发表主旨演讲。苹果研究团队成员 <strong>Patricia Vitoria Carrera</strong> 与 <strong>Tanya Glozman</strong> 也将参与 “女性在计算机视觉”<em>（<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsites.google.com%2Fview%2Fwicv-iccv-2025" target="_blank">Women in Computer Vision (WiCV) Workshop</a>）</em>工作坊担任导师，支持学术多元化。</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-a28fbc2140.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-a28fbc2140.png" medium="image"/>
    <pubDate>Tue, 14 Oct 2025 14:48:30 +0800</pubDate>
  </item><item>
    <title><![CDATA[微软发布首款自主开发图像生成模型 MAI-Image-1]]></title>
    <link>https://www.oschina.net/news/377352/microsoft-ai-mai-image-1-debuting-in-the-top-10-on-lmarena</link>
    <itunes:title><![CDATA[微软发布首款自主开发图像生成模型 MAI-Image-1]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>微软正式推出其首个完全自主研发的图像生成模型 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmicrosoft.ai%2Fnews%2Fintroducing-mai-image-1-debuting-in-the-top-10-on-lmarena%2F" target="_blank">MAI-Image-1</a>，并在知名 AI 模型评测平台 LMArena 上首次亮相就进入了文本到图像模型的 Top 10 排行（<em>https://lmarena.ai/leaderboard/text-to-image</em>）。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-0bba5f7d39.png"></p>
<p>据介绍，MAI-Image-1 专注于高保真、真实感图像生成，能够在光照、细节和构图等方面展现出强大表现，同时兼顾生成速度与效率。微软称该模型的目标是让创作者能以更自然的方式，将文字想法快速转化为视觉作品。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-20979b94b0.png"></p>
<p>该模型目前已在 LMArena 上开放测试，微软计划根据社区反馈持续优化，并逐步将其集成到 Copilot、Bing Image Creator 等产品中。微软强调，MAI-Image-1 的开发遵循负责任的 AI 原则，确保内容生成的安全与合规。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>微软正式推出其首个完全自主研发的图像生成模型 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmicrosoft.ai%2Fnews%2Fintroducing-mai-image-1-debuting-in-the-top-10-on-lmarena%2F" target="_blank">MAI-Image-1</a>，并在知名 AI 模型评测平台 LMArena 上首次亮相就进入了文本到图像模型的 Top 10 排行（<em>https://lmarena.ai/leaderboard/text-to-image</em>）。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-0bba5f7d39.png"></p>
<p>据介绍，MAI-Image-1 专注于高保真、真实感图像生成，能够在光照、细节和构图等方面展现出强大表现，同时兼顾生成速度与效率。微软称该模型的目标是让创作者能以更自然的方式，将文字想法快速转化为视觉作品。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-20979b94b0.png"></p>
<p>该模型目前已在 LMArena 上开放测试，微软计划根据社区反馈持续优化，并逐步将其集成到 Copilot、Bing Image Creator 等产品中。微软强调，MAI-Image-1 的开发遵循负责任的 AI 原则，确保内容生成的安全与合规。</p>]]>
    </description>
    <content:encoded><![CDATA[<p>微软正式推出其首个完全自主研发的图像生成模型 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmicrosoft.ai%2Fnews%2Fintroducing-mai-image-1-debuting-in-the-top-10-on-lmarena%2F" target="_blank">MAI-Image-1</a>，并在知名 AI 模型评测平台 LMArena 上首次亮相就进入了文本到图像模型的 Top 10 排行（<em>https://lmarena.ai/leaderboard/text-to-image</em>）。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-0bba5f7d39.png"></p>
<p>据介绍，MAI-Image-1 专注于高保真、真实感图像生成，能够在光照、细节和构图等方面展现出强大表现，同时兼顾生成速度与效率。微软称该模型的目标是让创作者能以更自然的方式，将文字想法快速转化为视觉作品。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-20979b94b0.png"></p>
<p>该模型目前已在 LMArena 上开放测试，微软计划根据社区反馈持续优化，并逐步将其集成到 Copilot、Bing Image Creator 等产品中。微软强调，MAI-Image-1 的开发遵循负责任的 AI 原则，确保内容生成的安全与合规。</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-0bba5f7d39.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-0bba5f7d39.png" medium="image"/>
    <pubDate>Tue, 14 Oct 2025 14:40:07 +0800</pubDate>
  </item><item>
    <title><![CDATA[中国农业大学发布神农大模型 3.0]]></title>
    <link>https://www.oschina.net/news/377346</link>
    <itunes:title><![CDATA[中国农业大学发布神农大模型 3.0]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p><span>中国农业大学发布神农大模型3.0。这是目前全国覆盖农业学科和场景最全的大模型，具备农业知识问答、生产决策推理等功能，标志着我国农业人工智能发展迈入新阶段。</span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-a7bf8ea13a.png"></p>
<p><span>此前，神农大模型1.0主要实现农业知识问答，神农大模型2.0主要具备多模态能力并向农业应用延伸。此次发布的神农大模型3.0则聚焦36个农业智能体，模型以“小体积、高智能、低成本”为核心突破，推出32B、7B、1B三个版本，通过动态稀疏机制与增量压缩技术实现模型算力缩小50%，同时关键任务性能损失低于1%，全面推动农业AI从“能用”向“好用、普惠”跃升。</span></p>
<p><span>团队同步推出“神农大模型智能体平台”，构建覆盖农业全链路的轻量级、可部署、可协同的AI应用生态。平台深度融合神农大模型3.0，兼容主流通用大模型，支持智能体在端、边、云环境中跨平台灵活部署。现已上线智慧育种、智慧种植、智慧养殖、遥感气象、智慧教育等六大类共36个智能体，提供低代码开发工具，支持快速构建与迭代智能体，兼容30多种编程语言开发的应用程序接入，并遵循MCP服务协议实现知识库与结构化数据的便捷接入。智能体间支持相互调用与通信，形成任务协同网络，推动农业AI从“单点智能”走向“系统智能”。</span></p>
<p><span>同时，三款专用一体机业同步推出——“神农-启航”（适配1B模型）、“神农-拓疆”（适配7B模型）与“神农-至臻”（适配32B模型）。一体机支持完全断网运行，具备“开箱即用”特性，确保农业数据不出本地，大幅提升数据隐私与作业安全性。其三防设计（防水、防尘、防震）适配田间地头、温室大棚、加工车间等恶劣环境，为农业用户提供软硬一体、自主可控的轻量化AI解决方案。</span></p>
<p><span>目前，神农大模型已在北京周边、内蒙古、黑龙江等地区推广应用，服务用户超10万人。</span></p>
<p><span>中国农大介绍，大模型以“神农”命名，是对神农氏这一农业之神和医药之祖的致敬，也是对中华优秀传统农耕文化的传承和弘扬。未来，学校还将持续对大模型开展研发升级，让它在更大范围内普惠落地。</span></p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p><span>中国农业大学发布神农大模型3.0。这是目前全国覆盖农业学科和场景最全的大模型，具备农业知识问答、生产决策推理等功能，标志着我国农业人工智能发展迈入新阶段。</span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-a7bf8ea13a.png"></p>
<p><span>此前，神农大模型1.0主要实现农业知识问答，神农大模型2.0主要具备多模态能力并向农业应用延伸。此次发布的神农大模型3.0则聚焦36个农业智能体，模型以“小体积、高智能、低成本”为核心突破，推出32B、7B、1B三个版本，通过动态稀疏机制与增量压缩技术实现模型算力缩小50%，同时关键任务性能损失低于1%，全面推动农业AI从“能用”向“好用、普惠”跃升。</span></p>
<p><span>团队同步推出“神农大模型智能体平台”，构建覆盖农业全链路的轻量级、可部署、可协同的AI应用生态。平台深度融合神农大模型3.0，兼容主流通用大模型，支持智能体在端、边、云环境中跨平台灵活部署。现已上线智慧育种、智慧种植、智慧养殖、遥感气象、智慧教育等六大类共36个智能体，提供低代码开发工具，支持快速构建与迭代智能体，兼容30多种编程语言开发的应用程序接入，并遵循MCP服务协议实现知识库与结构化数据的便捷接入。智能体间支持相互调用与通信，形成任务协同网络，推动农业AI从“单点智能”走向“系统智能”。</span></p>
<p><span>同时，三款专用一体机业同步推出——“神农-启航”（适配1B模型）、“神农-拓疆”（适配7B模型）与“神农-至臻”（适配32B模型）。一体机支持完全断网运行，具备“开箱即用”特性，确保农业数据不出本地，大幅提升数据隐私与作业安全性。其三防设计（防水、防尘、防震）适配田间地头、温室大棚、加工车间等恶劣环境，为农业用户提供软硬一体、自主可控的轻量化AI解决方案。</span></p>
<p><span>目前，神农大模型已在北京周边、内蒙古、黑龙江等地区推广应用，服务用户超10万人。</span></p>
<p><span>中国农大介绍，大模型以“神农”命名，是对神农氏这一农业之神和医药之祖的致敬，也是对中华优秀传统农耕文化的传承和弘扬。未来，学校还将持续对大模型开展研发升级，让它在更大范围内普惠落地。</span></p>]]>
    </description>
    <content:encoded><![CDATA[<p><span>中国农业大学发布神农大模型3.0。这是目前全国覆盖农业学科和场景最全的大模型，具备农业知识问答、生产决策推理等功能，标志着我国农业人工智能发展迈入新阶段。</span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-a7bf8ea13a.png"></p>
<p><span>此前，神农大模型1.0主要实现农业知识问答，神农大模型2.0主要具备多模态能力并向农业应用延伸。此次发布的神农大模型3.0则聚焦36个农业智能体，模型以“小体积、高智能、低成本”为核心突破，推出32B、7B、1B三个版本，通过动态稀疏机制与增量压缩技术实现模型算力缩小50%，同时关键任务性能损失低于1%，全面推动农业AI从“能用”向“好用、普惠”跃升。</span></p>
<p><span>团队同步推出“神农大模型智能体平台”，构建覆盖农业全链路的轻量级、可部署、可协同的AI应用生态。平台深度融合神农大模型3.0，兼容主流通用大模型，支持智能体在端、边、云环境中跨平台灵活部署。现已上线智慧育种、智慧种植、智慧养殖、遥感气象、智慧教育等六大类共36个智能体，提供低代码开发工具，支持快速构建与迭代智能体，兼容30多种编程语言开发的应用程序接入，并遵循MCP服务协议实现知识库与结构化数据的便捷接入。智能体间支持相互调用与通信，形成任务协同网络，推动农业AI从“单点智能”走向“系统智能”。</span></p>
<p><span>同时，三款专用一体机业同步推出——“神农-启航”（适配1B模型）、“神农-拓疆”（适配7B模型）与“神农-至臻”（适配32B模型）。一体机支持完全断网运行，具备“开箱即用”特性，确保农业数据不出本地，大幅提升数据隐私与作业安全性。其三防设计（防水、防尘、防震）适配田间地头、温室大棚、加工车间等恶劣环境，为农业用户提供软硬一体、自主可控的轻量化AI解决方案。</span></p>
<p><span>目前，神农大模型已在北京周边、内蒙古、黑龙江等地区推广应用，服务用户超10万人。</span></p>
<p><span>中国农大介绍，大模型以“神农”命名，是对神农氏这一农业之神和医药之祖的致敬，也是对中华优秀传统农耕文化的传承和弘扬。未来，学校还将持续对大模型开展研发升级，让它在更大范围内普惠落地。</span></p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-a7bf8ea13a.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-a7bf8ea13a.png" medium="image"/>
    <pubDate>Tue, 14 Oct 2025 14:20:20 +0800</pubDate>
  </item><item>
    <title><![CDATA[团结引擎 1.7.1 preview 发布]]></title>
    <link>https://www.oschina.net/news/377344/unity-tuanjie-1-7-1-preview</link>
    <itunes:title><![CDATA[团结引擎 1.7.1 preview 发布]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>团结引擎 1.7.1 preview 已发布！本次技术更新涵盖渲染（Rendering）、实时动态全局光照系统（TuanjieGI）、团结粒子系统（Particle System）、团结动画系统（Animation）、ShaderGraph、Content Pipeline、 小游戏（MiniGame) 以及 Platform 几大方向。</p>
<h3><strong>渲染（Rendering）</strong></h3>
<p>在1.7.1 preview 版本中做了如下更新：</p>
<h4><strong>虚拟几何体功能支持通用渲染管线（URP）：</strong></h4>
<p>在 Tuanjie 1.7.1 preview 中，虚拟几何体功能进一步拓展了对团结引擎已有渲染管线的支持。重新设计模型的导入设置 UI，为开发者带来更优的模型导入使用体验。优化虚拟几何体执行效率，提升渲染性能。</p>
<ul>
<li>虚拟几何体功能现已支持团结引擎的通用渲染管线（URP），为其带来了同屏实时流畅渲染上亿三角形的能力。</li>
</ul>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6c864d82f1.png"></p>
<ul>
<li>使用虚拟几何体的渲染方式优化阴影绘制过程，使用 GPU 剔除，以 Multi View 的方式绘制光源所有的 Cascade，大幅减少阴影绘制所需的 Draw Call 数量。</li>
<li>进一步优化虚拟几何体的 CPU 和 GPU 执行效率，提升渲染性能。提供固定压缩比例的 Cluster 数据编码方式，获取更好的 GPU 性能。</li>
<li>重新设计的模型导入设置 UI，为开发者提供了更方便快捷管理的跨平台设置调整虚拟几何体导入参数的工作流。</li>
</ul>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-7fec8d849a.png"></p>
<p>更多使用指南参考 Tuanjie 虚拟几何体手册： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.unity.cn%2Fcn%2Ftuanjiemanual%2FManual%2FVirtualGeometry.html" target="_blank">https://docs.unity.cn/cn/tuanjiemanual/Manual/VirtualGeometry.html</a></p>
<h3><strong>实时动态全局光照（TuanjieGI）</strong></h3>
<p>在 Tuanjie 1.7.1 preview 中对实时动态全局光照系统做了以下功能改进：</p>
<ul>
<li><strong>新增 TuanjieGI 参数调节功能，通过 Volume Profile 提供灵活的参数配置管理，使开发者能够精细化调整全局或局部光照效果。</strong>开发者可自由调节直接光、天光及自发光在反弹后的颜色系数，并对最终计算出的间接光进行优化。借助该功能，开发者能够便捷地控制间接光照强度及颜色，打造理想的光线氛围</li>
<li><strong>新增可视化调试器，便于开发者调试实时光照效果</strong>，可通过 Window &gt; Analysis &gt; Rendering Debugger &gt; TuanjieGI 快速体验。</li>
<li><strong>新增 Screen Tracing 功能</strong>，利用屏幕空间信息模拟光线追踪效果，可通过 Volume Profile 控制开启或关闭。</li>
<li>支持 4K 及更高分辨率输出。</li>
<li>优化渲染性能并降低显存占用。</li>
</ul>
<p>获取 TuanjieGI 官方 Demo：</p>
<blockquote>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpackages.cdn.unity.cn%2Fgi%2FTuanjieGI_Demo_Tower_171.zip" target="_blank">https://packages.cdn.unity.cn/gi/TuanjieGI_Demo_Tower_171.zip</a></p>
</blockquote>
<blockquote>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcnb.cool%2Ftuanjie%2FTuanjieGI_Demo_Tower" target="_blank">https://cnb.cool/tuanjie/TuanjieGI_Demo_Tower</a></p>
</blockquote>
<p>更多使用指南参考 TuanjieGI 手册：</p>
<blockquote>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.unity.cn%2Fcn%2Ftuanjiemanual%2FManual%2FTuanjieGI.html" target="_blank">https://docs.unity.cn/cn/tuanjiemanual/Manual/TuanjieGI.html</a></p>
</blockquote>
<h3><strong>团结动画系统 (Animation）</strong></h3>
<p>在 Tuanjie 1.7.1 preview 中，团结动画系统在 1.7.0_preview 推出的 AnimGraph 和 IK&amp;Retargeter 模块的基础上持续进行升级、优化，主要包括：</p>
<ul>
<li><strong>全新推出 RigGraph（骨骼程序化绑定编辑器）</strong>，通过可视化界面进行模型骨骼绑定，支持一键生成高级骨骼绑定方案或自定义控制器进行个性化模型绑定</li>
<li><strong>升级 AnimGraph</strong>，包括添加反射 Missing 检测、Node Binding 等功能和 ApplyAdditive Node、Constraints Node、Mirror Node 等节点，提升使用体验；</li>
<li><strong>IK&amp;Retargeter 中新增基于 PBD 的 Fullbody IK 功能</strong>，同时修复了一系列 preview 版本中的异常，在前一版本基础上优化、提升了 Editor 的使用。</li>
</ul>
<p>更多使用指南参考 Tuanjie Animation 用户手册：</p>
<blockquote>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.unity.cn%2Fcn%2Ftuanjiemanual%2FManual%2FAnimation-whats-new.html" target="_blank">https://docs.unity.cn/cn/tuanjiemanual/Manual/Animation-whats-new.html</a></p>
</blockquote>
<h3><strong>团结粒子系统（Particle System)</strong></h3>
<p>在 Tuanjie 1.7.1 preview 中，优化了 Infinity 粒子系统的性能。按以下步骤即可快速体验：</p>
<p>1.打开或新建一个 URP 项目（未来将支持 HDRP 管线）。</p>
<p>2.打开 <strong>Package Manager</strong>，点击左上角的 <strong>+</strong> 图标，选择 <strong>Add package by name</strong>，输入 cn.tuanjie.infinity 并安装。</p>
<p>3.在 <strong>Hierarchy</strong> 面板中右键单击，从 <strong>Effects</strong> 折叠菜单中选择 <strong>Infinity Particle System</strong>，即可向场景添加粒子系统。其操作方式与内置粒子系统保持一致。</p>
<p>4.通过菜单 <strong>Tools &gt; Convert Particle System to Infinity</strong>，可轻松迁移现有粒子系统资产。</p>
<p>更多使用指南参阅文档 :</p>
<blockquote>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.unity.cn%2Fcn%2FPackages-cn%2Fcn.tuanjie.infinity%401.2%2Fmanual%2F" target="_blank">https://docs.unity.cn/cn/Packages-cn/cn.tuanjie.infinity@1.2/manual/</a></p>
</blockquote>
<h3><strong>Shader Graph</strong></h3>
<p>在本次更新中进行了如下优化：</p>
<h4><strong>易用性优化</strong></h4>
<p>在最新版本的团结引擎 Shader Graph 中对 <strong>Portal Nodes（入口/出口节点）</strong> 的快捷创建功能进行了优化，让开发者的工作流更加高效、直观。</p>
<ul>
<li>一键生成多个 Get Var Node，自动贴近端口</li>
</ul>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-c28a5b5f1e.gif"></p>
<ul>
<li>新建 Group 智能命名：框选若干与 Register 节点相连的节点，右键选择 Group Selection 或直接按 Ctrl + G，新建的 Group 框顶部会自动显示其中 Register 节点的变量名集合，省去手动修改。</li>
</ul>
<h4><strong>Scalable Lit 支持 Custom Pass</strong></h4>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-c9dd92f793.png"></p>
<p>在新版本中，用户可以在 Scalable Lit 单个 Shader Graph中定义和配置多个 Pass。每个自定义 Pass 拥有独立的顶点和片段着色器，并可配置其渲染状态（如混合模式、深度测试等）。上图展示了使用多 Pass 可实现一些特定的渲染效果。</p>
<h4><strong>支持URP Stencil Test</strong></h4>
<p>现在可在 Shader Graph 中直接使用和配置 Stencil Buffer。方便快速实现游戏中常用的遮挡描边/透视效果。</p>
<h3><strong>Content Pipeline</strong></h3>
<p>在 Tuaniie 1.7.1 preview 版本中，深入理解开发者对 <strong>Instant Asset</strong> 功能模块的体验和建议，并进行了多项升级：</p>
<ul>
<li> <p><strong>新增 Instant Asset 场景资产构建与编辑器模拟运行</strong>：支持场景资产构建能力，同时支持了在编辑器中直接模拟运行测试，加速项目开发迭代流程；</p> </li>
<li> <p><strong>新增 Instant Asset 资源表管理接口与确定性资产构建</strong>：支持资源表合并、Diff 接口和确定性资产构建机制，确保增量构建精准高效，完美适配热更新等第三方解决方案，轻松应对复杂项目兼容挑战。</p> </li>
</ul>
<h3><strong>小游戏（MiniGame）</strong></h3>
<p>在 Tuanjie 1.7.1 preview 版本中，团结引擎小游戏平台<strong>新增了对 TapTap 子平台的支持。</strong>此次更新进一步扩展了平台发布能力，对 TapTap 子平台的构建支持，使开发者能够更便捷地发布游戏至 TapTap 平台，触达更广泛的玩家群体。</p>
<h3><strong>Platform</strong></h3>
<h4><strong>OpenHarmony 平台</strong></h4>
<ul>
<li>更完善的 UAAL 模式，从 1.7.1 的版本开始，导出工程的 ETS 代码会被封装到 har 包里面去，并且 Default 的模式不再提供，UAAL 成为 Default 模式。模块集成到原生应用更加的便捷。</li>
<li>新增蓝牙键盘鼠标支持，可在 PC/平板中使用该能力。</li>
<li>Webview 接口新增 registerJavaScriptProxy API 和 border 属性相关 API。</li>
<li>新增 Strip Engine Code 支持，进一步降低包体占用。</li>
<li>开发工具上，除了此前支持的 ARM 架构 DevEco Studio 的 Emulator，完善了 x64 架构适配支持。目前 DevEco Studio 的 Emulator 可以在 Window 跟 Mac 上均可流畅使用。</li>
</ul>
<p>更多详情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.unity.cn%2Fprojects%2F68e72ddcedbc2a001ec6b74e" target="_blank">查看官方公告</a>。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>团结引擎 1.7.1 preview 已发布！本次技术更新涵盖渲染（Rendering）、实时动态全局光照系统（TuanjieGI）、团结粒子系统（Particle System）、团结动画系统（Animation）、ShaderGraph、Content Pipeline、 小游戏（MiniGame) 以及 Platform 几大方向。</p>
<h3><strong>渲染（Rendering）</strong></h3>
<p>在1.7.1 preview 版本中做了如下更新：</p>
<h4><strong>虚拟几何体功能支持通用渲染管线（URP）：</strong></h4>
<p>在 Tuanjie 1.7.1 preview 中，虚拟几何体功能进一步拓展了对团结引擎已有渲染管线的支持。重新设计模型的导入设置 UI，为开发者带来更优的模型导入使用体验。优化虚拟几何体执行效率，提升渲染性能。</p>
<ul>
<li>虚拟几何体功能现已支持团结引擎的通用渲染管线（URP），为其带来了同屏实时流畅渲染上亿三角形的能力。</li>
</ul>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6c864d82f1.png"></p>
<ul>
<li>使用虚拟几何体的渲染方式优化阴影绘制过程，使用 GPU 剔除，以 Multi View 的方式绘制光源所有的 Cascade，大幅减少阴影绘制所需的 Draw Call 数量。</li>
<li>进一步优化虚拟几何体的 CPU 和 GPU 执行效率，提升渲染性能。提供固定压缩比例的 Cluster 数据编码方式，获取更好的 GPU 性能。</li>
<li>重新设计的模型导入设置 UI，为开发者提供了更方便快捷管理的跨平台设置调整虚拟几何体导入参数的工作流。</li>
</ul>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-7fec8d849a.png"></p>
<p>更多使用指南参考 Tuanjie 虚拟几何体手册： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.unity.cn%2Fcn%2Ftuanjiemanual%2FManual%2FVirtualGeometry.html" target="_blank">https://docs.unity.cn/cn/tuanjiemanual/Manual/VirtualGeometry.html</a></p>
<h3><strong>实时动态全局光照（TuanjieGI）</strong></h3>
<p>在 Tuanjie 1.7.1 preview 中对实时动态全局光照系统做了以下功能改进：</p>
<ul>
<li><strong>新增 TuanjieGI 参数调节功能，通过 Volume Profile 提供灵活的参数配置管理，使开发者能够精细化调整全局或局部光照效果。</strong>开发者可自由调节直接光、天光及自发光在反弹后的颜色系数，并对最终计算出的间接光进行优化。借助该功能，开发者能够便捷地控制间接光照强度及颜色，打造理想的光线氛围</li>
<li><strong>新增可视化调试器，便于开发者调试实时光照效果</strong>，可通过 Window &gt; Analysis &gt; Rendering Debugger &gt; TuanjieGI 快速体验。</li>
<li><strong>新增 Screen Tracing 功能</strong>，利用屏幕空间信息模拟光线追踪效果，可通过 Volume Profile 控制开启或关闭。</li>
<li>支持 4K 及更高分辨率输出。</li>
<li>优化渲染性能并降低显存占用。</li>
</ul>
<p>获取 TuanjieGI 官方 Demo：</p>
<blockquote>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpackages.cdn.unity.cn%2Fgi%2FTuanjieGI_Demo_Tower_171.zip" target="_blank">https://packages.cdn.unity.cn/gi/TuanjieGI_Demo_Tower_171.zip</a></p>
</blockquote>
<blockquote>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcnb.cool%2Ftuanjie%2FTuanjieGI_Demo_Tower" target="_blank">https://cnb.cool/tuanjie/TuanjieGI_Demo_Tower</a></p>
</blockquote>
<p>更多使用指南参考 TuanjieGI 手册：</p>
<blockquote>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.unity.cn%2Fcn%2Ftuanjiemanual%2FManual%2FTuanjieGI.html" target="_blank">https://docs.unity.cn/cn/tuanjiemanual/Manual/TuanjieGI.html</a></p>
</blockquote>
<h3><strong>团结动画系统 (Animation）</strong></h3>
<p>在 Tuanjie 1.7.1 preview 中，团结动画系统在 1.7.0_preview 推出的 AnimGraph 和 IK&amp;Retargeter 模块的基础上持续进行升级、优化，主要包括：</p>
<ul>
<li><strong>全新推出 RigGraph（骨骼程序化绑定编辑器）</strong>，通过可视化界面进行模型骨骼绑定，支持一键生成高级骨骼绑定方案或自定义控制器进行个性化模型绑定</li>
<li><strong>升级 AnimGraph</strong>，包括添加反射 Missing 检测、Node Binding 等功能和 ApplyAdditive Node、Constraints Node、Mirror Node 等节点，提升使用体验；</li>
<li><strong>IK&amp;Retargeter 中新增基于 PBD 的 Fullbody IK 功能</strong>，同时修复了一系列 preview 版本中的异常，在前一版本基础上优化、提升了 Editor 的使用。</li>
</ul>
<p>更多使用指南参考 Tuanjie Animation 用户手册：</p>
<blockquote>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.unity.cn%2Fcn%2Ftuanjiemanual%2FManual%2FAnimation-whats-new.html" target="_blank">https://docs.unity.cn/cn/tuanjiemanual/Manual/Animation-whats-new.html</a></p>
</blockquote>
<h3><strong>团结粒子系统（Particle System)</strong></h3>
<p>在 Tuanjie 1.7.1 preview 中，优化了 Infinity 粒子系统的性能。按以下步骤即可快速体验：</p>
<p>1.打开或新建一个 URP 项目（未来将支持 HDRP 管线）。</p>
<p>2.打开 <strong>Package Manager</strong>，点击左上角的 <strong>+</strong> 图标，选择 <strong>Add package by name</strong>，输入 cn.tuanjie.infinity 并安装。</p>
<p>3.在 <strong>Hierarchy</strong> 面板中右键单击，从 <strong>Effects</strong> 折叠菜单中选择 <strong>Infinity Particle System</strong>，即可向场景添加粒子系统。其操作方式与内置粒子系统保持一致。</p>
<p>4.通过菜单 <strong>Tools &gt; Convert Particle System to Infinity</strong>，可轻松迁移现有粒子系统资产。</p>
<p>更多使用指南参阅文档 :</p>
<blockquote>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.unity.cn%2Fcn%2FPackages-cn%2Fcn.tuanjie.infinity%401.2%2Fmanual%2F" target="_blank">https://docs.unity.cn/cn/Packages-cn/cn.tuanjie.infinity@1.2/manual/</a></p>
</blockquote>
<h3><strong>Shader Graph</strong></h3>
<p>在本次更新中进行了如下优化：</p>
<h4><strong>易用性优化</strong></h4>
<p>在最新版本的团结引擎 Shader Graph 中对 <strong>Portal Nodes（入口/出口节点）</strong> 的快捷创建功能进行了优化，让开发者的工作流更加高效、直观。</p>
<ul>
<li>一键生成多个 Get Var Node，自动贴近端口</li>
</ul>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-c28a5b5f1e.gif"></p>
<ul>
<li>新建 Group 智能命名：框选若干与 Register 节点相连的节点，右键选择 Group Selection 或直接按 Ctrl + G，新建的 Group 框顶部会自动显示其中 Register 节点的变量名集合，省去手动修改。</li>
</ul>
<h4><strong>Scalable Lit 支持 Custom Pass</strong></h4>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-c9dd92f793.png"></p>
<p>在新版本中，用户可以在 Scalable Lit 单个 Shader Graph中定义和配置多个 Pass。每个自定义 Pass 拥有独立的顶点和片段着色器，并可配置其渲染状态（如混合模式、深度测试等）。上图展示了使用多 Pass 可实现一些特定的渲染效果。</p>
<h4><strong>支持URP Stencil Test</strong></h4>
<p>现在可在 Shader Graph 中直接使用和配置 Stencil Buffer。方便快速实现游戏中常用的遮挡描边/透视效果。</p>
<h3><strong>Content Pipeline</strong></h3>
<p>在 Tuaniie 1.7.1 preview 版本中，深入理解开发者对 <strong>Instant Asset</strong> 功能模块的体验和建议，并进行了多项升级：</p>
<ul>
<li> <p><strong>新增 Instant Asset 场景资产构建与编辑器模拟运行</strong>：支持场景资产构建能力，同时支持了在编辑器中直接模拟运行测试，加速项目开发迭代流程；</p> </li>
<li> <p><strong>新增 Instant Asset 资源表管理接口与确定性资产构建</strong>：支持资源表合并、Diff 接口和确定性资产构建机制，确保增量构建精准高效，完美适配热更新等第三方解决方案，轻松应对复杂项目兼容挑战。</p> </li>
</ul>
<h3><strong>小游戏（MiniGame）</strong></h3>
<p>在 Tuanjie 1.7.1 preview 版本中，团结引擎小游戏平台<strong>新增了对 TapTap 子平台的支持。</strong>此次更新进一步扩展了平台发布能力，对 TapTap 子平台的构建支持，使开发者能够更便捷地发布游戏至 TapTap 平台，触达更广泛的玩家群体。</p>
<h3><strong>Platform</strong></h3>
<h4><strong>OpenHarmony 平台</strong></h4>
<ul>
<li>更完善的 UAAL 模式，从 1.7.1 的版本开始，导出工程的 ETS 代码会被封装到 har 包里面去，并且 Default 的模式不再提供，UAAL 成为 Default 模式。模块集成到原生应用更加的便捷。</li>
<li>新增蓝牙键盘鼠标支持，可在 PC/平板中使用该能力。</li>
<li>Webview 接口新增 registerJavaScriptProxy API 和 border 属性相关 API。</li>
<li>新增 Strip Engine Code 支持，进一步降低包体占用。</li>
<li>开发工具上，除了此前支持的 ARM 架构 DevEco Studio 的 Emulator，完善了 x64 架构适配支持。目前 DevEco Studio 的 Emulator 可以在 Window 跟 Mac 上均可流畅使用。</li>
</ul>
<p>更多详情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.unity.cn%2Fprojects%2F68e72ddcedbc2a001ec6b74e" target="_blank">查看官方公告</a>。</p>]]>
    </description>
    <content:encoded><![CDATA[<p>团结引擎 1.7.1 preview 已发布！本次技术更新涵盖渲染（Rendering）、实时动态全局光照系统（TuanjieGI）、团结粒子系统（Particle System）、团结动画系统（Animation）、ShaderGraph、Content Pipeline、 小游戏（MiniGame) 以及 Platform 几大方向。</p>
<h3><strong>渲染（Rendering）</strong></h3>
<p>在1.7.1 preview 版本中做了如下更新：</p>
<h4><strong>虚拟几何体功能支持通用渲染管线（URP）：</strong></h4>
<p>在 Tuanjie 1.7.1 preview 中，虚拟几何体功能进一步拓展了对团结引擎已有渲染管线的支持。重新设计模型的导入设置 UI，为开发者带来更优的模型导入使用体验。优化虚拟几何体执行效率，提升渲染性能。</p>
<ul>
<li>虚拟几何体功能现已支持团结引擎的通用渲染管线（URP），为其带来了同屏实时流畅渲染上亿三角形的能力。</li>
</ul>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6c864d82f1.png"></p>
<ul>
<li>使用虚拟几何体的渲染方式优化阴影绘制过程，使用 GPU 剔除，以 Multi View 的方式绘制光源所有的 Cascade，大幅减少阴影绘制所需的 Draw Call 数量。</li>
<li>进一步优化虚拟几何体的 CPU 和 GPU 执行效率，提升渲染性能。提供固定压缩比例的 Cluster 数据编码方式，获取更好的 GPU 性能。</li>
<li>重新设计的模型导入设置 UI，为开发者提供了更方便快捷管理的跨平台设置调整虚拟几何体导入参数的工作流。</li>
</ul>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-7fec8d849a.png"></p>
<p>更多使用指南参考 Tuanjie 虚拟几何体手册： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.unity.cn%2Fcn%2Ftuanjiemanual%2FManual%2FVirtualGeometry.html" target="_blank">https://docs.unity.cn/cn/tuanjiemanual/Manual/VirtualGeometry.html</a></p>
<h3><strong>实时动态全局光照（TuanjieGI）</strong></h3>
<p>在 Tuanjie 1.7.1 preview 中对实时动态全局光照系统做了以下功能改进：</p>
<ul>
<li><strong>新增 TuanjieGI 参数调节功能，通过 Volume Profile 提供灵活的参数配置管理，使开发者能够精细化调整全局或局部光照效果。</strong>开发者可自由调节直接光、天光及自发光在反弹后的颜色系数，并对最终计算出的间接光进行优化。借助该功能，开发者能够便捷地控制间接光照强度及颜色，打造理想的光线氛围</li>
<li><strong>新增可视化调试器，便于开发者调试实时光照效果</strong>，可通过 Window &gt; Analysis &gt; Rendering Debugger &gt; TuanjieGI 快速体验。</li>
<li><strong>新增 Screen Tracing 功能</strong>，利用屏幕空间信息模拟光线追踪效果，可通过 Volume Profile 控制开启或关闭。</li>
<li>支持 4K 及更高分辨率输出。</li>
<li>优化渲染性能并降低显存占用。</li>
</ul>
<p>获取 TuanjieGI 官方 Demo：</p>
<blockquote>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpackages.cdn.unity.cn%2Fgi%2FTuanjieGI_Demo_Tower_171.zip" target="_blank">https://packages.cdn.unity.cn/gi/TuanjieGI_Demo_Tower_171.zip</a></p>
</blockquote>
<blockquote>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcnb.cool%2Ftuanjie%2FTuanjieGI_Demo_Tower" target="_blank">https://cnb.cool/tuanjie/TuanjieGI_Demo_Tower</a></p>
</blockquote>
<p>更多使用指南参考 TuanjieGI 手册：</p>
<blockquote>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.unity.cn%2Fcn%2Ftuanjiemanual%2FManual%2FTuanjieGI.html" target="_blank">https://docs.unity.cn/cn/tuanjiemanual/Manual/TuanjieGI.html</a></p>
</blockquote>
<h3><strong>团结动画系统 (Animation）</strong></h3>
<p>在 Tuanjie 1.7.1 preview 中，团结动画系统在 1.7.0_preview 推出的 AnimGraph 和 IK&amp;Retargeter 模块的基础上持续进行升级、优化，主要包括：</p>
<ul>
<li><strong>全新推出 RigGraph（骨骼程序化绑定编辑器）</strong>，通过可视化界面进行模型骨骼绑定，支持一键生成高级骨骼绑定方案或自定义控制器进行个性化模型绑定</li>
<li><strong>升级 AnimGraph</strong>，包括添加反射 Missing 检测、Node Binding 等功能和 ApplyAdditive Node、Constraints Node、Mirror Node 等节点，提升使用体验；</li>
<li><strong>IK&amp;Retargeter 中新增基于 PBD 的 Fullbody IK 功能</strong>，同时修复了一系列 preview 版本中的异常，在前一版本基础上优化、提升了 Editor 的使用。</li>
</ul>
<p>更多使用指南参考 Tuanjie Animation 用户手册：</p>
<blockquote>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.unity.cn%2Fcn%2Ftuanjiemanual%2FManual%2FAnimation-whats-new.html" target="_blank">https://docs.unity.cn/cn/tuanjiemanual/Manual/Animation-whats-new.html</a></p>
</blockquote>
<h3><strong>团结粒子系统（Particle System)</strong></h3>
<p>在 Tuanjie 1.7.1 preview 中，优化了 Infinity 粒子系统的性能。按以下步骤即可快速体验：</p>
<p>1.打开或新建一个 URP 项目（未来将支持 HDRP 管线）。</p>
<p>2.打开 <strong>Package Manager</strong>，点击左上角的 <strong>+</strong> 图标，选择 <strong>Add package by name</strong>，输入 cn.tuanjie.infinity 并安装。</p>
<p>3.在 <strong>Hierarchy</strong> 面板中右键单击，从 <strong>Effects</strong> 折叠菜单中选择 <strong>Infinity Particle System</strong>，即可向场景添加粒子系统。其操作方式与内置粒子系统保持一致。</p>
<p>4.通过菜单 <strong>Tools &gt; Convert Particle System to Infinity</strong>，可轻松迁移现有粒子系统资产。</p>
<p>更多使用指南参阅文档 :</p>
<blockquote>
<p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.unity.cn%2Fcn%2FPackages-cn%2Fcn.tuanjie.infinity%401.2%2Fmanual%2F" target="_blank">https://docs.unity.cn/cn/Packages-cn/cn.tuanjie.infinity@1.2/manual/</a></p>
</blockquote>
<h3><strong>Shader Graph</strong></h3>
<p>在本次更新中进行了如下优化：</p>
<h4><strong>易用性优化</strong></h4>
<p>在最新版本的团结引擎 Shader Graph 中对 <strong>Portal Nodes（入口/出口节点）</strong> 的快捷创建功能进行了优化，让开发者的工作流更加高效、直观。</p>
<ul>
<li>一键生成多个 Get Var Node，自动贴近端口</li>
</ul>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-c28a5b5f1e.gif"></p>
<ul>
<li>新建 Group 智能命名：框选若干与 Register 节点相连的节点，右键选择 Group Selection 或直接按 Ctrl + G，新建的 Group 框顶部会自动显示其中 Register 节点的变量名集合，省去手动修改。</li>
</ul>
<h4><strong>Scalable Lit 支持 Custom Pass</strong></h4>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-c9dd92f793.png"></p>
<p>在新版本中，用户可以在 Scalable Lit 单个 Shader Graph中定义和配置多个 Pass。每个自定义 Pass 拥有独立的顶点和片段着色器，并可配置其渲染状态（如混合模式、深度测试等）。上图展示了使用多 Pass 可实现一些特定的渲染效果。</p>
<h4><strong>支持URP Stencil Test</strong></h4>
<p>现在可在 Shader Graph 中直接使用和配置 Stencil Buffer。方便快速实现游戏中常用的遮挡描边/透视效果。</p>
<h3><strong>Content Pipeline</strong></h3>
<p>在 Tuaniie 1.7.1 preview 版本中，深入理解开发者对 <strong>Instant Asset</strong> 功能模块的体验和建议，并进行了多项升级：</p>
<ul>
<li> <p><strong>新增 Instant Asset 场景资产构建与编辑器模拟运行</strong>：支持场景资产构建能力，同时支持了在编辑器中直接模拟运行测试，加速项目开发迭代流程；</p> </li>
<li> <p><strong>新增 Instant Asset 资源表管理接口与确定性资产构建</strong>：支持资源表合并、Diff 接口和确定性资产构建机制，确保增量构建精准高效，完美适配热更新等第三方解决方案，轻松应对复杂项目兼容挑战。</p> </li>
</ul>
<h3><strong>小游戏（MiniGame）</strong></h3>
<p>在 Tuanjie 1.7.1 preview 版本中，团结引擎小游戏平台<strong>新增了对 TapTap 子平台的支持。</strong>此次更新进一步扩展了平台发布能力，对 TapTap 子平台的构建支持，使开发者能够更便捷地发布游戏至 TapTap 平台，触达更广泛的玩家群体。</p>
<h3><strong>Platform</strong></h3>
<h4><strong>OpenHarmony 平台</strong></h4>
<ul>
<li>更完善的 UAAL 模式，从 1.7.1 的版本开始，导出工程的 ETS 代码会被封装到 har 包里面去，并且 Default 的模式不再提供，UAAL 成为 Default 模式。模块集成到原生应用更加的便捷。</li>
<li>新增蓝牙键盘鼠标支持，可在 PC/平板中使用该能力。</li>
<li>Webview 接口新增 registerJavaScriptProxy API 和 border 属性相关 API。</li>
<li>新增 Strip Engine Code 支持，进一步降低包体占用。</li>
<li>开发工具上，除了此前支持的 ARM 架构 DevEco Studio 的 Emulator，完善了 x64 架构适配支持。目前 DevEco Studio 的 Emulator 可以在 Window 跟 Mac 上均可流畅使用。</li>
</ul>
<p>更多详情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.unity.cn%2Fprojects%2F68e72ddcedbc2a001ec6b74e" target="_blank">查看官方公告</a>。</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6c864d82f1.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-6c864d82f1.png" medium="image"/>
    <pubDate>Tue, 14 Oct 2025 14:10:59 +0800</pubDate>
  </item><item>
    <title><![CDATA[小米登记第三代人形机器人 CyberOne 作品著作权]]></title>
    <link>https://www.oschina.net/news/377341</link>
    <itunes:title><![CDATA[小米登记第三代人形机器人 CyberOne 作品著作权]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p><span>天眼查App显示，10月10日，北京小米机器人技术有限公司登记“第三代人形机器人CyberOne”作品著作权，作品类别为美术。</span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-c972e81ff5.png"></p>
<p><span>该公司成立于2023年4月，法定代表人为曾学忠，注册资本约5556万人民币，经营范围包括工业机器人制造、工业机器人销售、服务消费机器人制造等，由北京小米智能科技有限公司、北京屹唐创欣创业投资中心（有限合伙）共同持股。</span></p>
<p><span>公开资料显示，CyberOne（中文名：铁大）是小米集团于2022年8月11日发布的首款全尺寸人形仿生机器人，主要应用于家庭护理与陪伴场景。今年2月，小米开始推进该机器人在自有制造产线的分阶段落地。</span></p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p><span>天眼查App显示，10月10日，北京小米机器人技术有限公司登记“第三代人形机器人CyberOne”作品著作权，作品类别为美术。</span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-c972e81ff5.png"></p>
<p><span>该公司成立于2023年4月，法定代表人为曾学忠，注册资本约5556万人民币，经营范围包括工业机器人制造、工业机器人销售、服务消费机器人制造等，由北京小米智能科技有限公司、北京屹唐创欣创业投资中心（有限合伙）共同持股。</span></p>
<p><span>公开资料显示，CyberOne（中文名：铁大）是小米集团于2022年8月11日发布的首款全尺寸人形仿生机器人，主要应用于家庭护理与陪伴场景。今年2月，小米开始推进该机器人在自有制造产线的分阶段落地。</span></p>]]>
    </description>
    <content:encoded><![CDATA[<p><span>天眼查App显示，10月10日，北京小米机器人技术有限公司登记“第三代人形机器人CyberOne”作品著作权，作品类别为美术。</span></p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-c972e81ff5.png"></p>
<p><span>该公司成立于2023年4月，法定代表人为曾学忠，注册资本约5556万人民币，经营范围包括工业机器人制造、工业机器人销售、服务消费机器人制造等，由北京小米智能科技有限公司、北京屹唐创欣创业投资中心（有限合伙）共同持股。</span></p>
<p><span>公开资料显示，CyberOne（中文名：铁大）是小米集团于2022年8月11日发布的首款全尺寸人形仿生机器人，主要应用于家庭护理与陪伴场景。今年2月，小米开始推进该机器人在自有制造产线的分阶段落地。</span></p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-c972e81ff5.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-c972e81ff5.png" medium="image"/>
    <pubDate>Tue, 14 Oct 2025 13:59:17 +0800</pubDate>
  </item><item>
    <title><![CDATA[Bun 1.3 正式发布]]></title>
    <link>https://www.oschina.net/news/377329/bun-v1-3</link>
    <itunes:title><![CDATA[Bun 1.3 正式发布]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>2025年10月10日，高性能 JavaScript 运行时 Bun 发布了 1.3 版本。这是 Bun 项目迄今为止最重大的版本更新，标志着 Bun 从单纯的运行时工具演变为一个功能完备的全栈 JavaScript 开发平台。</p>
<h2>从运行时到全栈平台的跨越</h2>
<p>Bun 1.3 的核心突破在于将前端开发能力深度整合进运行时。据官方介绍，此次更新新增了对前端开发的一级支持，开发者现在可以直接运行 HTML 文件，无需额外配置即可启动一个功能完整的开发服务器。</p>
<pre><code>bun ./**/*.html
</code></pre>
<p>执行上述命令后，Bun 会自动识别项目中的 HTML 文件并启动开发服务器，包括热模块替换（HMR）、React Fast Refresh 等现代前端开发必备功能。这种「开箱即用」的设计理念贯穿整个 1.3 版本。</p>
<p>值得注意的是，Bun 的开发服务器并非简单的静态文件服务器，而是集成了原生的 JavaScript、CSS 和 HTML 转译与打包能力。这意味着开发者可以在同一个进程中同时处理前后端代码，从根本上解决了传统开发中前后端端口分离导致的 CORS 跨域问题。</p>
<h2>内置数据库客户端：性能与便利的平衡</h2>
<p>数据库访问是后端开发的核心需求。Bun 1.3 将内置数据库支持从单一的 PostgreSQL 扩展到 MySQL、MariaDB 和 SQLite，并提供了统一的 <code>Bun.SQL</code> API。这一设计大幅降低了项目的依赖复杂度，同时带来显著的性能提升。</p>
<pre><code>import { sql, SQL } from "bun";
// 使用统一 API 连接不同数据库
const postgres = new SQL("postgres://localhost/mydb");
const mysql = new SQL("mysql://localhost/mydb");
const sqlite = new SQL("sqlite://data.db");
// 自动从环境变量读取连接信息
const seniorAge = 65;
const seniorUsers = await sql`
SELECT name, age FROM users
WHERE age &gt;= ${seniorAge}
`;
</code></pre>
<p>虽然现有的 npm 包如 <code>postgres</code> 和 <code>mysql2</code> 在 Bun 中已有不错的性能表现，但原生实现带来的优势不容小觑。官方数据显示，内置客户端在某些场景下性能提升可达数倍。</p>
<p>新版本还新增了 Redis 客户端支持，官方基准测试显示其性能是流行的 ioredis 库的 7.9 倍以上。对于需要缓存和消息队列的应用场景，这一改进意义重大。</p>
<p><img alt="Redis 性能对比" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-662ba9a9f1.png"></p>
<h2>路由系统：简化全栈应用架构</h2>
<p>Bun 1.3 为 <code>Bun.serve()</code> 引入了内置路由系统，支持参数化路由和通配符，让开发者能够在同一服务中优雅地处理前端页面和后端 API。</p>
<pre><code>import { serve, sql } from "bun";
import App from "./myReactSPA.html";
serve({
port: 3000,
routes: {
"/*": App,
"/api/users": {
GET: async () =&gt; Response.json(await sql`SELECT * FROM users LIMIT 10`),
POST: async (req) =&gt; {
const { name, email } = await req.json();
const [user] = await sql`
INSERT INTO users ${sql({ name, email })}
RETURNING *;
`;
return Response.json(user);
},
},
"/api/users/:id": async (req) =&gt; {
const { id } = req.params;
const [user] = await sql`SELECT * FROM users WHERE id = ${id} LIMIT 1`;
if (!user) return new Response("User not found", { status: 404 });
return Response.json(user);
},
},
});
</code></pre>
<p>这种设计让全栈应用的部署变得极为简单。更令人印象深刻的是，Bun 的打包器现在支持将前后端代码打包成单一的可执行文件:</p>
<pre><code>bun build --compile ./index.html --outfile myapp
</code></pre>
<p>生成的可执行文件可以在任何地方运行，无需安装 Node.js 或其他依赖，这对于微服务部署和边缘计算场景具有重要价值。</p>
<h2>Cookie 管理：告别第三方库</h2>
<p>Web 应用中的 Cookie 处理一直是个痛点。开发者要么选择单一功能的 <code>tough-cookie</code> 库，要么被迫引入 Express、Elysia 等完整框架。Bun 1.3 提供了原生的 Cookie API，采用类似 Map 的接口设计:</p>
<pre><code>import { serve, randomUUIDv7 } from "bun";
serve({
routes: {
"/api/users/sign-in": (request) =&gt; {
request.cookies.set("sessionId", randomUUIDv7(), {
httpOnly: true,
sameSite: "strict",
});
return new Response("Signed in");
},
"/api/users/sign-out": (request) =&gt; {
request.cookies.delete("sessionId");
return new Response("Signed out");
},
},
});
</code></pre>
<p>这个 API 的巧妙之处在于零性能开销的延迟解析——只有在实际访问 <code>request.cookies</code> 时才会解析请求头中的 Cookie，避免了不必要的计算。</p>
<h2>包管理器的重大革新</h2>
<p>Bun 的包管理器在 1.3 版本中获得了多项企业级特性。其中最值得关注的是<strong>隔离安装模式</strong>成为工作空间的默认行为。这一改变解决了大型 monorepo 项目中最常见的问题之一：包的幽灵依赖（phantom dependencies）。</p>
<p>在传统的提升安装模式下，所有依赖都平铺在根目录的 <code>node_modules</code> 中，包可能意外访问到未在 <code>package.json</code> 中声明的依赖。隔离模式确保每个包只能访问其明确声明的依赖，提高了构建的可预测性和可靠性。</p>
<p><strong>依赖目录 (Catalogs)</strong> 功能为 monorepo 中的版本管理提供了优雅的解决方案:</p>
<pre><code>{
"name": "monorepo",
"workspaces": ["packages/*"],
"catalog": {
"react": "^18.0.0",
"typescript": "^5.0.0"
}
}
</code></pre>
<p>工作空间包可以通过 <code>"react": "catalog:"</code> 引用目录中的版本，实现集中式版本管理。这一设计借鉴了 pnpm 的成功经验，但整合得更加自然。</p>
<p>新增的<strong>安全扫描 API</strong> 让企业能够在安装阶段拦截恶意包。Bun 团队与 Socket 安全公司合作，推出了官方安全扫描器 <code>@socketsecurity/bun-security-scanner</code>。开发者也可以基于公开的 API 编写自定义扫描器，满足特定的安全合规需求。</p>
<pre><code>[install.security]
scanner = "@socketsecurity/bun-security-scanner"
</code></pre>
<p><strong>最小发布时间限制</strong>功能则提供了对供应链攻击的防护:</p>
<pre><code>[install]
minimumReleaseAge = 604800  # 7天
</code></pre>
<p>这项配置要求包必须发布至少指定时间后才允许安装，给社区留出时间识别潜在的恶意包。</p>
<p>交互式更新命令 <code>bun update --interactive</code> 让依赖升级变得可控:</p>
<pre><code>bun update --interactive
</code></pre>
<p>开发者可以逐个选择要更新的包，而不是一次性升级所有依赖，从而更好地控制潜在的破坏性变更。</p>
<h2>测试框架的成熟化</h2>
<p>Bun 的测试运行器在 1.3 版本中获得了与 VS Code Test Explorer 的深度集成。开发者可以直接在编辑器侧边栏查看测试列表，一键运行或调试单个测试，内联查看错误信息。这种开发体验与 Jest + VS Code Jest 扩展相当，但得益于 Bun 的性能优势，测试执行速度更快。</p>
<p>并发测试支持的加入让 I/O 密集型测试套件的运行时间大幅缩短：</p>
<pre><code>import { test } from "bun:test";
test.concurrent("fetch user 1", async () =&gt; {
const res = await fetch("https://api.example.com/users/1");
expect(res.status).toBe(200);
});
describe.concurrent("server tests", () =&gt; {
test("sends a request to server 1", async () =&gt; {
const response = await fetch("https://example.com/server-1");
expect(response.status).toBe(200);
});
});
</code></pre>
<p>默认情况下，最多 20 个测试会并发运行，这个数字可以通过 <code>--max-concurrency</code> 标志调整。对于需要保持串行执行的测试，可以使用 <code>test.serial</code> 修饰符。</p>
<p>类型测试功能 <code>expectTypeOf()</code> 的引入是另一个亮点。开发者现在可以在单元测试中直接验证 TypeScript 类型:</p>
<pre><code>import { expectTypeOf, test } from "bun:test";
test("types are correct", () =&gt; {
expectTypeOf&lt;string&gt;().toEqualTypeOf&lt;string&gt;();
expectTypeOf({ foo: 1 }).toHaveProperty("foo");
expectTypeOf&lt;Promise&lt;number&gt;&gt;().resolves.toBeNumber();
});
</code></pre>
<p>这些类型断言可以通过 <code>bunx tsc --noEmit</code> 在 CI 流程中验证，将类型安全检查提升到了新的高度。</p>
<h2>Node.js 兼容性的持续推进</h2>
<p>Bun 1.3 在每次提交时运行 Node.js 测试套件中额外的 800 个测试用例。官方数据显示，N-API 测试通过率已达 98% 以上，timers 模块通过率达到 98.4%。</p>
<p>对 <code>node:vm</code> 模块的全面支持是本次更新的重要成果。这个模块常用于代码沙箱、插件系统等高级场景，其实现难度较大。Bun 1.3 不仅支持基础的 <code>vm.Script</code>，还实现了 <code>vm.SourceTextModule</code>、<code>vm.SyntheticModule</code> 等高级 API，并支持字节码缓存以提升编译性能。</p>
<pre><code>import vm from "node:vm";
const script = new vm.Script('console.log("Hello from VM")');
script.runInThisContext();
</code></pre>
<p><code>node:test</code> 模块的初步支持让使用 Node.js 原生测试框架的项目能够在 Bun 上运行，这对于生态系统的兼容性意义重大。</p>
<p>加密性能的提升令人瞩目。DiffieHellman 和 Cipheriv/Decipheriv 的速度提升了约 400 倍，scrypt 提升了 6 倍。这些改进通过将关键路径用原生 C++ 重写实现，大幅降低了密码学操作的开销。</p>
<h2>Web 标准与现代 API</h2>
<p>Bun 1.3 新增了对多项 Web 标准的支持。<strong>YAML 原生支持</strong>让配置文件处理变得简单：</p>
<pre><code>import { YAML } from "bun";
const obj = YAML.parse("key: value");
const yaml = YAML.stringify({ key: "value" }, 0, 2);
// 直接导入 YAML 文件
import config from "./config.yaml";
</code></pre>
<p>官方实现的 YAML 解析器目前通过了官方测试套件的 90% 用例，性能表现优异。</p>
<p><strong>WebSocket 压缩</strong>功能的自动协商是另一个实用特性。当连接支持 <code>permessage-deflate</code> 时，Bun 会自动启用压缩，对于 JSON 等结构化数据，压缩率可达 60-80%，显著减少带宽消耗。</p>
<p><strong>Zstandard 压缩</strong>的全面支持包括 <code>fetch()</code> 的自动解压和手动压缩 API：</p>
<pre><code>import { zstdCompress, zstdDecompress } from "bun";
const compressed = await zstdCompress("Hello, world!");
const decompressed = await zstdDecompress(compressed);
</code></pre>
<p><code>DisposableStack</code> 和 <code>AsyncDisposableStack</code> 的实现体现了 Bun 对 TC39 提案的快速跟进。这些 API 与 <code>using</code> 和 <code>await using</code> 声明配合，提供了优雅的资源管理机制。</p>
<h2>性能优化：细节见真章</h2>
<p>Bun 1.3 的性能优化遍布各个层面。空闲 CPU 占用的降低源于对垃圾回收调度的优化，在没有进行中的请求时，<code>Bun.serve</code> 的计时器不再活跃。JavaScript 内存占用降低 10-30% (Next.js 应用降低 28%，Elysia 降低 11%) 归功于更智能的 GC 计时器调度。</p>
<p>I/O 线程池的优化让 macOS 上的 <code>Bun.build</code> 快了 60%。Express 性能提升 9%，Fastify 提升 5.4%，这些改进来自对 <code>node:http</code> 模块的持续优化。</p>
<p><code>postMessage</code> 的性能提升尤为惊人——字符串传递快了 500 倍，简单对象快了 240 倍。这通过避免对安全共享的字符串进行序列化实现，同时减少了约 22 倍的峰值内存使用。</p>
<pre><code>// 在 Worker 间传递大型 JSON 字符串现在快了 500 倍
const response = await fetch("https://api.example.com/data");
const json = await response.text();
postMessage(json);
</code></pre>
<p>启动时间减少了 1ms，内存占用减少了 3MB，这些看似微小的优化累积起来，对用户体验产生显著影响。</p>
<h2>开发者体验的精心打磨</h2>
<p>Bun 1.3 在开发者体验上的改进同样值得称道。TypeScript 默认配置改为 <code>"module": "Preserve"</code>，保留模块语法的原始形态，更符合 Bun 作为原生 ES 模块运行时的定位。</p>
<p><code>console.log()</code> 的深度控制让调试大型对象变得可控:</p>
<pre><code>bun --console-depth=5 ./app.ts
</code></pre>
<pre><code>[console]
depth = 5
</code></pre>
<p><code>BUN_OPTIONS</code> 环境变量提供了设置默认 CLI 参数的便捷方式：</p>
<pre><code>export BUN_OPTIONS="--watch --hot"
bun run ./app.ts
# 等同于: bun --watch --hot run ./app.ts
</code></pre>
<p><code>bunx --package</code> 标志让运行二进制文件与包名不一致的包变得简单：</p>
<pre><code>bunx --package=@typescript-eslint/parser eslint ./src
</code></pre>
<p>新增的 <code>bun why</code> 命令清晰地展示依赖链，解答「为什么这个包会出现在我的项目中」：</p>
<pre><code>bun why tailwindcss
</code></pre>
<p>这些看似细小的改进，体现了 Bun 团队对开发者日常工作流程的深刻理解。</p>
<h2>打包器与构建系统的增强</h2>
<p>Bun 的打包器在 1.3 版本中获得了跨平台编译能力。开发者现在可以在任何平台上为 Windows、macOS 和 Linux 构建可执行文件：</p>
<pre><code>bun build --compile --target=linux-x64 ./app.ts --outfile myapp-linux
bun build --compile --target=darwin-arm64 ./app.ts --outfile myapp-macos
bun build --compile --target=windows-x64 ./app.ts --outfile myapp.exe
</code></pre>
<p>Windows 可执行文件元数据的支持让企业应用的打包更加专业：</p>
<pre><code>bun build --compile --target=windows-x64 \\
--title="My App" \\
--publisher="My Company" \\
--version="1.0.0" \\
./app.ts
</code></pre>
<p>代码签名支持（Windows 的 Authenticode 和 macOS 的 codesign）确保了发布的可执行文件可以通过操作系统的安全验证。</p>
<p>压缩器变得更加智能，能够移除未使用的函数和类名，优化 <code>new Object()</code>、<code>new Array()</code> 等表达式，消除无用的 <code>try...catch...finally</code> 块。这些优化让生产构建的体积进一步缩小。</p>
<h2>安全性的持续关注</h2>
<p>Bun 1.3 引入了 <code>Bun.secrets</code> API，利用操作系统的原生凭据存储（macOS 的 Keychain、Linux 的 libsecret、Windows 的 Credential Manager）：</p>
<pre><code>import { secrets } from "bun";
await secrets.set({
service: "my-app",
name: "api-key",
value: "secret-value",
});
const key = await secrets.get({
service: "my-app",
name: "api-key",
});
</code></pre>
<p>凭据在静态时被加密，与环境变量分离存储，提供了更高的安全保障。</p>
<p><code>Bun.CSRF</code> 模块为跨站请求伪造防护提供了原生支持：</p>
<pre><code>import { CSRF } from "bun";
const secret = "your-secret-key";
const token = CSRF.generate({ secret, encoding: "hex", expiresIn: 60 * 1000 });
const isValid = CSRF.verify(token, { secret });
</code></pre>
<p>这些安全特性的内置化降低了开发者的心智负担，让安全最佳实践更容易落地。</p>
<h2>生态系统的影响与展望</h2>
<p>Bun 1.3 的发布标志着该项目从「快速运行时」向「完整开发平台」的战略转型。Midjourney 等知名公司已在生产环境中使用 Bun 进行前端开发，这证明了其稳定性和可靠性。</p>
<p>官方提到，每个提交都会运行大量的 Node.js 测试套件，表明 Bun 团队对兼容性的重视。对 <code>pnpm.lock</code> 和 <code>yarn.lock</code> 的迁移支持，让团队可以无痛试用 Bun，而无需说服所有成员同时升级工具链。</p>
<p>不过，1.3 版本也带来了一些破坏性变更。<code>Bun.serve()</code> 的 TypeScript 类型被重构，WebSocket 数据定义方式发生变化；SQL 客户端现在强制使用标签模板语法；测试过滤器在没有匹配用例时会报错而非静默成功。这些变更虽然可能给现有项目带来迁移成本，但从长远看有利于 API 的一致性和可维护性。</p>
<h2>数据说话：性能对比</h2>
<p>根据官方提供的基准测试数据:</p>
<ul>
<li><strong>Redis 客户端</strong>: 比 ioredis 快 7.9 倍以上</li>
<li><strong>postMessage 字符串</strong>: 速度提升 500 倍，内存减少 22 倍</li>
<li><strong>postMessage 对象</strong>: 速度提升 240 倍</li>
<li><strong>DiffieHellman</strong>: 约快 400 倍</li>
<li><strong>Cipheriv/Decipheriv</strong>: 约快 400 倍</li>
<li><strong>scrypt</strong>: 快 6 倍</li>
<li><strong><code>AbortSignal.timeout</code></strong>: 快 40 倍</li>
<li><strong><code>Headers</code> 操作</strong>: 快 2 倍</li>
<li><strong><code>Bun.build</code> on macOS</strong>: 快 60%</li>
<li><strong>Express</strong>: 快 9%</li>
<li><strong>Fastify</strong>: 快 5.4%</li>
</ul>
<p>这些数据展示了 Bun 在性能上的持续领先优势。</p>
<h2>社区反响与未来规划</h2>
<p>Bun 1.3 的发布在社区引发了热烈讨论。开发者们尤其关注全栈开发能力的提升和包管理器的企业级特性。Socket 公司 CTO Ahmad Nassri 对安全扫描 API 的评价颇具代表性：「Bun 团队行动迅速，在包管理器层面保护开发者。开放安全扫描 API，让 Socket 这样的工具能够在安装过程中提供实时威胁检测。这是让开源开发默认更安全的重要一步。」</p>
<p>官方表示，1.3 系列将持续关注全栈应用开发体验的提升。Redis 集群、流式处理和 Lua 脚本支持已在规划中。WebAssembly 流式编译的实现，以及对更多 TC39 提案的支持，也在进行中。</p>
<p>Bun 的快速迭代和对社区反馈的积极响应，让人对其未来发展充满期待。从一个「更快的 Node.js」到一个「完整的 JavaScript 平台」，Bun 正在书写属于自己的故事。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>2025年10月10日，高性能 JavaScript 运行时 Bun 发布了 1.3 版本。这是 Bun 项目迄今为止最重大的版本更新，标志着 Bun 从单纯的运行时工具演变为一个功能完备的全栈 JavaScript 开发平台。</p>
<h2>从运行时到全栈平台的跨越</h2>
<p>Bun 1.3 的核心突破在于将前端开发能力深度整合进运行时。据官方介绍，此次更新新增了对前端开发的一级支持，开发者现在可以直接运行 HTML 文件，无需额外配置即可启动一个功能完整的开发服务器。</p>
<pre><code>bun ./**/*.html
</code></pre>
<p>执行上述命令后，Bun 会自动识别项目中的 HTML 文件并启动开发服务器，包括热模块替换（HMR）、React Fast Refresh 等现代前端开发必备功能。这种「开箱即用」的设计理念贯穿整个 1.3 版本。</p>
<p>值得注意的是，Bun 的开发服务器并非简单的静态文件服务器，而是集成了原生的 JavaScript、CSS 和 HTML 转译与打包能力。这意味着开发者可以在同一个进程中同时处理前后端代码，从根本上解决了传统开发中前后端端口分离导致的 CORS 跨域问题。</p>
<h2>内置数据库客户端：性能与便利的平衡</h2>
<p>数据库访问是后端开发的核心需求。Bun 1.3 将内置数据库支持从单一的 PostgreSQL 扩展到 MySQL、MariaDB 和 SQLite，并提供了统一的 <code>Bun.SQL</code> API。这一设计大幅降低了项目的依赖复杂度，同时带来显著的性能提升。</p>
<pre><code>import { sql, SQL } from "bun";
// 使用统一 API 连接不同数据库
const postgres = new SQL("postgres://localhost/mydb");
const mysql = new SQL("mysql://localhost/mydb");
const sqlite = new SQL("sqlite://data.db");
// 自动从环境变量读取连接信息
const seniorAge = 65;
const seniorUsers = await sql`
SELECT name, age FROM users
WHERE age &gt;= ${seniorAge}
`;
</code></pre>
<p>虽然现有的 npm 包如 <code>postgres</code> 和 <code>mysql2</code> 在 Bun 中已有不错的性能表现，但原生实现带来的优势不容小觑。官方数据显示，内置客户端在某些场景下性能提升可达数倍。</p>
<p>新版本还新增了 Redis 客户端支持，官方基准测试显示其性能是流行的 ioredis 库的 7.9 倍以上。对于需要缓存和消息队列的应用场景，这一改进意义重大。</p>
<p><img alt="Redis 性能对比" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-662ba9a9f1.png"></p>
<h2>路由系统：简化全栈应用架构</h2>
<p>Bun 1.3 为 <code>Bun.serve()</code> 引入了内置路由系统，支持参数化路由和通配符，让开发者能够在同一服务中优雅地处理前端页面和后端 API。</p>
<pre><code>import { serve, sql } from "bun";
import App from "./myReactSPA.html";
serve({
port: 3000,
routes: {
"/*": App,
"/api/users": {
GET: async () =&gt; Response.json(await sql`SELECT * FROM users LIMIT 10`),
POST: async (req) =&gt; {
const { name, email } = await req.json();
const [user] = await sql`
INSERT INTO users ${sql({ name, email })}
RETURNING *;
`;
return Response.json(user);
},
},
"/api/users/:id": async (req) =&gt; {
const { id } = req.params;
const [user] = await sql`SELECT * FROM users WHERE id = ${id} LIMIT 1`;
if (!user) return new Response("User not found", { status: 404 });
return Response.json(user);
},
},
});
</code></pre>
<p>这种设计让全栈应用的部署变得极为简单。更令人印象深刻的是，Bun 的打包器现在支持将前后端代码打包成单一的可执行文件:</p>
<pre><code>bun build --compile ./index.html --outfile myapp
</code></pre>
<p>生成的可执行文件可以在任何地方运行，无需安装 Node.js 或其他依赖，这对于微服务部署和边缘计算场景具有重要价值。</p>
<h2>Cookie 管理：告别第三方库</h2>
<p>Web 应用中的 Cookie 处理一直是个痛点。开发者要么选择单一功能的 <code>tough-cookie</code> 库，要么被迫引入 Express、Elysia 等完整框架。Bun 1.3 提供了原生的 Cookie API，采用类似 Map 的接口设计:</p>
<pre><code>import { serve, randomUUIDv7 } from "bun";
serve({
routes: {
"/api/users/sign-in": (request) =&gt; {
request.cookies.set("sessionId", randomUUIDv7(), {
httpOnly: true,
sameSite: "strict",
});
return new Response("Signed in");
},
"/api/users/sign-out": (request) =&gt; {
request.cookies.delete("sessionId");
return new Response("Signed out");
},
},
});
</code></pre>
<p>这个 API 的巧妙之处在于零性能开销的延迟解析——只有在实际访问 <code>request.cookies</code> 时才会解析请求头中的 Cookie，避免了不必要的计算。</p>
<h2>包管理器的重大革新</h2>
<p>Bun 的包管理器在 1.3 版本中获得了多项企业级特性。其中最值得关注的是<strong>隔离安装模式</strong>成为工作空间的默认行为。这一改变解决了大型 monorepo 项目中最常见的问题之一：包的幽灵依赖（phantom dependencies）。</p>
<p>在传统的提升安装模式下，所有依赖都平铺在根目录的 <code>node_modules</code> 中，包可能意外访问到未在 <code>package.json</code> 中声明的依赖。隔离模式确保每个包只能访问其明确声明的依赖，提高了构建的可预测性和可靠性。</p>
<p><strong>依赖目录 (Catalogs)</strong> 功能为 monorepo 中的版本管理提供了优雅的解决方案:</p>
<pre><code>{
"name": "monorepo",
"workspaces": ["packages/*"],
"catalog": {
"react": "^18.0.0",
"typescript": "^5.0.0"
}
}
</code></pre>
<p>工作空间包可以通过 <code>"react": "catalog:"</code> 引用目录中的版本，实现集中式版本管理。这一设计借鉴了 pnpm 的成功经验，但整合得更加自然。</p>
<p>新增的<strong>安全扫描 API</strong> 让企业能够在安装阶段拦截恶意包。Bun 团队与 Socket 安全公司合作，推出了官方安全扫描器 <code>@socketsecurity/bun-security-scanner</code>。开发者也可以基于公开的 API 编写自定义扫描器，满足特定的安全合规需求。</p>
<pre><code>[install.security]
scanner = "@socketsecurity/bun-security-scanner"
</code></pre>
<p><strong>最小发布时间限制</strong>功能则提供了对供应链攻击的防护:</p>
<pre><code>[install]
minimumReleaseAge = 604800  # 7天
</code></pre>
<p>这项配置要求包必须发布至少指定时间后才允许安装，给社区留出时间识别潜在的恶意包。</p>
<p>交互式更新命令 <code>bun update --interactive</code> 让依赖升级变得可控:</p>
<pre><code>bun update --interactive
</code></pre>
<p>开发者可以逐个选择要更新的包，而不是一次性升级所有依赖，从而更好地控制潜在的破坏性变更。</p>
<h2>测试框架的成熟化</h2>
<p>Bun 的测试运行器在 1.3 版本中获得了与 VS Code Test Explorer 的深度集成。开发者可以直接在编辑器侧边栏查看测试列表，一键运行或调试单个测试，内联查看错误信息。这种开发体验与 Jest + VS Code Jest 扩展相当，但得益于 Bun 的性能优势，测试执行速度更快。</p>
<p>并发测试支持的加入让 I/O 密集型测试套件的运行时间大幅缩短：</p>
<pre><code>import { test } from "bun:test";
test.concurrent("fetch user 1", async () =&gt; {
const res = await fetch("https://api.example.com/users/1");
expect(res.status).toBe(200);
});
describe.concurrent("server tests", () =&gt; {
test("sends a request to server 1", async () =&gt; {
const response = await fetch("https://example.com/server-1");
expect(response.status).toBe(200);
});
});
</code></pre>
<p>默认情况下，最多 20 个测试会并发运行，这个数字可以通过 <code>--max-concurrency</code> 标志调整。对于需要保持串行执行的测试，可以使用 <code>test.serial</code> 修饰符。</p>
<p>类型测试功能 <code>expectTypeOf()</code> 的引入是另一个亮点。开发者现在可以在单元测试中直接验证 TypeScript 类型:</p>
<pre><code>import { expectTypeOf, test } from "bun:test";
test("types are correct", () =&gt; {
expectTypeOf&lt;string&gt;().toEqualTypeOf&lt;string&gt;();
expectTypeOf({ foo: 1 }).toHaveProperty("foo");
expectTypeOf&lt;Promise&lt;number&gt;&gt;().resolves.toBeNumber();
});
</code></pre>
<p>这些类型断言可以通过 <code>bunx tsc --noEmit</code> 在 CI 流程中验证，将类型安全检查提升到了新的高度。</p>
<h2>Node.js 兼容性的持续推进</h2>
<p>Bun 1.3 在每次提交时运行 Node.js 测试套件中额外的 800 个测试用例。官方数据显示，N-API 测试通过率已达 98% 以上，timers 模块通过率达到 98.4%。</p>
<p>对 <code>node:vm</code> 模块的全面支持是本次更新的重要成果。这个模块常用于代码沙箱、插件系统等高级场景，其实现难度较大。Bun 1.3 不仅支持基础的 <code>vm.Script</code>，还实现了 <code>vm.SourceTextModule</code>、<code>vm.SyntheticModule</code> 等高级 API，并支持字节码缓存以提升编译性能。</p>
<pre><code>import vm from "node:vm";
const script = new vm.Script('console.log("Hello from VM")');
script.runInThisContext();
</code></pre>
<p><code>node:test</code> 模块的初步支持让使用 Node.js 原生测试框架的项目能够在 Bun 上运行，这对于生态系统的兼容性意义重大。</p>
<p>加密性能的提升令人瞩目。DiffieHellman 和 Cipheriv/Decipheriv 的速度提升了约 400 倍，scrypt 提升了 6 倍。这些改进通过将关键路径用原生 C++ 重写实现，大幅降低了密码学操作的开销。</p>
<h2>Web 标准与现代 API</h2>
<p>Bun 1.3 新增了对多项 Web 标准的支持。<strong>YAML 原生支持</strong>让配置文件处理变得简单：</p>
<pre><code>import { YAML } from "bun";
const obj = YAML.parse("key: value");
const yaml = YAML.stringify({ key: "value" }, 0, 2);
// 直接导入 YAML 文件
import config from "./config.yaml";
</code></pre>
<p>官方实现的 YAML 解析器目前通过了官方测试套件的 90% 用例，性能表现优异。</p>
<p><strong>WebSocket 压缩</strong>功能的自动协商是另一个实用特性。当连接支持 <code>permessage-deflate</code> 时，Bun 会自动启用压缩，对于 JSON 等结构化数据，压缩率可达 60-80%，显著减少带宽消耗。</p>
<p><strong>Zstandard 压缩</strong>的全面支持包括 <code>fetch()</code> 的自动解压和手动压缩 API：</p>
<pre><code>import { zstdCompress, zstdDecompress } from "bun";
const compressed = await zstdCompress("Hello, world!");
const decompressed = await zstdDecompress(compressed);
</code></pre>
<p><code>DisposableStack</code> 和 <code>AsyncDisposableStack</code> 的实现体现了 Bun 对 TC39 提案的快速跟进。这些 API 与 <code>using</code> 和 <code>await using</code> 声明配合，提供了优雅的资源管理机制。</p>
<h2>性能优化：细节见真章</h2>
<p>Bun 1.3 的性能优化遍布各个层面。空闲 CPU 占用的降低源于对垃圾回收调度的优化，在没有进行中的请求时，<code>Bun.serve</code> 的计时器不再活跃。JavaScript 内存占用降低 10-30% (Next.js 应用降低 28%，Elysia 降低 11%) 归功于更智能的 GC 计时器调度。</p>
<p>I/O 线程池的优化让 macOS 上的 <code>Bun.build</code> 快了 60%。Express 性能提升 9%，Fastify 提升 5.4%，这些改进来自对 <code>node:http</code> 模块的持续优化。</p>
<p><code>postMessage</code> 的性能提升尤为惊人——字符串传递快了 500 倍，简单对象快了 240 倍。这通过避免对安全共享的字符串进行序列化实现，同时减少了约 22 倍的峰值内存使用。</p>
<pre><code>// 在 Worker 间传递大型 JSON 字符串现在快了 500 倍
const response = await fetch("https://api.example.com/data");
const json = await response.text();
postMessage(json);
</code></pre>
<p>启动时间减少了 1ms，内存占用减少了 3MB，这些看似微小的优化累积起来，对用户体验产生显著影响。</p>
<h2>开发者体验的精心打磨</h2>
<p>Bun 1.3 在开发者体验上的改进同样值得称道。TypeScript 默认配置改为 <code>"module": "Preserve"</code>，保留模块语法的原始形态，更符合 Bun 作为原生 ES 模块运行时的定位。</p>
<p><code>console.log()</code> 的深度控制让调试大型对象变得可控:</p>
<pre><code>bun --console-depth=5 ./app.ts
</code></pre>
<pre><code>[console]
depth = 5
</code></pre>
<p><code>BUN_OPTIONS</code> 环境变量提供了设置默认 CLI 参数的便捷方式：</p>
<pre><code>export BUN_OPTIONS="--watch --hot"
bun run ./app.ts
# 等同于: bun --watch --hot run ./app.ts
</code></pre>
<p><code>bunx --package</code> 标志让运行二进制文件与包名不一致的包变得简单：</p>
<pre><code>bunx --package=@typescript-eslint/parser eslint ./src
</code></pre>
<p>新增的 <code>bun why</code> 命令清晰地展示依赖链，解答「为什么这个包会出现在我的项目中」：</p>
<pre><code>bun why tailwindcss
</code></pre>
<p>这些看似细小的改进，体现了 Bun 团队对开发者日常工作流程的深刻理解。</p>
<h2>打包器与构建系统的增强</h2>
<p>Bun 的打包器在 1.3 版本中获得了跨平台编译能力。开发者现在可以在任何平台上为 Windows、macOS 和 Linux 构建可执行文件：</p>
<pre><code>bun build --compile --target=linux-x64 ./app.ts --outfile myapp-linux
bun build --compile --target=darwin-arm64 ./app.ts --outfile myapp-macos
bun build --compile --target=windows-x64 ./app.ts --outfile myapp.exe
</code></pre>
<p>Windows 可执行文件元数据的支持让企业应用的打包更加专业：</p>
<pre><code>bun build --compile --target=windows-x64 \\
--title="My App" \\
--publisher="My Company" \\
--version="1.0.0" \\
./app.ts
</code></pre>
<p>代码签名支持（Windows 的 Authenticode 和 macOS 的 codesign）确保了发布的可执行文件可以通过操作系统的安全验证。</p>
<p>压缩器变得更加智能，能够移除未使用的函数和类名，优化 <code>new Object()</code>、<code>new Array()</code> 等表达式，消除无用的 <code>try...catch...finally</code> 块。这些优化让生产构建的体积进一步缩小。</p>
<h2>安全性的持续关注</h2>
<p>Bun 1.3 引入了 <code>Bun.secrets</code> API，利用操作系统的原生凭据存储（macOS 的 Keychain、Linux 的 libsecret、Windows 的 Credential Manager）：</p>
<pre><code>import { secrets } from "bun";
await secrets.set({
service: "my-app",
name: "api-key",
value: "secret-value",
});
const key = await secrets.get({
service: "my-app",
name: "api-key",
});
</code></pre>
<p>凭据在静态时被加密，与环境变量分离存储，提供了更高的安全保障。</p>
<p><code>Bun.CSRF</code> 模块为跨站请求伪造防护提供了原生支持：</p>
<pre><code>import { CSRF } from "bun";
const secret = "your-secret-key";
const token = CSRF.generate({ secret, encoding: "hex", expiresIn: 60 * 1000 });
const isValid = CSRF.verify(token, { secret });
</code></pre>
<p>这些安全特性的内置化降低了开发者的心智负担，让安全最佳实践更容易落地。</p>
<h2>生态系统的影响与展望</h2>
<p>Bun 1.3 的发布标志着该项目从「快速运行时」向「完整开发平台」的战略转型。Midjourney 等知名公司已在生产环境中使用 Bun 进行前端开发，这证明了其稳定性和可靠性。</p>
<p>官方提到，每个提交都会运行大量的 Node.js 测试套件，表明 Bun 团队对兼容性的重视。对 <code>pnpm.lock</code> 和 <code>yarn.lock</code> 的迁移支持，让团队可以无痛试用 Bun，而无需说服所有成员同时升级工具链。</p>
<p>不过，1.3 版本也带来了一些破坏性变更。<code>Bun.serve()</code> 的 TypeScript 类型被重构，WebSocket 数据定义方式发生变化；SQL 客户端现在强制使用标签模板语法；测试过滤器在没有匹配用例时会报错而非静默成功。这些变更虽然可能给现有项目带来迁移成本，但从长远看有利于 API 的一致性和可维护性。</p>
<h2>数据说话：性能对比</h2>
<p>根据官方提供的基准测试数据:</p>
<ul>
<li><strong>Redis 客户端</strong>: 比 ioredis 快 7.9 倍以上</li>
<li><strong>postMessage 字符串</strong>: 速度提升 500 倍，内存减少 22 倍</li>
<li><strong>postMessage 对象</strong>: 速度提升 240 倍</li>
<li><strong>DiffieHellman</strong>: 约快 400 倍</li>
<li><strong>Cipheriv/Decipheriv</strong>: 约快 400 倍</li>
<li><strong>scrypt</strong>: 快 6 倍</li>
<li><strong><code>AbortSignal.timeout</code></strong>: 快 40 倍</li>
<li><strong><code>Headers</code> 操作</strong>: 快 2 倍</li>
<li><strong><code>Bun.build</code> on macOS</strong>: 快 60%</li>
<li><strong>Express</strong>: 快 9%</li>
<li><strong>Fastify</strong>: 快 5.4%</li>
</ul>
<p>这些数据展示了 Bun 在性能上的持续领先优势。</p>
<h2>社区反响与未来规划</h2>
<p>Bun 1.3 的发布在社区引发了热烈讨论。开发者们尤其关注全栈开发能力的提升和包管理器的企业级特性。Socket 公司 CTO Ahmad Nassri 对安全扫描 API 的评价颇具代表性：「Bun 团队行动迅速，在包管理器层面保护开发者。开放安全扫描 API，让 Socket 这样的工具能够在安装过程中提供实时威胁检测。这是让开源开发默认更安全的重要一步。」</p>
<p>官方表示，1.3 系列将持续关注全栈应用开发体验的提升。Redis 集群、流式处理和 Lua 脚本支持已在规划中。WebAssembly 流式编译的实现，以及对更多 TC39 提案的支持，也在进行中。</p>
<p>Bun 的快速迭代和对社区反馈的积极响应，让人对其未来发展充满期待。从一个「更快的 Node.js」到一个「完整的 JavaScript 平台」，Bun 正在书写属于自己的故事。</p>]]>
    </description>
    <content:encoded><![CDATA[<p>2025年10月10日，高性能 JavaScript 运行时 Bun 发布了 1.3 版本。这是 Bun 项目迄今为止最重大的版本更新，标志着 Bun 从单纯的运行时工具演变为一个功能完备的全栈 JavaScript 开发平台。</p>
<h2>从运行时到全栈平台的跨越</h2>
<p>Bun 1.3 的核心突破在于将前端开发能力深度整合进运行时。据官方介绍，此次更新新增了对前端开发的一级支持，开发者现在可以直接运行 HTML 文件，无需额外配置即可启动一个功能完整的开发服务器。</p>
<pre><code>bun ./**/*.html
</code></pre>
<p>执行上述命令后，Bun 会自动识别项目中的 HTML 文件并启动开发服务器，包括热模块替换（HMR）、React Fast Refresh 等现代前端开发必备功能。这种「开箱即用」的设计理念贯穿整个 1.3 版本。</p>
<p>值得注意的是，Bun 的开发服务器并非简单的静态文件服务器，而是集成了原生的 JavaScript、CSS 和 HTML 转译与打包能力。这意味着开发者可以在同一个进程中同时处理前后端代码，从根本上解决了传统开发中前后端端口分离导致的 CORS 跨域问题。</p>
<h2>内置数据库客户端：性能与便利的平衡</h2>
<p>数据库访问是后端开发的核心需求。Bun 1.3 将内置数据库支持从单一的 PostgreSQL 扩展到 MySQL、MariaDB 和 SQLite，并提供了统一的 <code>Bun.SQL</code> API。这一设计大幅降低了项目的依赖复杂度，同时带来显著的性能提升。</p>
<pre><code>import { sql, SQL } from "bun";
// 使用统一 API 连接不同数据库
const postgres = new SQL("postgres://localhost/mydb");
const mysql = new SQL("mysql://localhost/mydb");
const sqlite = new SQL("sqlite://data.db");
// 自动从环境变量读取连接信息
const seniorAge = 65;
const seniorUsers = await sql`
SELECT name, age FROM users
WHERE age &gt;= ${seniorAge}
`;
</code></pre>
<p>虽然现有的 npm 包如 <code>postgres</code> 和 <code>mysql2</code> 在 Bun 中已有不错的性能表现，但原生实现带来的优势不容小觑。官方数据显示，内置客户端在某些场景下性能提升可达数倍。</p>
<p>新版本还新增了 Redis 客户端支持，官方基准测试显示其性能是流行的 ioredis 库的 7.9 倍以上。对于需要缓存和消息队列的应用场景，这一改进意义重大。</p>
<p><img alt="Redis 性能对比" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-662ba9a9f1.png"></p>
<h2>路由系统：简化全栈应用架构</h2>
<p>Bun 1.3 为 <code>Bun.serve()</code> 引入了内置路由系统，支持参数化路由和通配符，让开发者能够在同一服务中优雅地处理前端页面和后端 API。</p>
<pre><code>import { serve, sql } from "bun";
import App from "./myReactSPA.html";
serve({
port: 3000,
routes: {
"/*": App,
"/api/users": {
GET: async () =&gt; Response.json(await sql`SELECT * FROM users LIMIT 10`),
POST: async (req) =&gt; {
const { name, email } = await req.json();
const [user] = await sql`
INSERT INTO users ${sql({ name, email })}
RETURNING *;
`;
return Response.json(user);
},
},
"/api/users/:id": async (req) =&gt; {
const { id } = req.params;
const [user] = await sql`SELECT * FROM users WHERE id = ${id} LIMIT 1`;
if (!user) return new Response("User not found", { status: 404 });
return Response.json(user);
},
},
});
</code></pre>
<p>这种设计让全栈应用的部署变得极为简单。更令人印象深刻的是，Bun 的打包器现在支持将前后端代码打包成单一的可执行文件:</p>
<pre><code>bun build --compile ./index.html --outfile myapp
</code></pre>
<p>生成的可执行文件可以在任何地方运行，无需安装 Node.js 或其他依赖，这对于微服务部署和边缘计算场景具有重要价值。</p>
<h2>Cookie 管理：告别第三方库</h2>
<p>Web 应用中的 Cookie 处理一直是个痛点。开发者要么选择单一功能的 <code>tough-cookie</code> 库，要么被迫引入 Express、Elysia 等完整框架。Bun 1.3 提供了原生的 Cookie API，采用类似 Map 的接口设计:</p>
<pre><code>import { serve, randomUUIDv7 } from "bun";
serve({
routes: {
"/api/users/sign-in": (request) =&gt; {
request.cookies.set("sessionId", randomUUIDv7(), {
httpOnly: true,
sameSite: "strict",
});
return new Response("Signed in");
},
"/api/users/sign-out": (request) =&gt; {
request.cookies.delete("sessionId");
return new Response("Signed out");
},
},
});
</code></pre>
<p>这个 API 的巧妙之处在于零性能开销的延迟解析——只有在实际访问 <code>request.cookies</code> 时才会解析请求头中的 Cookie，避免了不必要的计算。</p>
<h2>包管理器的重大革新</h2>
<p>Bun 的包管理器在 1.3 版本中获得了多项企业级特性。其中最值得关注的是<strong>隔离安装模式</strong>成为工作空间的默认行为。这一改变解决了大型 monorepo 项目中最常见的问题之一：包的幽灵依赖（phantom dependencies）。</p>
<p>在传统的提升安装模式下，所有依赖都平铺在根目录的 <code>node_modules</code> 中，包可能意外访问到未在 <code>package.json</code> 中声明的依赖。隔离模式确保每个包只能访问其明确声明的依赖，提高了构建的可预测性和可靠性。</p>
<p><strong>依赖目录 (Catalogs)</strong> 功能为 monorepo 中的版本管理提供了优雅的解决方案:</p>
<pre><code>{
"name": "monorepo",
"workspaces": ["packages/*"],
"catalog": {
"react": "^18.0.0",
"typescript": "^5.0.0"
}
}
</code></pre>
<p>工作空间包可以通过 <code>"react": "catalog:"</code> 引用目录中的版本，实现集中式版本管理。这一设计借鉴了 pnpm 的成功经验，但整合得更加自然。</p>
<p>新增的<strong>安全扫描 API</strong> 让企业能够在安装阶段拦截恶意包。Bun 团队与 Socket 安全公司合作，推出了官方安全扫描器 <code>@socketsecurity/bun-security-scanner</code>。开发者也可以基于公开的 API 编写自定义扫描器，满足特定的安全合规需求。</p>
<pre><code>[install.security]
scanner = "@socketsecurity/bun-security-scanner"
</code></pre>
<p><strong>最小发布时间限制</strong>功能则提供了对供应链攻击的防护:</p>
<pre><code>[install]
minimumReleaseAge = 604800  # 7天
</code></pre>
<p>这项配置要求包必须发布至少指定时间后才允许安装，给社区留出时间识别潜在的恶意包。</p>
<p>交互式更新命令 <code>bun update --interactive</code> 让依赖升级变得可控:</p>
<pre><code>bun update --interactive
</code></pre>
<p>开发者可以逐个选择要更新的包，而不是一次性升级所有依赖，从而更好地控制潜在的破坏性变更。</p>
<h2>测试框架的成熟化</h2>
<p>Bun 的测试运行器在 1.3 版本中获得了与 VS Code Test Explorer 的深度集成。开发者可以直接在编辑器侧边栏查看测试列表，一键运行或调试单个测试，内联查看错误信息。这种开发体验与 Jest + VS Code Jest 扩展相当，但得益于 Bun 的性能优势，测试执行速度更快。</p>
<p>并发测试支持的加入让 I/O 密集型测试套件的运行时间大幅缩短：</p>
<pre><code>import { test } from "bun:test";
test.concurrent("fetch user 1", async () =&gt; {
const res = await fetch("https://api.example.com/users/1");
expect(res.status).toBe(200);
});
describe.concurrent("server tests", () =&gt; {
test("sends a request to server 1", async () =&gt; {
const response = await fetch("https://example.com/server-1");
expect(response.status).toBe(200);
});
});
</code></pre>
<p>默认情况下，最多 20 个测试会并发运行，这个数字可以通过 <code>--max-concurrency</code> 标志调整。对于需要保持串行执行的测试，可以使用 <code>test.serial</code> 修饰符。</p>
<p>类型测试功能 <code>expectTypeOf()</code> 的引入是另一个亮点。开发者现在可以在单元测试中直接验证 TypeScript 类型:</p>
<pre><code>import { expectTypeOf, test } from "bun:test";
test("types are correct", () =&gt; {
expectTypeOf&lt;string&gt;().toEqualTypeOf&lt;string&gt;();
expectTypeOf({ foo: 1 }).toHaveProperty("foo");
expectTypeOf&lt;Promise&lt;number&gt;&gt;().resolves.toBeNumber();
});
</code></pre>
<p>这些类型断言可以通过 <code>bunx tsc --noEmit</code> 在 CI 流程中验证，将类型安全检查提升到了新的高度。</p>
<h2>Node.js 兼容性的持续推进</h2>
<p>Bun 1.3 在每次提交时运行 Node.js 测试套件中额外的 800 个测试用例。官方数据显示，N-API 测试通过率已达 98% 以上，timers 模块通过率达到 98.4%。</p>
<p>对 <code>node:vm</code> 模块的全面支持是本次更新的重要成果。这个模块常用于代码沙箱、插件系统等高级场景，其实现难度较大。Bun 1.3 不仅支持基础的 <code>vm.Script</code>，还实现了 <code>vm.SourceTextModule</code>、<code>vm.SyntheticModule</code> 等高级 API，并支持字节码缓存以提升编译性能。</p>
<pre><code>import vm from "node:vm";
const script = new vm.Script('console.log("Hello from VM")');
script.runInThisContext();
</code></pre>
<p><code>node:test</code> 模块的初步支持让使用 Node.js 原生测试框架的项目能够在 Bun 上运行，这对于生态系统的兼容性意义重大。</p>
<p>加密性能的提升令人瞩目。DiffieHellman 和 Cipheriv/Decipheriv 的速度提升了约 400 倍，scrypt 提升了 6 倍。这些改进通过将关键路径用原生 C++ 重写实现，大幅降低了密码学操作的开销。</p>
<h2>Web 标准与现代 API</h2>
<p>Bun 1.3 新增了对多项 Web 标准的支持。<strong>YAML 原生支持</strong>让配置文件处理变得简单：</p>
<pre><code>import { YAML } from "bun";
const obj = YAML.parse("key: value");
const yaml = YAML.stringify({ key: "value" }, 0, 2);
// 直接导入 YAML 文件
import config from "./config.yaml";
</code></pre>
<p>官方实现的 YAML 解析器目前通过了官方测试套件的 90% 用例，性能表现优异。</p>
<p><strong>WebSocket 压缩</strong>功能的自动协商是另一个实用特性。当连接支持 <code>permessage-deflate</code> 时，Bun 会自动启用压缩，对于 JSON 等结构化数据，压缩率可达 60-80%，显著减少带宽消耗。</p>
<p><strong>Zstandard 压缩</strong>的全面支持包括 <code>fetch()</code> 的自动解压和手动压缩 API：</p>
<pre><code>import { zstdCompress, zstdDecompress } from "bun";
const compressed = await zstdCompress("Hello, world!");
const decompressed = await zstdDecompress(compressed);
</code></pre>
<p><code>DisposableStack</code> 和 <code>AsyncDisposableStack</code> 的实现体现了 Bun 对 TC39 提案的快速跟进。这些 API 与 <code>using</code> 和 <code>await using</code> 声明配合，提供了优雅的资源管理机制。</p>
<h2>性能优化：细节见真章</h2>
<p>Bun 1.3 的性能优化遍布各个层面。空闲 CPU 占用的降低源于对垃圾回收调度的优化，在没有进行中的请求时，<code>Bun.serve</code> 的计时器不再活跃。JavaScript 内存占用降低 10-30% (Next.js 应用降低 28%，Elysia 降低 11%) 归功于更智能的 GC 计时器调度。</p>
<p>I/O 线程池的优化让 macOS 上的 <code>Bun.build</code> 快了 60%。Express 性能提升 9%，Fastify 提升 5.4%，这些改进来自对 <code>node:http</code> 模块的持续优化。</p>
<p><code>postMessage</code> 的性能提升尤为惊人——字符串传递快了 500 倍，简单对象快了 240 倍。这通过避免对安全共享的字符串进行序列化实现，同时减少了约 22 倍的峰值内存使用。</p>
<pre><code>// 在 Worker 间传递大型 JSON 字符串现在快了 500 倍
const response = await fetch("https://api.example.com/data");
const json = await response.text();
postMessage(json);
</code></pre>
<p>启动时间减少了 1ms，内存占用减少了 3MB，这些看似微小的优化累积起来，对用户体验产生显著影响。</p>
<h2>开发者体验的精心打磨</h2>
<p>Bun 1.3 在开发者体验上的改进同样值得称道。TypeScript 默认配置改为 <code>"module": "Preserve"</code>，保留模块语法的原始形态，更符合 Bun 作为原生 ES 模块运行时的定位。</p>
<p><code>console.log()</code> 的深度控制让调试大型对象变得可控:</p>
<pre><code>bun --console-depth=5 ./app.ts
</code></pre>
<pre><code>[console]
depth = 5
</code></pre>
<p><code>BUN_OPTIONS</code> 环境变量提供了设置默认 CLI 参数的便捷方式：</p>
<pre><code>export BUN_OPTIONS="--watch --hot"
bun run ./app.ts
# 等同于: bun --watch --hot run ./app.ts
</code></pre>
<p><code>bunx --package</code> 标志让运行二进制文件与包名不一致的包变得简单：</p>
<pre><code>bunx --package=@typescript-eslint/parser eslint ./src
</code></pre>
<p>新增的 <code>bun why</code> 命令清晰地展示依赖链，解答「为什么这个包会出现在我的项目中」：</p>
<pre><code>bun why tailwindcss
</code></pre>
<p>这些看似细小的改进，体现了 Bun 团队对开发者日常工作流程的深刻理解。</p>
<h2>打包器与构建系统的增强</h2>
<p>Bun 的打包器在 1.3 版本中获得了跨平台编译能力。开发者现在可以在任何平台上为 Windows、macOS 和 Linux 构建可执行文件：</p>
<pre><code>bun build --compile --target=linux-x64 ./app.ts --outfile myapp-linux
bun build --compile --target=darwin-arm64 ./app.ts --outfile myapp-macos
bun build --compile --target=windows-x64 ./app.ts --outfile myapp.exe
</code></pre>
<p>Windows 可执行文件元数据的支持让企业应用的打包更加专业：</p>
<pre><code>bun build --compile --target=windows-x64 \\
--title="My App" \\
--publisher="My Company" \\
--version="1.0.0" \\
./app.ts
</code></pre>
<p>代码签名支持（Windows 的 Authenticode 和 macOS 的 codesign）确保了发布的可执行文件可以通过操作系统的安全验证。</p>
<p>压缩器变得更加智能，能够移除未使用的函数和类名，优化 <code>new Object()</code>、<code>new Array()</code> 等表达式，消除无用的 <code>try...catch...finally</code> 块。这些优化让生产构建的体积进一步缩小。</p>
<h2>安全性的持续关注</h2>
<p>Bun 1.3 引入了 <code>Bun.secrets</code> API，利用操作系统的原生凭据存储（macOS 的 Keychain、Linux 的 libsecret、Windows 的 Credential Manager）：</p>
<pre><code>import { secrets } from "bun";
await secrets.set({
service: "my-app",
name: "api-key",
value: "secret-value",
});
const key = await secrets.get({
service: "my-app",
name: "api-key",
});
</code></pre>
<p>凭据在静态时被加密，与环境变量分离存储，提供了更高的安全保障。</p>
<p><code>Bun.CSRF</code> 模块为跨站请求伪造防护提供了原生支持：</p>
<pre><code>import { CSRF } from "bun";
const secret = "your-secret-key";
const token = CSRF.generate({ secret, encoding: "hex", expiresIn: 60 * 1000 });
const isValid = CSRF.verify(token, { secret });
</code></pre>
<p>这些安全特性的内置化降低了开发者的心智负担，让安全最佳实践更容易落地。</p>
<h2>生态系统的影响与展望</h2>
<p>Bun 1.3 的发布标志着该项目从「快速运行时」向「完整开发平台」的战略转型。Midjourney 等知名公司已在生产环境中使用 Bun 进行前端开发，这证明了其稳定性和可靠性。</p>
<p>官方提到，每个提交都会运行大量的 Node.js 测试套件，表明 Bun 团队对兼容性的重视。对 <code>pnpm.lock</code> 和 <code>yarn.lock</code> 的迁移支持，让团队可以无痛试用 Bun，而无需说服所有成员同时升级工具链。</p>
<p>不过，1.3 版本也带来了一些破坏性变更。<code>Bun.serve()</code> 的 TypeScript 类型被重构，WebSocket 数据定义方式发生变化；SQL 客户端现在强制使用标签模板语法；测试过滤器在没有匹配用例时会报错而非静默成功。这些变更虽然可能给现有项目带来迁移成本，但从长远看有利于 API 的一致性和可维护性。</p>
<h2>数据说话：性能对比</h2>
<p>根据官方提供的基准测试数据:</p>
<ul>
<li><strong>Redis 客户端</strong>: 比 ioredis 快 7.9 倍以上</li>
<li><strong>postMessage 字符串</strong>: 速度提升 500 倍，内存减少 22 倍</li>
<li><strong>postMessage 对象</strong>: 速度提升 240 倍</li>
<li><strong>DiffieHellman</strong>: 约快 400 倍</li>
<li><strong>Cipheriv/Decipheriv</strong>: 约快 400 倍</li>
<li><strong>scrypt</strong>: 快 6 倍</li>
<li><strong><code>AbortSignal.timeout</code></strong>: 快 40 倍</li>
<li><strong><code>Headers</code> 操作</strong>: 快 2 倍</li>
<li><strong><code>Bun.build</code> on macOS</strong>: 快 60%</li>
<li><strong>Express</strong>: 快 9%</li>
<li><strong>Fastify</strong>: 快 5.4%</li>
</ul>
<p>这些数据展示了 Bun 在性能上的持续领先优势。</p>
<h2>社区反响与未来规划</h2>
<p>Bun 1.3 的发布在社区引发了热烈讨论。开发者们尤其关注全栈开发能力的提升和包管理器的企业级特性。Socket 公司 CTO Ahmad Nassri 对安全扫描 API 的评价颇具代表性：「Bun 团队行动迅速，在包管理器层面保护开发者。开放安全扫描 API，让 Socket 这样的工具能够在安装过程中提供实时威胁检测。这是让开源开发默认更安全的重要一步。」</p>
<p>官方表示，1.3 系列将持续关注全栈应用开发体验的提升。Redis 集群、流式处理和 Lua 脚本支持已在规划中。WebAssembly 流式编译的实现，以及对更多 TC39 提案的支持，也在进行中。</p>
<p>Bun 的快速迭代和对社区反馈的积极响应，让人对其未来发展充满期待。从一个「更快的 Node.js」到一个「完整的 JavaScript 平台」，Bun 正在书写属于自己的故事。</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-662ba9a9f1.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-662ba9a9f1.png" medium="image"/>
    <pubDate>Tue, 14 Oct 2025 12:33:57 +0800</pubDate>
  </item><item>
    <title><![CDATA[知鱼 v1.4.0 发布，项目管理系统]]></title>
    <link>https://www.oschina.net/news/377327</link>
    <itunes:title><![CDATA[知鱼 v1.4.0 发布，项目管理系统]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>知鱼项目管理系统1.4.0版本发布了，主要增加了甘特图功能，具体功能如下：</p>
<p>一、甘特图 增加工时导入功能，可通过甘特图方式查看项目任务进度</p>
<p>二、任务看板功能 任务看板增加了两侧任务栏的收起和展开功能，更方便界面的浏览 增加了任务启动时的开始时间和结束时间设置</p>
<p>三、其他 bug 修复： 修复项目任务未开始时进度显示错误问题 修复了知识库等一些权限问题 修复了任务详情页面的权限问题</p>
<p>功能预览 <img alt="输入图片说明" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/foruda.gitee.com-c540ab112a.png"><img alt="输入图片说明" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/foruda.gitee.com-55a1da0508.png"><img alt="输入图片说明" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/foruda.gitee.com-c405456208.png"><img alt="输入图片说明" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/foruda.gitee.com-929de46543.png"><img alt="输入图片说明" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/foruda.gitee.com-6181c4f607.png"><img alt="输入图片说明" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/foruda.gitee.com-bc8a5a1533.png"><img alt="输入图片说明" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/foruda.gitee.com-25174560bb.png"></p>
<p>其他下载方式：</p>
<p><a href="https://gitee.com/link?target=https%3A%2F%2Fwww.zhiyupm.com%2Fdownloads%2F" target="_blank">https://www.zhiyupm.com/downloads/</a></p>
<p>安装使用： <a href="https://gitee.com/link?target=https%3A%2F%2Fwww.zhiyupm.com%2Fwiki%2F" target="_blank">https://www.zhiyupm.com/wiki/</a></p>
<p>详情查看：<a href="https://gitee.com/wy-soft/zhiyu/releases/v1.4.0">https://gitee.com/wy-soft/zhiyu/releases/v1.4.0</a></p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>知鱼项目管理系统1.4.0版本发布了，主要增加了甘特图功能，具体功能如下：</p>
<p>一、甘特图 增加工时导入功能，可通过甘特图方式查看项目任务进度</p>
<p>二、任务看板功能 任务看板增加了两侧任务栏的收起和展开功能，更方便界面的浏览 增加了任务启动时的开始时间和结束时间设置</p>
<p>三、其他 bug 修复： 修复项目任务未开始时进度显示错误问题 修复了知识库等一些权限问题 修复了任务详情页面的权限问题</p>
<p>功能预览 <img alt="输入图片说明" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/foruda.gitee.com-c540ab112a.png"><img alt="输入图片说明" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/foruda.gitee.com-55a1da0508.png"><img alt="输入图片说明" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/foruda.gitee.com-c405456208.png"><img alt="输入图片说明" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/foruda.gitee.com-929de46543.png"><img alt="输入图片说明" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/foruda.gitee.com-6181c4f607.png"><img alt="输入图片说明" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/foruda.gitee.com-bc8a5a1533.png"><img alt="输入图片说明" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/foruda.gitee.com-25174560bb.png"></p>
<p>其他下载方式：</p>
<p><a href="https://gitee.com/link?target=https%3A%2F%2Fwww.zhiyupm.com%2Fdownloads%2F" target="_blank">https://www.zhiyupm.com/downloads/</a></p>
<p>安装使用： <a href="https://gitee.com/link?target=https%3A%2F%2Fwww.zhiyupm.com%2Fwiki%2F" target="_blank">https://www.zhiyupm.com/wiki/</a></p>
<p>详情查看：<a href="https://gitee.com/wy-soft/zhiyu/releases/v1.4.0">https://gitee.com/wy-soft/zhiyu/releases/v1.4.0</a></p>]]>
    </description>
    <content:encoded><![CDATA[<p>知鱼项目管理系统1.4.0版本发布了，主要增加了甘特图功能，具体功能如下：</p>
<p>一、甘特图 增加工时导入功能，可通过甘特图方式查看项目任务进度</p>
<p>二、任务看板功能 任务看板增加了两侧任务栏的收起和展开功能，更方便界面的浏览 增加了任务启动时的开始时间和结束时间设置</p>
<p>三、其他 bug 修复： 修复项目任务未开始时进度显示错误问题 修复了知识库等一些权限问题 修复了任务详情页面的权限问题</p>
<p>功能预览 <img alt="输入图片说明" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/foruda.gitee.com-c540ab112a.png"><img alt="输入图片说明" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/foruda.gitee.com-55a1da0508.png"><img alt="输入图片说明" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/foruda.gitee.com-c405456208.png"><img alt="输入图片说明" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/foruda.gitee.com-929de46543.png"><img alt="输入图片说明" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/foruda.gitee.com-6181c4f607.png"><img alt="输入图片说明" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/foruda.gitee.com-bc8a5a1533.png"><img alt="输入图片说明" src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/foruda.gitee.com-25174560bb.png"></p>
<p>其他下载方式：</p>
<p><a href="https://gitee.com/link?target=https%3A%2F%2Fwww.zhiyupm.com%2Fdownloads%2F" target="_blank">https://www.zhiyupm.com/downloads/</a></p>
<p>安装使用： <a href="https://gitee.com/link?target=https%3A%2F%2Fwww.zhiyupm.com%2Fwiki%2F" target="_blank">https://www.zhiyupm.com/wiki/</a></p>
<p>详情查看：<a href="https://gitee.com/wy-soft/zhiyu/releases/v1.4.0">https://gitee.com/wy-soft/zhiyu/releases/v1.4.0</a></p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/foruda.gitee.com-c540ab112a.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/foruda.gitee.com-c540ab112a.png" medium="image"/>
    <pubDate>Tue, 14 Oct 2025 12:23:20 +0800</pubDate>
  </item><item>
    <title><![CDATA[微软 Copilot AI 实现邮件和文件直接连接]]></title>
    <link>https://www.oschina.net/news/377321</link>
    <itunes:title><![CDATA[微软 Copilot AI 实现邮件和文件直接连接]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>微软近日宣布对其 Copilot AI 助手进行了重要升级，允许用户直接连接 Outlook、Gmail 等多款个人生产力应用。这项新功能的推出，使得用户在处理日常工作任务时更加高效，能够更轻松地获取所需信息。</p>
<p>根据微软的介绍，这项连接器功能是可选的，用户可以在设置中选择需要连接的服务。通过自然语言的提示，Copilot 可以自动查找邮件内容，例如总结同事发送的工作项目时间表，节省了用户查找信息的时间和精力。</p>
<p>此外，微软还宣布 Copilot 用户现在可以通过自然语言指令创建和导出 Word 文档、Excel 电子表格、PDF 文件和 PowerPoint 演示文稿。这意味着，用户只需简单输入提示，就可以立即将想法、笔记和数据转换为可分享和可编辑的文档。例如，用户可以要求 Copilot 帮助生成一个针对即将到来的假期的日常旅行行程，并将该行程上传至 PowerPoint 演示文稿中，然后导出文件与他人分享。</p>
<p>目前，这项升级和新连接器功能正逐步向微软 Copilot 的 “内测者” 计划成员推送。尽管该功能正在推广中，但并不是所有的内测者都会立刻获得这项更新。</p>
<p>这一升级的推出，正值微软加大力度扩展其核心 AI 产品的同时，努力将其与日常使用的生产力应用紧密结合。在这方面，微软与其他科技公司的竞争也愈加激烈。例如，近期，Perplexity 推出了新的 Email Assistant，能够直接从用户的 Gmail 或 Outlook 账户中提取信息。同时，微软还与 AI 初创公司 Anthropic 建立了合作关系，计划在 Microsoft365套件中嵌入该公司的 AI 系统。</p>
<p>对于企业用户来说，这些新功能的推出意味着他们可以更高效地管理日常工作流程，减少在信息检索和文档制作上的时间，提升整体办公效率。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>微软近日宣布对其 Copilot AI 助手进行了重要升级，允许用户直接连接 Outlook、Gmail 等多款个人生产力应用。这项新功能的推出，使得用户在处理日常工作任务时更加高效，能够更轻松地获取所需信息。</p>
<p>根据微软的介绍，这项连接器功能是可选的，用户可以在设置中选择需要连接的服务。通过自然语言的提示，Copilot 可以自动查找邮件内容，例如总结同事发送的工作项目时间表，节省了用户查找信息的时间和精力。</p>
<p>此外，微软还宣布 Copilot 用户现在可以通过自然语言指令创建和导出 Word 文档、Excel 电子表格、PDF 文件和 PowerPoint 演示文稿。这意味着，用户只需简单输入提示，就可以立即将想法、笔记和数据转换为可分享和可编辑的文档。例如，用户可以要求 Copilot 帮助生成一个针对即将到来的假期的日常旅行行程，并将该行程上传至 PowerPoint 演示文稿中，然后导出文件与他人分享。</p>
<p>目前，这项升级和新连接器功能正逐步向微软 Copilot 的 “内测者” 计划成员推送。尽管该功能正在推广中，但并不是所有的内测者都会立刻获得这项更新。</p>
<p>这一升级的推出，正值微软加大力度扩展其核心 AI 产品的同时，努力将其与日常使用的生产力应用紧密结合。在这方面，微软与其他科技公司的竞争也愈加激烈。例如，近期，Perplexity 推出了新的 Email Assistant，能够直接从用户的 Gmail 或 Outlook 账户中提取信息。同时，微软还与 AI 初创公司 Anthropic 建立了合作关系，计划在 Microsoft365套件中嵌入该公司的 AI 系统。</p>
<p>对于企业用户来说，这些新功能的推出意味着他们可以更高效地管理日常工作流程，减少在信息检索和文档制作上的时间，提升整体办公效率。</p>]]>
    </description>
    <content:encoded><![CDATA[<p>微软近日宣布对其 Copilot AI 助手进行了重要升级，允许用户直接连接 Outlook、Gmail 等多款个人生产力应用。这项新功能的推出，使得用户在处理日常工作任务时更加高效，能够更轻松地获取所需信息。</p>
<p>根据微软的介绍，这项连接器功能是可选的，用户可以在设置中选择需要连接的服务。通过自然语言的提示，Copilot 可以自动查找邮件内容，例如总结同事发送的工作项目时间表，节省了用户查找信息的时间和精力。</p>
<p>此外，微软还宣布 Copilot 用户现在可以通过自然语言指令创建和导出 Word 文档、Excel 电子表格、PDF 文件和 PowerPoint 演示文稿。这意味着，用户只需简单输入提示，就可以立即将想法、笔记和数据转换为可分享和可编辑的文档。例如，用户可以要求 Copilot 帮助生成一个针对即将到来的假期的日常旅行行程，并将该行程上传至 PowerPoint 演示文稿中，然后导出文件与他人分享。</p>
<p>目前，这项升级和新连接器功能正逐步向微软 Copilot 的 “内测者” 计划成员推送。尽管该功能正在推广中，但并不是所有的内测者都会立刻获得这项更新。</p>
<p>这一升级的推出，正值微软加大力度扩展其核心 AI 产品的同时，努力将其与日常使用的生产力应用紧密结合。在这方面，微软与其他科技公司的竞争也愈加激烈。例如，近期，Perplexity 推出了新的 Email Assistant，能够直接从用户的 Gmail 或 Outlook 账户中提取信息。同时，微软还与 AI 初创公司 Anthropic 建立了合作关系，计划在 Microsoft365套件中嵌入该公司的 AI 系统。</p>
<p>对于企业用户来说，这些新功能的推出意味着他们可以更高效地管理日常工作流程，减少在信息检索和文档制作上的时间，提升整体办公效率。</p>]]></content:encoded>
    
    <pubDate>Tue, 14 Oct 2025 11:49:57 +0800</pubDate>
  </item><item>
    <title><![CDATA[宇树 G1 机器人最新演示视频：耍起了功夫、后空翻稳健落地]]></title>
    <link>https://www.oschina.net/news/377320</link>
    <itunes:title><![CDATA[宇树 G1 机器人最新演示视频：耍起了功夫、后空翻稳健落地]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>宇树科技昨天<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1818617132%2FQ8WcC724X%3Fpagetype%3Dprofilefeed" target="_blank">发布</a>最新演示视频，展示了其 G1 人形机器人在复杂动作上的新突破。视频中，机器人不仅完成了标准的功夫招式，还流畅地完成了后空翻、翻跟头等高难度动作，整体表现更加自然、连贯。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-9bc6474cda.png"></p>
<p>官方介绍称，这一版本在动作控制与稳定性方面进行了大幅优化，使机器人能够在高速运动中保持平衡，并展现出接近人类的灵活性。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-484d233ac8.gif"></p>
<p>相比此前的演示，本次视频更强调“功夫”元素，动作衔接丝滑，观感更具娱乐性与观赏性。此前，宇树科技曾发布机器人<a href="https://www.oschina.net/news/373906" target="_blank">被“围殴”的视频</a>，视频中的机器人在遭受围堵、多次被踹倒的情况下依然能快速起身、保持平衡，并作出多次后空翻等高难度动作。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>宇树科技昨天<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1818617132%2FQ8WcC724X%3Fpagetype%3Dprofilefeed" target="_blank">发布</a>最新演示视频，展示了其 G1 人形机器人在复杂动作上的新突破。视频中，机器人不仅完成了标准的功夫招式，还流畅地完成了后空翻、翻跟头等高难度动作，整体表现更加自然、连贯。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-9bc6474cda.png"></p>
<p>官方介绍称，这一版本在动作控制与稳定性方面进行了大幅优化，使机器人能够在高速运动中保持平衡，并展现出接近人类的灵活性。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-484d233ac8.gif"></p>
<p>相比此前的演示，本次视频更强调“功夫”元素，动作衔接丝滑，观感更具娱乐性与观赏性。此前，宇树科技曾发布机器人<a href="https://www.oschina.net/news/373906" target="_blank">被“围殴”的视频</a>，视频中的机器人在遭受围堵、多次被踹倒的情况下依然能快速起身、保持平衡，并作出多次后空翻等高难度动作。</p>]]>
    </description>
    <content:encoded><![CDATA[<p>宇树科技昨天<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1818617132%2FQ8WcC724X%3Fpagetype%3Dprofilefeed" target="_blank">发布</a>最新演示视频，展示了其 G1 人形机器人在复杂动作上的新突破。视频中，机器人不仅完成了标准的功夫招式，还流畅地完成了后空翻、翻跟头等高难度动作，整体表现更加自然、连贯。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-9bc6474cda.png"></p>
<p>官方介绍称，这一版本在动作控制与稳定性方面进行了大幅优化，使机器人能够在高速运动中保持平衡，并展现出接近人类的灵活性。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-484d233ac8.gif"></p>
<p>相比此前的演示，本次视频更强调“功夫”元素，动作衔接丝滑，观感更具娱乐性与观赏性。此前，宇树科技曾发布机器人<a href="https://www.oschina.net/news/373906" target="_blank">被“围殴”的视频</a>，视频中的机器人在遭受围堵、多次被踹倒的情况下依然能快速起身、保持平衡，并作出多次后空翻等高难度动作。</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-9bc6474cda.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-9bc6474cda.png" medium="image"/>
    <pubDate>Tue, 14 Oct 2025 11:46:07 +0800</pubDate>
  </item><item>
    <title><![CDATA[微软 Windows 10 停服在即，官方升级工具却突然罢工]]></title>
    <link>https://www.oschina.net/news/377316</link>
    <itunes:title><![CDATA[微软 Windows 10 停服在即，官方升级工具却突然罢工]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>10月13日消息，Windows 10的官方支持将在10月14日<a href="https://www.oschina.net/news/377083" target="_blank">结束</a>，微软最近也经常发布广告和推广内容，以突出Windows 11的巨大优势，不少用户也选择升级到Windows 11。</p>
<p>不过讽刺的是，就在这个关键时刻，微软的官方工具却出现了问题。微软的官方可启动ISO创建工具——媒体创建工具（Media Creation Tool，MCT）在Windows 10上突然无法正常工作。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-3b361c0c47.png"></p>
<p>微软确认了这一问题，并表示：“Windows 11媒体创建工具26100.6584（于2025年9月29日发布）在Windows 10设备上使用时可能无法按预期工作。该工具可能会意外关闭，且不会显示任何错误信息。”对于用户来说，如果电脑满足硬件要求，升级到Windows 11的最简单方法是打开Windows 10的“设置”，选择“更新与安全”&gt;“Windows更新”，然后点击“检查更新”。</p>
<p>如果想要全新安装，目前最可靠的方法仍然是使用Windows 11媒体创建工具，但不幸的是，这个工具现在却因为微软的失误而无法使用。微软表示正在努力修复这一问题，并将在未来发布更新，但没有明确的时间表。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>10月13日消息，Windows 10的官方支持将在10月14日<a href="https://www.oschina.net/news/377083" target="_blank">结束</a>，微软最近也经常发布广告和推广内容，以突出Windows 11的巨大优势，不少用户也选择升级到Windows 11。</p>
<p>不过讽刺的是，就在这个关键时刻，微软的官方工具却出现了问题。微软的官方可启动ISO创建工具——媒体创建工具（Media Creation Tool，MCT）在Windows 10上突然无法正常工作。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-3b361c0c47.png"></p>
<p>微软确认了这一问题，并表示：“Windows 11媒体创建工具26100.6584（于2025年9月29日发布）在Windows 10设备上使用时可能无法按预期工作。该工具可能会意外关闭，且不会显示任何错误信息。”对于用户来说，如果电脑满足硬件要求，升级到Windows 11的最简单方法是打开Windows 10的“设置”，选择“更新与安全”&gt;“Windows更新”，然后点击“检查更新”。</p>
<p>如果想要全新安装，目前最可靠的方法仍然是使用Windows 11媒体创建工具，但不幸的是，这个工具现在却因为微软的失误而无法使用。微软表示正在努力修复这一问题，并将在未来发布更新，但没有明确的时间表。</p>]]>
    </description>
    <content:encoded><![CDATA[<p>10月13日消息，Windows 10的官方支持将在10月14日<a href="https://www.oschina.net/news/377083" target="_blank">结束</a>，微软最近也经常发布广告和推广内容，以突出Windows 11的巨大优势，不少用户也选择升级到Windows 11。</p>
<p>不过讽刺的是，就在这个关键时刻，微软的官方工具却出现了问题。微软的官方可启动ISO创建工具——媒体创建工具（Media Creation Tool，MCT）在Windows 10上突然无法正常工作。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-3b361c0c47.png"></p>
<p>微软确认了这一问题，并表示：“Windows 11媒体创建工具26100.6584（于2025年9月29日发布）在Windows 10设备上使用时可能无法按预期工作。该工具可能会意外关闭，且不会显示任何错误信息。”对于用户来说，如果电脑满足硬件要求，升级到Windows 11的最简单方法是打开Windows 10的“设置”，选择“更新与安全”&gt;“Windows更新”，然后点击“检查更新”。</p>
<p>如果想要全新安装，目前最可靠的方法仍然是使用Windows 11媒体创建工具，但不幸的是，这个工具现在却因为微软的失误而无法使用。微软表示正在努力修复这一问题，并将在未来发布更新，但没有明确的时间表。</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-3b361c0c47.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-3b361c0c47.png" medium="image"/>
    <pubDate>Tue, 14 Oct 2025 11:35:46 +0800</pubDate>
  </item><item>
    <title><![CDATA[蚂蚁百灵大模型团队正式发布并开源万亿思考模型 Ring-1T]]></title>
    <link>https://www.oschina.net/news/377308</link>
    <itunes:title><![CDATA[蚂蚁百灵大模型团队正式发布并开源万亿思考模型 Ring-1T]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>蚂蚁百灵大模型团队正式发布了万亿思考模型Ring-1T。发布即开源，开发者可以通过Hugging Face、魔搭社区下载模型权重，也可以通过Ling Chat页面和ZenMux 进行直连模型的chat体验和API 调用。</p>
<blockquote>
<p>Hugging Face：https://huggingface.co/inclusionAI/Ring-1T<br> ModelScope：https://modelscope.cn/models/inclusionAI/Ring-1T<br> Ling chat（国内用户）：https://ling.tbox.cn/chat<br> ZenMux（海外开发者，Chat/API ）：https://zenmux.ai/inclusionai/ring-1t</p>
</blockquote>
<p>Ring-1T是一款基于Ling 2.0架构的万亿参数思考模型。其总参数量达到1万亿，激活参数为500亿，并支持128K上下文窗口。模型权重已同步上线Hugging Face与ModelScope，同时提供了FP8版本。</p>
<p>正式版在上月底发布的<a href="https://www.oschina.net/news/375363" target="_blank"> preview 版本</a>基础上，持续扩展大规模可验证奖励强化学习（RLVR）训练，进一步激发万亿基座的自然语言推理能力，并通过 RLHF 训练完善模型通用能力，使得本次发布的 Ring-1T 在各项任务上表现更均衡。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-41c62cd65d.png"></p>
<p>Ring-1T 沿用 Ling 2.0 架构，在1T总参数、50B激活参数的 Ling-1T-base 基座上进行训练，支持最高 128K 上下文窗口。依托自研的强化学习稳定训练方法icepop（棒冰）与高效强化学习系统&nbsp;ASystem（其中&nbsp;AReaL 框架已开源），实现了从百亿（Ring-mini-2.0）到千亿（Ring-flash-2.0）再到万亿（Ring-1T）的&nbsp;MoE 架构强化学习平稳扩展，显著提升模型的深度思考与自然语言推理能力。</p>
<blockquote>
<p>相关阅读：<em><a href="https://www.oschina.net/news/376333" target="news">蚂蚁百灵大模型团队发布 Ling-1T：万亿参数“非思考”模型、基于 MoE 架构</a></em></p>
</blockquote>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>蚂蚁百灵大模型团队正式发布了万亿思考模型Ring-1T。发布即开源，开发者可以通过Hugging Face、魔搭社区下载模型权重，也可以通过Ling Chat页面和ZenMux 进行直连模型的chat体验和API 调用。</p>
<blockquote>
<p>Hugging Face：https://huggingface.co/inclusionAI/Ring-1T<br> ModelScope：https://modelscope.cn/models/inclusionAI/Ring-1T<br> Ling chat（国内用户）：https://ling.tbox.cn/chat<br> ZenMux（海外开发者，Chat/API ）：https://zenmux.ai/inclusionai/ring-1t</p>
</blockquote>
<p>Ring-1T是一款基于Ling 2.0架构的万亿参数思考模型。其总参数量达到1万亿，激活参数为500亿，并支持128K上下文窗口。模型权重已同步上线Hugging Face与ModelScope，同时提供了FP8版本。</p>
<p>正式版在上月底发布的<a href="https://www.oschina.net/news/375363" target="_blank"> preview 版本</a>基础上，持续扩展大规模可验证奖励强化学习（RLVR）训练，进一步激发万亿基座的自然语言推理能力，并通过 RLHF 训练完善模型通用能力，使得本次发布的 Ring-1T 在各项任务上表现更均衡。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-41c62cd65d.png"></p>
<p>Ring-1T 沿用 Ling 2.0 架构，在1T总参数、50B激活参数的 Ling-1T-base 基座上进行训练，支持最高 128K 上下文窗口。依托自研的强化学习稳定训练方法icepop（棒冰）与高效强化学习系统&nbsp;ASystem（其中&nbsp;AReaL 框架已开源），实现了从百亿（Ring-mini-2.0）到千亿（Ring-flash-2.0）再到万亿（Ring-1T）的&nbsp;MoE 架构强化学习平稳扩展，显著提升模型的深度思考与自然语言推理能力。</p>
<blockquote>
<p>相关阅读：<em><a href="https://www.oschina.net/news/376333" target="news">蚂蚁百灵大模型团队发布 Ling-1T：万亿参数“非思考”模型、基于 MoE 架构</a></em></p>
</blockquote>]]>
    </description>
    <content:encoded><![CDATA[<p>蚂蚁百灵大模型团队正式发布了万亿思考模型Ring-1T。发布即开源，开发者可以通过Hugging Face、魔搭社区下载模型权重，也可以通过Ling Chat页面和ZenMux 进行直连模型的chat体验和API 调用。</p>
<blockquote>
<p>Hugging Face：https://huggingface.co/inclusionAI/Ring-1T<br> ModelScope：https://modelscope.cn/models/inclusionAI/Ring-1T<br> Ling chat（国内用户）：https://ling.tbox.cn/chat<br> ZenMux（海外开发者，Chat/API ）：https://zenmux.ai/inclusionai/ring-1t</p>
</blockquote>
<p>Ring-1T是一款基于Ling 2.0架构的万亿参数思考模型。其总参数量达到1万亿，激活参数为500亿，并支持128K上下文窗口。模型权重已同步上线Hugging Face与ModelScope，同时提供了FP8版本。</p>
<p>正式版在上月底发布的<a href="https://www.oschina.net/news/375363" target="_blank"> preview 版本</a>基础上，持续扩展大规模可验证奖励强化学习（RLVR）训练，进一步激发万亿基座的自然语言推理能力，并通过 RLHF 训练完善模型通用能力，使得本次发布的 Ring-1T 在各项任务上表现更均衡。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-41c62cd65d.png"></p>
<p>Ring-1T 沿用 Ling 2.0 架构，在1T总参数、50B激活参数的 Ling-1T-base 基座上进行训练，支持最高 128K 上下文窗口。依托自研的强化学习稳定训练方法icepop（棒冰）与高效强化学习系统&nbsp;ASystem（其中&nbsp;AReaL 框架已开源），实现了从百亿（Ring-mini-2.0）到千亿（Ring-flash-2.0）再到万亿（Ring-1T）的&nbsp;MoE 架构强化学习平稳扩展，显著提升模型的深度思考与自然语言推理能力。</p>
<blockquote>
<p>相关阅读：<em><a href="https://www.oschina.net/news/376333" target="news">蚂蚁百灵大模型团队发布 Ling-1T：万亿参数“非思考”模型、基于 MoE 架构</a></em></p>
</blockquote>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-41c62cd65d.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/static.oschina.net-41c62cd65d.png" medium="image"/>
    <pubDate>Tue, 14 Oct 2025 11:18:17 +0800</pubDate>
  </item><item>
    <title><![CDATA[MuseScore Studio 4.6.2 发布]]></title>
    <link>https://www.oschina.net/news/377305/musescore-4-6-2-released</link>
    <itunes:title><![CDATA[MuseScore Studio 4.6.2 发布]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p><span>MuseScore&nbsp;是一个可运行在多种平台上的 WYSIWYG 的音乐制谱软件。目前，MuseScore 4.6.2 已正式<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmusescore.org%2Fen%2F4.6.2" target="_blank">发布</a>，<span>本次更新修复了几个重要的回归问题。</span></span></p>
<p><span><span>此版本还恢复了与 macOS 10.15 和 11 的兼容性。该兼容性在 4.6 版本中因升级至 Qt 6.9.2 而意外丢失。现已对 Qt 进行修补，确保其与上述版本以及最新发布的 macOS Tahoe 26 保持兼容。</span></span></p>
<p><span>具体更新内容如下：</span></p>
<p><span><span><strong>Engraving</strong></span></span></p>
<ul>
<li><span>修复了和弦符号中的回归问题，其中“omit”呈现为“sommit”</span></li>
<li><span>修复了不可见 measure numbers 影响垂直间距的回归问题</span></li>
<li><span>修复了音符括号被错误标记为<code>generated</code>导致保存加载异常的回归问题</span></li>
</ul>
<p><span><span><strong>Interaction</strong></span></span></p>
<ul>
<li><span>修复了使用鼠标拖动音符导致系统高度缩小的问题</span></li>
<li><span>修复了对某系统音符进行微调会导致后续系统指板图位移的回归问题</span></li>
</ul>
<p><span><span><strong>UI</strong></span></span></p>
<ul>
<li><span>修复了应用程序若在最后退出前处于最小化状态，则下次启动时仍保持最小化的回归问题</span></li>
</ul>
<p><span><span>此版本还包含&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmusescore.org%2Fen%2F4.6" target="_blank"><span>4.6</span></a>&nbsp;<span>和&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmusescore.org%2Fen%2F4.6.1" target="_blank"><span>4.6.1</span></a>&nbsp;<span>中的所有新功能，详情可查看</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DJ2gY9CbMuoI" target="_blank">4.6 版本视频</a><span>。</span></span></p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p><span>MuseScore&nbsp;是一个可运行在多种平台上的 WYSIWYG 的音乐制谱软件。目前，MuseScore 4.6.2 已正式<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmusescore.org%2Fen%2F4.6.2" target="_blank">发布</a>，<span>本次更新修复了几个重要的回归问题。</span></span></p>
<p><span><span>此版本还恢复了与 macOS 10.15 和 11 的兼容性。该兼容性在 4.6 版本中因升级至 Qt 6.9.2 而意外丢失。现已对 Qt 进行修补，确保其与上述版本以及最新发布的 macOS Tahoe 26 保持兼容。</span></span></p>
<p><span>具体更新内容如下：</span></p>
<p><span><span><strong>Engraving</strong></span></span></p>
<ul>
<li><span>修复了和弦符号中的回归问题，其中“omit”呈现为“sommit”</span></li>
<li><span>修复了不可见 measure numbers 影响垂直间距的回归问题</span></li>
<li><span>修复了音符括号被错误标记为<code>generated</code>导致保存加载异常的回归问题</span></li>
</ul>
<p><span><span><strong>Interaction</strong></span></span></p>
<ul>
<li><span>修复了使用鼠标拖动音符导致系统高度缩小的问题</span></li>
<li><span>修复了对某系统音符进行微调会导致后续系统指板图位移的回归问题</span></li>
</ul>
<p><span><span><strong>UI</strong></span></span></p>
<ul>
<li><span>修复了应用程序若在最后退出前处于最小化状态，则下次启动时仍保持最小化的回归问题</span></li>
</ul>
<p><span><span>此版本还包含&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmusescore.org%2Fen%2F4.6" target="_blank"><span>4.6</span></a>&nbsp;<span>和&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmusescore.org%2Fen%2F4.6.1" target="_blank"><span>4.6.1</span></a>&nbsp;<span>中的所有新功能，详情可查看</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DJ2gY9CbMuoI" target="_blank">4.6 版本视频</a><span>。</span></span></p>]]>
    </description>
    <content:encoded><![CDATA[<p><span>MuseScore&nbsp;是一个可运行在多种平台上的 WYSIWYG 的音乐制谱软件。目前，MuseScore 4.6.2 已正式<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmusescore.org%2Fen%2F4.6.2" target="_blank">发布</a>，<span>本次更新修复了几个重要的回归问题。</span></span></p>
<p><span><span>此版本还恢复了与 macOS 10.15 和 11 的兼容性。该兼容性在 4.6 版本中因升级至 Qt 6.9.2 而意外丢失。现已对 Qt 进行修补，确保其与上述版本以及最新发布的 macOS Tahoe 26 保持兼容。</span></span></p>
<p><span>具体更新内容如下：</span></p>
<p><span><span><strong>Engraving</strong></span></span></p>
<ul>
<li><span>修复了和弦符号中的回归问题，其中“omit”呈现为“sommit”</span></li>
<li><span>修复了不可见 measure numbers 影响垂直间距的回归问题</span></li>
<li><span>修复了音符括号被错误标记为<code>generated</code>导致保存加载异常的回归问题</span></li>
</ul>
<p><span><span><strong>Interaction</strong></span></span></p>
<ul>
<li><span>修复了使用鼠标拖动音符导致系统高度缩小的问题</span></li>
<li><span>修复了对某系统音符进行微调会导致后续系统指板图位移的回归问题</span></li>
</ul>
<p><span><span><strong>UI</strong></span></span></p>
<ul>
<li><span>修复了应用程序若在最后退出前处于最小化状态，则下次启动时仍保持最小化的回归问题</span></li>
</ul>
<p><span><span>此版本还包含&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmusescore.org%2Fen%2F4.6" target="_blank"><span>4.6</span></a>&nbsp;<span>和&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmusescore.org%2Fen%2F4.6.1" target="_blank"><span>4.6.1</span></a>&nbsp;<span>中的所有新功能，详情可查看</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DJ2gY9CbMuoI" target="_blank">4.6 版本视频</a><span>。</span></span></p>]]></content:encoded>
    
    <pubDate>Tue, 14 Oct 2025 11:08:15 +0800</pubDate>
  </item><item>
    <title><![CDATA[Meta 超级智能实验室推出新技术，使大模型 RAG 推理速度提升 30 倍]]></title>
    <link>https://www.oschina.net/news/377303</link>
    <itunes:title><![CDATA[Meta 超级智能实验室推出新技术，使大模型 RAG 推理速度提升 30 倍]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>Meta 的<span>超级</span>智能实验室（Meta Superintelligence Labs，MSL）发表了首篇重要论文，研究成果显著提升了大语言模型在检索增强生成(RAG)任务中的推理速度，提升幅度达到了30倍以上。</p>
<p>这篇论文名为《<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2509.01092" target="_blank">REFRAG:Rethinking RAG based Decoding</a>》，主要探讨如何让大型语言模型在执行 RAG 任务时，快速提炼出重要信息，以减少计算量并缩短反应时间，而同时保持准确性不变。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-8e8164a9e5.png"></p>
<p>Meta<span>&nbsp;</span><span>超级</span>智能实验室于今年6月正式成立，总部位于加利福尼亚州的门洛帕克，旨在研发<span>超级</span>智能技术。根据报道，扎克伯格在4月份对 Meta<span>&nbsp;</span><span>最新</span>发布的 Llama4模型表现不满，甚至要求员工加班加点来改进。这促使他成立了这个新实验室，并引入了大量<span>顶尖</span>人才，包括 Scale AI 的创始人 Alexandr Wang。</p>
<p>在实验室内部，团队被分为四个小组，分别负责大语言模型的研发、人工智能基础研究、产品技术落地以及基础设施的保障。REFRAG 框架的提出，正是实验室在优化大语言模型性能方面的<span>第一</span>步。</p>
<p>REFRAG 框架的核心理念是，通过一个轻量级模型将冗长的上下文内容压缩成摘要，减少解码器处理的输入信息。这种方法不仅加快了处理速度，还降低了计算量，提高了模型的效率。此外，研究团队还采用了 “持续预训练” 的方法，通过重建任务训练模型，以便在压缩信息的同时，尽量保留重要的细节。</p>
<p>经过全面测试，REFRAG 在多种任务中表现出色，尤其在时间延迟和吞吐量方面大幅提升。实验结果显示，REFRAG 在压缩比为16倍的情况下，能够在速度上超越之前的<span>最先</span>进模型 CEPE，并且在准确性上几乎没有损失。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>Meta 的<span>超级</span>智能实验室（Meta Superintelligence Labs，MSL）发表了首篇重要论文，研究成果显著提升了大语言模型在检索增强生成(RAG)任务中的推理速度，提升幅度达到了30倍以上。</p>
<p>这篇论文名为《<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2509.01092" target="_blank">REFRAG:Rethinking RAG based Decoding</a>》，主要探讨如何让大型语言模型在执行 RAG 任务时，快速提炼出重要信息，以减少计算量并缩短反应时间，而同时保持准确性不变。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-8e8164a9e5.png"></p>
<p>Meta<span>&nbsp;</span><span>超级</span>智能实验室于今年6月正式成立，总部位于加利福尼亚州的门洛帕克，旨在研发<span>超级</span>智能技术。根据报道，扎克伯格在4月份对 Meta<span>&nbsp;</span><span>最新</span>发布的 Llama4模型表现不满，甚至要求员工加班加点来改进。这促使他成立了这个新实验室，并引入了大量<span>顶尖</span>人才，包括 Scale AI 的创始人 Alexandr Wang。</p>
<p>在实验室内部，团队被分为四个小组，分别负责大语言模型的研发、人工智能基础研究、产品技术落地以及基础设施的保障。REFRAG 框架的提出，正是实验室在优化大语言模型性能方面的<span>第一</span>步。</p>
<p>REFRAG 框架的核心理念是，通过一个轻量级模型将冗长的上下文内容压缩成摘要，减少解码器处理的输入信息。这种方法不仅加快了处理速度，还降低了计算量，提高了模型的效率。此外，研究团队还采用了 “持续预训练” 的方法，通过重建任务训练模型，以便在压缩信息的同时，尽量保留重要的细节。</p>
<p>经过全面测试，REFRAG 在多种任务中表现出色，尤其在时间延迟和吞吐量方面大幅提升。实验结果显示，REFRAG 在压缩比为16倍的情况下，能够在速度上超越之前的<span>最先</span>进模型 CEPE，并且在准确性上几乎没有损失。</p>]]>
    </description>
    <content:encoded><![CDATA[<p>Meta 的<span>超级</span>智能实验室（Meta Superintelligence Labs，MSL）发表了首篇重要论文，研究成果显著提升了大语言模型在检索增强生成(RAG)任务中的推理速度，提升幅度达到了30倍以上。</p>
<p>这篇论文名为《<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2509.01092" target="_blank">REFRAG:Rethinking RAG based Decoding</a>》，主要探讨如何让大型语言模型在执行 RAG 任务时，快速提炼出重要信息，以减少计算量并缩短反应时间，而同时保持准确性不变。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-8e8164a9e5.png"></p>
<p>Meta<span>&nbsp;</span><span>超级</span>智能实验室于今年6月正式成立，总部位于加利福尼亚州的门洛帕克，旨在研发<span>超级</span>智能技术。根据报道，扎克伯格在4月份对 Meta<span>&nbsp;</span><span>最新</span>发布的 Llama4模型表现不满，甚至要求员工加班加点来改进。这促使他成立了这个新实验室，并引入了大量<span>顶尖</span>人才，包括 Scale AI 的创始人 Alexandr Wang。</p>
<p>在实验室内部，团队被分为四个小组，分别负责大语言模型的研发、人工智能基础研究、产品技术落地以及基础设施的保障。REFRAG 框架的提出，正是实验室在优化大语言模型性能方面的<span>第一</span>步。</p>
<p>REFRAG 框架的核心理念是，通过一个轻量级模型将冗长的上下文内容压缩成摘要，减少解码器处理的输入信息。这种方法不仅加快了处理速度，还降低了计算量，提高了模型的效率。此外，研究团队还采用了 “持续预训练” 的方法，通过重建任务训练模型，以便在压缩信息的同时，尽量保留重要的细节。</p>
<p>经过全面测试，REFRAG 在多种任务中表现出色，尤其在时间延迟和吞吐量方面大幅提升。实验结果显示，REFRAG 在压缩比为16倍的情况下，能够在速度上超越之前的<span>最先</span>进模型 CEPE，并且在准确性上几乎没有损失。</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-8e8164a9e5.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-8e8164a9e5.png" medium="image"/>
    <pubDate>Tue, 14 Oct 2025 10:56:19 +0800</pubDate>
  </item><item>
    <title><![CDATA[Rancher 社区双周报｜ Longhorn v1.10.0 重磅发布]]></title>
    <link>https://my.oschina.net/rancher/blog/18695411</link>
    <itunes:title><![CDATA[Rancher 社区双周报｜ Longhorn v1.10.0 重磅发布]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>在本期 <strong>Rancher 社区双周报</strong> 中，我们为大家带来了多个核心产品的最新版本动态： <strong>Longhorn</strong> 发布了 v1.9.2 与 v1.10.0 两个版本，其中 v1.10.0 引入了 V2 Data Engine 的重大增强，带来更高性能与更强扩展性； <strong>Rancher</strong> 发布了四个版本（v2.9.12、v2.10.10、v2.11.6、v2.12.2），其中多个 Prime 版本聚焦于安全修复与系统稳健性提升； <strong>RKE2 与 K3s</strong> 分支均完成了 Kubernetes 版本的例行更新，优化核心组件并强化集群可靠性； 同时，<strong>Harvester v1.5.2</strong> 带来了更流畅的虚拟化体验，<strong>K3k v0.3.5</strong> 则在资源同步与镜像管理方面持续进化。</p>
<p>这一系列更新共同展现了 Rancher 技术生态的持续完善与活力，为用户在容器、虚拟化与边缘计算场景中的落地提供了更加坚实的基础。</p>
<h2>Longhorn</h2>
<p>Longhorn 发布了 <strong>v1.9.2</strong> 与 <strong>v1.10.0</strong> 两个版本更新。本次更新聚焦于系统稳定性与性能增强，同时引入了多项新特性与兼容性优化，进一步提升了 Longhorn 在企业级云原生存储场景中的可靠性与易用性。</p>
<h3>Longhorn v1.9.2</h3>
<p>Longhorn v1.9.2 版本主要聚焦于系统稳定性和可靠性提升，修复了多个潜在问题，包括卷扩容时可能出现的数据损坏、磁盘空间不足引起的卷异常、以及备份目标不可用导致的恢复失败等。该版本还改进了探针配置、日志输出及备份超时机制，优化了支持包的收集范围，进一步提升了系统的可维护性和故障排查效率。</p>
<h3>Longhorn v1.10.0</h3>
<p>Longhorn v1.10.0 是一次重要的功能更新，引入了对 <strong>V2 Data Engine</strong> 的全面增强，在性能、资源占用和可扩展性方面均有显著提升。 该版本在存储引擎层面增加了中断模式以降低 CPU 消耗，支持卷克隆、在线扩容、QoS 限速等关键能力，为多租户与高负载场景提供了更高的灵活性和性能保障。</p>
<p>此外，Longhorn v1.10.0 进一步完善了网络与存储调度支持，新增 <strong>IPv6 网络兼容</strong> 与 <strong>CSIStorageCapacity</strong> 调度优化机制；在数据保护方面，引入了可配置的备份块大小与更高效的备份清理逻辑。 同时，Longhorn 统一了配置文件格式，移除了旧版 v1beta1 API，并对 UI 界面与监控指标体系进行了重构，使系统的可观测性、操作体验与上层产品（如 Harvester）的集成能力显著增强。</p>
<p>如需详细了解各版本的更新内容，请查阅：</p>
<ul>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Flonghorn%2Flonghorn%2Freleases%2Ftag%2Fv1.9.2" target="_blank">Longhorn v1.9.2 发布说明</a></li>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Flonghorn%2Flonghorn%2Freleases%2Ftag%2Fv1.10.0" target="_blank">Longhorn v1.10.0 发布说明</a></li>
</ul>
<h2>Rancher</h2>
<p>近期，Rancher 团队同步发布了多个补丁版本：<strong>v2.9.12、v2.10.10、v2.11.6 与 v2.12.2</strong>。其中，<strong>v2.9.12、v2.10.10 和 v2.11.6 为 Prime 版本</strong>，主要面向企业用户提供安全加固与维护修复；<strong>v2.12.2 则为 Community 与 Prime 双版本同步更新</strong>，覆盖了开源与商业发行渠道。</p>
<p>本次更新的核心聚焦于 <strong>安全漏洞修复与系统稳健性提升</strong>，共涉及以下三个安全问题：</p>
<h3>安全修复重点</h3>
<ul>
<li> <p><strong>用户名唯一性限制（CVE-2024-58260）</strong> 之前版本中，若用户 A 和 B 拥有相同用户名，可能导致任一用户无法登录，甚至可被恶意利用阻止管理员登录。 新版本中，用户名一旦设置将不可修改，且禁止创建重复用户名，从根本上防止该问题发生。</p> </li>
<li> <p><strong>CLI 登录安全增强（CVE-2024-58267）</strong> Rancher CLI 现已在登录过程中更明显地显示 <code>requestId</code>，并在请求中添加 <code>cli=true</code> 标识。 Rancher Dashboard 会根据该标识识别请求来源并提示用户验证操作，从而防止伪造登录请求。</p> </li>
<li> <p><strong>敏感头字段清理（CVE-2025-54468）</strong> Rancher 现已移除 <code>/meta/proxy</code> 接口中的 <code>Impersonate-*</code> 请求头，避免在创建云凭证等场景中泄露可识别或敏感信息。</p> </li>
</ul>
<p>这些修复已全部在 <strong>v2.9.12、v2.10.10、v2.11.6 与 v2.12.2</strong> 中生效，显著提升了 Rancher 在身份验证与数据安全方面的防护能力。</p>
<p>如需详细了解各版本发布内容，可参阅：</p>
<ul>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Francher%2Francher%2Freleases%2Ftag%2Fv2.9.12" target="_blank">Rancher v2.9.12 发布说明</a></li>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Francher%2Francher%2Freleases%2Ftag%2Fv2.10.10" target="_blank">Rancher v2.10.10 发布说明</a></li>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Francher%2Francher%2Freleases%2Ftag%2Fv2.11.6" target="_blank">Rancher v2.11.6 发布说明</a></li>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Francher%2Francher%2Freleases%2Ftag%2Fv2.12.2" target="_blank">Rancher v2.12.2 发布说明</a></li>
</ul>
<h2>Harvester</h2>
<p>在本次更新中，<strong>Harvester 发布了 v1.5.2 版本</strong>，带来了多项功能优化与系统修复，进一步提升了稳定性与用户体验。本次版本将底层组件全面升级至最新补丁版本，包括 <strong>Rancher v2.11.3</strong>、<strong>RKE2 v1.32.7+rke2r1</strong> 与 <strong>KubeVirt v1.4.1</strong>，从而增强虚拟化性能与资源管理能力。同时，系统在高可用性与升级流程方面也进行了改进，确保集群运行更流畅可靠。</p>
<p>在修复部分，v1.5.2 解决了多项关键问题，如 RWX 卷竞争条件、ShareManager 异常终止、EFI 模式下 PXE 启动失败以及版本同步器崩溃等问题。此外，还修复了节点磁盘使用多路径（mpath）时的升级卡顿问题，并改善了 Rancher 集成时的 UI 兼容性。</p>
<p>详细内容请参阅：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fharvester%2Fharvester%2Freleases%2Ftag%2Fv1.5.2" target="_blank">Harvester v1.5.2 发布说明</a></p>
<h2>RKE2</h2>
<p>在本次更新中，RKE2 各稳定分支均完成了例行版本升级，分别对应最新的 Kubernetes 版本：v1.31.13、v1.32.9、v1.33.5、v1.34.1。</p>
<p>目前，RKE2 stable 版本为 <strong>v1.33.5+rke2r1</strong>，latest 版本为 <strong>v1.34.1+rke2r1</strong>。</p>
<p>此外，还同步更新了 containerd、runc、etcd、CoreDNS、metrics-server 等核心组件，CNI 插件（Calico、Cilium）与 ingress-nginx 也获得了新版本支持。此次更新同时提升了对 vSphere 环境的兼容性，并引入了 Go 语言版本更新，以进一步增强系统的稳定性与性能。</p>
<p>详细更新内容可查看以下发布说明：</p>
<ul>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Francher%2Frke2%2Freleases%2Ftag%2Fv1.31.13%252Brke2r1" target="_blank">RKE2 v1.31.13+rke2r1 发布说明</a></li>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Francher%2Frke2%2Freleases%2Ftag%2Fv1.32.9%252Brke2r1" target="_blank">RKE2 v1.32.9+rke2r1 发布说明</a></li>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Francher%2Frke2%2Freleases%2Ftag%2Fv1.33.5%252Brke2r1" target="_blank">RKE2 v1.33.5+rke2r1 发布说明</a></li>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Francher%2Frke2%2Freleases%2Ftag%2Fv1.34.1%252Brke2r1" target="_blank">RKE2 v1.34.1+rke2r1 发布说明</a></li>
</ul>
<h2>K3S</h2>
<p>在本次更新中，<strong>K3s 发布了 v1.31.13+k3s1、v1.32.9+k3s1、v1.33.5+k3s1 和 v1.34.1+k3s1</strong> 四个版本，其中 <strong>stable 版本为 v1.33.5+k3s1</strong>，<strong>latest 版本为 v1.34.1+k3s1</strong>。这些版本同步更新至对应的 Kubernetes 版本，集中修复了多项组件问题，并优化了 etcd、containerd、runc 等关键模块的性能与可靠性。</p>
<p>更新亮点包括：改进 <strong>etcd 节点加入与超时机制</strong>、优化 <strong>Spegel 日志与启动流程</strong>、支持通过 <code>--debug</code> 统一控制 cri-dockerd 日志等级、增强 <strong>CRD 创建冲突的重试机制</strong>，并新增 <strong>kine 与 remotedialer 指标采集</strong> 功能。特别是 v1.34.1 版本引入了基于 <strong>Buildroot 2025.02 LTS</strong> 的用户态二进制包，并支持 <strong>nft json 输出格式</strong>，提升了与 kube-proxy 的兼容性。</p>
<p>详细更新内容请参阅以下发布说明：</p>
<ul>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fk3s-io%2Fk3s%2Freleases%2Ftag%2Fv1.31.13%2Bk3s1" target="_blank">K3s v1.31.13 发布说明</a></li>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fk3s-io%2Fk3s%2Freleases%2Ftag%2Fv1.32.9%2Bk3s1" target="_blank">K3s v1.32.9 发布说明</a></li>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fk3s-io%2Fk3s%2Freleases%2Ftag%2Fv1.33.5%2Bk3s1" target="_blank">K3s v1.33.5 发布说明</a></li>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fk3s-io%2Fk3s%2Freleases%2Ftag%2Fv1.34.1%2Bk3s1" target="_blank">K3s v1.34.1 发布说明</a></li>
</ul>
<h2>K3K</h2>
<p><strong>K3k v0.3.5</strong> 发布，本次更新进一步完善了虚拟集群同步与资源管理逻辑，显著提升了系统稳定性与易用性。版本中新增了 <strong>资源同步配置（Resource Sync Configuration）</strong>，允许用户更灵活地控制虚拟集群与宿主集群间的同步范围；同时增强了 <strong>PVC 同步机制</strong>，修复了默认值处理异常问题。此外，还新增了 <strong>镜像拉取凭证（ImagePullSecrets）</strong> 支持，使控制器、Server 与 Agent 的镜像管理更加安全可靠。</p>
<p>开发与测试方面，K3k v0.3.5 引入了 <strong>控制器覆盖率统计</strong>、<strong>单实例暴露模式验证</strong> 以及测试拆分优化，提升了代码可维护性与持续集成质量。</p>
<p>详细更新内容请参阅：</p>
<ul>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Francher%2Fk3k%2Freleases%2Ftag%2Fv0.3.5" target="_blank">K3k v0.3.5 发布说明</a></li>
</ul>
<h2>写在最后</h2>
<p>通过本期更新，我们可以看到 Rancher 在多产品线间保持着稳定且高频的版本节奏，不仅持续强化底层技术栈的安全性与性能，也在不断优化用户体验与生态协同。 未来，Rancher 社区将继续聚焦开源创新，推动 Kubernetes 与云原生技术的普惠化与场景化应用，助力更多企业构建更高效、更可信赖的基础设施。</p>
<p>敬请关注 <strong>Rancher 官方微信公众号</strong>，获取最新版本动态、实践案例与技术分享。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-d7043d10d7.png"></p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>在本期 <strong>Rancher 社区双周报</strong> 中，我们为大家带来了多个核心产品的最新版本动态： <strong>Longhorn</strong> 发布了 v1.9.2 与 v1.10.0 两个版本，其中 v1.10.0 引入了 V2 Data Engine 的重大增强，带来更高性能与更强扩展性； <strong>Rancher</strong> 发布了四个版本（v2.9.12、v2.10.10、v2.11.6、v2.12.2），其中多个 Prime 版本聚焦于安全修复与系统稳健性提升； <strong>RKE2 与 K3s</strong> 分支均完成了 Kubernetes 版本的例行更新，优化核心组件并强化集群可靠性； 同时，<strong>Harvester v1.5.2</strong> 带来了更流畅的虚拟化体验，<strong>K3k v0.3.5</strong> 则在资源同步与镜像管理方面持续进化。</p>
<p>这一系列更新共同展现了 Rancher 技术生态的持续完善与活力，为用户在容器、虚拟化与边缘计算场景中的落地提供了更加坚实的基础。</p>
<h2>Longhorn</h2>
<p>Longhorn 发布了 <strong>v1.9.2</strong> 与 <strong>v1.10.0</strong> 两个版本更新。本次更新聚焦于系统稳定性与性能增强，同时引入了多项新特性与兼容性优化，进一步提升了 Longhorn 在企业级云原生存储场景中的可靠性与易用性。</p>
<h3>Longhorn v1.9.2</h3>
<p>Longhorn v1.9.2 版本主要聚焦于系统稳定性和可靠性提升，修复了多个潜在问题，包括卷扩容时可能出现的数据损坏、磁盘空间不足引起的卷异常、以及备份目标不可用导致的恢复失败等。该版本还改进了探针配置、日志输出及备份超时机制，优化了支持包的收集范围，进一步提升了系统的可维护性和故障排查效率。</p>
<h3>Longhorn v1.10.0</h3>
<p>Longhorn v1.10.0 是一次重要的功能更新，引入了对 <strong>V2 Data Engine</strong> 的全面增强，在性能、资源占用和可扩展性方面均有显著提升。 该版本在存储引擎层面增加了中断模式以降低 CPU 消耗，支持卷克隆、在线扩容、QoS 限速等关键能力，为多租户与高负载场景提供了更高的灵活性和性能保障。</p>
<p>此外，Longhorn v1.10.0 进一步完善了网络与存储调度支持，新增 <strong>IPv6 网络兼容</strong> 与 <strong>CSIStorageCapacity</strong> 调度优化机制；在数据保护方面，引入了可配置的备份块大小与更高效的备份清理逻辑。 同时，Longhorn 统一了配置文件格式，移除了旧版 v1beta1 API，并对 UI 界面与监控指标体系进行了重构，使系统的可观测性、操作体验与上层产品（如 Harvester）的集成能力显著增强。</p>
<p>如需详细了解各版本的更新内容，请查阅：</p>
<ul>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Flonghorn%2Flonghorn%2Freleases%2Ftag%2Fv1.9.2" target="_blank">Longhorn v1.9.2 发布说明</a></li>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Flonghorn%2Flonghorn%2Freleases%2Ftag%2Fv1.10.0" target="_blank">Longhorn v1.10.0 发布说明</a></li>
</ul>
<h2>Rancher</h2>
<p>近期，Rancher 团队同步发布了多个补丁版本：<strong>v2.9.12、v2.10.10、v2.11.6 与 v2.12.2</strong>。其中，<strong>v2.9.12、v2.10.10 和 v2.11.6 为 Prime 版本</strong>，主要面向企业用户提供安全加固与维护修复；<strong>v2.12.2 则为 Community 与 Prime 双版本同步更新</strong>，覆盖了开源与商业发行渠道。</p>
<p>本次更新的核心聚焦于 <strong>安全漏洞修复与系统稳健性提升</strong>，共涉及以下三个安全问题：</p>
<h3>安全修复重点</h3>
<ul>
<li> <p><strong>用户名唯一性限制（CVE-2024-58260）</strong> 之前版本中，若用户 A 和 B 拥有相同用户名，可能导致任一用户无法登录，甚至可被恶意利用阻止管理员登录。 新版本中，用户名一旦设置将不可修改，且禁止创建重复用户名，从根本上防止该问题发生。</p> </li>
<li> <p><strong>CLI 登录安全增强（CVE-2024-58267）</strong> Rancher CLI 现已在登录过程中更明显地显示 <code>requestId</code>，并在请求中添加 <code>cli=true</code> 标识。 Rancher Dashboard 会根据该标识识别请求来源并提示用户验证操作，从而防止伪造登录请求。</p> </li>
<li> <p><strong>敏感头字段清理（CVE-2025-54468）</strong> Rancher 现已移除 <code>/meta/proxy</code> 接口中的 <code>Impersonate-*</code> 请求头，避免在创建云凭证等场景中泄露可识别或敏感信息。</p> </li>
</ul>
<p>这些修复已全部在 <strong>v2.9.12、v2.10.10、v2.11.6 与 v2.12.2</strong> 中生效，显著提升了 Rancher 在身份验证与数据安全方面的防护能力。</p>
<p>如需详细了解各版本发布内容，可参阅：</p>
<ul>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Francher%2Francher%2Freleases%2Ftag%2Fv2.9.12" target="_blank">Rancher v2.9.12 发布说明</a></li>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Francher%2Francher%2Freleases%2Ftag%2Fv2.10.10" target="_blank">Rancher v2.10.10 发布说明</a></li>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Francher%2Francher%2Freleases%2Ftag%2Fv2.11.6" target="_blank">Rancher v2.11.6 发布说明</a></li>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Francher%2Francher%2Freleases%2Ftag%2Fv2.12.2" target="_blank">Rancher v2.12.2 发布说明</a></li>
</ul>
<h2>Harvester</h2>
<p>在本次更新中，<strong>Harvester 发布了 v1.5.2 版本</strong>，带来了多项功能优化与系统修复，进一步提升了稳定性与用户体验。本次版本将底层组件全面升级至最新补丁版本，包括 <strong>Rancher v2.11.3</strong>、<strong>RKE2 v1.32.7+rke2r1</strong> 与 <strong>KubeVirt v1.4.1</strong>，从而增强虚拟化性能与资源管理能力。同时，系统在高可用性与升级流程方面也进行了改进，确保集群运行更流畅可靠。</p>
<p>在修复部分，v1.5.2 解决了多项关键问题，如 RWX 卷竞争条件、ShareManager 异常终止、EFI 模式下 PXE 启动失败以及版本同步器崩溃等问题。此外，还修复了节点磁盘使用多路径（mpath）时的升级卡顿问题，并改善了 Rancher 集成时的 UI 兼容性。</p>
<p>详细内容请参阅：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fharvester%2Fharvester%2Freleases%2Ftag%2Fv1.5.2" target="_blank">Harvester v1.5.2 发布说明</a></p>
<h2>RKE2</h2>
<p>在本次更新中，RKE2 各稳定分支均完成了例行版本升级，分别对应最新的 Kubernetes 版本：v1.31.13、v1.32.9、v1.33.5、v1.34.1。</p>
<p>目前，RKE2 stable 版本为 <strong>v1.33.5+rke2r1</strong>，latest 版本为 <strong>v1.34.1+rke2r1</strong>。</p>
<p>此外，还同步更新了 containerd、runc、etcd、CoreDNS、metrics-server 等核心组件，CNI 插件（Calico、Cilium）与 ingress-nginx 也获得了新版本支持。此次更新同时提升了对 vSphere 环境的兼容性，并引入了 Go 语言版本更新，以进一步增强系统的稳定性与性能。</p>
<p>详细更新内容可查看以下发布说明：</p>
<ul>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Francher%2Frke2%2Freleases%2Ftag%2Fv1.31.13%252Brke2r1" target="_blank">RKE2 v1.31.13+rke2r1 发布说明</a></li>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Francher%2Frke2%2Freleases%2Ftag%2Fv1.32.9%252Brke2r1" target="_blank">RKE2 v1.32.9+rke2r1 发布说明</a></li>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Francher%2Frke2%2Freleases%2Ftag%2Fv1.33.5%252Brke2r1" target="_blank">RKE2 v1.33.5+rke2r1 发布说明</a></li>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Francher%2Frke2%2Freleases%2Ftag%2Fv1.34.1%252Brke2r1" target="_blank">RKE2 v1.34.1+rke2r1 发布说明</a></li>
</ul>
<h2>K3S</h2>
<p>在本次更新中，<strong>K3s 发布了 v1.31.13+k3s1、v1.32.9+k3s1、v1.33.5+k3s1 和 v1.34.1+k3s1</strong> 四个版本，其中 <strong>stable 版本为 v1.33.5+k3s1</strong>，<strong>latest 版本为 v1.34.1+k3s1</strong>。这些版本同步更新至对应的 Kubernetes 版本，集中修复了多项组件问题，并优化了 etcd、containerd、runc 等关键模块的性能与可靠性。</p>
<p>更新亮点包括：改进 <strong>etcd 节点加入与超时机制</strong>、优化 <strong>Spegel 日志与启动流程</strong>、支持通过 <code>--debug</code> 统一控制 cri-dockerd 日志等级、增强 <strong>CRD 创建冲突的重试机制</strong>，并新增 <strong>kine 与 remotedialer 指标采集</strong> 功能。特别是 v1.34.1 版本引入了基于 <strong>Buildroot 2025.02 LTS</strong> 的用户态二进制包，并支持 <strong>nft json 输出格式</strong>，提升了与 kube-proxy 的兼容性。</p>
<p>详细更新内容请参阅以下发布说明：</p>
<ul>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fk3s-io%2Fk3s%2Freleases%2Ftag%2Fv1.31.13%2Bk3s1" target="_blank">K3s v1.31.13 发布说明</a></li>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fk3s-io%2Fk3s%2Freleases%2Ftag%2Fv1.32.9%2Bk3s1" target="_blank">K3s v1.32.9 发布说明</a></li>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fk3s-io%2Fk3s%2Freleases%2Ftag%2Fv1.33.5%2Bk3s1" target="_blank">K3s v1.33.5 发布说明</a></li>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fk3s-io%2Fk3s%2Freleases%2Ftag%2Fv1.34.1%2Bk3s1" target="_blank">K3s v1.34.1 发布说明</a></li>
</ul>
<h2>K3K</h2>
<p><strong>K3k v0.3.5</strong> 发布，本次更新进一步完善了虚拟集群同步与资源管理逻辑，显著提升了系统稳定性与易用性。版本中新增了 <strong>资源同步配置（Resource Sync Configuration）</strong>，允许用户更灵活地控制虚拟集群与宿主集群间的同步范围；同时增强了 <strong>PVC 同步机制</strong>，修复了默认值处理异常问题。此外，还新增了 <strong>镜像拉取凭证（ImagePullSecrets）</strong> 支持，使控制器、Server 与 Agent 的镜像管理更加安全可靠。</p>
<p>开发与测试方面，K3k v0.3.5 引入了 <strong>控制器覆盖率统计</strong>、<strong>单实例暴露模式验证</strong> 以及测试拆分优化，提升了代码可维护性与持续集成质量。</p>
<p>详细更新内容请参阅：</p>
<ul>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Francher%2Fk3k%2Freleases%2Ftag%2Fv0.3.5" target="_blank">K3k v0.3.5 发布说明</a></li>
</ul>
<h2>写在最后</h2>
<p>通过本期更新，我们可以看到 Rancher 在多产品线间保持着稳定且高频的版本节奏，不仅持续强化底层技术栈的安全性与性能，也在不断优化用户体验与生态协同。 未来，Rancher 社区将继续聚焦开源创新，推动 Kubernetes 与云原生技术的普惠化与场景化应用，助力更多企业构建更高效、更可信赖的基础设施。</p>
<p>敬请关注 <strong>Rancher 官方微信公众号</strong>，获取最新版本动态、实践案例与技术分享。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-d7043d10d7.png"></p>]]>
    </description>
    <content:encoded><![CDATA[<p>在本期 <strong>Rancher 社区双周报</strong> 中，我们为大家带来了多个核心产品的最新版本动态： <strong>Longhorn</strong> 发布了 v1.9.2 与 v1.10.0 两个版本，其中 v1.10.0 引入了 V2 Data Engine 的重大增强，带来更高性能与更强扩展性； <strong>Rancher</strong> 发布了四个版本（v2.9.12、v2.10.10、v2.11.6、v2.12.2），其中多个 Prime 版本聚焦于安全修复与系统稳健性提升； <strong>RKE2 与 K3s</strong> 分支均完成了 Kubernetes 版本的例行更新，优化核心组件并强化集群可靠性； 同时，<strong>Harvester v1.5.2</strong> 带来了更流畅的虚拟化体验，<strong>K3k v0.3.5</strong> 则在资源同步与镜像管理方面持续进化。</p>
<p>这一系列更新共同展现了 Rancher 技术生态的持续完善与活力，为用户在容器、虚拟化与边缘计算场景中的落地提供了更加坚实的基础。</p>
<h2>Longhorn</h2>
<p>Longhorn 发布了 <strong>v1.9.2</strong> 与 <strong>v1.10.0</strong> 两个版本更新。本次更新聚焦于系统稳定性与性能增强，同时引入了多项新特性与兼容性优化，进一步提升了 Longhorn 在企业级云原生存储场景中的可靠性与易用性。</p>
<h3>Longhorn v1.9.2</h3>
<p>Longhorn v1.9.2 版本主要聚焦于系统稳定性和可靠性提升，修复了多个潜在问题，包括卷扩容时可能出现的数据损坏、磁盘空间不足引起的卷异常、以及备份目标不可用导致的恢复失败等。该版本还改进了探针配置、日志输出及备份超时机制，优化了支持包的收集范围，进一步提升了系统的可维护性和故障排查效率。</p>
<h3>Longhorn v1.10.0</h3>
<p>Longhorn v1.10.0 是一次重要的功能更新，引入了对 <strong>V2 Data Engine</strong> 的全面增强，在性能、资源占用和可扩展性方面均有显著提升。 该版本在存储引擎层面增加了中断模式以降低 CPU 消耗，支持卷克隆、在线扩容、QoS 限速等关键能力，为多租户与高负载场景提供了更高的灵活性和性能保障。</p>
<p>此外，Longhorn v1.10.0 进一步完善了网络与存储调度支持，新增 <strong>IPv6 网络兼容</strong> 与 <strong>CSIStorageCapacity</strong> 调度优化机制；在数据保护方面，引入了可配置的备份块大小与更高效的备份清理逻辑。 同时，Longhorn 统一了配置文件格式，移除了旧版 v1beta1 API，并对 UI 界面与监控指标体系进行了重构，使系统的可观测性、操作体验与上层产品（如 Harvester）的集成能力显著增强。</p>
<p>如需详细了解各版本的更新内容，请查阅：</p>
<ul>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Flonghorn%2Flonghorn%2Freleases%2Ftag%2Fv1.9.2" target="_blank">Longhorn v1.9.2 发布说明</a></li>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Flonghorn%2Flonghorn%2Freleases%2Ftag%2Fv1.10.0" target="_blank">Longhorn v1.10.0 发布说明</a></li>
</ul>
<h2>Rancher</h2>
<p>近期，Rancher 团队同步发布了多个补丁版本：<strong>v2.9.12、v2.10.10、v2.11.6 与 v2.12.2</strong>。其中，<strong>v2.9.12、v2.10.10 和 v2.11.6 为 Prime 版本</strong>，主要面向企业用户提供安全加固与维护修复；<strong>v2.12.2 则为 Community 与 Prime 双版本同步更新</strong>，覆盖了开源与商业发行渠道。</p>
<p>本次更新的核心聚焦于 <strong>安全漏洞修复与系统稳健性提升</strong>，共涉及以下三个安全问题：</p>
<h3>安全修复重点</h3>
<ul>
<li> <p><strong>用户名唯一性限制（CVE-2024-58260）</strong> 之前版本中，若用户 A 和 B 拥有相同用户名，可能导致任一用户无法登录，甚至可被恶意利用阻止管理员登录。 新版本中，用户名一旦设置将不可修改，且禁止创建重复用户名，从根本上防止该问题发生。</p> </li>
<li> <p><strong>CLI 登录安全增强（CVE-2024-58267）</strong> Rancher CLI 现已在登录过程中更明显地显示 <code>requestId</code>，并在请求中添加 <code>cli=true</code> 标识。 Rancher Dashboard 会根据该标识识别请求来源并提示用户验证操作，从而防止伪造登录请求。</p> </li>
<li> <p><strong>敏感头字段清理（CVE-2025-54468）</strong> Rancher 现已移除 <code>/meta/proxy</code> 接口中的 <code>Impersonate-*</code> 请求头，避免在创建云凭证等场景中泄露可识别或敏感信息。</p> </li>
</ul>
<p>这些修复已全部在 <strong>v2.9.12、v2.10.10、v2.11.6 与 v2.12.2</strong> 中生效，显著提升了 Rancher 在身份验证与数据安全方面的防护能力。</p>
<p>如需详细了解各版本发布内容，可参阅：</p>
<ul>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Francher%2Francher%2Freleases%2Ftag%2Fv2.9.12" target="_blank">Rancher v2.9.12 发布说明</a></li>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Francher%2Francher%2Freleases%2Ftag%2Fv2.10.10" target="_blank">Rancher v2.10.10 发布说明</a></li>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Francher%2Francher%2Freleases%2Ftag%2Fv2.11.6" target="_blank">Rancher v2.11.6 发布说明</a></li>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Francher%2Francher%2Freleases%2Ftag%2Fv2.12.2" target="_blank">Rancher v2.12.2 发布说明</a></li>
</ul>
<h2>Harvester</h2>
<p>在本次更新中，<strong>Harvester 发布了 v1.5.2 版本</strong>，带来了多项功能优化与系统修复，进一步提升了稳定性与用户体验。本次版本将底层组件全面升级至最新补丁版本，包括 <strong>Rancher v2.11.3</strong>、<strong>RKE2 v1.32.7+rke2r1</strong> 与 <strong>KubeVirt v1.4.1</strong>，从而增强虚拟化性能与资源管理能力。同时，系统在高可用性与升级流程方面也进行了改进，确保集群运行更流畅可靠。</p>
<p>在修复部分，v1.5.2 解决了多项关键问题，如 RWX 卷竞争条件、ShareManager 异常终止、EFI 模式下 PXE 启动失败以及版本同步器崩溃等问题。此外，还修复了节点磁盘使用多路径（mpath）时的升级卡顿问题，并改善了 Rancher 集成时的 UI 兼容性。</p>
<p>详细内容请参阅：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fharvester%2Fharvester%2Freleases%2Ftag%2Fv1.5.2" target="_blank">Harvester v1.5.2 发布说明</a></p>
<h2>RKE2</h2>
<p>在本次更新中，RKE2 各稳定分支均完成了例行版本升级，分别对应最新的 Kubernetes 版本：v1.31.13、v1.32.9、v1.33.5、v1.34.1。</p>
<p>目前，RKE2 stable 版本为 <strong>v1.33.5+rke2r1</strong>，latest 版本为 <strong>v1.34.1+rke2r1</strong>。</p>
<p>此外，还同步更新了 containerd、runc、etcd、CoreDNS、metrics-server 等核心组件，CNI 插件（Calico、Cilium）与 ingress-nginx 也获得了新版本支持。此次更新同时提升了对 vSphere 环境的兼容性，并引入了 Go 语言版本更新，以进一步增强系统的稳定性与性能。</p>
<p>详细更新内容可查看以下发布说明：</p>
<ul>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Francher%2Frke2%2Freleases%2Ftag%2Fv1.31.13%252Brke2r1" target="_blank">RKE2 v1.31.13+rke2r1 发布说明</a></li>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Francher%2Frke2%2Freleases%2Ftag%2Fv1.32.9%252Brke2r1" target="_blank">RKE2 v1.32.9+rke2r1 发布说明</a></li>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Francher%2Frke2%2Freleases%2Ftag%2Fv1.33.5%252Brke2r1" target="_blank">RKE2 v1.33.5+rke2r1 发布说明</a></li>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Francher%2Frke2%2Freleases%2Ftag%2Fv1.34.1%252Brke2r1" target="_blank">RKE2 v1.34.1+rke2r1 发布说明</a></li>
</ul>
<h2>K3S</h2>
<p>在本次更新中，<strong>K3s 发布了 v1.31.13+k3s1、v1.32.9+k3s1、v1.33.5+k3s1 和 v1.34.1+k3s1</strong> 四个版本，其中 <strong>stable 版本为 v1.33.5+k3s1</strong>，<strong>latest 版本为 v1.34.1+k3s1</strong>。这些版本同步更新至对应的 Kubernetes 版本，集中修复了多项组件问题，并优化了 etcd、containerd、runc 等关键模块的性能与可靠性。</p>
<p>更新亮点包括：改进 <strong>etcd 节点加入与超时机制</strong>、优化 <strong>Spegel 日志与启动流程</strong>、支持通过 <code>--debug</code> 统一控制 cri-dockerd 日志等级、增强 <strong>CRD 创建冲突的重试机制</strong>，并新增 <strong>kine 与 remotedialer 指标采集</strong> 功能。特别是 v1.34.1 版本引入了基于 <strong>Buildroot 2025.02 LTS</strong> 的用户态二进制包，并支持 <strong>nft json 输出格式</strong>，提升了与 kube-proxy 的兼容性。</p>
<p>详细更新内容请参阅以下发布说明：</p>
<ul>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fk3s-io%2Fk3s%2Freleases%2Ftag%2Fv1.31.13%2Bk3s1" target="_blank">K3s v1.31.13 发布说明</a></li>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fk3s-io%2Fk3s%2Freleases%2Ftag%2Fv1.32.9%2Bk3s1" target="_blank">K3s v1.32.9 发布说明</a></li>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fk3s-io%2Fk3s%2Freleases%2Ftag%2Fv1.33.5%2Bk3s1" target="_blank">K3s v1.33.5 发布说明</a></li>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fk3s-io%2Fk3s%2Freleases%2Ftag%2Fv1.34.1%2Bk3s1" target="_blank">K3s v1.34.1 发布说明</a></li>
</ul>
<h2>K3K</h2>
<p><strong>K3k v0.3.5</strong> 发布，本次更新进一步完善了虚拟集群同步与资源管理逻辑，显著提升了系统稳定性与易用性。版本中新增了 <strong>资源同步配置（Resource Sync Configuration）</strong>，允许用户更灵活地控制虚拟集群与宿主集群间的同步范围；同时增强了 <strong>PVC 同步机制</strong>，修复了默认值处理异常问题。此外，还新增了 <strong>镜像拉取凭证（ImagePullSecrets）</strong> 支持，使控制器、Server 与 Agent 的镜像管理更加安全可靠。</p>
<p>开发与测试方面，K3k v0.3.5 引入了 <strong>控制器覆盖率统计</strong>、<strong>单实例暴露模式验证</strong> 以及测试拆分优化，提升了代码可维护性与持续集成质量。</p>
<p>详细更新内容请参阅：</p>
<ul>
<li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Francher%2Fk3k%2Freleases%2Ftag%2Fv0.3.5" target="_blank">K3k v0.3.5 发布说明</a></li>
</ul>
<h2>写在最后</h2>
<p>通过本期更新，我们可以看到 Rancher 在多产品线间保持着稳定且高频的版本节奏，不仅持续强化底层技术栈的安全性与性能，也在不断优化用户体验与生态协同。 未来，Rancher 社区将继续聚焦开源创新，推动 Kubernetes 与云原生技术的普惠化与场景化应用，助力更多企业构建更高效、更可信赖的基础设施。</p>
<p>敬请关注 <strong>Rancher 官方微信公众号</strong>，获取最新版本动态、实践案例与技术分享。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-d7043d10d7.png"></p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-d7043d10d7.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-d7043d10d7.png" medium="image"/>
    <pubDate>Tue, 14 Oct 2025 10:49:33 +0800</pubDate>
  </item><item>
    <title><![CDATA[OpenAI 与博通达成战略合作，开发定制 AI 芯片]]></title>
    <link>https://www.oschina.net/news/377300</link>
    <itunes:title><![CDATA[OpenAI 与博通达成战略合作，开发定制 AI 芯片]]></itunes:title>
    <itunes:author><![CDATA[OSCHINA 社区最新新闻[RSS+]]]></itunes:author>
    <itunes:summary>
      <![CDATA[<p>OpenAI<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Findex%2Fopenai-and-broadcom-announce-strategic-collaboration%2F" target="_blank">官宣</a>与博通（Broadcom）建立战略协作，双方将联合开发定制AI芯片并部署规模达10吉瓦的推理基础设施，计划于2026至2029年分阶段落地，标志着OpenAI向AI基础设施自主化迈出关键一步。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-d8a0590e31.png"></p>
<p><span><strong>此次合作突破传统“采购芯片”模式，由OpenAI主导芯片设计</strong></span>，注入模型算法洞见，博通则负责底层架构协作、硬件集成及网络方案支撑，涵盖芯片制造、网络互联至数据中心优化全链路。其定制芯片针对大型语言模型负载优化，结合博通硅光子学技术，可降低15-20%功耗并减少30%以上数据传输瓶颈。</p>
<p>OpenAI CEO Sam Altman表示，此举旨在构建从硬件到服务的全链条系统，破解算力短缺难题。该合作预计将大幅缩短万亿参数模型训练周期，为全球数十亿用户的智能助理规模化落地提供算力基座，同时推动AI硬件从通用向专用化转型。</p>]]>
    </itunes:summary>
    <description>
      <![CDATA[<p>OpenAI<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Findex%2Fopenai-and-broadcom-announce-strategic-collaboration%2F" target="_blank">官宣</a>与博通（Broadcom）建立战略协作，双方将联合开发定制AI芯片并部署规模达10吉瓦的推理基础设施，计划于2026至2029年分阶段落地，标志着OpenAI向AI基础设施自主化迈出关键一步。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-d8a0590e31.png"></p>
<p><span><strong>此次合作突破传统“采购芯片”模式，由OpenAI主导芯片设计</strong></span>，注入模型算法洞见，博通则负责底层架构协作、硬件集成及网络方案支撑，涵盖芯片制造、网络互联至数据中心优化全链路。其定制芯片针对大型语言模型负载优化，结合博通硅光子学技术，可降低15-20%功耗并减少30%以上数据传输瓶颈。</p>
<p>OpenAI CEO Sam Altman表示，此举旨在构建从硬件到服务的全链条系统，破解算力短缺难题。该合作预计将大幅缩短万亿参数模型训练周期，为全球数十亿用户的智能助理规模化落地提供算力基座，同时推动AI硬件从通用向专用化转型。</p>]]>
    </description>
    <content:encoded><![CDATA[<p>OpenAI<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Findex%2Fopenai-and-broadcom-announce-strategic-collaboration%2F" target="_blank">官宣</a>与博通（Broadcom）建立战略协作，双方将联合开发定制AI芯片并部署规模达10吉瓦的推理基础设施，计划于2026至2029年分阶段落地，标志着OpenAI向AI基础设施自主化迈出关键一步。</p>
<p><img src="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-d8a0590e31.png"></p>
<p><span><strong>此次合作突破传统“采购芯片”模式，由OpenAI主导芯片设计</strong></span>，注入模型算法洞见，博通则负责底层架构协作、硬件集成及网络方案支撑，涵盖芯片制造、网络互联至数据中心优化全链路。其定制芯片针对大型语言模型负载优化，结合博通硅光子学技术，可降低15-20%功耗并减少30%以上数据传输瓶颈。</p>
<p>OpenAI CEO Sam Altman表示，此举旨在构建从硬件到服务的全链条系统，破解算力短缺难题。该合作预计将大幅缩短万亿参数模型训练周期，为全球数十亿用户的智能助理规模化落地提供算力基座，同时推动AI硬件从通用向专用化转型。</p>]]></content:encoded>
    <itunes:image href="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-d8a0590e31.png"/>
          <media:content url="https://democwise2016.github.io/action-RSS-Fulltext/file-cache/oscimg.oschina.net-d8a0590e31.png" medium="image"/>
    <pubDate>Tue, 14 Oct 2025 10:47:27 +0800</pubDate>
  </item></channel>
</rss>